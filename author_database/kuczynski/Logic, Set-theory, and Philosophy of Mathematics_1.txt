
Logic, Set-theory, and Philosophy of Mathematics Selected Papers
 
J.-M. Kuczynski, PhD
 
Chapter 1
Key Definitions and Principles of Set-theory and Mathematical Logic
The propositional calculus: Definitions
Propositional calculus: Theorems
Predicate calculus, Set Theory, and Boolean Algebra: Definitions
Predicate Calculus: Derived definitions
Predicate calculus: Theorems
Boolean Algebra: Theorems
Modality
Set Theory: Axioms and basic theorems
Advanced Set Theory: Definitions
Advanced Set Theory: Principles and Derived Definitions
Chapter 2
Set Theory and Logic (2015)
Introduction
Section 1
Von Neumann arithmetic
1.0 Preliminary definitions and principles
1.2 Von Neumann arithmetic
1.2.1 Von Neumann arithmetic (continued)
Section 2
Frege-Russell arithmetic
2.0 Preliminary definitions and principles
2.2 Frege-Russell arithmetic
2.3 Why this system is not guilty of the vicious circularity of which it seems to be guilty
Section 3.0: Generalizations of cardinal arithmetic
3.1 Preliminary definitions and principles
3.2 The concept of an enlargement
3.3 Rationals, Reals, and other Hyper-cardinals: Introductory Remarks 3.4 Signed Integers
3.5 Rationals
3.6 Reals that correspond to rationals
3.7 Reals that do not correspond to rationals
3.8 + ℝ and × ℝ defined
3.9 Ordinal numbers
3.10 Complex numbers
4.0 Relevant metamathematical concepts and principles
4.1 Numbers of one kind never size-comparable with numbers of any other kind
4.2 Recursivity
4.3 Sequences as discrete series
4.4 Recursivity and Computability
4.5 Recursive definition of ℚ
5.0 Relevant principles of set theory and logic
5.1 
5.2 
5.3 Some anticipatory points about model-theory
5.4 PK=2[K]
5.5 Infinite classes as reflexive classes
5.6 Infinite classes as classes with non-inductive cardinalities
5.6.1 The Axiom of Choice in relation to these two conceptions of the infinite
5.7 n<2n
5.8 Cardinality vs. cardinality-type
5.9 Irrational numbers in relation to continuity
5.10 Two conceptions of cardinality
5.11 Cardinality vs. cardinality-type
5.12 Number-classes as classes of isomorphic model-spaces
6.0 Recursivity and Incompleteness
7.0 Formal languages: introductory points
7.1 Natural languages as recursive sentence-classes
7.2 Formal languages as recursive sentence-classes
8.0 Definition of “formal truth”
8.1 No formal characterization of the property of formal truth
9.0 Function-theoretic Characterizations of Logical Operations
Chapter 3
Mathematics as the study of ordinal relations (2014) Invariance
Chapter 4
Five philosophies of mathematics (2014)
Conventionalism evaluated
The laws of logic not conventions
Formalism
Formalism evaluated
Conceptualism
Transcendental Idealism
Empiricism
The spuriousness of the distinction between mathematical and nonmathematical laws
Platonism
Chapter 5
Logicism (2014)
An informal refutation of logicism
Chapter 6
The so-called Laws of Logic (2014)
Chapter 7
Real numbers as outputs of metrical operations (2014)
Diachronic measurement the only kind
The arbitrariness of the metrical unit
The importance of the reals
Chapter 8
Soundness vs. completeness (2014)
Object-language vs. meta-language
Intertranslatibility
Productivity and systematicity
Cryptography and language
Philosophical applications: Skepticism and anti-realism refuted
Formal calculi inherently incomplete
Chapter 9
Formal languages, axiom sets, and incompleteness
Semantic rules
Languages as integrated sets of semantic rules Contextual Definition:
Use vs. mention
Languages as integrated sets of semantic rules (resumed) Recursivity and computation
Recursivity
Recursive definition
Computability in relation to recursivity
Computability in relation to language
Truth-in-L in connection with the concept of incompleteness
Language: formal, informal, natural, artificial
The concept of a formal language: Uninterpreted calculi
An example of an uninterpreted formal calculus
Definitions of key terms
Our discussion of R1-R4 continued
The concept of a formal language: Languages as interpreted calculi
Truth-predicates
Incompleteness: some introductory remarks
Chapter 10
Analytic truth vs. formal truth (2014)
Statements vs. statement-forms
The Concept of an Axiomatic System
Redundancy
Chapter 11
The logic of context-sensitive expressions (2014)
Why indexical-free languages cannot express perspectival information (continued)
Why there are non-perspectival truths that an indexical-free language is ipso facto unable to express
Why there are non-perspectival truths that an indexical-free language is ipso facto unable to express (continued)
Chapter 12
Why Empirical Theories are not Formal Calculi (2014)
Rules of inference identical with conditional propositions
What empirical scientists mean by the word 'theory'
What logicians/mathematicians mean by the word "theory"
Empirical theories as interpreted formal calculi
Why this analysis is not tenable: First reason
Second reason
Third reason
Fourth reason
Fifth reason
Chapter 13
Numbers as Ordered Pairs (2014)
Chapter 14
Alan Turing’s Analysis of Computation and its Significance for Psychology
(2014)
Part 1: Turing’s Analysis of Computability
Explaining Turing’s Analysis
Evaluating Turing’s Analysis
The Concept of a Turing Machine
The intuitive basis for Turing’s analysis
A Turing-unsolvable Problem
Part 2: Philosophical Implications
Chapter 15
The Raven Paradox (2014)
The original Raven Paradox stated in full
Another such paradox
Hempel’s solution
The problem with Hempel’s solution
The actual solution
Chapter 16
Zeno’s Paradox (2015)
Eugene Mills’ solution to Zeno’s paradox
Problems with Mills’ solution
Bertrand Russell’s solution to Zeno’s paradox
Problems with Russell’s solution
The actual solution to Zeno’s paradox
Chapter 17
The Coin Paradox (2015)
Chapter 18
Vagueness
Non-epistemic indeterminacy
An objection to the argument just presented
Chapter 19
Three Different Kinds of Sorites Paradoxes (2010)
These points generalized
A confusion side-stepped
A different kind of Sorites Paradox
A third kind of Sorites Paradox
Chapter 20
The Theory of Types (2010)
Russell’s Solution
The Theory of Types evaluated
More problems with The Theory of Types
The Theory of Types unnecessary
The problem with 2 ("Every assertion is false")
The problem with 3 ('K is a member of K')
The problem with 4 ("'impredicative' is impredicative")
Conclusion
Chapter 21
Set Theoretic Characterizations of Truth and Meaning (2007)
Introduction
1.0 The Argument
2.0 The unity of the proposition
3.0 More on the decomposition of propositions
3.1 A corollary
 
 
Chapter 1
Key Definitions and Principles of Set-theory and Mathematical
Logic
 
The propositional calculus: Definitions
 
P ⋁ Q
P or Q
 
P ⋀ Q
P and Q
 
¬P
Not P
 
P→Q
¬(P ⋀ ¬Q)
 
P ↛ Q
¬(P→Q)
 
P↔Q
(P→Q) ⋀ (Q→P)
 
P/Q
¬P ⋀ ¬Q
 
P ↛ Q
¬(P→Q)
 
  
 
Propositional calculus: Theorems
 
 
(¬P ∨ Q)↔¬(P ⋀ ¬Q)
 
(P→Q)↔(¬P ∨ Q)
 
¬(P ⋀ Q) ↔(¬P ∨ ¬Q)
 
¬(P ∨ Q) ↔(¬P ⋀ ¬Q)
 
P→P
Self-entailment
 
 P↔¬¬P
Double Negation
 
P ∨ ¬P
Excluded Middle
 
¬(P ⋀ ¬P)
Non-contradiction
 
(P ∨ Q)↔(Q ∨ P)
Interchange
 
 (P ⋀ Q)↔(Q ⋀ P)
Interchange
 
(¬P ∨ Q)↔(P→Q)
 
(P ⋀ (P→Q))→Q
Modus Ponens
 
((P→Q) ⋀ ¬Q) →¬P
Modus Tollens
 
((P ∨ Q) ⋀ ¬P)→Q
DeMorgan’s
 
(P→¬P)→¬P
Statements are false that self-refute.
 
(¬P→P)→P
Statements are true that self-verify.
 
(P ⋀ ¬P)→Q
Nothing doesn’t follow from a contradiction.
 
P→(Q ∨ ¬Q)
Nothing doesn’t entail a tautology.
 
(P→(Q ⋀ ¬Q))→¬P
No contradiction follows from a truth.
 
((Q ∨ ¬Q)→P)→P
No falsehood follows from a tautology.
P→(P ∨ Q)
Logical Addition
 
(P ⋀ Q)→P
Simplification
 
((P→Q) ⋀ (Q→R))→(P→R)
 Transitivity
 
(P→Q)→((Q→R)→(P→R))
 Transitivity
 
P→Q→((P ⋀ R)→Q)
Monotony
 
(P1…Pn→Q)→((P1…Pn ⋀ Pn+1)→Q) Monotony
 
P↔(P ⋁ P)
Precursor of n+0=0
 
P↔(P ⋀ P)
Precursor of nx1=n
 
(P ⋁ (Q ⋀ ¬Q))↔P
Absorption
 
(P ⋀ (Q ⋁ ¬Q))↔P
Absorption
 
P ⋁ (Q ⋀ R)↔((P ⋁ Q) ⋀ P ⋁ R))
 
P ⋀ (Q ⋁ r)↔((P ⋀ Q) ⋁ (P ⋀ R))
 
¬(P ⋁ Q)↔(¬P ⋀ ¬Q)
 
¬(P ⋀ Q)↔(¬P ⋁ ¬Q)
 
 P / Q ↔DF(¬P ⋀ ¬Q)
 
(P/P)
¬P
 
(P/P)/( P/P)
P
 
(P/Q)/(P/Q)
P ⋁Q
 
((P/P)/( P/P))/((Q/Q)/(Q/Q))
¬(P ⋀ Q)
 
(((P/P)/( P/P))/(Q/Q))/(((P/P)/(P/P))/(Q/Q))
¬(P ⋀ ¬Q)
P→Q
 
 
Predicate calculus, Set Theory, and Boolean Algebra: Definitions
 
{x: φx}
The extension of φ.
 
φ
The intension of {x: φx}
 
x ∈ k
x is a member of k
 
x ∉ k
¬x ∈ k
 
∀ xφx
For all x, φx
∃ xφx
For some x, φx
 
k ∪ k* {x: x ∈ k ⋁ x ∈ k*}
 
k ⋂ k*
{x: x ∈ k ⋀ x ∈ k*}
 
Ck
The complement of k
{x: x ∉ k}
 
V
The universal class
{x: x=x}
 
[k]
The number of objects in k
k’s cardinal number
 
k≈k*
[k]=[k*]
 
Predicate Calculus: Derived definitions
¬ ∀ xφx
It is not the case that, for all x, φx
For some x, ¬φx
 
¬ ∃ xφx
Nothing has φ
 
∀ x¬φx
Everything is a non-phi.
 
¬ ∃ xφx↔ ∀ x¬φx
∃ x(φx ⋀ ψx)
For some x, φx and ψx
 
∀ x(φx→ψx)
All φ’s are ψ’s.
 
∃ x(φx ⋀ ¬ψx)
Not all φ’s are ψ’s.
 
 
Predicate calculus: Theorems
 
 
φx↔x ∈ {y:φy}
 
∃ xφx↔¬ ∀ x¬φx
 
∀ xφx ⋀∀ xψx↔ ∀ x(φx ⋀ ψx)
 
∃ x(φx ⋀ ψx)→( ∃ xφx ⋀∃ xψx)
 
( ∃ xφx ⋀∃ xψx) ↛∃ x(φx ⋀ ψx)
 
∀ xφx→( ∀ xφx ∨∀ xψx)
 
α=β→(φα↔φβ)
Indiscernibility of identicals.
 
(φα↔φβ)→α=β
Identity of indiscernibles.
 
((α ∈ k1→α ∈ k2) ⋀ (α ∈ k2→α ∈ k3))→(α ∈ k1→α ∈ k3)
Transitivity
 
α ∈ k↔ α ∈ CCk
Double Negation
α ∈ k→(α ∈ k ⋁ α ∈ k*)
Logical Addition
 
(α ∈ k ⋀ α ∈ k*)→α ∈ k
Simplification
 
(α ∈ k ⋀ α ∈ k*)↔(α ∈ k* ⋀ α ∈ k)
 
((α ∈ k ⋁ α ∈ k*) ⋀ α ∉ k)→α ∈ k*
 
((α ∈ k→α ∈ k*) ⋀ α ∈ k))→α ∈ k*
 
((α ∈ k→α ∈ k*) ⋀ α ∉ k*)→α ∉ k
 
¬ ∃ xφx→ ∀ x(φx→ψx)
 
¬ ∃ xφx→ ∀ x(φx→¬ψx)
 
P↔ ∀ xP
 
P↔ ∃ xP
 
 
Boolean Algebra: Theorems
 
 
k1 ∪ (k2 ⋂ k3)=(k1 ∪ k2) ⋂ (k1 ∪ k3)
Analogue of (p ⋁ (q ⋀ r))↔((p ⋁ q) ⋀ (p ⋁ r))
 
k1 ⋂ (k2 ∪ k3)=(k1 ⋂ k2) ∪ (k1 ⋂ k3)
Analogue of (p ⋀ (q ⋁ r))↔((p ⋀ q) ⋁ (p ⋀ r))
 
k1=k1 ∪ k1
Analogue of P→P ⋁ P
 
k1= k1 ⋂ k1
Analogue of P→P ⋀ P
 
k ∪∅ =k
 
k ⋂ V=k
 
k1 ∪ (k1 ⋂ k2)=k1 Absorption
 
k1 ⋂ (k1 ∪ k2)=k1 Absorption
 
CCk=k
 
Ck= ∅ ↔k=V
 
Modality
 
□P
Necessarily P
 
◊P
Possibly P
 
A truth is necessary if it follows from any given statement-set.
□P↔ ∀ Q(Q→P)
 
A truth is necessary if its negation does entails a contradiction.
□P↔¬ ∃ Q(¬P→ ( Q ⋀ ¬Q))
 
A truth is possible if it does not entail a contradiction.
◊P↔¬ ∃ Q(P→(Q ⋀ ¬Q))
 
A truth is possible if its negation is not necessary.
◊P↔¬□¬P
 
A truth is necessary if its negation is not possible.
□P↔¬◊¬P
 
What is necessary is actual.
□P→P
 
What is actual is possible.
P→◊P
 
 (□P ⋀ □Q)↔□(P ⋀ Q)
 
◊(P ⋀ Q)→(◊P ⋀ ◊Q)
 
(◊P ⋀ ◊Q) ↛ ◊(P ⋀ Q)
 
Set Theory: Derived Definitions
 
∀ x ∀ y(φx ⋀ φy↔x=y)
At most one thing has φ.
 
∃ x(φx ⋀∀ y(φy→x=y))
Exactly one thing has φ.
 
∃ x ∀ y(φx ⋀ (φy→x=y))
Exactly one thing has φ.
 
∃ x ∀ y(φy↔x=y)
Exactly one thing has φ.
 
∃ x ∃ y(φx ⋀ φy ⋀ x≠y)
At least two things have φ.
 
∀ x ∀ y ∀ z(φx ⋀ φy ⋀ (φz↔y=z))
At most two things have φ.
 
∃ x ∃ y(φx ⋀ φy ⋀ x≠y ⋀∀ z(φz→(x=z ⋁ y=z)))
Exactly two things have φ
 
∃ x ∃ y ∀ z(φx ⋀ φy ⋀ x≠y ⋀ (φz→(x=z ⋁ y=z))) Exactly two things have φ
 
k=k*↔ ∀ x(x ∈ k↔x ∈ k*)
 
 
Set Theory: Axioms and basic theorems
 
 
Classes are identical when membership-identical (Axiom of
Extensionality)
k=k*↔(α ∈ k↔α ∈ k*)
 
Any given property generates a class (Axiom of Comprehension)
∀ φ ∃ k ∀ x(x ∈ k↔φx)
 
There is at most one empty class.
∀ k ∀ x(x ∉ k→k= ∅ ))
 
There is exactly one empty class
 ∃ k ∀ x(k= ∅ ↔x ∉ k)
 
[k]=0↔k≈ ∅
 
[k]=1↔k≈{ ∅ }
 
[k]=2↔k≈{{ ∅ }, ∅ }
 
[k]=3↔k≈{{{ ∅ }, ∅ },{ ∅ }, ∅ }
 
[k]=n+1↔ ∃ k*([k*]=n ⋀ k≈{x:x ∈ k* ⋁ x=k})
 
[k]=0↔¬ ∃ x(x ∈ k)
 
 [k]=0↔ ∀ x(x ∉ k)
 
 [k]=1↔ ∃ x ∀ y(y ∈ k ↔x=y)
 
 [k]=2↔ ∃ x ∃ y ∀ z(x ∈ k ⋀ y ∈ k ⋀ x≠y ⋀ (z ∈ k→(x=z ⋁ y=z))
 
[k]=n+1↔ ∀ k* ∃ x ∀ y((x ∈ k ⋀ x ∉ k* ⋀ (x≠y→y ∈ k*))→[k*]=n) k has n+1 members exactly if k* has n members, where k* is any
class such that, for some x, x ∈ k and x ∉ k* and such that k and k* are otherwise membership-identical.
 
[k]=1↔ ∀ k*(([k*]=0 ⋀ α ∉ k*)→[k* ∪ α]=[k])
 
[k]=n+1↔ ∀ k*(([k*]=n ⋀ α ∉ k*)→[k* ∪ α]=[k])
 
 
Advanced Set Theory: Definitions
 
CP(k ∪ k*)={α: ∃ β ∃ γ(β ∈ k ⋀ γ ∈ k* ⋀ (α=(β,γ) ⋁ α=(γ,β)))
The Cartesian Product of k and k* is the smallest class K such that, whenever x belongs to k and y belongs to k*, (x,y) ∈ K and (y,x) ∈ K
 
k=ΣK
k is a selection from K
 
k is a selection from K, where K is a class of classes, if, whenever k*
belongs to K, exactly one member of k* is a member of k.
k=ΣK↔DF ∀ k*(k* ∈ K→[k ⋂ k*]=1)
k=ΣK↔DF ∀ k*(k* ∈ K→ ∃ x(x ∈ k* ⋀ x ∈ k ⋀∀ y((x≠y ⋀ y ∈ k*)→y ∉ k)))
 
A function is a rule that assigns exactly one object (an ordered ntuple, in the case of functions of more than variable) to each member of some class of objects.
ϕ(x)=y→(ϕ(x)=z→y=x)
 
 ϕ is a one-one function if, for some function ψ, ψ(y)=x whenever
ϕ(x)=y.
 
ϕ is a one-one function from k to k* if there some function ψ such
that, for any element x of k, there is some element y of k* such that ϕ(x)=y↔ ψ(y)=x.
 
k and k* are bijected by a function ϕ just in case ϕ is a one-one
function from k to k*.
 
[k]=[k*] iff there is a one-one function from k to k*.
[k]=[k*]↔ ∃ ϕ ∃ ψ ∀ x ∃ y (x ∈ k →(y ∈ k* ⋀ ϕ(x)=y ⋀
ψ(y)=x))
 
For any class K, PK is the class of all subsets of K
PK={k: k ⊂ K}
 
 
[Pk]=2[k]
Proof by induction
First suppose that k= ∅ . In that case, [Pk]=1.
Therefore, if [k]=0, then [Pk]=2[k].
Lemma: If [Pk]=2n, then 2[k ∪ α]=2n+1, whenever α ∉ k.
Proof of lemma
∀ k*(k* ∈ Pk ⟶ α ∉ k*)
For each subset of k that does not contain α, there is exactly one subset of k that does contain α. Symbolically, ∀ k#
(k# ∈ Pk ∪ α ∧ α ∉ k#) ⟶∃ 1k^(k^ ∈ Pk ∧ α ∈ k^)
Therefore, [Pk ∪ α]=[Pk]×2.
Therefore, when α ∉ k, 2[k ∪ α]=2[k] × 2.
Therefore, when α ∉ k, 2[k ∪ α]=2[k]+1.
Therefore, if [k]=n and [Pk]=2n, then [Pk ∪ α]= 2n+1, whenever α ∉ k.
Therefore, [Pk]=2[k]. Q.E.D.
 
Advanced Set Theory: Principles and Derived Definitions
 
Cardinal Number: The number of elements in a class. When you ask “how many?”, you are asking for a cardinal number. (When you ask ‘how many dogs does Jim have?’, you are asking ‘how large is k?’, where k is the class of Jim’s dogs).
 
Ordinal number: An ordinal number is position. In the series
0,1,2,3...n...,1’s ordinal number is 2. In the series, 1,2,3...n..,1’s ordinal number is 1.
 
Signed Integer: +x is the relation that n bears to m when n-x=m, and -x is the relation that n bears to m when n+x=m.
For example, +4 is the relation that n bears to m when n-4=m, and -4 is the relation that n bears to m when n+4=m.
 
Rational: m/n is the relation that x bears to y when x×n=y×m. For example, ¾ is the relation that x bears to y when x×4=y×3.
 
Real Number: Real numbers are degrees, a degree being a position in a continuous series. Therefore, a real number is a position in a onedimensional space.
 
Complex Number: A complex number is a pair of real numbers. Therefore, a complex number is a position in a two-dimensional space.
 
 (A,B)={A, {A, B}}
An ordered pair is identical with a suitably membered unordered pair.
Explanation: When we talk about (3,5), we say that 3 is the “first” member and 5 is the “second.” When we talk about {3, {3,5}}, we say that 3 is the “uncoupled” member and 5 is the “coupled” member. It is obviously a matter of indifference whether we distinguish them by using the terms “first” and “second” or “coupled” and “uncoupled”. It is necessary only that there be some way of marking the difference between the two.
 
(A,B,C)={A,{A,B,},{A,B,C}}
An ordered triple is identical with a suitably membered unordered
triple.
 
 (A1…An-1, B)={(A1…An-1),{ A1…An-1, B}}
An ordered n-tuple is identical with a suitably membered unordered n-tuple.
 
(1,2,3)={1, {1,2}, {1,2,3}}
(1,2,3,4)={1, {1,2}, {1,2,3}, {1,2,3,4}}
(1,2,3,…n)={1, {1,2}, {1,2,3}, {1,2,3,4},…{1,2,3,…n}}
 
A n-membered sequence is an ordered n-tuple and, therefore, a suitably membered unordered n-tuple.
 
R strictly orders k exactly if, whenever x,y,z ∈ k,
 

	* ¬xRx (R is non-reflexive)

	* xRy→¬yRx (R is asymmetric)

	* (xRy ⋀ yRz)→xRz (R is transitive)
 
ℕ
The class of all cardinal numbers
 
ℕ =DF{x: x=0 ⋁∃ y(y ∈ℕ⋀ x=y+1)}
x is a number just in case x=0 or x=y+1, for some number y.
 
We have just given a recursive definition of ℕ . It is classes that are recursively defined, a recursive definition of a class k being one of the form:
 

	* α ∈ k, and

	* γ ∈ k, whenever, for some β such that β ∈ k, β bears R to γ, where R is a relation that strictly orders k.
 
ℤ
The class of signed integers
 
ℤ =DF{x: ∃ y(y ∈ℕ⋀ (x=+y ⋁ x=−y))}
 
ℚ
The class of rational numbers
 
ℚ =DF{x: ∃ p ∃ q(p ∈ℕ⋀ q ∈ℕ⋀ x=p/q)}
 
K is an initial segment of ℚ just in case K is a non-empty proper subset of the class of rationals such that x doesn’t belong to K unless, whenever y<x, y also belongs to K.
 
SG(K)
K is an initial segment of ℚ
 
Given some initial segment K of ℚ , x is the least upper bound of K just in case (i) x<y, where y is any member of K and (ii) x<z, z is any nonmember, other than x itself, of K.
 
L(K)=x
x is K’s least upper bound.
 
ℝ
The class of real numbers.
 
ℝ =DF{x: ∃ k(SG(k) ⋀ x=L(k))}
 
ℂ
The class of complex numbers
 
ℂ =DF{x: ∀ y(y ∈ℝ⋀ ((y<0→ ∃ z(z<0 ⋀ z2=y)) ⋀ (y>0→ ∃ w(w<0 ⋀ w2=y)))
 
Series: An ordered pair (k, R), where k is a class and R is a relation that strictly orders k.
 
Progression: A function from ℕ to k, for some class k.
 
Sequence: The initial part of a progression. (Note: In the present paper, “progression” and “sequence” are used interchangeably.)
 
 k≈ ℕ ↔DF[k]= ℵ 0
 
[ ℕ ]=DF ℵ 0
 
[ ℚ ]= ℵ 0
 
k is finite iff k has finitely many members; and k has finitely many
members iff [k]=n, where n ∈ℕ .
 
k is infinite iff k has infinitely many members; and k has infinitely
many members if [k]>n, whenever n ∈ℕ .
 
n is an inductive cardinal if n ∈ℕ .
 
n is a non-inductive cardinal if, for some k, n=[k] and, whenever m ∈ℕ , n>m.
 
k is infinitely large if [k] is a non-inductive cardinal.
 
[k] is transfinite whenever k is infinitely large.
 
A discrete series is a sequence, a sequence being a series each of whose non-terminal members has an immediate successor. ( ℕ , <) is a discrete series.
 
A compact series is a series that is not discrete; equivalently, a series is compact if there is a member between any two members.
( ℚ , <) is a compact series.
 
A continuous series is a compact series that contains each of its own limiting points. ( ℝ , <) is a continuous series.
 
L is a sequence-limit iff there is some sequence α1, α2, α3,… αn,… such that, for any ε, there is some ν such that the difference between αν and L is less than ε. Thus, 1 is the limit of ½, ¾, 7/8, 15/16,…
 
L is a series-limit iff there is some compact series S such that L is the least upper bound of S, meaning that if R is the relation that generates S, then
 

	* Anything that bears R to L belongs to S, and

	* Anything to which L bears R does not belong to S.
 
Thus, 1 is the least upper bound, and therefore the limit, of (κ,<), where κ is the class of proper fractions; and √2 is the least upper bound, and therefore the limit, of (κ#,<), where κ# is the class of rationals p/q such that (p/q)2<2.  
ℝ =DFThe class of limiting points of segments of ( ℚ ,<).
 
Continuous series: S is a continuous series if S is a compact series that contains all of its own limiting points.
 
( ℝ ,<) is a continuous series.
 
( ℚ ,<) is not a continuous series. This is because no irrational belongs to ( ℚ ,<) even though any given irrational is a limiting point of subseries of ( ℚ ,<).
 
 
 
Chapter 2 Set Theory and Logic (2015)
 
 
Introduction
 
Statements about number are encrypted statements about order.
Mathematics is the study of ordinal relations.
Any given truth concerning ordinal relations is equivalent with a truth of set-theory.
Set-theory is the smallest class of truths consisting solely of the following concepts:
 
 
∅ The empty set
∈ The relation between class-member and class
⊂ The relation of subset to set
Not
And
Or
If…then…
Identity
All
Some
Property
Relation
 
In the present work, it will be shown that truths about seemingly exotic mathematical entities (e.g. complex numbers, formal languages, ndimensional manifolds) are identical with truths consisting solely of the justnamed concepts.
It will also be shown that all of the truths of mathematical logic and all of the core truths of philosophical logic can be understood in terms of those concepts. Mathematical logic is the discipline that codifies the rules of inference involved in mathematical reasoning. Philosophical logic is the discipline that identifies the scope and limit of mathematical logic.
 
 
 
Section 1 Von Neumann arithmetic
 
1.0 Preliminary definitions and principles
 
We will now identify a set-theoretic characterization of arithmetic (due to J. von Neumann (1920)). In other words, we will show how, when given an arbitrary statement S of arithmetic, to identify an equivalent statement S* such that
 

	* S* contains no expressions referring to numbers or, indeed, to anyspecifically arithmetical entities and, more specifically,

	* None of the expressions in S* refers to anything that is not on thelist of concepts in the Introduction.
 
We will start by stating some important notational conventions and identifying some of the principles embodied therein.
 
 
1. x ∈ K
x belongs to K
 

	1. {x: φx}
The class of things that have φ.
 

	1. ∀ xφx
Everything has φ
 

	1. ∃ xφx
Something has φ
 

	1. P ⋀ Q
P and Q
 

	1. P ⋁ Q
Either P or Q or both
 

	1. ¬P
Not-P
 

	1. x ∉ k
¬(x ∈ k)
 

	1. P→Q
¬(P ⋀ ¬Q)[1]
 
 

	* P↔Q
(P→Q) ⋀ (Q→P)
 

	* k ⊆ k*
k is a subset of k*
k* is a superset of k
 

	* k ⊆ k*↔ ∀ x(x ∈ k→x ∈ k*)
 

	* k ⊂ k*↔ ∀ x((x ∈ k→x ∈ k*) ⋀∃ y(y ∉ k ⋀ y ∈ k*))
 

	* ∀ x(φx→ ψx)
All φ’s are ψ’s
 

	* ∃ x(φx ⋀ ¬ ψx)
Not all φ’s are ψ’s
 

	* ∅
The empty set
{x: x≠x}
 

	* [k]
The number of objects in k k’s cardinal number
k’s cardinality
 

	* k≈k*[k]=[k*]
k has exactly as many members as k*
 

	* ℕ
The natural numbers
{0, 1, 2, 3,…}
The posterity of 0 with respect to the relation that n bears to n+1
 

	* ℕ =DF{n: n=0 ⋁∃ m(m ∈ℕ⋀ n=m+1)}
 

	* The posterity of α with respect to relation RThe smallest class K such that:
 

	* α belongs to K and

	* n belongs to K whenever m belongs to K, provided that m bearsR to n.
 
22. +n, ×n, ζn
The operations of addition, multiplication, and exponentiation.
Formally, +n, ×n, and ζn are, respectively, the relation of α to β when:
β=Sn(α), where S1(α)= α+1 and Sn+1(α)= S1(Sn(α)), β=Pn(α), where P1(α)= α and Pn+1(α)= Pn(α)+α, and β=En(α), where E1(α)=α and En+1(α)= En(α)×α.
 
 
1.2 Von Neumann arithmetic
 
 
Cardinal numbers are class-sizes. For example, if k is the class of Jim’s houses, then
 

	* Jim has 0 houses

	* Jim has 1 house,

	* Jim has 2 houses,

	* Jim has 3 houses,

	* Jim has n+1 houses,
 
 
are equivalent with, respectively,
 
(a*) k≈ ∅ , (b*) k≈{ ∅ }.
(c*) k≈{{ ∅ }, ∅ }, and
(d*) k≈{{{ ∅ }, ∅ }, { ∅ }, ∅ }
 (e*) ∀ k*(k≈k* ∪ α↔([k*]=1 ⋀ α ∉ k*))
 
The meaning of (e*) is this: If k* has n members and α is not an element of k*, then k has the same number of members as k* ∪ α.
There are no number-expressions in (a*)-(d*). Thus, all of the number-expressions in (a)-(d) have been successfully eliminated. (There are number-expressions in (e*), but we are about to see how to produce an equivalent statement that contains no such expressions.)
 Given obviously generalizations of the fact that (a)-(d)- are equivalent with (a*)-(d*), ℕ may be identified with the posterity of ∅ with respect to Φ, where Φ is the relation that {n: nϵα} bears to {n: n ∈ α ∨ n=α}. (In other words, 1={ ∅ }, and 2={{ ∅ }, ∅ }, and so on.) Stated formally, n is a cardinal iff either
 

	* n= ∅ or

	* n=β,
 
where, for some γ, Φ(γ)=β.
 And given that ℕ may be identified with the posterity of ∅ with respect to ρ, it follows that (e*) is equivalent with:
 
(e#) ∀ k* ∀ x(x ∈ {α: α= ∅∨∃ β(Φ(β)=α)} ⋀ k*≈x)→ ∃ y(Φ(x)=y ⋀ k≈y)),
 
which, unlike each of (e) and (e*), contains no number-expressions.
 
 
 
1.2.1 Von Neumann arithmetic (continued)
 
It follows that, for any number α,
 
(+V1) α+1={n: n=α or n ∈ α}, and α=β+1 exactly if α ={n: n=β ⋁ n ∈ β}.
 
Given (+V1), it follows that the following definitions are both consistent with one another and otherwise admissible:
 
(+) {n: n ∈ α}+0=DF{n: n ∈ α}; and {n: nϵα}+n+1=DF{n: n=α or n ∈ α}+n. (×){n: n ∈ α}×0=DF ∅ ; and {n: n ∈ α}×n+1=DF{{n: n ∈ α}×n}+α, and (ζ) {n: n ∈ α}ζ0=DF{ ∅ }; and {n: n ∈ α}ζn+1=DF{n: n ∈ α}ζn}×α.
 
(+), (×), and (ζ) are equivalent with, respectively:
 
(A) α+0=α; and α+(β+1)= (α+β)+1, (B) α×0=0; and α×(β+1)= (α×β)+ α, (C) α0=1; αn+1= αn×α.
 
these being the recursions that define +, ×, and ζ, respectively.
Relative to this construction of arithmetic, the meanings of
 

	* α+β=γ

	* α×β=γ, and

	* αβ=γ
 
are, respectively,
 

	* {n: n ∈ α}+β ={n: n ∈ γ},
(IIV) {n: n ∈ α}×β={n: n ∈ γ}, and (IIIV) {n: n ∈ α} ζβ={n: n ∈ γ}.
 
 
Section 2 Frege-Russell arithmetic
 
2.0 Preliminary definitions and principles
 
 
We will now put forth a different set-theoretic of arithmetic (due to G. Frege (1884), refined by B. Russell and A.N. Whitehead (1912)). We will begin, as before, by stating some notational conventions and identifying some of the principles embodied therein.
 
23. Kn
The class of all n-tuples,
The class of all classes having n members,
{k: [k]=n}
 
24.
K = {k: ∃ x … ∃ x ((1≤i≤n ⋀ 1≤j≤n ⋀ i≠j)→(x ∈ k ⋀ x ∈ k ⋀ x ≠x ⋀∀ y(y ∈ k↔ ∃ λ(1≤ λ ≤n ⋀ y=x )))) n DF 1 n i j i j λ
 

	* CP(k,k*)
The Cartesian Product of k and k*,
The class of all pairs (x,y) such that either (i) x belongs to k and y
belongs to k* or (ii) x belongs to k* and y belongs to k
 

	* CP(k,k*)=DF{k#: ∃ x ∃ y(k#=(x,y) ∧ ((x ∈ k ∧ y ∈ k*) ∨ (x ∈ k* ∧ y ∈ k)))}
 

	* Selection
S is a selection from a non-empty class K just in case S contains exactly one member from each class belonging to K.
 

	* SK↔ ∀ k(k ∈ K→ ∃ x(x ∈ k ⋀ x ∈ S ⋀∀ y(y ∈ k ⋀ y ∈ S→(x=y)))
 

	* ΣK
The class of all selections from K
Anticipation: If K is a class of classes, ΣK is the smallest class containing every selection from K. It follows that ΣK={ ∅ } if K= ∅ and, in general, that for all β≥0, [ΣK]= αβ if K is a β-tuple whose members are αtuples. Thus, exponentiation can be understood in terms of the concept of a selection and, for reasons that will emerge, ultimately must be so understood.
 

	* Axiom of Extensionality
Classes are identical when membership-identical.
∀ k ∀ k*(k=k*↔ ∀ x(x ∈ k↔x ∈ k*)
 

	* Leibniz’s Law
Things are property-identical when identical
α=β→ ∀ φ(φα↔ φβ)
 

	* Indiscernibility of identicals
Things are identical when property-identical.
∀ φ(φα↔ φβ)→α=β)
2.2 Frege-Russell arithmetic
 
For any n,
 

	* John has n cars
 
is equivalent with
 

	* k ∈ Kn,
 
where k is the class of John’s cars and Kn is the class of all n-tuples.
 A class k is empty, and thus a 0-tuple, exactly if, for any x, x ∉ k.
 A class k is an n+1-tuple exactly if, for any x such that x ∈ k, k* is
an n-tuple, where x ∉ k* but where k and k* otherwise have the same members.
Therefore,
 

	* 0= ∅
 
and
 

	* n+1=Kn+1,
 
where k ∈ Kn+1 exactly if, for some x such that x ∈ k, k* ∈ Kn,
where x ∉ k* but where k and k* otherwise have the same members.
Therefore,
 
(+F1) α=β+1 exactly if k ∈ α↔ ∀ x(x ∈ k→ ∀ k*(((x ∉ k* ⋀∀ y(x≠y ⋀ y ∈ k))→ y ∈ k*)→k* ∈ β)).
 
Given (+F1), it follows that the following definitions are consistent with one another and otherwise admissible:
 
(+F) K+0=DF{k:k ∈ K}; and
K+n+1=DF{k: ∀ k* ∃ x((x ∈ k ⋀ x ∉ k* ⋀ ∀ y((x≠y ⋀ y ∈ k)→y ∈ k*))→k* ∈ K+n)}
 
(×F) K×0=DF ∅ ; and
K×n+1=DF{k:k ∈ K×n}+n
 
(ζ F) Kζ0=DF{k: ∃ x ∀ y(y ∈ k↔x=y)}; and
Kζn+1=DF{k:k ∈ K ζn}×n
 
(+F), (×F), and (ζ F) are equivalent with, respectively:
 

	* α+0=α;
and
α+(β+1)=(α+β)+1,
 

	* α×0=0;and
α×(β+1)=(α×β)+ α,
 

	* α0=1; and αn+1=αn×α.
 
 Relative to this construction of arithmetic, the meanings of:
 
(I) α+β=γ (II) α×β=γ, and
(III) αβ=γ
 
are, respectively,
 
(IF) The union of an α-membered class and a non-overlapping βmembered class is a γ-membered class,
(IIF) The Cartesian product of an α-membered class and a βmembered class is a γ-membered class, and
(IIIF) The class of all selections from a β-membered class of αmembered classes is a γ-membered class.
 
Symbolically,
 
(I*F) ∀ k ∀ k*(((k ∈ Kα ⋀ k* ∈ Kβ) ⋀ (kα∩kβ= ∅ ))→kα ∪ kβ ∈ kγ)
 
(II*F) ∀ k ∀ k* ((k ∈ Kα ⋀ k* ∈ Kβ)→
∀ k# ∀ x((x ∈ k#↔ ∃ y ∃ z(y ∈ k ⋀ z ∈ k* ⋀ (x=(y,z) ⋁ x=(z,y))) →k# ∈ Kγ)),
 
and
 
(III*F) ksk* ∈ Kγ↔(k* ∈ Kα ⋀∀ x(x ∈ k*↔ ∃ k#(x=k# ⋀ k# ∈ Kβ)))
 
Given (IF)-(IIIF), it follows that (A)-C) are equivalent with:
 
(I#F) [k ∪∅ ]=[k]; and
∀ k ∀ k((k ⋂ k*= ∅ ) ∧ ((α ∉ k ⋀ α ∉ k*)→[k ∪ (k* ∪ α)]= [(k ∪ k*) ∪ α]))
 
(II#F) [CP(k, ∅ )]= ∅ ;
and ∀ k ∀ k* ∀ k#(α ∉ k*→[CP(k,k* ∪ α)]=[k ∪ CP(k,k*)]),
 
and
 
(III#F) [Σ ∅ ]=[{ ∅ }]; and
∀ k ∀ k*(((α ∉ k ∧ α ∉ k*) ∧ (k ⋂ k*= ∅ ))→[Σ(k ∪ (k* ∪ α))]=[CP(Σ(k ∪ k*),k)])
 
 
2.3 Why this system is not guilty of the vicious circularity of which it seems to be guilty
 
According to the analysis just-presented, n=Kn, where Kn is the class of all n-tuples. Thus, that analysis appears to define “n” in terms of itself and therefore to be guilty of vicious circularity.
But it is not guilty of vicious circularity. For any n, [k]=n is equivalent with a proposition that contains no mention of n or of any other number. This is because the meanings of:
 

	* [k]=0

	* [k]=1

	* [k]=2,

	* [k]=3, and
(n+1) [k]= n+1
 
are equivalent with:
 
(0*) k is empty
(1*) For some x, x belongs to k and a class k* is empty if k* does not contain x but is otherwise membership-identical with k,
 
(2*) For some x, x belongs to k and a class k* is a one-tuple if k* does not contain x but is otherwise membership-identical with k
 
(3*) For some x, x belongs to k and a class k* is a two-tuple if k* does not contain x but is otherwise membership-identical with k, and
 
(n+1*) For any x, if x belongs to k and for any k* such that x does not belong to k* but such that k and k* are otherwise membership-identical, [k*]=n.
 
There are no number-expressions in (0*)-(3*): all of the numberexpressions in (0)-(3) have been eliminated. (There are number-expressions in (n+1*), but in a moment we will how to produce an equivalent statement that contains no number-expressions.)
Given that (0)-(3) are equivalent with, respectively, (0*)-(3*), it follows that any given cardinal n may, without circularity, be identified with the class of all n-tuples.
And given that n may be identified with the class of all n-tuples, it follows that (n+1*) is equivalent with:
 
(n+1#) ∀ K(K={C: ∃ C!(C≈C!)}→ ∀ k* ∀ x((k* ∈ K ⋀ x ∉ k*)→k≈k* ∪ x)),
 
which, unlike each of (n+1) and (n+1*), contains no number-
expressions.
 The meaning of (n+1#) is this: If K is the class of all classes equinumerous with a given class and k* is a member of K, then, if x is not a member of k*, k is equinumerous with k* ∪ x.
Even though (0*)-(n+1*) are perspicuous renderings of (0)-(n+1), (0*)-(n+1*) are not formal renderings of (0*)-(n+1*).
A perspicuous statement is one whose semantics corresponds to its syntax. A formal statement is one that is perspicuous for the reason that it is stated in a notation or language that prohibits the formation of nonperspicuous statements. Given that English permits the construction of nonperspicuous statements, (1*)-(n+1*), though perspicuous, are not formal. In any case, when stated formally, (0)-(n+1) come out to:
 
 
(0#) ∀ x(x ∉ k)
(1#) ∃ x ∀ y(y ∈ k↔x=y)
(2#) ∃ x ∃ y ∀ z(x ∈ k ⋀ y ∈ k ⋀ x≠y ⋀ (z ∈ k↔(z=x ∨ z=y)
(3#) ∃ x ∃ y ∃ z ∀ w(x ∈ k ⋀ y ∈ k ⋀ z ∈ k ⋀ x≠y ⋀ y≠z ⋀ x≠z ⋀ (w ∈ k↔(w=x ∨ w=y ∨ w=z), and
(n+1#) ∀ k ∀ k* ∀ x((x ∈ k*→x ∈ k ⋀∃ y ∀ z((z ∈ k ⋀ z ∉ k*)↔y=z))→[k*]=n)
 
 
which, unlike each of (n+1) and (n+1*), contains no number-
expressions.
 
 
Section 3.0: Generalizations of cardinal arithmetic
 
Cardinal arithmetic is ℕ -arithmetic. In this section, we will discuss the most generalizations of -arithmetic, these being:
 
ℚ -arithmetic: the arithmetic of rational numbers
ℤ -arithmetic: the arithmetic of signed integers
ℝ -arithmetic: the arithmetic of real numbers ℂ -arithmetic: the arithmetic of complex numbers, and Ordinal arithmetic: the arithmetic of ordinal numbers.
 
 In Section 6, we will discuss the arithmetic of transfinites, this being another yet another generalization of cardinal arithmetic.
It will be shown that none of these arithmetics requires the existence of anything not required by ℕ -arithmetic.
 
3.1 Preliminary definitions and principles
 
In this section and the next one, we will state some of the requisite notational conventions and will identify some of the more important principles embodied therein.

	* ℚ
The class of rational numbers
 

	* ℚ =DF{n: ∃ p ∃ q(p ∈ℕ⋀ q ∈ℕ⋀ n=p/q}
 

	* ℤ
The class of signed integers
 
36.
ℤ = DF{n: ∃ m(m ∈ℕ⋀ (n=+m ⋁ n=−m))}
 
37. ( ℕ ,<)
The series 0,1,2,3,….
The natural numbers in ascending order
 
38.
( ℚ ,<)
The rational numbers in ascending order
 

	* ℝ
The class of real numbers
The class of least upper bounds of initial segments of ( ℚ ,<), an initial segment being one that doesn’t contain m unless it contains n, for each n<m.
The class of limiting points of ( ℚ ,<)
 

	* ℝ = DF{n: ∃ k(k ⊂ℚ⋀ n ∉ k ⋀∀ α ∀ β((α ∈ k ⋀ β ∈ℚ⋀ β<α)→β ∈ k) ⋀∀ γ((γ ∈ℚ⋀ γ ∉ k ⋀ γ≠n)
→n<γ))
 

	* ℂ
The class of complex numbers
The class of numbers n such that, if n is negative, then there is some negative real number r such that n2=r and such that, if n is positive, then there is some positive real number r* such that n2=r*.
 

	* ℂ =DF{n: ∃ α (α ∈ℝ⋀ (α>0→ (n>0 ⋀ n2= α)) ⋀ (α<0→ ( n<0 ⋀
n2= α )))
 

	* ℚℛ
The class of rationals whose least upper bound is ℛ , where ℛ is a real number.
ℚℛ =DF{B: B ∈ℚ⋀ B< ℛ }
 

	* n ℚ
The rational number n n/1
 

	* n ℝ
The real number n
The limit of a series S=α1, α2, α3,…such that, for any ϵ, there is some m such that the absolute value of the difference between αm and n is less than ϵ.
The least upper bound of the class of rationals (p/q) such that (p/q) <(n/1).
 

	* Power-set
The power-set of a given class K is the class of all subclasses of K.
 

	* PK=DF{k: k ⊆ K}
Given a class K, PK is the power-set of K.
 

	* Axiom of Choice
Given any class K, there is a class K* such that K*= ΣK.
Given any class K whose members are themselves classes, there is a class K* such that K* contains exactly one member from each of the members of K.
∀ K ∃ K* ∀ x(x ∈ K*↔ ∃ k(k ∈ K ⋀ x ∈ k ⋀∀ y((y ∈ k ⋀ x≠y)→y ∉ k)))
 

	* ∀ K( ∅⊆ K)
Explanation: Given that nothing belongs to any empty set, it follows that any given empty-set is membership-identical, and therefore identical, with ∅ .
 
3.2 The concept of an enlargement
 
In mathematics, it is often necessary to considered ordered n-tuples (K, O1, O2…On), where K is a class and Oi (1≤i≤n) is an operation that is defined for m-tuples (m≥1) whose members belong to K. Thus, ( ℕ , +, ×) defines the class of arithmetical truths. In the expression “( ℕ , +, ×)”, the occurrences of “+” and “×” denote relations that hold between cardinal numbers. They do not denote relations that hold between signed integers (e.g. −8, +3) or between rationals (e.g. ¾, ½) or, therefore, between signed rationals (e.g. −3/4, +7/8). (For reasons yet to be disclosed, +5 is not the same entity as 5.)
 Therefore, if ℤ is the smallest class containing both +n and –n, for every cardinal n, then, in “( ℤ , +, ×)”, the occurrences of “+” and “×” do not denote the same relations as their homonyms in “( ℕ , +, ×).” Taking + ℕ and × ℕ to be the second pair of relations and + ℤ and × ℤ to be the first, + ℕ and × ℕ denote relations between unsigned integers, whereas + ℤ and × ℤ denote relations between signed integers.
Nonetheless, for obvious reasons, given any truths of the form α
+ ℕβ=γ and α× ℕβ=γ there are analogous truths of the form α+ ℤβ=γ and α× ℤβ=γ. To that extent, ( ℤ , +, ×) may be said to correspond to (though not to coincide with) ( ℕ , +, ×).
At the same time, there are truths in ( ℤ , +, ×), e.g. 5−8=−3, that do not have counterparts in ( ℕ , +, ×). To that extent, ( ℤ , +, ×) is larger than ( ℕ , +, ×). Thus, ( ℤ , +, ×) may be said to be an enlargement of ( ℕ , +, ×). But ( ℤ , +, ×) is not a superset of ( ℕ , +, ×), given that the two statement-sets are disjoint.
 In general, (K, O1, O2…On) is an enlargement of (K*, O*1, O*2… O*m) if, for any statement in (K*, O*1, O*2…O*m), there is an analogous statement in (K*, O*1, O*2…O*m) but not vice versa.
 In most cases that are of mathematical interest, if (K, O1, O2…On) is an enlargement of (K*, O*1, O*2…O*m), (K, O1, O2…On) is not a superset of (K*, O*1, O*2…O*m). The reason is simply that if (K, O1, O2…On) is both an enlargement and a superset of (K*, O*1, O*2…O*m), then (K*, O*1, O*2… O*m) ceases to be of interest, and therefore drops out of consideration, except in so far as it is a subset of (K, O1, O2…On).
 During what follows, when we’ll be discussing the class of rationals, reals, and other (as we might describe them) hyper-cardinals, it must be borne in mind that no class of hyper-cardinals is a superset of the class of cardinals, since (for reasons about to be stated) no cardinal is a hyper-cardinal.
 
3.3 Rationals, Reals, and other Hyper-cardinals: Introductory
Remarks
 
ℕ is closed with respect to the operations of addition, multiplication, and exponentiation (henceforth “+”, “×” and “ζ”). In other words, if m ∈ℕ and n ∈ℕ , then (m+n) ∈ℕ , (m×n) ∈ℕ , and mn ∈ℕ .
ℕ is not closed with respect to the inverses of these operations, namely, subtraction, division, and root-extraction (henceforth, “−”, “÷”, and “Λ”). In other words, if m ∈ℕ and n ∈ℕ , it is possible that (m−n) ∉ℕ , (m÷n) ∉ℕ , and m1/n ∉ℕ .
We may now state precisely what is meant by the commonly used expressions “ ℤ ”, “ ℚ ”, “ ℝ ” and “ ℂ ”:
 
ℤ =DF the smallest enlargement of ℕ that is closed with respect to both + and –
ℚ =DF the smallest enlargement of ℤ that is closed with respect to both × and ÷
ℝ =DF the smallest enlargement of ℚ that is closed with respect to both ζ and Λ
ℂ =DF the smallest enlargement of ℝ that is closed with respect to Π, where, for any n, Π(−n)=√−n
 
But given only that we have so defined these expressions, it no more follows that the corresponding sets are non-empty than the existence of a cancer-preventing vaccine follows from the fact that we define “δ” to mean “the first cancer-preventing vaccine ever created.” Lest “ ℤ ”, “ ℚ ”, “ ℝ ” be so many ways of referring to ∅ , it must be proved that there exist objects having the requisite properties. This can be proved, and we will now prove it.
 
3.4 Signed Integers
 
 
+n is the relation that m bears to m−n, and −n is the relation that m bears to m+n.
Thus, (α, β) is an instance of +n just in case β=α−n, and (α, β) is an instance of –n just in case β=α+n.
Therefore, (1,3), (35, 37) and (87,89) are all instances of the relationship that 0 bears to 2; and (3,1), (37, 35) and (89,87) are all instances of the relationship that 2 bears to 0.
The following identities jointly model the arithmetic of signed integers:
 

	* +n =(n,0)

	* (α, β) =(n,0) whenever α−n= β

	* –n=(0, n)

	* (α, β) with (0,n) whenever α+n=β

	* (α, β)+(γ,δ)=(α+γ, β+δ)

	* (α, β) ×(γ,δ)=(α×γ)+( α×δ)+(β×γ)+(δ×γ)
 
Therefore, the meanings of
 

	* +3+−9=−6

	* −2+−11=−13, and

	* +3++7=+10
 
are, respectively,
 

	* (3,0)+(0,9)=(3+0, 0+9)=(3,9)=(0,6)=DF−6

	* (0,2)+(0,11)=(0+0, 2+13)=(0,13)= DF −13, and

	* (3,0)+(7,0)=(3+7,0+0)=(10,0)= DF +10
 
And the meanings of
 

	* −3×−3=9

	* +2×+4=+8, and

	* +3×−7=−21
 
are, respectively,
 
(xvi)(0,3)×(0,3)=(0×0)+(0×3)+(3×0)+(3×3)=9

	* (2,0)×(4,0)=(2×4)+(2×0)+(0×4)+(0×0)=8, and

	* (3,0)×(0,7)=(3×0)+(3×7)+(0×0)+(0×7)=21
 
 Given that +n is identical with (n,0) relative to the assumption that + and × are defined in the just-described way, it follows that, strictly speaking, it is false to say that +n=(n,0). The truth of the matter is that +n is identical with the ordered triple ((n,0),+S, × S,), where and +S and × S are the justmentioned analogues of + and ×. For the same reason mutatis mutandis, −n is identical with the ordered triple ((0,n) +S, × S).
 
3.5 Rationals
 
 The following identities jointly model the arithmetic of rationals:
 

	* (p/q)+(p*/q*)=(((p×q*)+(p*×q)), q×q)

	* (p/q)×(p*/q*)=((p×p*),(q×q*))
 
So the meanings of
 

	* (2/3)+(7/8)=37/24

	* (2/3)×(7/8)=14/24=7/12, and

	* (3/1)×(4/1)=12
 
are, respectively
 

	* (2×8)+(3×7), 3×8)=(16+21,24)=(37,24)=DF37/24

	* ((2×7),(3×8))=(14,24)=DF14/24=7/12, and

	* ((3×4),(1×1))=(12,1)= DF12
 
 
3.6 Reals that correspond to rationals
 
 
A real number is the least upper bound of a class Qi of rationals such that
 

	* Qi is a non-empty proper subset of the class of rationals and

	* Qi contains a given rational q only if it contains every rational p such that p<q.
 
Thus, a real number is the least upper bound of a class of rationals that doesn’t contain a given rational unless it contains every smaller rational.
For any n, n ℝ is the least upper bound of the class of rationals (p/q) such that n×q>p.
Thus, 1 ℝ is the least upper bond class of all proper fractions; 2 ℝ is the least upper bound of the class of rationals (p/q) such that 2×q>p; 3 ℝ is the least upper bound of the class of rationals (p/q) such that 3×q>p; and so on.
For any rational α such that α=(p/q), where p and q are cardinals, α ℝ is the least upper bound of the class of fractions p*/q* such that p*/q*<α.
 
3.7 Reals that do not correspond to rationals
 
Not all reals correspond to rationals, i.e. for some real numbers r, there is no rational q such that r is the limit of (Qq,<). An example of such a real is √2.
√2=DF the limit of (Q#2,<), where Q#2 is the class of rationals q such that q2<2.
But given only that “√2” is so defined, it doesn’t follow that (Q#2,<) has a limit. Lest “√2” be an empty label, like “phlogiston” or “Zeus”, it must be proved that an entity having the requisite properties exists.
As it happens, such an entity does exist. Let us start with some stipulative definitions:
 

	* Qn=n ℝ, where Qn is the smallest class containing every rational m<n and is n ℝ is the real number corresponding to cardinal number n.

	* √2DF=Q#2, where Q#2, is the class of all rationals whose squares are less than 2 ℚ.

	* √2DF=Q#3, where Q#3, is the class of all rationals whose squares are less than 3 ℚ.

	* Q1=1 ℝ, where Q1 is the smallest class containing every proper fraction.
 
Given (i)-(iv), it follows that each of the following propositions:
 

	* If α belongs to Q#2, α2<γ, for some member γ of Q2,

	* If α and β belong to Q#3, and γ is an arbitrary member of Q3, αβ× γ
< δ, for some member γ of Q9,

	* If α and β belong to Q2 and Q3, respectively, α+β<γ, for some member γ of Q5,

	* If α and β belong to Q2 and Q3, respectively, α×β<γ, for some member γ of Q6,

	* If α, β, and γ belong to Q3, αβ×γ< δ, for some member δ of Q27,
 
encodes the same information as the same-lettered counterpart on the following list:
 

	* √2×√2=2,

	* (√3×√3)×3=9,

	* 2+3=5,(D) 2×3=6, (E) (3×3)×3=27.
 
 
3.8 +ℝ and × ℝ defined
 
For any real numbers μ, ν, and ξ, the meanings of
 

	* μ+ν=ξ,

	* μ×ν=ξ,

	* μν=ξ,
 
are, respectively,
 
(IR) ∀ α ∀ β((α ∈ℚ μ ⋀ β ∈ℚ ν)→ ∃ γ(γ ∈ℚ ξ ⋀ α+β<γ))
(IIR) ∀ α ∀ β((α ∈ℚ μ ⋀ β ∈ℚ ν)→ ∃ γ(γ ∈ℚ ξ ⋀ α×β<γ))
(IIIR) ∀ α ∀ β((α ∈ℚ μ ⋀ β ∈ℚ ν)→ ∃ γ(γ ∈ℚ ξ ⋀ αβ<γ))
 
 
 Each occurrence of “<” in (IR)-(IIIR) can be replaced salva veritate with “ ∈ ”, given that when it is said of some rational number τ that τ precedes ρ, where ρ is a real number, this means that τ belongs to ρ.
 
3.9 Ordinal numbers
 
Ordinal numbers are positions. In the series,
 
2, 4, 6, 8…n…
 
6’s ordinal number is 3, but in the series
 
6, 7, 8, 9…m…
 
6’s ordinal number is 1.
If Jim comes in first in the 100 meter dash and second in 200 meter dash, then Jim’s ordinal numbers with respect to the 100 meter dash is 1 and his ordinal number with respect to the 200 meter dash is 2.
For any x, it is only in relation to a given series S that x has an ordinal number.
A series is defined by an ordered pair (k,R) such that K is a class and a relation that strictly orders k.
R strictly orders a class k just in case, if x, y, and z are any elements of k,
 

	* ¬xRx

	* xRy→¬yRx, and(iii) (xRy ∧ yRz)→xRz.
 
In other words, R strictly orders k just in case, with respect to the members of K,
 
(i*) R is non-reflexive, (ii*) R is asymmetric, and (iii*) R is transitive.
 
Given some series S=(k,R),
 

	* x’s ordinal number with respect to S is 1 just in case, for all y in
S, ¬xRy, and

	* x’s ordinal number with respect to S is n+1 just in case if y’sordinal number with respect S is n, then x is y’s immediate R-successor, i.e.
xRy and, for any z such that z bears R to y, either x=z or zRx.
 
Thus, 1o (the subscript is an “o”, for “ordinal”, not a “0”) is the relation that x bears to S=(k, R) when x ∈ k and, whenever y ∈ k, ¬xRy; and (n+1)o is the relation that x bears to S when xRy, where y is the nth member of S, and xRz and zRy is false for all z.
Where finite numbers are concerned, +O and ×O are exact analogues of + and ×. This is because, whenever m and n are finite, + and × commutative, meaning that m+n=n+m and m×n=n×m.
For reasons that will be discussed later , + and × are not commutative when m and n are not finite.
If nO is the ordinal number corresponding to n, then the following stipulations jointly model the arithmetic of ordinal numbers:
 

	* nO=(n,0)

	* (n, 0)+(m, 0)=(n+m, 0+0)

	* (n, 0)×(m, 0)=(n×m)+(n×0)+(0×n)+(0×0)
 
Of course, (3) is output-identical with each of:
 
(31) (n×m)+(n, 0)+(m, 0)+(0×n)
(32)(n×m)+(n, 0)+(m, 0)+(0×0)
(33)(n×m)+(n, 0)

	* (n×m)+(m, 0), and

	* (n×m)
 
But (3i) (for each i such that 1≤i≤5) and (3) are structurally different; and even though those structural differences are not important in this context, they are important in other contexts (e.g. in contexts involving transfinites or, more importantly, those involving generalized vectors). It is therefore important in this context not to distort underlying structure, lest the wrong results be generated in other contexts.
 
3.10 Complex numbers
 
Real numbers are positions in one-dimensional series. A onedimensional series is a continuous series whose members are not themselves series.
An n+1 dimensional series is a continuous series each of whose members is an n-dimensional series. Thus, a 2-dimensional series is a continuous series whose members are one-dimensional series.
Given that real numbers are positions in one-dimensional series, it follows that pairs/triples/n-tuples of real numbers are positions in two dimensional/three-dimensional/n-dimensional series.
When n>2, an n-tuple of real numbers is a vector.
Complex numbers are positions in 2-dimensional series and they are therefore vectors.
(Strictly speaking, complex numbers are complex numbers are pairs of signed reals, not reals per se. We will revisit this point later.)
ℂ is the Cartesian product of ℝ and ℝ , i.e. ℂ is the smallest class containing (m, n), for any reals m and n.
Thus, ℂ defines a Cartesian plane. If an ordered pair corresponds to a position on the x-axis, that pair corresponds to a real number.
Given any real number, there is a corresponding complex number. But not all complex numbers correspond to real numbers, i.e. some complex numbers are imaginary, an imaginary number being the nth root of –m, where m is a positive real and n is an even positive. Thus, there is no real number corresponding to √−1, but there is a complex number corresponding to √−1.
The existence of such a complex number is a consequence of the
following stipulations, which, taken jointly, model the arithmetic of complex numbers:
 

	1. A complex number α corresponds to a real number if, for somereal number m, α=(m,0).

	2. α corresponds to an imaginary number if, for some real number m, α=(0,m). β is an imaginary number if, for some positive real m, there is some even number n such that βn=−m.

	3. When n is positive, (n,0) corresponds to n ℝ and (−n,0) corresponds to −n ℝ. Thus, (1,0) corresponds to 1 ℝ, and (−1) corresponds to
−1 ℝ.

	1. √−1 = (0, 1).

	2. √−n = (0, n), when n is positive.

	3. (x, y)+ ℂ(x*, y*)=(x+x*, y+y*), where + ℂ is the ℂ -analogue of +,

	4. (x, y)× ℂ(x*, y*)=((x×x*)−(y×y*), (x×y*)+(y×x*)), where × ℂ is the ℂ -analogue of ×.
 
Thus, √−1 × √−1 = (0,1) × ℂ(0,1)= ((0×0)−(1×1), (0×1)+(0×1))=
(−1,0)=DF−1.
 In general, this calculus yields the desired results where operations with imaginaries are concerned and the right results where operations with reals are concerned.
 
4.0 Relevant metamathematical concepts and principles
 
4.1 Numbers of one kind never size-comparable with numbers of any other kind
 
To say of a given person that his net worth is negative $5 is to say that his financial obligations exceed his assets by $5. It is to say that α+5=β, where α and β represent his assets and his obligations, respectively, and to say that his net worth is positive $5 is to say that α−5=β.
Thus, −5 is the relation that α bears to β when α+5=β, and +5 is the relation that α bears to β when α−5= β. For any n, −n is the relation that α bears to β when α+n=β, and +n is the inverse relation.
Neither +n nor –n is a class-size. It is therefore no less wrong to
identify n with +n than with –n.
Since n ∉ℤ , for any cardinal n, it follows that ℕ and ℤ do not have a single member in common and are therefore disjoint.
It also follows that + ℤ and × ℤ are mere analogues of + and ×. Whereas + and × are relations holding among cardinals, + ℤ and × ℤ are relations holding among relations holding among cardinals.
 For similar reasons, ℚ does not have a single member in common with either ℤ or of ℕ . Smith has ¾ as many houses as Brown iff α×3=β×4, where α is the number of houses belonging to Brown and β is the number of houses belonging to Smith. 4/4 is the relation α bears to β when α×4=β×4. In general, m/n is the relation that α bears to β when α×n=β×m.
Therefore, 4/1 is not identical with 4. 4/1 is relation that α bears to β when α×1=β×4. Since 4/1 is a relation between cardinal numbers, it is not itself a cardinal number and therefore is not identical with 4.
Given that +4 is the relation that 4 bears to 0, as opposed to the relation that n bears to m when 4×m=1×n, 4/1 is not identical with +4.
Given that + ℚ and × ℚ are relations among relations of the first kind, whereas + ℤ and × ℤ are relations among relations of the second kind, it follows that + ℚ and × ℚ are mere analogues of + ℤ and × ℤ.
Given that that + and × are relations among cardinals per se, as opposed to relations among relations among cardinals, it follows that + and × are mere analogues of + ℤ and × ℤ, respectively, and of + ℚ and × ℚ, respectively.
Also, signed rationals, e.g. +(4/3) and –(3/8), can no more be identified with their unsigned counterparts than –4 can be identified with 4. Whereas cardinals are class-sizes and rationals are relations between classsizes, signed rationals are relations between relations between class-sizes. + (4/3) is the relation that m/n bears to α/β when 4×β=3×α. 4/3 is the relation that m bears to n when 4×n=3×m.
But even though none of the just-mentioned number-sets has even a single member in common with any of the others and even though no operation that is defined for any given one of those sets is defined for any of the others, there is a significant respect in which ℚ and ℤ are contained in ℕ . Statements about rationals are abbreviated statements about cardinals, the same obviously being true of statements about signed integers. There is nothing that either ℚ or ℤ enables us to say about the world that ℕ doesn’t allow us to say. The discovery of ℚ -arithmetic and ℤ -arithmetic were ultimately more notational than mathematical. In discovering these arithmetics, we were only discovering new ways of symbolizing what we already knew about number; we were not otherwise learning anything new about number or anything else.
But the discovery of ℝ -arithmetic was a genuine intellectual advance. And even though ℝ , like each of ℚ and ℤ , can be constructed out of the elements of ℕ , the relation that ℝ bears to ℕ differs fundamentally from the relation that either ℚ or ℤ bears to ℕ . This is because, whereas each of ℚ and ℤ can be constructed out of ℕ entirely on the basis of principles that are implicit in ℕ -arithmetic, the principals involved in the construction of ℝ are foreign to ℕ -arithmetic. Even though ℝ is built out of the same ingredients as ℚ and ℤ and therefore ℕ itself, the way in which those ingredients are arranged in ℝ differs fundamentally from the way in which they are arranged in any given one of the other three classes. The justification for these points lies in the following truths:
 

	* ℕ is defined recursively;

	* Each of ℚ and ℤ is defined recursively; and (iii) ℝ is not defined recursively.
 
A class K is defined recursively just in case, for some α ∈ K and some ordering relation R, x ∈ K just in case
 

	* x=α or

	* β bears R to α,
 where β ∈ K.
 
4.2 Recursivity
 
The membership of ℕ is given by the following recursion:
 
x ∈ℕ just in case either
 

	* x=0 or

	* x=y+1,
 
where y ∈ℕ .
 Stated formally:
 
∀ x(x ∈ℕ ↔(x=0 ⋁∃ y(y ∈ℕ⋀ x=y+1))
 
In general, a recursive definition of a class κ is a true proposition of the form:
 
∀ x(x ∈ κ↔(x=α ⋁∃ β(β ∈ κ ⋀ β ℛ x)),
 
where
 

	* ℛ is a relation that strictly orders κ and

	* α is the ℛ -smallest element of κ, meaning that there is something to which α bears ℛ but nothing that bears ℛ to α.
 
 
 
4.3 Sequences as discrete series
 
A sequence is a discrete series. A discrete series is one whose every non-terminal member has an immediate successor. ( ℕ ,<) is a discrete series.
A discrete series is a recursively defined class of pairs (x, x*), where x is a cardinal number and x* is a member K, for some class K. For example, Let S0 be the series:
 
0, 1, 2, 3,…
 
In S0, 0 has the first position; 1, the second; 2 the third; and so on. Therefore, S0 is identical with the class of pairs S0 is identical with the class of pairs
 
(0,1), (1,2), (2,3), (3,4),….
 
For analogous reasons, if S# is the series:
 
1, 4, 9, 16,…
 
S# is identical with the class of pairs:
 
(1,1), (2,4), (3,9), (4,16),….
 
S0 and S# may be identified with, respectively, K0 and K#, where
 
K0={(x,y): ∀ x(x ∈ℕ⋀ (x=0→y=1) ⋀ (x>0→y=(x+1)}, and K#={(x,y): ∀ x(x ∈ℕ⋀ (x=0→y=1) ⋀ (x>0→y=(x+1)2}.
 
 
K0 and K# are unordered classes. Any given series σ may be identified with an unordered class κ of pairs (x,y), where x ∈ℕ and y ∈ κ, provided that, if z ∈ κ and (n+1, z) ∈ Σ, then (n+1, w) ∈ Σ, where w ∈ κ. S0 and S# are generated by, respectively, ϕ0 and ϕ#, where
 
ϕ0(0)=1; ϕ0(n+1)=1+ϕ0(n)
 
and
 
ϕ#(0)=1; ϕ#(n+1)=(n+2)2.
 
 Each of these functions is a recursive function.
All sequences are generated by recursive functions, and all recursive functions generate sequences.
 
4.4 Recursivity and Computability
 
According to the conventional wisdom, the solution to a problem is computable exactly if the solution is the output to a recursive function.
Though the essence of the matter, this statement needs to be qualified. Technically, the solution to any given problem is the solution to some recursive function. If A is the answer to any question Q, it is always possible to define some recursively defined class K to which A belongs.
So when it is said that the answer to A can be computed, what is
meant is that, for some class K*,
 

	* K* is recursively defined,

	* A belongs to K*

	* K* is of independent interest, meaning that some comprehensivesector of reality is incapable of being understood except in terms of K*.
 
An algorithm is simply a useful recursion. The recursions that define +, ×, and ζ are the best known algorithms. But whenever somebody articulates a thought, he does by computing the identity of the appropriate expression; and whenever somebody understands the words of another, he does so by computing its meaning.
 
4.5 Recursive definition of ℚ
 
The membership of ℚ is given by the following recursive definition (henceforth “RD”, for “rationals defined”):
 
x ∈ℚ just in case either
 

	* x ∈ Q2 or

	* x ∈ Qn+1, provided that Qn ∈ℚ ,
 
where, for any cardinal n, Qn is the class of rationals (p/q) such that p+q=n.
 
Thus, Q2=(1/1); Q3={1/2, 2/1}; Q4={1/3, 3/1, 2/2}; and so on.
RD generates the following series (henceforth “SR”, for “series of rationals”):
 
1/1, ½, 2/1, 1/3, 3/1, 2/2, ¼, 4/1, 2/3, 3/2,….
 
There is no rational that does not occur on SR.
 
 
 
 
5.0 Relevant principles of set theory and logic
 
5.1 [ℚ ]=[ ℕ ]
 
Any two classes that can be recursively defined have the same cardinality. A recursive definition of a class K is one that bijects K and ℕ . (A bijection is a one-one function.) Therefore, any recursively definable class has the same cardinality as ℕ . Therefore, [ ℕ ]=[ ℚ ], i.e. there are exactly as many naturals as there are rationals.
 
5.2 [ℚ ]<[ ℝ ]
 
A list, as we will be using this word, is simply a graphic representation of the elements of a class.
If k is infinite, the elements of a class k can be listed just in case k is recursively definable.
The elements of ℕ can be listed, as can the elements of ℚ .
Proposition: The elements of ℝ cannot be listed.
Proof: Given any top-down list of elements of ℝ , expressed as nonterminating decimals, there is a number, namely D(L) (read: the diagonal of L), that is not in L, where D(L) is generated by a function ϕ that associates m with m+1 when m<9 and otherwise associates m with 0, where m is the figure in the nth decimal place in the nth member L.
Since, for any sequence L, D(L) is a real number, there is no sequence containing every member of ℝ . Therefore, there is no enumerative definition of ℝ . Therefore, there is no recursive definition of ℝ .
Since D(S) ∉ S, where S is any sequence of real numbers, it follows that [ ℝ ] is larger than [K], where K is any class, such as ℕ or ℚ , that can be recursively defined. Therefore, [ ℝ ]>[ ℕ ] and [ ℝ ]>[ ℚ ].
The technique just used is known as diagonalization, the reason being that D(L) starts at the top left of L and moves in a straight line towards the bottom right.
 It follows that, D(S) does not occur on L. It also follows that D(S)is given by a decimal starts at the top left corner of L and moves in a perfectly straight, southeasterly direction. It therefore follows that D(S) is given by diagonalizing on S, the just-given proof being an example of a diagonal argument.
Diagonal arguments are always used to prove incompleteness. k is incomplete if s(k) is non-recursive, where s(k) is the corresponding statement-class. If k is itself a statement-class, then k=s(k). If k is not a statement-class, then s(k) is the smallest class of true statements of the form
x ∈ k.
k is non-recursive is obviously equivalent with s(k) is non-recursive. Given that D(S) ∉ℝ , it follows that ℝ is non-recursive and also, equivalently, that s( ℝ ) is non-recursive.
 
5.3 Some anticipatory points about model-theory
 
Even though diagonalization always establishes incompleteness, incompleteness is not always established through diagonalization. This is because there is another way to prove incompleteness, namely, by establishing proving non-monomorphicity. If it can be proved that, for any given model M of a given axiom-set, there is a model M* of that same axiom-set that is non-isomorphic with M*, then that axiom-set is incomplete. On the other hand, if any given model M of a given axiom-set is isomorphic with any other model M* of that same axiom-set, then that axiom-set is complete. Let us take a moment to explain the meaning of these words.
Let k be a class of open-sentences. An open-sentence is an expression that contains a free variable, and is therefore neither true nor false, but is otherwise sentence-like. “x is even” is an open-sentence. “2 is even” is a closed sentence. A mathematical model M is simply a truth-conducive assignment of constants to variables. Thus, if k is the class of open-sentences of the form “x is even and x is divisible y”, then M=(4,2) is a model of k, whereas M*=(4,3) is not such a model.
If an open-sentence S consists primarily or exclusively of variables, then then S is a sentence-schema (plural: sentence-schemata). An example of a sentence-schema is ϕ1(α)=β.
Model-theory is the branch of mathematics that studies classes of sentence-schemata. Its job is to say, when given a class k of sentenceschemata,
 
*Whether or not k can be modelled;
*If not, why not;
*If so, to identify the most significant models and, in addition, to
identify structural similarities among those models.
 
For example, let K be the smallest class containing the following sentence-schemata:
 
S1: ϕ1(α)=β
S2: ϕn(x,y) ∧ ϕn(y,z) → ϕn+1(x)=y
S3: φα
S4: ¬φγ
S5: (x ∈ k ∧ φx ∧ ϕn(x)=y ∧ ϕn(y)=z) →φz.
S6: α ∈ k
S7: ∀ x(x ∈ k)→(x=α ∨∃ m(ϕm(α)=x)).
 
 (7) is the closure-clause, its meaning being that nothing belongs to k that isn’t either identical with α or capable of being reached through a finite number of applications of ϕ1, starting with ϕ1(α).
M models K, where M is the following class of meaningassignments:
 
ϕ1(x)=y: y=x+2
α: 2 β: 4 γ: 5 φx: x is even.
∧ : and
∨ : or
→: if...then...
=: equals
 
But k may be also be taken to be the class of odd numbers (set α=1 and redefine the other expressions correspondingly). Quite obviously, there are infinitely many viable models of (1)-(7).
More importantly, taking M to be any one of the just-proposed models of K, there are models M* of K that are non-isomorphic with M. To wit, let K* be the following sentence-schemata-class:
 
S1: ϕ1(α)=β
S2: ϕn(x,y) ∧ ϕn(y,z) → ϕn+1(x)=y
S3: φα
S4: ¬φγ
S5: (x ∈ k ∧ φx ∧ ϕn(x)=y ∧ ϕn(y)=z) →φz.
S6: α ∈ k
S7: ∀ x(x ∈ k)→(x=α ∨∃ m(ϕm(α)=x)).
S8: ∃ m ∃ ε(φε ∧ ϕm(ε)=α)
 
M* models K*, where M* is just like M, except that, in M*, ϕ1(x)=y means y=x+2 if x<10; and if x=10, then ϕ1(x)=x−8.
M is infinitely large, since, for infinitely many n, M contains the statement n is even. M* contains only finitely many statements. Therefore, if Δ is the class of functions ψ mapping elements of K into other such elements and Δ* is the class of functions ψ* mapping elements of K* into other such elements, there does not exist a one-one function from Δ to Δ*. In other words, M and M* are non-isomorphic and K is therefore non-monomorphic.
Let Σ be a class of bona fide statements, as opposed to statementschemata. Further, suppose that the elements of Σ are truths of logic or mathematics. The question inevitably arises whether Σ can be formalized.
If Σ is finite, the answer is trivially “yes”: to formalize a statementclass is to axiomatize it, and a finite statement-class is axiomatized by stipulating that all of its members are axioms. So we will henceforth take it for granted that Σ is not finite and therefore either recursive or nondenumerable.)
Σ can be formalized exactly if the following three conditions can be satisfied:
 

	* There exists a sentence-schemata-class Γ such that Σ is a modelof Γ,

	* Γ is recursive, and(3) Γ is monomorphic.
 
Contrariwise, let us suppose, for some statement-schemata-class Γ, that:
 

	* Σ is a model of Γ, and

	* Given any model M of Γ, there is some model N of Γ such that Nis non-isomorphic with M.
 
In that case,
 
(i) Σ cannot formalized, and (ii) Σ is non-denumerable.
 
(i) and (ii) are tautologically equivalent. This is because:
 
(α) To formalize a statement-class is to identify a recursion that generates it, and
(β) For a class to be non-denumerable is, by definition, for there to be no recursion that generates it.
 
Later we will prove the incompleteness of several scientifically important statement-classes.
 Attempts have been to formalize empirical statement-classes---to show, more specifically, that physics and other empirical disciplines can be formalized.
There are many reasons why no scientific discipline can be formalized. Some of these reasons will be identified below. But right now, let us resume our discussion of the rudiments of set-theory and formal logic.
 
 
5.4 PK=2[K]
 
Proposition: Given any class K, [Pk]=2[K]. In other words, if n is the number of members of K, the number of subsets of a class K is 2n.
Proof by induction: If K is empty, i.e. if [K]=0=n, 2n=1, given that the empty set, being a subset of any given set, is a subset of itself. As for cases where [K]=n and n>0, suppose that for some n, [PK]=2n, where [K]=n.
If α ∉ K, for arbitrary α, then α ∉ k, where k is an arbitrary subset of K. Therefore, for each subset k of K, k ∪ α ∉ K. This means that, if K*=K ∪ α, then, for any subset of k of K, k is also a subset of K* and, moreover, k ∪ α, is also a subset of K*. Thus, K* has two subsets for every one subset of K.
Consequently, [PK*]=2n×2=2n+1. Since, by hypothesis, [PK]=2n, it follows that [PK*]=2n+1. Q.E.D.
 
5.5 Infinite classes as reflexive classes
 
A finite class is one that has a finite number of members. An infinite class is one that is not finite.
If k and k* are finite classes, then [k]=[k*] exactly if k≈k*. k≈k* exactly if there is a one-one function from k to k*.
A class k is finite if, for any proper subset k* of k, k ≉ k*.
A class k is infinite, if, for some proper subset k* of k, k≈k*.
If a class k has at least one proper subset k* such that k≈k*, then k is reflexive. Otherwise, k is non-reflexive.
ℕ is reflexive, and therefore infinite, since, for any n, ℕ ≈ ℕ n, where ℕ n contains only multiples of n.
Thus, ℕ 2≈ ℕ , given that ϕ(x)=2x bijects ℕ 2≈ ℕ and ℕ 2.
ℕ ≈ ℚ , given that ϕ(x)=xSR, where xSR is x’s position in the series
(henceforth “SR”):
 
 1/1, ½, 2/1, 1/3, 3/1, 2/2, ¼, 4/1, 2/3, 3/2,….
 
 
5.6 Infinite classes as classes with non-inductive cardinalities
 
k is a finite class exactly if [k]=n, where n is an inductive cardinal,
meaning that either
 

	* n=0 or

	* For some inductive cardinal m, n=m+1.
 
k is infinite if [k] is non-inductive.
 
5.6.1 The Axiom of Choice in relation to these two conceptions of the infinite
 
 
According to many mathematicians, including G. Cantor, the
inventor of set-theory,
 

	* k is reflexive
 
is equivalent with
 

	* k’s cardinality is non-inductive.
 
 The present author happens to believe that (1) and (2) are in fact equivalent.
But (1) and (2) are not indisputably equivalent. They are equivalent only if the Axiom of Choice is true.
The Axiom of Choice is the proposition that:
 
(AC) Given any class K whose members are themselves classes, there exists a class K* such that, for each element k of K, there is exactly one element x of k such that x is an element of K*.
 
Stated formally:
 
(ACF)
∀ K ∃ K* ∀ k ∃ x ∀ y((k ∈ K ∧ x ∈ k)→((y ∈ k ∧ y ∈ K*)↔x=y))
 
Thus, far AC has not been proved and it has not been disproved. In any case, it would be convenient if AC were true, since a number of important mathematical principles are impossible to prove unless AC is true.
xxx
 
 
5.7 n<2n
 
We have already established that [PK]=2[K]. This means that if K is finite, [K]<[PK]. We will now show that [K]<[PK] even when K is infinite.
Assume arguendo that K≈PK.
That means that there is a function ϕ that bijects K and PK.
Define a subset k of PK such that, whenever x ∈ K, x ∈ k just in case x ∉ ϕ(x).
Suppose that ϕ(α)=k, where α ∈ K. If α ∈ k, then α ∉ ϕ(α); and if α ∉ k, then α ∈ ϕ(α), then α ∈ k.
Thus, if ϕ(α)=k, then α ∈ k↔α ∉ k.
Therefore, ϕ(α)≠k, for all α.
Therefore, K ≉ PK.
Given that {y} ∈ PK whenever y ∈ K, it follows that PK≥K.
Given that K ≉ PK, it follows that [K]<[PK]. Q.E.D.
Hence, the Power Set Theorem (PST): n<2n, for all n.
 
 
 5.8 Cardinality vs. cardinality-type There are three orders of magnitude:
 

	1. Finite

	2. Denumerably infinite

	3. Non-denumerably infinite
 
A class k is finite if, for any x such that x ∉ k, [k ∪ x]>k, in the sense that k can be bijected with a proper subset of k ∪ x but not vice versa.
 If k is finite, it is not generated by a recursion. This is because a recursion R is a one-one function such that:
 
(a) R is defined for each of its own outputs, and (b) R never outputs one of its inputs.
 
 (a) does not rule the possibility that R loops and therefore has a finite-output; but (b) prevents R from looping and therefore ensures that its output is never-ending.
A class k is denumerably infinite if there is a recursive definition of k. k is non-denumerably infinite if it is infinite and there is no recursive definition of it.
Non-denumerably infinite classes are formed by identifying counterrecursions. k is denumerably infinite iff it is infinite and its members can be
enumerated.
To enumerate the members of a class k is to assign a cardinal number
to each one, on the condition that no two members are assigned the same cardinal number and on the further condition that a given member x is assigned n+1 only if some other member y is assigned n.
An enumeration of a class k is a function ϕ such that:
 

	* ϕ assigns each member of k to a cardinal number,

	* ϕ never assigns the same cardinal twice, and

	* When n>1, ϕ never assigns n unless it also assigns n−1.
 
If k is denumerably infinite, then [k]= ℵ 0.
If k is non-denumerably infinite, then [k]≥ ℵ 1.
It is known that 2 ℵ 0> ℵ 1. It is not known whether 2 ℵ 0= ℵ 1.
The hypothesis that 2 ℵ 0= ℵ 1 is known as the Continuum Hypothesis.
It is known that, for any n, 2 ℵ n> ℵ n. It is not known whether
2 ℵ n= ℵ n+1.
The hypothesis that 2 ℵ n= ℵ n+1 is known as the Generalized Continuum Hypothesis.
 
5.9 Irrational numbers in relation to continuity
 
Given any two rational numbers, there is an irrational number in between them. Since there is a rational between any two rationals, it follows that there are infinitely many irrationals between any two rationals.
Given any two rational lengths (lengths that are given by rational by numbers), it follows that there are infinitely many intermediate irrational lengths.
Therefore, an object’s length cannot increase all without assuming infinitely many irrational values.
Therefore, for any length L, if, for any length L* such that L*≤L, the ratio of L*’s length to L’s is rational, then L is vanishingly short.
Therefore, unless n≥ ℵ 1, any length consisting of n-many points is vanishingly short.
Therefore, unless n≥ ℵ 1, no occupant of a manifold consisting of nmany points can have a positive length. Consequently, no such occupant can to any degree grow or otherwise length-change.
Therefore, no such occupant can change in respect of its area (since area≈length squared), volume (since volume≈length cubed), rate of motion (since rate of motion=displacement/time), mass (since mass≈resistance to displacement), or density (since density=mass/volume).
Therefore, if m is the area, volume, mass, density, or rate of motion of any such occupant, m is at most vanishingly small.
 This means that any manifold that can host change, i.e. any spatiotemporal manifold, consists of non-denumerably many points. This in turn means that a mathematical system is powerless to describe such a manifold unless that system grants the existence of classes whose cardinalities exceed ℵ 0. And this in its turn means that no recursively definable set can describe such a manifold.
 
5.10 Two conceptions of cardinality
 
Given two classes k and k*, the statement
 
(0) [k]=[k*], i.e. k has the same number of members as k*,
 
is ambiguous between
 
(C1) k≈k*, i.e. k and k* can be bijected;
 
and
 
(C2) There is no proper subset k# of k such that k*≈k#; and, finally, there is no proper subset k$ of k* such that k≈k$.
 
By C1, [ ℕ 2] ≈[ ℕ ]. By C2, [ ℕ 2]<[ ℕ ].
By either criterion, [ ℕ ]<[ ℝ ]. This is because, as we have already seen, it is not possible to biject classes whose cardinalities are ℕ and ℝ .
 Unless there is an explicit indication to the contrary, we will henceforth use C1. But, for reasons to be stated in the next section, a case can be made that C2 embodies a more accurate conception of the nature of cardinality than does C1.
 
 
5.11 Cardinality vs. cardinality-type
 
 If k and k* are finite classes, [K]=[K*]. This suggests, though it does not definitively establish, that, for any two cardinalities, C and C*, whether finite or transfinite, C=C* exactly if [kC]=[k*C], where kC and k*C are any two classes having C-many and C*-many members, respectively.
 Relative to this conception of cardinality, we end up with the (arguably) paradoxical result that there are as many multiples of ten as there are multiples of five, even though, from some other viewpoint, a collection of multiples of 5 is ipso facto twice as well populated as an otherwise identical collection of multiples of 10.
 We know with certainty that:
 

	* For any finite classes c and c*, [c]=[c*] if c≈c*.
 
 We also know with certainty that:
 

	* For some infinitely large classes k and k*, k≈k*, even thoughk ⊂ k*,
 
 According to the conventional wisdom, (i) and (ii), taken jointly, entail that, for some values of k and k*:
 

	* k ⊂ k* and [k]=[k*].
 
 But (iii) is not a consequence of (i) and (ii). The reason is that cardinals (so-called) are in fact classes of cardinals. ℵ 0 is not a single cardinal. It is an infinitely large class of cardinals any two of whose elements can be bijected. As for finite cardinals, they too are classes of cardinals, with the qualification that any such class only has one member.
Thus, C1 represents a viable conception of cardinality-type, whereas C2 represents a viable conception of cardinality-proper. Where finite cardinals are concerned, there is only instance of any given cardinality-type, a consequence being that C1 and C2 are output-identical (extensionally equivalent) with respect to finites. But there are multiple instances of any given transfinite cardinality-type, and C1 and C2 are therefore output-distinct with respect to transfinites.
George Cantor (1884) developed an arithmetic of transfinites, described in toto in Section 6.0. According to most authorities, Cantor’s system rests in its entirety on the supposition that C2 is simply erroneous, C1 being the only viable conception of cardinality.
We will see in Section 7.0 that, give or take a phraseological details, C2 is compatible with Cantor’s system.
In any case, if C2 is simply wrong, then there is nothing paradoxical about the fact that, if ℕ 2 is the class of even numbers,
 
(A) ℕ ≈ ℕ 2 even though ℕ 2 ⊂ ℕ .
 
Galileo (1638) was the first to note of (A). According to Galileo, (A) is a paradox, i.e. (A) is not an exotic but otherwise innocuous fact but is positively inconsistent with our beliefs.
Bertrand Russell took the position that (A) is not a paradox, his reasoning (in italics) being as follows:
 

	* Cantor’s system of arithmetic assumes that C2 is false. Therefore,

	* C2 is false. Therefore,

	* (A) is “merely an oddity” (Russell’s own words), and not a genuine paradox.
 
Right now, we will state the basic principles of Cantor’s transfinite arithmetic. It will then be shown that Cantor’s arithmetic can be interpreted as describing among classes of cardinals, as opposed to cardinals per se.
Galileo was right. (A) is a paradox. We believe each of the following:
 

	* C1 represents a viable conception of cardinality.

	* C2 represents a viable conception of cardinality.

	* Given C1, ℕ ≈ ℕ 2, entails that [ ℕ ]=[ ℕ 2].

	* Given C2, ℕ 2 ⊂ ℕ entails that [ ℕ ]>[ ℕ 2].
 
(1)-(4) is not a consistent set of propositions. At least one of them is false. The false one is (3). And the flaw in Russell’s is (i), since (for reasons that will be left implicit) Cantor’s system not only can but must be taken to concern transfinite cardinality-types. In fact, Cantor’s system is not really about number at all. It is an analysis of recursivity and its limits---that is to say, of completeness and incompleteness. This will become clear in Section 6.0.
 
 
5.12 Number-classes as classes of isomorphic model-spaces
 
ℕ is the most basic number-class. The elements of any other given number-class are constructed out of the elements of ℕ .
 Let us say that (Κ, Φ) is a quasi-m-space exactly if K is a non-empty class and F is a class of functions ϕ1, ϕ2,…from n-tuples of K-members to other such n-tuples.
 (Κ, Φ) and (Κ *, Φ*) correspond to the same number-kind whenever they are isomorphic. They are isomorphic exactly there is a one-one function Φ that maps true statements about (Κ, Φ) onto true statements about (K*, Φ*).
 A number-kind is the class of all quasi-m-model-spaces that are isomorphic with a given quasi-m-space.
 An m-space S is a continuous quasi-space.
 A hyper-m-space S is a self-contained space, meaning that if (Κ#, Φ#) belongs to S and φ belongs to Κ #, then
 

	* If x1…xn ∈ Κ# and φ(x1…xn)=(y1…ym), then y1…ym ∈ Κ#, and

	* If x1…xn ∈ Κ# and φ(x1…xn)=(y1…ym), there exists an operation ψ such that ψ(y1…ym)=(x1…xn).
 
 
6.0 Recursivity and Incompleteness
 
 This last theorem is extremely important; for in it lies the raison d’être for every single incompleteness proof. An incompleteness proof is simply a proof that, for some class C, there is no recursive definition of C.
For example, the non-recursivity of ℝ is really a consequence of the fact that [PK]>[K]. To say that [PK]>[K] is to say that, if R is the recursion that generates K, then R does not generate PK. Let R* be the recursion that generates an arbitrary list (or class) L of real numbers. In that case, R* does not generate PL (the power-set of L), even though, given that L is recursive, so is PL. That said, the union of the elements of PL itself defines a real number. Hence, the non-recursivity of ℝ .
The non-recursivity of ℝ is a consequence of the fact that there is no recursive definition of the class of all logically true statements.
 Explanation/proof: A statement-class is a class of true statements. A logic is a recursively defined class of true statements. I.e. a logic is the posterity of S with respect to Φ, where S is a true statement and Φ is a truthtransmissive operation, meaning that Φ(σ) is true, for any true statement σ.
Kurt Gödel’s celebrated (1931) incompleteness proof is to the effect that the class of all arithmetical truths is incomplete. A truth of arithmetic is one concerning such interrelations between integers as can be expressed in terms of the following concepts: 0, +, ×, some, all, negation, set-membership, and property.
Gödel’s theorem is really a special case of a more comprehensive principle, namely, that the class of recursive definitions is not itself recursively defined. Given any class k, there is an associated statement-class s(k). If k is itself a statement-class, then k=s(k). If k is not a statement-class, then s(k) is the smallest class of truths of the form x ∈ k. k is recursive just in case s(k) is recursive, and there is a one-one correspondence between K and S(K), where K is the class of recursive definitions and S(K) is the class of recursively There is a one-one correspondence between the class of recursively defined classes and the class of recursively defined statementclasses. Therefore, supposing that K is not recursively definable, it follows that S(K) is not recursively definable, i.e. it follows that the class of logics is not recursively definable, i.e. it follows that logic is incomplete.
 And given that [PK]>[K], it follows that, indeed, K is not recursively definable. For if k is a recursively defined class, Pk (the class of all subsets of k) is also a recursively defined class, but the recursion that generates k fails to generate Pk. Therefore, if k is a statement-class—if k is a logic, in other words—then Pk is also a logic, since Pk is a recursively generated statement-class and is ipso facto a logic, but the recursion that generates k fails to generate Pk. Thus, the class of logics is incomplete. In other words, there is no formal procedure by which, when given an arbitrary statement S, to determine whether or not S is a truth of logic. More plainly, the class of logical truths is non-recursive. Gödel’s theorem is to the effect that the class of arithmetical truths is non-recursive.
 
7.0 Formal languages: introductory points
 
For now, let us regard a language as a class of sentences, a sentence being an expression that expresses a proposition. Languages obviously contain subsentential expressions, but subsentential expressions are of interest only to the extent that they can be absorbed into sentences.
Also, in this context, we will set aside the fact that, in English and other natural languages, sentences tend to contain context-sensitive expressions, such as demonstratives (e.g. “that fellow”, “this cow”) and tense-markers (e.g. the “s” in “John plays rugby”), in virtue of which it is sentence-tokens, not sentences per se, that are true or false. (“It is raining” per se is neither true nor false, it being tokens (specific utterances or inscriptions) of that sentence that are true or false.)
In order to understand the concept of a formal language, we must introduce two new concepts: the concept of strict or actual entailment and the concept of syntactic entailment.
P strictly entails Q if Q is a logical consequence of P. Q is a logical consequence of P if there is no possible world where P is true and Q is false. P ⟹ Q≡DF Q is a logical consequence of P.
S1 ↦ S2≡DF S2 is a syntactic consequence of S1.
Strict entailment is a relation between propositions (a proposition being a truth or a falsehood).
Propositions are not symbols. The proposition that snow is white can be expressed by symbols of different languages; it is not itself a symbol.
Syntactic entailment is a relation between symbols.
Sm syntactically entails Sn (i.e. Sm ↦ Sn) if the following four conditions are satisfied:
 

	* Sm and Sn both belong to some language L,

	* L the posterity with respect to S1 (this being a sentence or class of sentences) of some recursion Φ,

	* Sn is in the Φ-posterity of Sm, and

	* Sm is not in the Φ-posterity of Sn, except in the case where
Sn=Sm.
 
7.1 Natural languages as recursive sentence-classes
 
A language is a recursively defined class of sentences.
Explanation: It is a datum that English and Spanish and other socalled natural languages are, indeed, languages. Any given natural language contains infinitely many sentences.
This is because any given sentence or n-tuple of sentences belonging to a given natural language can be combined into a new sentence, e.g. “snow is not white” can be converted into “John is happy about the fact that snow is which”, which in turn can converted into “John is happy about the fact that John is happy about the fact that snow is white”, and so on.
 Therefore, a ‘language’ that contains only finitely many expressions is but a caricature of a bona fide language.
At the same time, no natural language, and therefore no language in legitimate sense of the word, contains non-denumerably many expressions. A language is a class of comprehensible expressions. (Indeed,
“incomprehensible expression” is a veritable oxymoron.) If L is an infinitely large expression-class, it is not possible to memorize the meanings of L’s members. Therefore, L-expressions, if understood, are understood on the basis of other L-expressions. To say that one expression S2 is understood on the basis of some other expression S1 is to say that, for some recursion Φ, it is already known that:
 

	* Φ(S1)=S2, and

	* if σα means such and such, then, if Φ(σα)= σβ, then σβ means thus and such.
 
 
7.2 Formal languages as recursive sentence-classes
 
 
In the expression “formal language”, the word “language” has the same meaning that it has in the expression “natural language.”
In fact, there is no intrinsic difference between a formal language and a natural language. The class of natural languages is a proper subset of the class of formal languages.
When a language L is described as “formal”, what is meant is that it can be immediately be said exactly what Φ and Ψ are, where Φ is L’s syntax is and Ψ is L’s semantics. This condition is obviously met where artificial languages are concerned, simply because, given any such language, we stipulate what those values are.
This condition is not met where natural languages are concerned, since we don’t stipulate what those values are and therefore have to figure out what those values are. And given how expressively rich natural languages are, it cannot be readily figured out what Φ and Ψ are. But their approximate values can be determined quickly but non-immediately, and their specific values can be determined non-immediately and non-quickly.
That said, there is one intrinsic difference between formal (artificial) and natural languages, namely, that any given natural language is really hierarchy of languages. What this means, and why it is true, will presently be made clear.
 
8.0 Definition of “formal truth”
 
Logic is often described as the study of “formal truth.”
Depending on how it is taken, this characterization is either meaningless or false.
An individual logic L is a recursively defined class of true sentences.
To say that a given a sentence Sn is formally true is to say that that Sn belongs to the posterity of S1 with respect to ϕ, where S1 is a true statement
(or class of true statements) and ϕ is a truth-transmissive function. If that condition is met, then Sn is formally true with respect to (S1, ϕ). But given any true statement σn, there are infinitely many pairs (σ1, Φ), where σ1 is a true sentence and Φ is a truth-transmissive function, such that σn is not formally true with respect to (σ1, Φ).
Thus, the concept of formal truth is a relative notion.
The class of recursive statement-classes is non-recursive. We proved this earlier.
It follows that the class of logics is non-recursive. We also proved this earlier, but here is another proof.
 
8.1 No formal characterization of the property of formal truth
 
Proposition: The class of logics is non-recursive.
Proof: If an expression-class L is expressively rich enough to be described as a language, then L is negation-complete, meaning that whenever SL belongs to L, so does not-SL.
A logic is simply a language---that is, a recursively defined sentenceclass---that has been purged of its false members.
Given any sentence-pair (SL, not-SL), each of whose members belongs to L, exactly one member of that pair is true.
Let L* be the class of true members of L.
There obviously exists a one-one function that assigns each member SL* of L* to (SL, not-SL). Therefore, there is a one-one correspondence between the class of negation-complete languages and the class of logics.
Therefore, the class of logics is recursive exactly if the class of languages is recursive, and the class of logics is recursive exactly if the class of languages is non-recursive.
The class of languages is non-recursive. A language is simply a recursively defined statement-class, and it has already been proved that the class of recursively defined statement-classes is non-recursive.
Therefore, the class of logics is non-recursive.
Therefore, there is no recursive definition of the class of logical truths.
Therefore, if S is formally true with respect to (σ1, Φ1), there is some other pair (σ2, Φ2) with respect to which S is not formally true. In other words, there is no formal characterization (no recursive definition) of the class formal truths (the class of logics, i.e. of recursively defined classes of true sentences).
 
9.0 Function-theoretic Characterizations of Logical Operations
 
 ¬ (negation) is a function that assigns truth to P when P is false; otherwise, falsity.
 
 ∧ (conjunction) is a function that assigns truth to (P,Q) when P is true and Q is true; otherwise, falsity.
 
∨ (disjunction) is a function that assigns truth to (P,Q) when (¬P ∧ ¬Q) is false; otherwise, falsity.
 
A given property φ is a function that assigns truth to each of its instances and falsity to everything else.
 
∃ x (there exists and an x such that...) is a function that assigns truth to φ when φ is instantiated; otherwise, falsity.
 
(x) (for all x…) is a function that assigns truth to φ when ¬ φ is uninstantiated; otherwise, falsity.
 
/ (the Sheffer Stroke) is a function that assigns truth to P/Q exactly if P is false and Q is false.
 
⟹ (sign of the consequence-relation) is a function that assigns truth to (P,Q) whenever it is impossible that Q should be false if P is true.
 
A truth is a class of a properties p1…pn such that, for all i (1≤i≤n), pi is instantiated.
 
A falsehood is class of a properties p1…pn such that, for some i (1≤i≤n), pi is not instantiated.
 
0 is a function ϕ that assigns T to ∅ .
 
n+1 is a function ϕ that assigns T to k ∪ {x}, where x ∉ k, when ϕ assigns T to k.
 
 
Chapter 3 Mathematics as the study of ordinal relations (2014)
 
 Mathematics is the study of structure. Statements about order can always be expressed as statements about relations holding among numbers or sets thereof. (This is a tautology, since we can always invent a new kind of number to describe some structure that cannot be described in terms of numbers already known to us.) That is why most branches of mathematics are concerned with number. But mathematics is interested in number only because truths about number are encrypted truths about structure. That is why there are branches of mathematics, e.g. topology, that don't concern number.
 And it is also why mathematicians, like all intelligent people, are more interested in relative quantities than they are in absolute quantities; and, more generally, why they are more interested in relations than they are in properties; and, still more generally, why they are more interested in what is invariant than in what is variable.
Ordinal relations survive changes in absolute quantities. Indeed, the preservation of ordinal relations is often a consequence of changes in absolute quantities, and changes in absolute quantities are often a consequence of preservation of relative quantities.
 First example (due to David Hume): Suppose that on Monday everyone in the world woke up having twice as much paper currency as he had on Sunday. Would anyone be the wealthier for it? No. If a candy bar cost $1 on Sunday, it would cost $2 on Monday, since, owing to the uniform increase in paper-wealth, the ratio of paper-money-demand to paper-moneysupply would not have changed.
 Second example (due to Poincaré): Suppose that one night, while everybody was sleeping, everything in the universe doubled in size. Such a change would have no consequences. You'd be twice as tall, but your ceilings would be twice as high and your clothes would be twice as big. Your place of work would be twice as far away, but it would be twice as easy for you to get there, since the relevant ratios (e.g. car-size: distance between home and office) would have been preserved.
Third example (due to Einstein): The laws of optics are frameworkinvariant.
Fourth example (due to Einstein): The laws of mechanics are framework-invariant.
Laws of nature are invariances. Laws of nature are frameworkinvariant relations between objects, and such laws are given, not by statements that assign (context-dependent) properties to objects, but by statements that assign (context-independent) relations to multiplicities of objects.
Thanks to the differential calculus, such invariances can be stated precisely, this being why that discipline was invented. Advances in mathematics often involve the discovery of ways of describing precisely what could previously only be described imprecisely.
 
Invariance
 
Geometry is not interested in this or that circle or square. Given some particular instance x of some particular kind of shape s (i.e. given some particular circle or square or triangle), geometry is interested in the class of all shape-instances y such that, relative to some mapping-relation (some transformation), x is isomorphic (structure-identical) with y. So geometry isn't interested in shapes, but in properties of shapes that are transformationinvariant, i.e. geometry is interested in properties of shapes such that, given some transformation T, if T maps one shape onto some other shape, the second shape inherits the structural properties of the first.
 And given some particular rectangle x, analytic geometry (the branch of geometry that studies shapes by mapping spatial relations onto numerical relations) isn't interested in the dimensions of x in particular. It is interested in the class of all rectangles and, indeed, of all shapes that are isomorphic with x with respect to some transformation.
 So geometry, even analytic geometry, isn't interested in quantity; it is interested in context-invariant structural interrelations.
 Terms like "5" and "6" are scarcely ever mentioned in the discipline of mathematical logic. And when they do occur, it is almost always as expository aids of some kind (as e.g. superscripts, subscripts). Logic studies invariances among strings of symbols.
Formal logic is really the geometry of strings of symbols. It has nothing to do with rules of inference. When the term "rule of inference" occurs in a treatise on formal logic, it refers to a function that assigns meaningless expression-strings to other such strings. Formal logic is indeed less concerned with rules of inference than any other branch of mathematics or indeed any other discipline, since, unlike all other disciplines, it does nothing but manipulate meaningless strings in accordance with arbitrary rules.
Syntax is symbol-geometry. Semantics is symbol-meaning. Formal logic is syntax, not semantics.
Informal logic is semantics, not syntax. The purpose of informal logic is to identify structures that validate the meaningless strings studied by formal logic. Such a structure is a class of models that validates a class of such strings.
A model (or valuation) is an assignment of constants to variables.
A string consists of variables, since anything without a fixed meaning---and that means anything that is functioning merely as a shape, as opposed to a shape-meaning pair---is ipso facto a variable. A class of models is a class of such assignments.
In identifying classes of meaning-assignments, the discipline of informal logic is identifying classes of inter-translatable languages, i.e. languages that can be mapped onto one another, with the qualification that those mapping relations are coded into the purely structural properties of the expressions in question, so that the decrypting of an expression-string belonging to such a language doesn't require ad hoc, context-specific knowledge.
 There is no way to formalize the identification of structures that validate expression-strings. This is not an exotic mathematical theorem, but a mere tautology. Given some statement-class S, S’s syntactic or formal properties are precisely those that concern such relations of S-members to Smembers as can be understood independently of anything having to do with the relations of S-members to anything outside of S. Thus, two statementclasses S and S* coincide in their formal properties exactly if, setting aside anything having to do with the semantics of either statement-class, the interrelations of the members of the one statement-class coincide with the interrelations of the members of the other.
Meaning is a relation between statement and non-statement; truth is a property of meaning. Therefore, the concepts of meaning and truth have no place in the discipline of formal logic. Nor therefore does the concept of entailment, since p entails q exactly if q cannot be false if p is true.
Thus, to the extent that logic is concerned with meaning and truth, it is incapable of formalized; and to the extent that logic is capable of being formalized, it doesn’t concern meaning or truth. Since logic falls within the scope of distinctively mathematical methods of reasoning only to the extent that it can be formalized, it is but an innocuous platitude, and therefore no exaggeration, to say that formal logic is to no degree concerned with either meaning or truth, or with derivative notions such as entailment, and, since no other discipline is equally indifferent to meaning and truth, is of all the sciences the one that is the least concerned with them.
 
 
To sum up:
 
*Mathematics is the study of structure. Equivalently, it is the study of ordinal relations (relations of order). *Many branches of mathematics study numbers. But they do so only because statements about structure can be coded into statements about number.
 
*Geometrical truths can be represented as statements about classes of ordered-pairs (of, where n-dimensional shapes are concerned, for n>2, as ordered n-tuples).
 
*Truths of formal logic can be represented as statements about classes of numbers.
 
*A statement is formally true exactly if it holds entirely in virtue of geometrical interrelations of its constituent-expressions.
 
*Mathematics is the discipline that identifies structural invariants; that is, it identifies ordered pairs <C,T> such that C is a class whose members are pluralities of some kind and such that any two such pluralities are isomorphic with each other with respect to T or, equivalently, are such that any one such plurality is a T-transformation of any other such plurality.
 
Chapter 4 Five philosophies of mathematics (2014)
 
 There are five schools of thought concerning the nature of mathematical knowledge: conventionalism, formalism, conceptualism, empiricism, and Platonism (identical with mathematical realism).
 According to the Platonist view, numbers and other mathematical entities are non-spatiotemporal; their existence is no more mind-dependent than that of a rock or a tree, but, unlike rocks and trees, those entities are not in space or time. Statements like "2+3=5" represent facts, and statements like "2+3=6" are false because they do not represent facts.
 According to the conventionalist view, mathematical truths are tautologies (definitional truths). "2" is defined as "1+1"; "3" is defined as "2+1"; and so on. Given the most exotic mathematical truth, says the conventionalist, it turns out, when scrutinized, to be a tautology.
 If conventionalism is right, then, if S is a true mathematical statement, S holds in virtue of our linguistic conventions, not in virtue of some objective mathematical realm.
 The formalist holds that
 

	* Mathematics holds among meaningless expressions of arbitrarysymbolic calculi and

	* For that reason mathematical realities have no existence outside
of the calculi that we happen to create.
 
 
 We will find that (i) is defensible but that (ii) doesn’t follow from (i)---that, in fact, the negation of (ii) follows from (i).
 The conceptualist holds that the laws of mathematics are laws of psychology.
 The empiricist holds that the laws of mathematics are physical laws.
 Only one of these views (Platonism/realism) has even a chance of being correct. But given any one of these views other than the correct one--and the correct one is, ultimately, obviously correct---it would be hard to find one person in a 100 who advocated it and who also rejected each of its (obviously false) competitors.
 
Conventionalism evaluated
 
It is a matter of convention "1" refers to 1; that "+" denotes the addition-operation; and so on. But it is not a matter of convention that
"35,247×254=8,952,738" expresses the proposition that
35,247×254=8,952,738. The fact that "35,247×254=8,952,738" means 35,247×254=8,952,738 is a logical consequence of our conventions, and that fact is therefore convention-based, but not convention-determined.  Given that 35,247×254=8,952,738 is true, it follows "35,247×254=8,952,738" is true. Since that expression's having that proposition for its meaning has a basis in convention, and since that expression's being true is a consequence of that proposition's being true, that expression's being true has a basis in convention. But there are two respects in which that expression, though true, is not definitionally so.
 First, "35,247×254=8,952,738" is not defined to me
35,247×254=8,952,738; its having that meaning is a logical consequence of conventions. Second, that meaning's being true is to no degree conventional; so even though that expression's bearing that meaning has a basis in convention, that meaning's being true has none. It is therefore quite as misconceived to say that "35,247×254=8,952,738" is true by convention as it is to say that "snow is white" is true by convention.
 
The laws of logic not conventions
 
Suppose it strictly a matter of convention that each of the following is true:
 

	1. p1→(¬(p1& ¬p2) →p2)

	2. (p1&p2) →p1

	3. p1→(p1 or p2)
4 p1 or ¬p1

	1. ¬(p1 &¬p1)
 
1-5 jointly entail each of the following:
 

	1. (p1→p2) →((p2→p3) →(¬p3→¬p1))

	2. (p1→p2) →((¬(p2 & p2) →¬p1)

	3. (p1→p2) →((¬(p2 or p2) →¬p1)

	4. (p1→p2) →((¬(p2 & p2) → (¬p1 or p2))

	5. (p1→p2) →(¬(p2 & p2) → (¬p1 or p1) or ¬p1))
 
But there is no convention that directly concerns any one of 6-10. Each of 6-10 is a logical consequence of conventions, and the relation between 1-5 and 6-10, whereby the latter follow from the former, is entirely non-conventional. That relation is a non-conventional relation of logical dependence holding between statement-sets.
Nothing that follows from anything is a convention. Logical consequences of conventions are non-conventions that have a conventional basis.
No member of an axiom-set AS can meaningfully be described as
"true" or "false." Consequently, no consequence of that axiom set can be described as "true" or "false." What is unqualifiedly true or false is the assertion, for some statement Q, that if AS is supposed true, then Q must be supposed true.
 
Formalism
 
A position similar to conventionalism is known as formalism. According to this doctrine, mathematical symbols, e.g. "2", "+", and the sentences they compose, e.g. "2+3=5", are meaningless. When a mathematical statement is described as "true," what is meant is that string of expressions is in compliance with some set of rules that have been adopted. Those rules are a grammar, and mathematical truth is nothing but grammaticality. Given that, by hypothesis, mathematical symbols are meaningless and, consequently, that mathematical sentences are neither true nor false, it follows that those rules are arbitrarily adopted. Thus, "2+3=5" is grammatical, relative to some arbitrarily chosen grammar, and "2+3=7" is ungrammatical, relative to that same grammar; and that is why the first statement is true and the second is false.
 If formalism is correct, then mathematics is the study of uninterpreted formal calculi. A formal calculus L is given by an ordered triple <V1, V2, G>, where V1 is the class of L's primitive symbols (symbols that don't consist of other symbols); G is L's grammar, i.e. a set of rules identifying the L-permissible ways of combining expressions into larger strings of expressions; and V2 is the class of grammatical strings of Lexpressions.
 
Formalism evaluated
 
Mathematics is the study of uninterpreted formal calculi. And given any one such calculus, the rules assigning meaning to its primitive expressions (the axioms of that calculus, in other words) are indeed conventions and, therefore, tautologously true.
 But there is nothing conventional about the relationship between the axioms of a formal calculus and the consequences of those axioms: those relations are of a non-conventional, strictly logical nature.
 And given such a calculus, it is not a matter of convention whether
or not a given set of meaning-postulates adequately models that calculus. A meaning-postulate is simply a function that assigns a meaning---an object, a number, a property, a function, a proposition, a truth-value---to an otherwise meaningless expression.
A set of meaning-postulates models a given uninterpreted calculus just in case, if it is supposed that the expressions of that calculus have the meanings in question, the resulting interpreted calculus is consistent, i.e. it doesn't entail p and not-p, for any proposition p.
 A set of meaning-postulates with respect to a given calculus is an interpretation of that calculus.
 In many cases, the interpretation of a calculus assigns spatiotemporal entities---objects, physical forces, patterns of buying and spending---to the expressions and transformation-rules of a formal calculus.
When an interpretation adequately models a formal calculus, the result is a scientific discipline that describes the universe (or some sector thereof).
 Some philosophers—most notably Carnap---have gone so far as to say that a scientific discipline is the attempt to identify viable empirical interpretations of formal calculi.
 Carnap's position is not correct. Scientific disciplines first identify laws and then (sometimes) organize those laws in such a way that the discipline in question can be (partially) represented as a formal calculus coupled with a set of meaning-postulates.
 But Carnap's incorrect claim can be seen as a distortion of a profound truth about mathematics, namely, that when a mathematician chooses to study this as opposed to some other formal calculus, he does so because he has in mind some empirical interpretation of that calculus, which in most cases is strongly suggested by the empirical data.
 
Conceptualism
 
According to the conceptualist, categories, e.g. the category apple or number, are 'mental constructs,' meaning, presumably, that
 
(i) They have no mind-independent (or mind-external) existence and (ii) They are data-management-related cognitive protocols.
 
 Conceptualism fails for much the same reason as formalism and conventionalism. Let's suppose that numbers are cognitive protocols. Relations among those bits of software (or wetware or hardware, or whatever they are supposed to be) are not themselves mental constructs. It is up to the engineer what a machine consists of; it is not up to him whether it works. Supposing arguendo that "1" and “+” refer to bits of cognitive machinery, it doesn't follow that those various bits of cognitive machinery are compatible with one another; it doesn't follow that, taken jointly, they work. Given only that they are bits of machinery, it no more follows that they jointly constitute a viable information-processing system than it follows that a heap of auto parts amounts to a working car.
 By the same token, if those various bits of cognitive machinery do work—if, in other words, they facilitate/make-possible the organization of data—it is because their behavior vis-à-vis one another tracks machineindependent laws of some kind or another.
 Whenever it is assumed that logical/mathematical laws are creations of ours, the relations among those creations end up having all of the properties that numbers/mathematical entities per se are supposed to have. Consequently, attempts deflate mathematical truths, by turning them into fictions or artifices, end up collapsing into the very sort of mathematical realism that they are supposed to supplant.
 
Transcendental Idealism
 
Kant held that the laws of nature and the laws of mathematics are laws of thought: our bodily surfaces are bombarded by disturbances have their origins in the external world; our innate cognitive structure is such that we organize the psychical residues of those disturbances in such a way that on their basis we have cohesive and coherent bodies of experience; and what we describe as natural and mathematical laws are descriptions of elements of the aforementioned cognitive structure.
 Kant's doctrine is a form of conceptualism and therefore fails for the same reason as conceptualism. Unless our inborn psychological structure shadowed mind-independent facts, it wouldn't be able to organize the effects that such facts had on us.
 It's all very well to describe laws of nature and logic as laws of thought and to describe theories as means or organizing data or of obtaining desired results. But given that our minds are but grains of sand in a largely non-mental world, our theories and psychological mechanisms wouldn't do a very good job of organizing raw data unless they embodied a correct, if incomplete and approximate, description of reality.
 
Empiricism
 
According to John Stuart Mill, the laws of mathematics---of arithmetic, specifically—are physical laws. It is a fact that within the limits of observation (though not otherwise, as it turns out), a bag with six one lb.
bricks in it is:
 

	* Twice has heavy as one with 3 such bricks in it;

	* six times has heavy as one with one such brick in it;

	* 3/2 as heavy as one with four such bricks in it; and so on.
 
 According to Mill, the meanings of "6/3=2","6/1=1", and "'6/4=3/2" are given by (generalizations of) (i),(ii) and (iii), respectively.
 Two points:
 

	* Mill's position is false;

	* Even though it's false, there is an important truth in it.
 
 Empirical facts are evaluated in light of mathematical norms. It turned out that 6 lb. bricks jointly weigh slightly more than 6-times one lb. brick; and it turned out that a billion one ton bricks weigh vastly more than a billion-times one 1-ton brick.
 If arithmetical truths registered empirical facts, we'd have to adjust the laws of arithmetic with every such advance in our empirical knowledge. But we don't. The arithmetical norms remains fixed—as norms must—and we evaluate the empirical facts in light of those norms.
 For argument's sake, assume, with Mill, that:
 
(1) If 6 bricks jointly have ten times the mass of 1 brick, then 6(1)=10.
 
 In order to know that (1) is true, we must be able to correlate the
number of bricks in a bag with the aggregate mass of those bricks. That means that, when counting those bricks, we must use the usual arithmetical norms---we must assign "1" to one of those bricks, "2" another of those bricks, and so on, until each brick has been assigned a number. Setting aside the irrelevant possibility that there has been a change in the contents of the bag, the last number assigned is necessarily 6.
 The arithmetical truth that 6(1)=6 is the just-stated truth, or a generalization thereof, and (1) therefore assumes the very truth it negates, namely, that, when counting bricks, 6(1)=6 (and, therefore, that 6/2=3 and 6/4=3/2, etc.).
 (1) is therefore to the effect that
 
 (i) 6(1)=6 and 6(1)≠6,
 
and it is therefore false.
 The laws that coordinate the consequences of arithmetical operations (e.g. adding 1) with the consequences of physical operations (e.g. placing a brick in a bag) are not themselves arithmetical laws. Physical truths cannot be read off of strictly mathematical truths.
 But given a class K of physical truths, it may be possible to identify a purely formal calculus C such that
 

	* if the expressions of C are taken to refer to the physical objectsand processes described by K, the resulting statement set, i.e. the resulting interpreted calculus C*, is true; and

	* such that C* validates (is true with respect to) all extensions of K,meaning that C* may be true of the physical consequences of the states of affair described by K and also of states of affairs similar, if not causally related, to those described by K.
 
 Indeed, some such calculus must be identified if predictions are to be made, granting that such calculi, once identified, are seldom identified as such, even by those most adept at using them: whenever you organize data— be it in your capacity as humorist, poet, or sculptor---you are in fact doing what a logician does, the relevant difference being that his awareness of his calculus is conscious and discursive, whereas your awareness of yours is tacit, being mediated by unconscious and, indeed, subpersonal cognitive processes, similar to those that mediate audition or language-comprehension.
 In any case, what we refer to as physical laws are, operationally speaking, functions from expressions (describing known facts) to other expressions (describing other facts). If the laws describing physical events are to be any use to us, we must know
 

	* How to describe physical events and also

	* How to convert an expression describing a known physical factinto an expression that describes a hitherto unknown physical reality: we must have transformation-rules---rules telling us how to convert expressions into expressions---that track physical laws.
 
 The laws of nature, though not themselves mathematical laws, must be mapped onto mathematical laws if we are to generate accurate predictions or, therefore, explanations. (Explanation is retrodiction--back-tracking prediction. Hence the "therefore.") More precisely, if, on the basis of natural law, we are to be able to predict/explain anything, we must have mapped natural laws onto syntactic laws (laws assigning expressions of a given language with other, more complex expressions of that same language). Thus, oddly, mathematics turns out to be a kind of linguistics; and poets (and philosophers) turn out to be mathematicians, albeit ones whose data-sets, unlike those of physicists, are not best organized by calculi that are capable of numerical interpretations and whose calculi, only partly for that reason, are prohibitively difficult to state with any precision and, consequently, are unknown even to those most adept at operating with them.
 Thus, we can take (1) to mean:
 
(1*) A formal calculus, though not itself a body of physical truths, is of interest because it has a physical interpretation. When mathematicians choose to study this as opposed to that formal calculus, it is because, the empirical facts being what they are, he has reason to believe that this one, and not that one, has a physical interpretation.
 
 Thus taken, (1) is a distorted way of expressing an important truth.
 We can go further in this direction. The class of mathematical truths obviously isn't confined to calculus-internal truths. In fact, calculus-internal truths aren't mathematical truths; though they register facts about mathematical truths. Mathematics is the study, not of this or that formal calculus, but of relations between calculi, on the one hand, and, on the other hand, arbitrarily chosen statement-sets. Mathematical truths are not given by theorems (e.g. "1+2=2+1") or even by metatheorems (e.g. "a+b=b+a"); for, as these examples show, theorems and metatheorems are calculus internal. ("a+b=b+a" is false if a and b are infinite.) By the time it's possible to identify theorems and metatheorems, all the real work has been done: the relevant calculi have been invented and the general nature of their consequences, though not their precise identities, have therefore already been determined.
 Substantive mathematical truths are given by metan-theorems, where a meta1-theorem is a meta-theorem and metan+1-theoem is a meta-metantheorem, a metan-theorem being a truth to the effect that:
 
(MT) any calculus having formal properties φ1…φn is modeled by all, and only, those classes of truths having formal properties ψ1…ψm.
 
 Metan-theorems describe invariant, purely logical relations between statement sets. There are infinitely many different statement-sets. The statement-set that describes the real world is only one such set. Mathematicians—and, I would contend, all thinkers of all kinds---are interested, ultimately, only those statement-sets that either have empirical interpretations or in terms of which those that do have such interpretations are to be understood.
 (1) may therefore be taken to mean:
 
(iii) Without raw data, it isn't possible to identify prediction- and explanation-generative formal calculi; without formal calculi, it is not possible to convert raw data into predictions and explanations. Without mathematics, it isn't possible to identify the functions, from statement-sets to statement-sets that map the raw data onto the right calculi.
 
 (iii) is correct, and (i) is false. So the empiricist philosophy of mathematics, assuming it coherent, collapses into the very sort of realism about mathematical truth that it aspires to refute.
 
The spuriousness of the distinction between mathematical and non-mathematical laws
 
First of all, it isn’t laws that are mathematical; it is descriptions of laws.
Secondly, the distinction between mathematical and nonmathematical law-descriptions is misunderstood, and it’s misunderstood because the nature of mathematics is misunderstood.
The reason that physics can be mapped onto calculus is that calculus was invented to describe physical laws. The reason that banking can be mapped onto arithmetic is that arithmetic was invented to accommodate the needs of bankers.
The reason that psychology cannot be mapped onto either calculus or any other branch of mathematics is that none of the branches of mathematics was invented to describe psychological phenomena.
To be sure, truths of physics are not truths of calculus. The truths of physics are empirical, whereas those of calculus are strictly analytic. But it is because the laws of physics are so readily understood in terms of those particular analyticities that physicist chose to use the latter to describe the former.
Thus, the truths of the differential calculus are non-empirical but empirically motivated, the same being true of the truths of arithmetic, analytic geometry, and every other branch of mathematics. A failure to understand the distinction between empirical and empirically motivated has led to disastrously wrong theories, e.g. Mill’s empiricism and Hilbert’s formalism, concerning the nature of mathematics.
Aware that mathematical formalisms do a good job of modelling empirical data, Mill chose to say that those formalisms are themselves empirical truths. Mill overlooked the possibility that they are non-empirical truths that are tendentiously chosen, out of the limitless class of analytic truths, because of their consonance with empirical data.
Aware that useful classes of mathematical propositions do not describe empirical data, Hilbert chose to say that they are not true at all. Hilbert, like Kant, is therefore a crypto-empiricist. (Hilbert: If it isn’t empirically true, it isn’t true at all and is therefore either untrue but useful, like mathematics, or false. Kant: If it isn’t empirically true, it isn’t true at all and is therefore either an untrue but useful psychological heuristic or it is simply false.) Their positions are seeming diametrically opposed but ultimately identical ways of rationalizing the same wrong starting point.
When a formalism is invented, so as to provide a systematic way of interpreting empirical data, that formalism is almost always capable of multiple interpretations. There are two reasons for this. First, any formalism sufficiently rich to describe any domain worth studying, be it physics or banking, is necessarily rich enough to describe others.
Second, when an empirical scientist chooses a given a formalism, the reason he chooses it is precisely that it is schematic and therefore capable of a plurality of interpretations. He would rather work with a formalism that has a great deal of scope, but always yields low-resolution truths, than one that has minimal scope, but always yields high resolution truths. So the physicist will choose formalisms that are open-ended and therefore capable of accommodating unforeseen enlargements of his data-set. And if a formalism is unlimited in its ability to accommodate enlargements of one data-set, it is probably able to accommodate other, entirely distinct data sets.
When it is said that physics is a ‘mathematical’ discipline, whereas biology is not, what is meant is the formalisms used to model physics-related data-sets are so abstract they tend to have unintended interpretations. And when it is said that biology is a non-mathematical discipline, what is meant is that the formalisms tend not to be so abstract that they have unintended interpretations.
But given that even the most accurate sentence of natural language is nothing more than a schematic description of the corresponding fact, no discipline does not avail itself of formalisms, the difference between the ‘mathematical’ and ‘non-mathematical’ sciences being that, where the former but not the latter are concerned, the formalisms in question datasets additional to, and qualitatively unlike, the target-dataset.
As for the ubiquitousness of number in the mathematical disciplines, this is a consequence of the fact that a number is a class of isomorphic (structure-identical) models. An n-dimensional ordinal number is a class of isomorphic classes of ordered n-tuples. A cardinal number is a onedimensional ordinal and therefore a class of isomorphic one-tuples. (Two sets of one-tuples are isomorphic as long as they can be bijected.)
 
Platonism
 
We have seen that mathematical truths are not appropriately taken to
concern entities—rocks, ink-marks, or conventions—of any kind, but that they are appropriately taken to concern invariant relations among such entities. We have seen that, whenever mathematical truth is displaced from one entity-class onto another (e.g. from the class of numbers onto the class of ink-marks) the necessary truths concerning the relations among the members first class reinstate themselves as necessary truths concerning higher order relations among members of the second class.
 What this suggests is that the first class of statements—the class containing arithmetical truths (or whatever the members of the first class are)---has a multiplicity of interpretations, one of which concerns higherorder relations among conventions or ink-marks (or whatever the members of the second class are).
 Platonism is the doctrine that spatiotemporal entities are 'instances' of---meaning only that they are to be understood in terms of--- nonspatiotemporal entities.
 This doctrine is correct. To be a spatiotemporal entity is to occupy a region of space-time. Such regions are not themselves such occupants:
regions do not self-occupy. Relations between such occupants are identical with, or are to be understood in terms of, relations between such regions and, therefore, in terms of relations between entities that are not themselves spatiotemporal. There is one degree of separation between such regions and their occupants; two removes between relations among such regions and such occupants; and three removes between relations among such relations and such occupants. Physical laws concern entire classes of relations among such occupants, such that there is some form of resemblance, and thus some relation, borne by each member of such a class to each other member; and there are thus at least three degrees of separation between such laws, on the one hand, and, on the other hand, the occupants of space-time regions. Since such occupants are, by definition, the only spatiotemporal entities—since it is tautologously false to say "x is a spatiotemporal entity but there is no region of space-time that x occupies"---regions and region-involving relations are non-spatiotemporal. The spatiotemporal world is to be understood in terms of relations holding among its constituents and, therefore, in terms of relations holding among the space-time regions occupied by its constituents. Thus, the spatiotemporal is to be understood in terms of---and, in that sense, instantiates—the non-spatiotemporal; and Platonism is therefore correct.
 
 
Chapter 5 Logicism (2014)
 
 Russell and Frege advocate a doctrine known as logicism (L):
 
L: Mathematics is the class of all formal truths.
 
The motivation for L is given by the following reasoning:
 
(ML) Mathematical truths are not empirical. Non-empirical truths hold entirely in virtue of linguistic conventions. For, given that they don't hold in virtue of empirical facts, there are only two possibilities as to why they are true. (i) They hold in virtue of non-empirical (Platonic) facts. (ii) They hold in virtue of linguistic conventions. (i) is a non-starter. Therefore, (ii) is the right view. Thus, mathematical truths are definitional truths.
 
There are two questions to ask: (a) Is L correct? (b) Is ML good reasoning? The answer to each question is "no."
 
An informal refutation of logicism
 
Truths about structure cannot themselves always be structural truths. For example: In logic books, one reads about various "laws of logic," among which are:
 

	1. p or ¬p

	2. ¬(p & ¬p)

	3. ((p→q) & ¬q) →¬p)

	4. (x)((y) φy→ φx)

	5. p→(p or q),
 
where p→q means if p, then q; ¬p means not p, and (x)φx means for all x, φx.
 Not a single one of 1-5 is a law of logic; for not a single of them is true: for not a single one of them is either true or false. Each is a sentenceschema: a sentence-form; an open-sentence: an expression that contains at least one free variable, and therefore doesn't express a truth or a falsehood, but is otherwise just like a sentence.
 Each of 1-5 does indeed correspond to a law, however. But none of them is the corresponding law. 1-5 correspond to:
 
1*. (p) (p or ¬p)
2*. (p) ¬(p & ¬p)
3*. (p)(q)((p→q)& ¬q) →¬p) 4*. (φ)((x)((y) φy→ φx)) 5*. (p)(q)(p→(p or q)).
 
Each of (1*)-(*5) concerns a class K of propositions such that any given member of K is formally true. But none of 1*-5* is itself a formal truth. A formal truth is an instance of a sentence-form all of whose instances are true. Not a single of one of 1*-5* is such an instance, given that in each case replacing one of the sentence-variables with, say, a number-variable yields a falsehood.
 Mathematics aspires to identify, not this or that specific formal truth, but entire classes of formal truths. The propositions that identify such classes are not themselves formal truths. If we wished to convert 1*-5* into formal truths, we might be able to do so: but only by availing ourselves of principles given by propositions that were not themselves formally true. Given an arbitrary formal truth 1#, the proposition
 
(E1) 1# is equivalent with 1*,
 
cannot itself be formally true. By supposition, 1# is formally true, like Smith is tall or Smith is not tall. By supposition, 1* is informally true, like John can't know that snow is white unless he believes that snow is white. Therefore, the truth of the assertion that 1* and 1# are equivalent depends not on 1*'s form, but on its meaning. Therefore, E1's truth depends on the specific significance of one of its constituents and E1 is therefore not itself a formal truth. In general, if S is an informal truth and S* is a formal truth, S is equivalent with S* is not itself a formal truth. Since the foundational truths of mathematics are given by such equivalencies, mathematical propositions are not themselves formally true.
 Given that a formal truth is a structural truth, it might seem that L
coincides with our contention that
 
MS: mathematics is the study of structure.
 
Not so. L≠MS.
 MS is the contention that mathematical truths are truths about structure; it is not the contention that they are themselves structural truths. L, on the other hand, is the contention that mathematical truths are structural truths. And L, consequently, is not the contention that mathematical truths concern structure: "s is a formal/structural truth" doesn't entail "s itself concerns structure/structural truth": it would be viciously regressive, and otherwise incoherent, to say otherwise. Given only that a statement is structurally true, it doesn't follow that it itself concerns structure. And the contention---surely accepted by Russell-Frege---that mathematics is in the business of identifying classes of structural truths doesn't entail that the statements that identify such classes are themselves structural truths. And herein lies the problem with L.
 ML is not good reasoning: ML fails for much the same reason as L.
Truths about linguistic conventions are not themselves linguistic conventions. Right now we'll show that logical relations among conventions—and thus logical truths---are not conventions. In the next section, we'll show that specifically mathematical relations among conventions---and thus mathematical truths—are not conventions.
 For argument's sake, suppose each of 1-3 to hold entirely in virtue of our conventions:
 

	* "Snow is white" is true iff snow is white.

	* For any sentence S, "It is not the case that S" is true exactly if S isfalse.

	* For any sentences S and S*, "S and S*" is true exactly if both Sand S* are true.
 
A consequence of 1-3 is that
 
(SW) "Snow is white and it is not the case that snow is white"
 
is logically false. But the fact that 1-3 have that consequence is not
itself a convention. It is a convention-independent truth of logic that, if 1-3 are true, then SW is false.
Suppose that, in order to turn SW into a true statement, we adopted a fourth convention:
 
(4) "Snow is white and it is not the case that snow is white" is true if snow is either white or snow is not white.
 
4 is not consistent with 1-3: 1-4 are an inconsistent set of semantic rules. And even though each of 1-4 is a convention, and is therefore ours to accept or discard, it isn't up to us whether or not those conventions are consistent with one another. Given a set of linguistic conventions c1…cn, it is a matter of logic, not of convention, whether those conventions are consistent with one another; and, given some statement S, it isn't a matter of convention whether or not:
 
(CS) P is a logical consequence of c1…cn.
 
is true. Even though each of c1…cn is a convention, the assertion,
equivalent with CS, that
 
(CS*) If c1…cn, then P
 
is to no degree convention-dependent. CS*, if true, is true whether or
not c1…cn are conventions that anyone has adopted.
 Thus, truths about formal truths are not themselves formal truths, and truths about conventions are not themselves conventions.
 A corollary: Necessary consequences of tautologies are not themselves tautologies. A tautology is a definitionally true statement, e.g. "bachelors are males." It may be a tautology that:
 

	* Triangles have three sides;
 
and it may be a tautology that
 

	* pentagons have 5 sides.
 
But it isn't a tautology that, if x is the difference between y and z, where y is the number of sides of an arbitrary pentagon and z is the number of sides of an arbitrary triangle, then
 

	* x=2.
 
C obviously follows from A and B: but it is for that very reason that C is not a tautology. Stipulations don't follow from stipulations. Stipulations are arbitrary and ipso facto don't follow from anything.
 
 
Chapter 6 The so-called Laws of Logic (2014)
 
 The cornerstones of Classical Logic (CL) are
 
(LEM) The law of Excluded Middle: (p)(p or ¬p) (any given proposition is either true or false)
 
and
 
(LNC) The law of Non-Contradiction: (p)¬(p & ¬p) (no proposition is both true and false)
 
 It is often said that LEM is false, sometimes on the grounds that there are different degrees of truth and sometimes on the grounds that some propositions are neither true nor false.[1]
 LNC is more widely accepted than LEM, even though they are equivalent. (p or ¬p is what results when the outer negation sign ¬(p&¬p) is distributed and the “and” sign is duly replaced with an “or.”)
 In any case, the debate is made of straw. LEM is neither true nor false. LEM can be rejected so long as the remaining laws of logic are so modified that the resulting set of laws does the same inferential work as the original set of laws. If L1…Ln are the laws of CL, Ln can be replaced with some other law, provided that compensatory changes are made to L1…Ln-1. What matters is not this or that law, but the structure of the totality of laws; so long as that totality is structured in such a way that it can bear the same inferential burden as some other set of laws, those law-sets are ipso facto of equal value and the viability of this or that specific member of either set cannot be evaluated, except in relation to the value of the totality of which it is a part.
 So the real laws of logic are not LEM or LEC. The real laws of logic are meta-laws: laws about laws; laws that transform law-sets into different but equally powerful law-sets. When it is said that LEM is false, what is being said, if significant, is that purging the law-set that we use of LEM, but otherwise keeping that law-set unchanged, would yield a more powerful lawset.
 But a case can be made on the basis of this very point for acceptance of LEM. LEM tells us that, given a sentence-level expression, there are three possibilities:
 

	A. True.

	B. False.

	C. Ill-formed.
 
C doesn’t really count; a sentence-level expression is ill-formed only if it isn’t really a sentence. So LEM really gives us exactly two choices in connection with any such expression.
 Bearing this in mind, suppose that there were 10 such choices:
 

	1. False.

	2. Almost false.

	3. Medium false.

	4. Mildly false.

	5. As false as true.

	6. Mildly true.

	7. Medium true.

	8. Almost true.

	9. Vanishingly close to being completely true.

	10. True.
 
 There is obviously some sense in which 1-10, by itself, does a better job than A-B, by itself, of furnishing us with norms in terms of which to evaluate propositions.
 But A-B is not operating by itself. Whenever it is said that a proposition pn is ‘almost true’ or ‘as false as it is true,’ what is being said can be reinterpreted as a statement to the effect that (to name but a few possibilities), for some propositions p1…pn-1 such that pi (1≤i≤n) is either true or false:
 

	* pn is a conjunction, most of whose conjuncts are true;

	* pn is a conjunction most of whose conjuncts are false, but whose remaining conjuncts are both true and, in the context in question, of particular significance;

	* pn is a conjunction each of whose conjuncts is false, but some of whose conjuncts deviate from the truth by a tolerably small margin;

	* pn is false, but it wouldn’t be affirmed by anyone who didn’t know, and wasn’t trying to convey, some proposition pm that, unlike pn, was simply true.
 
And so on.
 One of the virtues of A-B is that, if an assertion occupies some noman’s land between truth and falsehood, that fact needn’t be taken as a primitive, as it can be decomposed into other facts---about its constituentpropositions or about otherwise related propositions.
 But this is not possible if 1-10 are taken as primitives. Relative to 110, a proposition’s being ‘medium true’ is not capable of analysis: it is the end of the line.
 So even though 1-10 seems like a more flexible and realistic logic than A-B, it’s the other way around. By reducing primitives to two, as opposed to n>2, A-B gives itself maximal flexibility in respect of its ability to categorize propositions. No viable logic has but one primitive category: there must be at least two. And however many primitive categories there are, they must be mutually exclusive: otherwise they aren’t primitive. But any logic that has n>2 primitive categories i ipso facto excluded from analyzing membership in at least one of those categories into membership in subcategories; and any n-valued logic to that extent lacks the diagnostic flexibility of CL.
 All of which shows that the laws of logic---the real laws of logic,
not the artifacts studied by so-called logicians---are not given by LEM or LNC or Double Negation (p↔¬¬p) but rather by statements to the effect that, given some data-set D=d1…dm, L1…Ln does a better job than some other law-set L*1…L*o of truth-preservingly mapping D-related statements onto Drelated statements. In fact, a bona fide logical law wouldn’t mention L1…Ln or L*1…L*o or any other specific law-set. Nor would it mention d1…dm or indeed any specific statement-set of any kind. Such a law would be to the effect that, given any data-set δα…δν having any statement-set having formal properties φα…φζ, and given any law-sets λα…λμ and λ*α…λ*ο, having properties Φα…Φπ and Ωα…Ωτ, respectively, the one law-set is better than the other at mapping bearing-relations of some specified kind holding among δα…δν.
 So bona fide logical laws don’t have remotely as simple a form as LEM or DN. LM and DN, etc. aren’t really even fragments of law-sets; they are fragments of models of law-sets. All of which bears out the contention that true logico-mathematical laws describing relations of invariances holding among arbitrary structures.
 
 
Chapter 7 Real numbers as outputs of metrical operations (2014)
 
Measurement is a determination of causal potency.
 Consider the following definitions of X has the same mass as Y
 

	1. Ceteris paribus neither overruns the other upon collision.

	2. Ceteris paribus no more energy is needed to displace the one than to displace the other.

	3. Ceteris paribus neither one’s gravitational field is stronger than the other’s.

	4. Ceteris paribus neither exceeds the other in respect of how much work is needed to raise its temperature by a given amount.
 
Now consider some definitions of length:
 

	a. When X and Y are juxtaposed, each endpoint of the one coincides
with exactly one end-point of the other; and each segment of the one is contiguous with some segment of the other.

	a. For some n, given either X or Y, a periodic process of a given kind
can occur n times in the time it takes a light-beam to travel from one endpoint of that object to the other.

	a. Ceteris paribus neither eats up more visual space than the other.

	b. Ceteris paribus neither exceeds the other in respect of how much
gasoline is needed to drive from endpoint to the other.
 
 Given any magnitude, analogues of 1/a-4/d are readily generated.
 For x to have a certain mass/length/temperature is for x to have certain causal properties. If C1…Cn are the causal properties that x has in virtue of having a certain length, it is no less absurd to distinguish x’s having C1…Cn from its having that length than it is to distinguish an object from the various property-instances associated with it. In fact, the first fallacy is a special case of the second.
 
Diachronic measurement the only kind
 
 Seemingly synchronic forms of measurement, e.g. the juxtaposition method of length-determination, collapse into their obviously diachronic counterparts. When you measure X’s length by juxtaposing it with some other object, you are in fact using the optical method. It isn’t that neither of X’s endpoints is a beginning for you; it is that, owing to your large size in relation to X, each such endpoint is a beginning.
 Optical or otherwise causal methods are always used in measurement. When this appears not to be so, it is because, owing to the smallness relative to the observer of what is being measured, no one metrical determination can be carried out with a plurality of other, result-identical determinations being carried out.
 Causal properties are change-dispositive properties. For X to have a certain mass or temperature/mass/volume/shape is for it to dispose objects in a certain region to undergo certain kinds of changes, and for X to occupy place p is for p to be the geometrical center of those disturbances.
 A static property, e.g. length, is a four-dimensional property. A dynamic property, e.g. velocity, is a change in a static property.
 A static property, e.g. length or mass, is a form of change-
dispositiveness. A dynamic property, e.g. velocity, is a change in a given form of change-dispositiveness.
 
The arbitrariness of the metrical unit
 
 What one regards as a unit of length (or time or mass) is obviously arbitrary. In fact, it is inherent in the nature of measurement that one’s choice of metrical unit be arbitrary. It would be non-arbitrary only if there were minimal units such that enumerations of such units yielded the appropriate metrical values. But it is classes, and thus non-spatiotemporal entities, that are enumerated, while it is changes, and thus spatiotemporal entities, that are measured. Since changes ipso facto involve non-denumerably (uncountably) different states, measurement is never the same thing as enumeration.
 And when a property is additive, that isn’t because the results of measurement coincide with those of enumeration. It is because the results of measurement yield the real numbers corresponding the cardinal numbers yielded by enumeration.
 So not only is it not a priori true that, e.g., the weight of n objects on a balancing pan equals the cardinal number of those objects on the pan: it is a priori false, for the reason that reals aren’t cardinals.
 And it is never a priori the case that the reals yielded by measurement correspond to the cardinals yielded by enumeration. Supposing that either volume or mass is additive, this isn’t a priori so.
 One reason is that large distances are non-integrable. They cannot be determined by adding together small distances. Length-determinations are implicated in metrical determinations of every other kind. As a rule, therefore, metrical determinations are non-additive.
 
The importance of the reals
 
 There are exactly as many rationals as there are cardinals. This means that the rationals are as measurement-useless as the cardinals. And that is why the series of rationals, though compact, is no substitute for the series of reals, which, appropriately, is referred to as “the Continuum.”
 There is a second reason why the reals are indispensable. Wherever complexity is involved, quantitative differences involve qualitative differences. An economy cannot grow or change along a given axis unless it undergoes a number of structural changes. That is why a big economy is not simply a big microeconomy. And that, in its turn, is why, when dealing with a complex system, the relevant question is not how many? but to what extent? No enumerable difference between economies is inherently significant. It’s of no use to know exactly, or even approximately, how many transactions are taking place or how many people are involved therein. The relevant parameters aren’t given by arithmetical propositions.
 Real numbers are explanatory. Cardinal numbers are not.
 When arithmetical propositions are explanatory, it is because facts about cardinality are shadowing facts about real number.
 
Chapter 8 Soundness vs. completeness (2014)
 
 Let ϕ→s ψ and ϕ→mψ mean, respectively, ϕ syntactically entails ψ and ϕ model-theoretically entails ψ.  ϕ syntactically entails ψ and ϕ model-theoretically entails ψ are
synonymous with, respectively, ϕ formally entails ψ ϕ semantically entails ψ  Given a formal calculus L and two sentences p and q in L, if
 

	* (p→sq)& ¬(p→mq),
 
then L is unsound; otherwise, sound.
 If
 

	* (p→mq)& ¬(p→sq),
 
then L is incomplete; otherwise, complete.
 If a system is unsound, then, and not otherwise, it is inconsistent, meaning that p & ¬p is a theorem of that system, for arbitrary p.
 Since an inconsistent system proves everything, it proves nothing and is therefore worthless.
 An incomplete system, on the other hand, is not worthless. In fact, very few systems are complete; and complete systems are so restricted in scope that it is only if embedded in larger, incomplete systems that they are of any use.
 
Object-language vs. meta-language
 
 When we talk about a language L, we must use a meta-language. That language may itself be L---as it would be if we were using English to talk about English. But, ultimately, metalanguage and object-language must pull part: No consistent language has the resources to adequately describe its own resources (cf. Tarski—The Concept of Truth in Formal Languages). What we refer to as “English” is a plurality of related languages; and although it is obviously is possible to use English to discuss English, it is possible only by switching from one of those sub-languages to another.
 Our using English to talk about English involves our actually using some language English2 to talk about English1, where English2 is homonymous in large part with English1, obscuring the fact that different sets of semantic rules, and thus different languages, are involved.
 
Intertranslatibility
 
 Two languages L and L* are intertranslatable iff there is a relation R that pairs off each sentence of the one language with a synonymous (meaning-identical) sentence of the other language.
 Of course, given two natural languages L and L*, any L-sentence is synonymous with many different L*-sentences, and any L*-sentence is synonymous with many different L-sentences. So R is a function, not from sentences to sentences, but from sentence-classes to sentence-classes; and R is therefore one-one, notwithstanding issues relating to ambiguity, intralinguistic redundancy, etc.
 
Productivity and systematicity
 
 
Any given language is both systematic and productive.
 “Systematic”: Complex expressions can be permuted to form other complex expressions: “John loves Mary” → “Mary loves John.”
 Productive: Any expression can be embedded in a larger expression. Thus, taking “→” to mean “embeds in”:
 

	* “Mary loves John”→”if Mary loves John, then Mary loves
someone”, and

	* "If Mary loves John, then Mary loves someone”→“if Mary lovesJohn, then Mary loves someone, unless John is a robot.”
 
 The more systematic a language is, the more precise are the statements belonging to it. (L is more systematic than L* iff L-expressions are on average more decomposable than are L*-sentences.) The more productive a language is, the greater scope it has. (So systematicity is an intensive quality: a language is systematic if it can speak precisely about whatever it is that speak about at all. And productivity is an extensive magnitude: a language is productive if there is much that it can speak about.)
 Of course, the easy way to add to a language’s expressive capabilities is simply to add more primitive expressions to it. But even though this must be done, it isn’t feasible, even theoretically, unless the new meaning-postulates are absorbed into a pre-existing systematicity- and productivity-conducive structure. A language L is useful to the extent that it can accommodate indefinitely many and many-sorted inferences concerning indefinitely voluminous and heterogeneous data-sets. A language must therefore be able to ‘turn over’, like an engine, an indefinitely large number of times: if, with respect to one class of inferences, it hits a wall after a certain number of rotations, it inevitably hits similar walls with respect to indefinitely many other such classes. It cannot be predetermined how large the expressive/inferential burden of a language will be, and a certain plasticity must therefore be built ab initio into any useful language.
 
Cryptography and language
 
 A language is a systematic way of encrypting information; it is a set of functions, which jointly define a single function, from data-sets to statements and vice versa.
 A translation-manual is a function that pairs off sentences of one language with synonymous sentences of some other language. So translationmanuals define relations of isomorphism between two structures, each of which in its turn defines a relation of isomorphism (between sentences and data-sets).
 All information-transmission relies on structure-preservation:
Structures must physically be preserved if it is to be possible to know about the past or to predict the future (or to make inferences about the nonperceptible present, since doing as much always involves an element of prediction or retrodiction). So there must be structure-preservation in a physical sense.
 But if there is to be language, there must be structure-preservation in a logical sense. A language is an artificial structure-preservative: While the fruit in the bowl is rotting, the sentence “in the bowl, there is an apple [etc.]” stays pristine. A language preserves evanescent physical structures by mapping them onto non-transient mathematical structures (functions from noise-types to meanings).
 A system of written language is a function from such a function to inscription-types.
 Perceptions are isomorphs of the external realities by which they are caused and which they depict. More accurately, classes of perceptions are isomorphic with the corresponding external causes: a given perception might or might not correspond to its referent---the square may look like a diamond, the oval like a circle, etc. The reason is that, encoded in any one perception is information both about the object of perception and also about the subject’s physical relation to it; and, in order to factor out the latter sort of information, so as to maximize the former sort, it is necessary to vary the perception-class as much as possible, holding the one parameter fixed while letting the others vary.
 Thoughts are perception-isomorphs.
 Languages are thought-isomorphs.
 Translation-manuals are language-isomorphs.
 Isomorphism is identity under some function. Functions are transformations. Transformations are mappings.
 A language is a digital characterization of analogue data.
 
Philosophical applications: Skepticism and anti-realism refuted
 
 Epistemologists to this day debate whether our sense-perceptions are veridical. But George Berkeley solved this puzzled long ago. The objects of perception may be identified with any structure that validates the presumption that our perceptions are accurate within the limits set by the fact that our perceptions are effects of their objects and, therefore, are at least slightly inaccurate.
Berkeley overlooked the italicized qualification, which is why the specific model he proposed is defective. So the way he implemented his analysis was defective. But his analysis itself was sound.
 And to this day philosophers of science whether the measure of a good theory is truth, on the one hand, or data-consistency, on the other. This debate would be meaningful, were it not for the fact that our theories themselves fall within the scope of our theories. The only data-consistent higher-order theories---theories as to why our lower-order theories are dataconsistent----are to the effect that our perceptions have external causes and, more generally, that the psychic residues of our interactions with the world tend, however feebly, to embody the structure of the world. Taken together with the fact that our various theories must not contradict one another, this entails that our lower theories can only be data-consistent if they are true; wherefore, there is no basis for the realism/anti-realism debate.
 
Formal calculi inherently incomplete
 
 Any given formal calculus is an instance of aleph-null, this being the cardinality of the class of natural numbers. This is because anything that is recursively defined is an instance of aleph-null. And this in turn is because for a set to be denumerable (to have a cardinality of aleph-null) is for it to be recursively definable.
Any class whose cardinality is infinite but non-denumerably has a cardinality of at least aleph-one, this being the power of the continuum (the number of real numbers).
 A formal calculus represents a given structure by virtue of being an instance of that structure. No formal calculus is an instance of aleph-one. That is why there is no formal calculus that doesn’t have a denumerable model and thus no formal characterization of the difference between the class of natural numbers and the class of real numbers. And that in its turn is why any formal characterization of the latter is incomplete.
 Let us describe a system S as finitary if S is capable only of a denumerable number of different configurations. There is nothing about a finitary system that cannot be represented as a truth about cardinal numbers.
When logicians talk about the propositional calculus, they use terms like ‘true’ and ‘false.’ Thus used, such terms are just labels chosen for their mnemonic value, not their descriptive legitimacy.
So used, in fact, ‘true’ and ‘false’ are positively inaccurate. The entities being described, first of all, are neither true nor false—they are always strings of uninterpreted expressions.
Second, the use of ‘true’ and ‘false’ masks the fundamentally nondescriptive nature of logic. Logic studies those geometrical properties of onedimensional expression-strings that are preserved under certain operations. Those expression-strings are sentence-like in some respects. Therefore, complexes of such strings are similar in some respects to compound sentences (sentences consisting of other sentences, linked together by “and”, “or’, and the like).
But resemblance isn’t identity. And in this context, we are dealing with resemblance, not identity.
 The non-descriptiveness of formal logic is a consequence of two facts:
 
(1). A truth is formal if it belongs to a language L such that true-in-L is recursively definable.

	* Any recursive definition, and thus any recursive definition of true-
in-L, can be expressed as a definition of some class of finite numbers.
 
 
Taken jointly, (1) and (2) entail that there is an arithmetical characterization of true-in-L, for any formal calculus L that contains arithmetic, and also for false-in-L. This means that there is an arithmetical characterization of
 

	* S-is-unprovable-in-L,
 
where S is an arbitrary arithmetical statement that is expressible in L and where (3) is itself a sentence of L. L is complete only if (3) is false, and L is consistent only if (3) is true.
 So it is a mistake to look for a definition of “arithmetically true” in a definition of “true in some formal calculus.” The latter notion is derivative of the former, since, given the just-stated incompleteness principle, any truth of formal logic can be coded into an arithmetical truth but not vice versa. Thus, arithmetic, though surely not correctly described as the study of truth and falsity, is more appropriately so described than formal logic.
 
 
Chapter 9 Formal languages, axiom sets, and incompleteness
 
 
Statements about a language L must be distinguished from statements within L. What can be said in L doesn't coincide with what can be said about L. If L* is the language being used to discuss L, then, in that discursive context, L* is functioning as a metalanguage and L is functioning as an object-language. In the statement:
 
(1) The Spanish word for snow is "nieve,"
 
English is the metalanguage and Spanish is the object-language. (1) is a sentence of English, not of Spanish.
 The distinction between metalanguage and object-language is not an arithmetical concept. A given sentence can be a sentence of English even if 99% of its words belong to Spanish. For example, if S is an extremely long sentence of Spanish, then "the following sentence [insert S, in quotation marks] is true in Spanish" is a sentence of English.
 As 1 illustrates, when a given language L is used to talk about another language L*, L assimilates all of L* and is therefore at least as expressively rich as L.
 
Semantic rules
 
A language is an integrated set of semantic rules.
A semantic rule is a proposition R to the effect that expression E has meaning M. Examples:
 

	a. "Snow" refers to snow.

	b. The Spanish word for snow is "nieve."

	c. "…all phi…" is true exactly if the property being a thing x such
that…x…is universally instantiated.

	a. "…some phi…" is true exactly if the property being a thing x such
that…x…is instantiated.

	a. "…no phi…" is true exactly if the property being a thing x such
that…x…is uninstantiated.
 
Languages as integrated sets of semantic rules
 
 A set of semantic rules is integrated if any given two of the expressions in that set can be combined into a third expression. Given two expressions of English, e.g. "snow" and "white," there is a third expression of which both are constituents, e.g. "snow is white." Given an expression of English, e.g. "nieve," and an expression of Spanish, e.g. "white," there is no third expression of which they are both constituents.
 
Contextual Definition:
 
Each of c-e is a contextual definition, meaning that the targetexpression is defined by saying what it is that a given sentence means in virtue of containing that expression. Ultimately, all definition is contextual definition. If you say that "John" refers to John, you are really saying that, in virtue of having the form "…John…", a sentence is true exactly if…John… To put it in terms of so-called lambda-notation, for "John" to refer to John is for it to be the case that, in virtue of having the form "…John…", a given sentence is to the effect that λx(…x…)John. To put it another way, there is some object O such that O=John such that, in virtue of having the form "… John…", a sentence is true exactly if…O…or, equivalently, exactly if λx(… x…)O.
 Explanation: "λx(x is even)4" means that 4 is a thing x such that x is even, i.e. it means that 4 is even. "λx(x is smart)Einstein" means that Einstein is a thing x such that x is smart, i.e. it means that Einstein is smart.
 
Use vs. mention
 
 In the previous section I said that '[g]iven an expression of English, e.g. "nieve," and an expression of Spanish, e.g. "white," there is no third expression of which they are both constituents.'
But that isn't true, it will be objected. Consider the sentence:
 
(SE) The words "nieve" and "white" belong to Spanish and English, respectively.
 
 In SE, each of "nieve" and "snow" occurs, contradicting what you
said."
 
 Not true: In SE, the word "nieve" is mentioned, but not used. What occurs in SE is not the Spanish word "nieve," but a quotation of that Spanish word; what occurs is '"nieve'", not "nieve." The Spanish word for snow is discussed in SE; but it is not itself a component of SE. What is such a component is a word that refers to the Spanish word for snow. For the same reason, the word "white" isn't a constituent of SE; what is such a constituent is an expression, namely '"white"', that refers to the word white. If I want to refer to you, I use the word "Joey." If I want to refer to the word that refers to you, I use the word '"Joey"'. These words have different referents and these differences are reflected in differences between meanings of sentences that contain "Joey" and sentences that contain '"Joey"'. The sentence:
 

	* Joey is a person
 
is true. The sentence
 

	* Joey has four letters
 
 is false, since people don't consist of letters.
 The sentence
 

	* "Joey" has four letters
 
is true. The sentence
 

	* "Joey" is a person
 
is false, since words are not people.
 
 
Languages as integrated sets of semantic rules (resumed)
 
It has been said that any set of semantic rules constitutes a language; more often than not, it is not said that any two of the expressions in question be capable of being combined into a third. Thus, logicians are likely to say that the smallest set S containing the following semantic rules constitutes a language:
 
R1: "blerk" means snow is white.
R2: "blurbo" means grass is green.
R3: "grumpo" means it is raining.
 
 But S is not a language. Obviously a given group of people could use R1-R3. But because no two of those expressions can combine into a third, the members of S the members of S per se have no bonds with one another that they don't have with any expression of English or Spanish or any other language, and there is thus no reason of a distinctively linguistic, as opposed to sociological, nature to regard R1-R3 as jointly constitutive of a single language.
 But suppose we add a fourth rule to S to the effect that:
 
R4: Given any two sentences S1 and S2 of S, "S1 blarg S2" is true exactly if S1 is true and S2 is also true.
 
In that case, any two expressions of S can be combined into a third and S consequently does constitute a language.
 
 
 
Recursivity and computation
 
Let L be the language constituted by R1-R4. We can define "sentenceof-L" as follows:
 
S is a sentence of L iff
 

	* If S is identical with "blerk" or "blurbo" or "grumpo," then S is asentence of L.

	* If S1 and S2 are sentences of L, then, if S is identical with "S1 blarg S2," S is a sentence of L.
 
We have just a given a recursive definition of "sentence of L." (1) is the base clause; (2) is the inductive, or recursive, clause.
 Because of (2), there are infinitely many sentences of L, and L is therefore "productive," to use Chomsky's expression. And, also because of (2), any two expressions of L can be combined into a third, and L is therefore "systematic," to use Chomsky's expression.
 We can also give a definition of "true-in-L":
 
(1*) S is a true sentence of L iff S is identical with
"blerk"/"blurbo"/"grumpo," and snow is white/grass is green/it is raining.
(2*) S1 and S2 are true sentences of L, and S is identical with "S1 blarg S2."
 
 
Whether "grumpo" is true depends on whether, at the time at which it is uttered, it is raining; and "grumpo" is therefore time-sensitive and therefore context-sensitive. In fact, sentences of natural language are categorically context-sensitive. But for expository reasons we are setting this subtlety aside for the moment.
 
 
Recursivity
 
Recursivity is a property of definitions of classes. It is also a property of functions ---or of definitions thereof, to be precise---but only because functions can be identified with classes, as we will see.
 Given a set (class) K, a recursive definition of K is a true statement to the effect that, for some object O and some relation R, x is an element of K just in case
 

	* x is identical with O or

	* There is some element y of K such that y bears R to x.
 
 
Examples:
 

	1. n is a natural number iff either (i) n=0 (base clause) or (ii) n=m+1, where m is a natural number.

	2. n is a perfect square iff either (i) n=1 or (ii) n=(m+1)2, where m is a perfect square.

	3. n is a multiple of 5 if either (i) n=5 or (ii) for some m, such that mis a multiple of 5, n=m+5.
 
 
Recursive definition
 
The class of natural numbers is the posterity of 0 with respect to the successor-relation (the relation that n+1 bears to n). In other words, if N is the class of natural numbers, then N is the smallest class containing 0 and the successor of anything that it contains.
In general, a class K is defined recursively if, for some x and some relation R, K is the smallest class containing x and containing m whenever, for some n such that n belongs to K, n bears R to m. Equivalently, K is a recursively defined class if K is the posterity of x under R, for some x and some R.
 
Computability in relation to recursivity
 
In this section, the expression “x solves problem y” does not mean “x discovers the solution to y.” Rather, it means “x produces inscriptions that, relative to the relevant body of linguistic conventions, represent a solution to y.” In this context, it is important to bear in mind the distinction between actual (thought-involving) and simulated (mechanical) problem-solving. Technically, ‘mechanical problem-solving’ is an oxymoron, since actual problem-solving, being a form of thought, is ipso facto non-mechanical.
A problem can be solved in a mechanical fashion, i.e. the solution to it can be computed, just in case the solution is the output of a recursive function.
This is the Church-Turing Thesis.
Given a class K, a recursive definition of K consists of three parts.
The first part (the base clause) is to the effect that X belongs to K,
where X is identified by its shape, not its meaning.
The second part (the inductive clause) is to the effect that if a given shape Y belongs to K, then a given shape Z also belongs to K, provided that Y bears R with respect to Z, where R is a strictly morphological relationship.
The third part (the closure clause) is to the effect that K is the smallest class containing the posterity of X with respect to R.
Thus, in order to compute F(n), where F is any recursive function and n is argument thereof, sensitivity to sensitivity to symbol-shape is sufficient. Sensitivity to symbol-meaning is not necessary.
If a given act is strictly shape-driven, it is not meaning-driven and is therefore mechanical in nature. Strictly shape-driven behaviors generate the solution to a given problem just in case the answer to that problem is the output of a recursive function. Hence the Church-Turing Thesis.
 
Computability in relation to language
 
You are able to interpret expressions that you have never before encountered (e.g. "you are able to interpret expressions that you have never before encountered"). Your ability to do this is a consequence of two facts, namely:
 

	* Those expressions are complex, meaning that they consist ofmultiple expressions; and

	* Because you know the relevant semantic rules, you can computetheir meanings on the basis of the meanings of the simple expressions that compose them.
 
 The reason you can compute their meanings is that the meaning of a complex expression is assigned to it by a recursive rule. To compute is to compute the value of a recursive function for a given argument. Thus, in using your knowledge of requisite recursions to identify a complex expression's meaning, you are computing its meaning.
 The meaning of a complex expression is a function of the meanings of the simple expressions composing it. This is the principle of compositionality. "Smith's father" does not have the same meaning as "Smith's mother," for the reason that "father" does not have the same meaning as "mother." "Smith's primary enemy" does have the same meaning as "Smith's primary foe," for the reason that "enemy" does have the same meaning as "foe."
 
 
Truth-in-L in connection with the concept of incompleteness
 
Truth-in-L cannot be defined in L. R1-R4 do not themselves constitute a definition of truth-in-L, they leave it open whether there are other sentences that belong to L. Suppose that, hoping to produce a definition in L of truth-inL, we stipulate that (1*) and (2*) are sentences of L. In that case, (1*) and (2*) are no longer true, since (1*) and (2*) are incompatible with their being sentences of L.
 R1-R4 is an axiom-set. An axiom set is a finite set of statements s1… sn such that, for some statement-class K, a given statement S is a member of K just in case either
 

	* S is identical with si (1≤i≤n) or

	* S is a member of the posterity of s1…sn with respect to the relation of logical consequence.
 
 Notice that the definition of "axiom set" is recursive. Axiom sets are themselves recursive definitions, and "axiom set" is itself recursively defined.
 L is generated by R1-R4. All languages, whether natural or artificial, are generated by axiom-sets.
 
 
Language: formal, informal, natural, artificial
 
 A language is a four-tuple <s1, s2, G, M> such that:
 

	* s1 is a set of simple expressions (expressions that don't consist of other expressions);

	* G is a set of rules, defined for s1, such that G says of any n-length string consisting exclusively of members of s1 whether or not that string is grammatical;

	* s2 is the smallest class containing every grammatical n-length
strings of s1-members.

	* M is a function that assigns a meaning to each element of s2 (and therefore to s1, since s1 is a proper subset of s2).
 
A formal language L is a class K of expressions such that
 

	* K’s membership is made to known to us through a recursivedefinition;

	* L’s semantics is made known to us through a recursive definition
D such that, for any member x of K, D assigns a semantic value to x; and
(iii) Each of the expressions belonging to L is non-contextually unambiguous.
 
Regarding (i) and (ii): Whenever one learns a natural language, one first learns what is meant by some reasonably large subset of the expressionclass generated that language and, on that basis, one infers what the relevant recursions are. On the basis of contextual information, not on the basis of semantic rules, one initially learns what is meant by L-expressions e1…en, where n is a large number and where ei, for at least some i (1≤i≤n) is a complex expression. Given a formal language, on the other hand, one first learns the relevant recursions in toto, and on that basis on then generates knowledge of some of that langauge’s complex expressions.
Also, one’s knowledge of the meanings of the primitive expressions of a formal language is derived entirely from one’s knowledge of the corresponding semantic rules. By contrast, one’s knowledge of the primitive expressions of a natural language is never, unless that language is a second language, based on knowledge of explicit definitions, being instead based on contextual information. And learning a second language properly typically involves acquiring context-based information as to what the expressions of that language mean.
Regarding (iii): In the English language, there are two kinds of expressions that are not contextually unambiguous:
 

	* Lexically ambiguous expressions (e.g. "bank," "dumb," "Jim is atthe bank," "Jim is not dumb") and

	* Syntactically ambiguous expressions (e.g. "Jim is strong because
his mother is a good person and his father is a good person too" which could mean either Jim's father is a good person; moreover, Jim is strong because Jim's mother is a good person or It is because Jim's mother and father are strong people that Jim is a good person).
 
 In this respect, English is typical of all natural languages. A natural language is one that comes into existence organically: nobody sits down and invents it; it is the unintentional or semi-intentional by-product of interactions among living creatures (usually, as far as we know, human beings).
 Artificial languages are languages that are not natural languages. In this paper, an artificial language will be described. That language will also be a formal language. But an artificial language isn't necessarily a formal language. One could invent a language that contained expressions that were not non-contextually unambiguous. (In fact, we will do so ourselves.)
 People seldom do invent such languages. There are two such reasons, each sociological, as opposed to logical, in nature. (1) First, in some cases people invent languages precisely because they wish to expedite communication in an arena in which contextual-ambiguity is a drawback. (There are many domains of discourse in which the absence of contextualambiguity is a massive hindrance, as we will see, though not in this paper.) Obviously mathematicians don't want the context to determine what is meant by "+," and "5" and the like. (2) Second, when languages are invented, it is often to study relations of logical dependence; and given the specific logical relations on which researchers have tended to focus, it is helpful to this end to focus on statement-sets whose elements are unambiguous in every way. But there are logical relations that are not best studied by examining such statement-sets, as semanticists/logicians have come to realize in the last few decades.
 The difference between a formal and an informal language is that, where informal languages are concerned, the amount of information needed to determine the identity/meaning of a given expression is greater than is the amount of information needed to identify the identity/meaning of an expression of a formal language. Where formal languages are concerned, only one kind of information is needed: morphological information—it must be known what shape the expression has (if it is written) or what sounds like (if it is spoken). Where informal languages are concerned, two kinds of information---morphological and contextual information---are needed to identify expression-identity and, therefore, expression-meaning.
 The distinction between artificial and natural languages is not of any significance to logic. This is because there is no difference between natural and artificial languages. We construct artificial languages; therefore, we have conscious knowledge of their structures. We do not construct natural languages; therefore, we do not have conscious knowledge of their structures. But any given artificial language could have arisen organically and any given natural language could have been consciously constructed: it is never in virtue of its intrinsic properties that a given language is natural as opposed to artificial or vice versa.
The distinction between formal and informal languages is of some significance to logic; but the nature of that significance is heuristic
(procedural), not substantive. In some contexts, in some respects, it is easier to express extremely high level truths of logic in formal languages than in informal languages.
 That said, it is a consequence of mathematical theorems, which we will discuss, that any language rich enough to express any given truth of logic or mathematics is such that there is no way to ensure that each expression belonging to it is non-contextually unambiguous. The exact meaning of this claim, and the justification for it, are not readily stated; but the points made in this paper jointly constitute a first step towards both explicating and justifying it.
 
 
The concept of a formal language: Uninterpreted calculi
 
 The concept of an interpreted calculus is to be understood in terms of the concept of an uninterpreted calculus. An uninterpreted calculus is an ordered triple <s1, s2, G> satisfying the following conditions.  s1 is a class of simple, undefined expressions. So the elements of s1 are variables. The ranges of the variables vary.
Some variables are individual-variables, i.e. their substituends are expressions like "John," "the Moon," etc.
Some are one-place predicate variables; their substituends are expressions like "is tall" (or "x is tall") or "is blue" ("x is blue").
Some are connective-variables, whose substituends might be "and" or "or" or "because."
Finally, some are quantifier-variables, whose substituends might be "some," "all," etc. But---and this is important---s1 per se does not have "John" or "is tall" or "for some x" as elements. Rather, s1 has for its elements expressions that, for reasons to be discussed, can in some contexts be interpreted as having such significances but do not in and of themselves have such significances. The elements of s1 are undefined or, as logicians say, uninterpreted.  s2 is the smallest class of all grammatical strings of members of s1. Whether a given sequence of expressions, or expression-variables, is grammatical or not depends on the identity of the grammar (set of grammatical rules) in question. In this context, G is the operative grammar. So G is the set of admissible ways of combining elements of s1 into complex elements; and s2 is the set of such G-appropriate strings of elements of s1. Thus, the elements of G are rules to the effect that it is appropriate to combine the elements of s1 in certain ways but not others.  Four points should be made clear.
 First, the elements of s1 mean nothing.
 Second, the elements of s2 mean nothing.
 Third, the elements G are not truths; they are prescriptions, not descriptions.
 Fourth, even though the elements of G are neither true nor false, and even though the elements of s1 and also of s2 are meaningless, it is, for any given string of s1-expressions, a matter of objective logical fact whether, relative to G, that string is an element of s2. In other words, if e1…en is a string of elements of S, and CG is the statement formed by conjoining all of the elements of G, then the statement
 
(*) "CG entails that e1…en is an element of s2"
 
is either true or false. It is not a matter of convention whether (*) is true or not; it is a matter of objective logical fact, notwithstanding that it is a matter of convention what the elements of s1 are and also what the elements of G are.
 Thus, (*) is a non-conventional consequence of conventions. Logical relations that hold among conventions are not themselves conventions.
 
 
An example of an uninterpreted formal calculus
 
 Let UC (short for "uninterpreted calculus") be the ordered triple <s1, s2, G>, where "s1," "s2," and "G" are defined as follows (mentally insert quotation marks where appropriate):
 
For any finite n, s1 includes xn, yn, and zn. (Thus, x1, y34, and z10,004 are elements of s1.) s1 includes the expressions "A" and "N." s1 includes "E," "O," and "W." s1 includes nothing else.
 
s2 is the posterity of s1 with respect to G, where G consists of the
following rules:
 

	1. For any expression e that belongs to s1, each of "Ee," "Oe," and "We" is a well-formed formula (wff) and belongs to s2. (A wff is expression that is just like a sentence except that the expressions composing it have yet to receive an interpretation).

	2. If e1 is a wff, then "Ne1" is a wff.

	3. If e1 is a wff and e2 is a wff, then "Ae1e2 " is a wff. 4. For any n, each of "Exn," "Eyn," and "Ezn" is a wff.

	4. For any n, each of "Oxn," "Oyn," and "Ozn" is a wff.

	5. For any n, each of "Wxn," "Wyn," and "Wzn" is a wff.

	6. If "Ne" is a wff, then "N(e)" is a wff and, moreover, is identicalwith (a notational variant of) "Ne."

	7. "Ae,e*" is a wff, then "A(e,e*)" is a wff and, moreover, is identicalwith "Ae,e*."

	8. If "Ee" is a wff, "E(e)" is a wff and, moreover, is identical (anotational variant of) "Ee," the same mutatis holding of 10 "Oe" and "We."
11. Nothing else is a wff.
 
 11. is a so-called closure clause. The concept of a closure clause is
important, in that, for reasons to be discussed, many languages are seldom rich enough to articulate their own closure clauses, a consequence being that it is hard to produce comprehensive consistent axiomatizations of mathematics.
 
Definitions of key terms
 
Before we proceed, let us define “axiomatization”, “consistent”, and
“complete.”
 'Axiomatization': Given some class of truths K, an axiomatization of K is a finite set of propositions k1…kn such that every element of K is either identical with ki (1≤i≤n) or is a consequence of k1…kn.
 An axiomatization is consistent if there is no proposition P such that P and not-P is a consequence of that axiomatization.
 An axiomatization is complete if, for each proposition P, either P or not-P is a consequence of that axiomatization.
 An axiomatization that is inconsistent is worthless. An axiomatization that is incomplete is not necessarily worthless. It is seldom possible to produce complete, consistent axiomatization of statement-sets that are of any scope or significance.
 
Our discussion of R1-R4 continued
 
Let us once again consider the following semantic rules:
 
R1: "blerk" means snow is white.
R2: "blurbo" means grass is green.
R3: "grumpo" means it is raining.
R4: Given any two sentences S1 and S2 of S, "S1 blarg S2" is true exactly if S1 is true and S2 is also true.
 
Right now, none of the members of s1 means anything and none of the members of s2 means anything. But even though those expressions are meaningless right now, there is an intended interpretation of them. These will be defined in the next section.
 
Each of the following is a wff (assume that each is flanked by quotation marks):
Ex34
E(x34)
O(z767)
A(Ox1,Ez23)
NOx2
N(Ox2)
N(O(x2))
N(A(Ex3,Oz8))
A(N(Ex3),W(z4))
N(A(N(Ex3),W(z4)))
A(N(A(N(Ex3),W(z4))), N(O(x2)))
N(A(N(A(N(Ex3),W(z4))), N(O(x2))))
A(N(A(N(A(N(Ex3),W(z4))), N(O(x2)))), Ex78)
N(A(N(A(N(A(N(Ex3),W(z4))), N(O(x2)))), Ex78))
A(N(A(N(A(N(A(N(Ex3),W(z4))), N(O(x2)))), Ex78)), Wz78)
A(N(A(N(A(N(A(N(Ex3),W(z4))), N(O(x2)))), Ex78)), N(Wz78))
A(N(A(N(A(N(A(N(Ex3),W(z4))), N(O(x2)))), Ex78)), A(Oz7,
N(Wz78)))
 
None of the following is a wff:
 
NEx8,Oz9
N(Ex8,Oz9)
A(Ez8)
AEz8
A(Wz8,Ez7N)
AWz8,Ez7N
N(Ox9,Ox10)
A(N(Ox9,)x10))
N(A(N(Ox9,)x10)))
 
 
The concept of a formal language: Languages as interpreted calculi
 
Let IC (short for "interpreted calculus") be the four-tuple <s1, s2, G, M>, where "s1," "s2," and "G" are defined as before and where "M" (short for
"meaning") is defined as follows:
 
 "E"/"O"/"W" are predicates signifying even/odd/whole number. "xn" refers to n; so "x24" refers to 24.
"yn" refers to n+1; so "y24" refers to 25.
"zn" refers to the smallest prime greater than n. So "z2" refers to 3.
"A" (short for "and") is the conjunction-operator. So "A(Ex2,Wz3)" means: 2 is even and 5 is a whole number.
"A" operates on sentence-pairs, not on single sentences.
"N" (short for "not") is the negation-operator. So "N(Ex4)" means: 4 is not even. And "N(Ex5)" means: 5 is not even.
"N" operates on single sentences, not on sentence n-tuples (n≥2).
 
 
Truth-predicates
 
Given a language L, a truth-predicate for L is a true proposition P such that, for any given sentence S of L, P says under what circumstances S is true.
 
Incompleteness: some introductory remarks
 
Let us once again consider R1-R4. There are two respects in which R1-R4 is an incomplete axiom set. Let K be the smallest set such that
 

	* K comprises R1-R4 , and

	* K comprises any logical consequence of anything that itcomprises.
 
K does not include a definition of what it is to be a sentence of L, and
R1-R4 is incomplete in that respect. A fortiori K does not include a definition of what it is to be a true sentence of L, and R1-R4 is incomplete in that respect.
 
 
 
Chapter 10 Analytic truth vs. formal truth (2014)
 
"Formally true" is synonymous with "syntactically true.”
 A truth is analytic just in case its truth-value is determined by its own structure and by the structures of the concepts composing it. Thus,
 

	* If there is no government in a given area, then there is no law inthat area (since laws are among the instruments of government),
 
is an analytic truth, and so is:
 

	* Unless a given entity is sentient, it is incapable of being literate(since anything that is literate is ipso facto sentient).
 
Mathematics (pure, not applied) and logic consist entirely of analytic truths. Cf.
 

	* x isn't a triangle unless it's the area bounded by three coplanarlines such that any given two of them intersect but not all three of them intersect;

	* There is no consistent, complete axiomatization of elementarynumber theory;

	* The extension of an infinitely large class cannot be definedextensionally and must therefore be defined intensionally;

	* All recursive definitions are intensional but not all intensionaldefinitions are recursive.

	* If a given region R of spacetime is three-dimensional with respectto one definition of "point," there is another definition of "point" relative to which R is 2 dimensional and another relative to which it is fourdimensional.
 
 
1-7 have an important property in common: they are not formal truths. T is a formal truth iff it is an instance of a statement-form all of whose instances are true. Examples of formal truths:
 

	* 5=5

	* If grass is green and Mary is tall, then Mary is tall.

	* If 2 is even, then, for some x, x is even.

	* If 'snow is white' entails 'grass is green', and 'grass is green'entails 'dragons eat tigers,' then 'snow is white entails 'dragons eat tigers.'
 
 8/9/10/11 is an instance of 12/13/14/15. There are no false instances of 12/13/14/15. Hence, each of 8/9/10/11 is a formal truth.
 
Statements vs. statement-forms
 
 It is important to distinguish bona fide statements from statementforms. Statement-forms are not truths; nor are they falsehoods. Nothing is true or false if it contains a free variable. Thus, none of the following is a formal truth, since none is either a truth or a falsehood:
 

	* x=x

	* If P and Q, then P.

	* If a has phi, then, for some x, x has phi

	* If P entails Q and Q entails R, then P entails R.
 
12-15 are statement-forms all of whose instances are truths, that being they are described as 'laws of logic.'
 Nota bene: This last statement is subject to some heavy qualifications
 First, there are many instances of 12-15 that are false, it being one of the purposes of this paper to identify a class of sentences that invalidate (the likes of) 12-15. For example, "that guy is identical with that guy," which is an instance of the sentence-form "x=x," is false, if, as may well be the case, the first occurrence of "that guy" refers to one person and the second refers to some other person. We will find that, given any given one of the sentenceforms typically described as "laws of logic," it is easier to find false instances of that sentence-form than it is find true ones; and we will find some reason to believe that, given any sentence that appears to be a true instance of one of those sentence-forms, careful scrutiny of its syntactic structure indicates that it is not in fact such an instance.
 That said, there is a large and explanatorily important class of truths any given one of whose members is an instance of 12-15; and it is for that
reason that the likes of 12-15 are described as 'logical truths')  Second, formal truth is a doubly relative concept.
 First of all, sentences are not themselves truths or falsehood. When it is said of a sentence that it is true, what is meant is that it expresses a true proposition. The proposition meant by "snow is white" is true, and so is the proposition meant by the L-translation, for any language L, of "snow is white." "Snow is white" is not identical with "la neige est blanche" or "le nieve es Blanca,' but all three sentences encode the same proposition.
 So when it is said of a sentence S that it is "true," what is meant is that it expresses a truth, not that it is a truth. When it is said of a proposition P that it is true, what is meant is that it is a truth, not that it expresses a truth. Thus, the word "true" has one meaning in "the sentence 'snow is white' is true" and an entirely different meaning in: "it is true that snow is white." And when it is said of a given open sentence S* that it is 'true under all of its valuations,' what is meant is that, if S# is any given instance of S*, then S# expresses a true proposition. To say that S# is an instance of S* is to say that S* is what results when at least some of the constants in S# are replaced with variables.
 Secondly, supposing that S is a statement that qualifies as 'formally true,' with respect to the two just-cited criteria, it still cannot be said, without further qualification, that S is formally true. For supposing that S satisfies those two desiderata, what follows is not that S is formally true sans qualification but that S is formally true in certain respects. Given any sentence S, it is only relative to a certain definition of 'syntax' that S is formally true. Relative to one legitimate conception of syntax, "Bob is tall and Bob is not tall" has the same syntax as "Bob is tall or Bob is not tall." Relative to a different, equally legitimate conception of syntax, those sentences have different syntaxes.
 To be sure, the word 'syntax' is ambiguous, but that fact isn't relevant in this context. There is some one, unambiguous and precise delineation of the term 'syntax' relative to which these points hold, and those points
therefore have nothing to do with a failure to use the word 'syntax' in a uniform manner. Setting aside the fact that open-sentences are neither true nor false along with the fact that it is only relative to a language that a sentence(-form) is formally true, there is some one, perfectly precise definition of the term 'syntax' such that a sentence is 'formally true' in certain respects and not formally true in others.
 
 
The Concept of an Axiomatic System
 
 Two preliminary point: First---The natural numbers are 0 plus the posterity of 0 with respect to the relation predecessor of. Equivalently, the natural numbers are the smallest set that contains zero and is closed with respect to the successor-relation. In general, the posterity of x with respect to relation R is the smallest class K such that x belongs to K and such that anything to which anything bears R belongs to K. Equivalently, the posterity of x with respect to relation R is the smallest set K that contains x and that contains anything to which anything bears R.
 Second, "□P" means necessarily P, "◊P" means possibly P. The box and the diamond are modal operators.
 No more preliminaries: An axiomatic system[5] consists of two parts:
 

	* A set of statements or statement-forms that are stipulated to betrue; and

	* The posterity of that statement-set with respect to the relation oflogical consequence.
 
In this context, "statement" is ambiguous between statement and statement-form, it being a function of the context how a given occurrence of "statement" is to be disambiguated.
The members of the statement-set that are not axioms are theorems.
The members of that set, taken jointly, are a theory.
 Example: Consider the following axiom-set:
 

	1. If (P and Q), then P.

	2. If P, then (P or Q).

	3. Not both (P and not-P).

	4. Either (P or not-P).

	5. Not both (Q and not-Q).

	6. If ((if P, then Q) and P), then Q.

	7. If ((P or Q) and ~Q), then P.

	8. Alphabetic variants of one another have the same truth-value.

	9. If Q or P, then P,

	10. (~(~(P and Q) and (P and Q)) and ~(~(Q and P) and (Q and P)))
 
 But relative to 1*-3*, 11-13 are not syntactically true:
 

	* If □P2, then P2.

	* If □□P3, then □P3.

	* If □P6, then ◊P.
 
 
However, relative to the following axiom-set,11-13 are syntactically true:
 

	* If □P22, then P22.

	* If □□P23, then □P23.

	* If □P26, then ◊P26.

	* Alphabetic variants are truth-value-identical
 
 So whether or not a given well-formed formula is "formally true" depends on the identity of the relevant axiom set. Thus, the search for a definition of "formal truth," over and above the one given here is futile. Any true sentence is formally true with respect to some axiom set. When it is said sans qualification that a given truth is "formally true," what is meant, supposing it true, is that the relevant axiom-set is an important one.[9]
 
 
 
 
Redundancy
 
 
Consider Euclid's five axioms:
 

	1. Given any two points, there is a straight line that connects them.

	2. Any line segment is part of a line that does not terminate.

	3. Given any straight line segment LS, a circle CR can be drawn suchthat the center of CR is one of LS's endpoints.

	4. All right angles are equal.

	5. Given a straight line L and a point p not on L, there is exactly one
line L* that passes through p that does not intersect with L.
 
5. is the famous Parallel Postulate. For thousands of years, mathematicians tried to show that 5 was redundant, i.e. that it could be deduced from the other four.
 In the 1800s it was shown that 5 was not redundant. This was done by constructing a model in which 1-4 are true but in which 5 is false.
 Let S be a sphere. Let a "line" be a great circle. A 'great circle' is a continuous series of points on a sphere's surface that bisects that sphere. (The equator is a great circle.) Given two great circles, C1 and C2, that divide S's surface into four equal-sized areas, let a "right angle" be the angle formed by any one of the intersection points of C1 and C2.
 
1*. Given any two points, there is a straight line that connects them.
True: Given any two points on the surface of a sphere, there is a great circle that passes through both.

	1. Any line segment is part of a line that does not terminate.
True: Given any segment s of a great circle, and thus of a 'line', as we are using that term, no matter how much that line is extended, no point will be reached beyond which it cannot be further extended.

	1. Given any straight line segment LS, a circle CR can be drawn suchthat the center of CR is one of LS's endpoints.
True: A circle is the class of all co-planar points equidistant from a given point. Let LS be any line segment (any part of a great circle) on S. Let P be either one of LS's endpoints. If LS were to rotate, like the hand of a clock, with P as its axis of rotation, the area swept out would be a circle, in that the distance of each point on the periphery of that area would be identical with the length of LS and, for some single distance D, each such point's distance from P would be D.

	1. All right angles are equal.
True: Let C1 be a great circle that intersects the North and South Poles (as it were) of S, and let C2 be a great circle such that the four areas bounded by the intersection-points of C1 and C2 are of equal size. In that case, any given two right angles, as we are using the term, are obviously equal.

	1. Given a straight line L and a point p not on L, there is exactly oneline L* that passes through p that does not intersect with L.
False: Any two great circles intersect. Therefore, any two lines, as we are using this term, would intersect.
 
We have constructed a consistent model in which 1-4 are true and 5 is false. Therefore, the Parallel Postulate is independent of the other four.
 
 
Chapter 11 The logic of context-sensitive expressions (2014)
 
 
 
 In any sentence of English, or any other natural language, every sentence contains an indexical. An indexical is a context-sensitive expressions. Examples are "he", "that", "now", "today", and "I." Other examples are tense-markers (e.g. present-tense markers (such as "-s"), pasttense markers (such as "-ed"). If L is an indexical-free language
 
(i) L cannot express contextual information,
 
a consequence being that
 
(ii) There are many context-invariant relations of logical dependence that L also cannot express.
 
 
Let L be a language that contains no context-sensitive expressions. In that case, L is incapable of expressing perspectival information. It is not possible to say in L:
 

	* I am now tired.
 
One could say:
 

	* John-Michael is tired at 5:52 pm, June 14.
 
But (1) and (2) are completely distinct statements. For were I to say
 

	* I am tired, but it is not now 5:52 pm,
 
I would be speaking falsely, but not incoherently: I would not be in the position of somebody who claims that triangles have four sides.
 More importantly, the information borne by (2) is meaningful only relative to a non-egocentric frame of reference; i.e. it is meaningful only on the condition that one has access to a world-map (a map of the constituents of both space and time) that didn't embody the perspective of any specific being. There are two problems with such a map.
 First, in order to use such a map, one must be able to have an indexical-thought. If I am to use a map of the world, I must be able to have a correct thought of the form: I am there, where the 'there' corresponds to some particular place on the map. Similarly, if I am to understand non-perspectival utterances, e.g. "Peter is taller than Mary at 5:53 pm, June 14, 2014," I must understand perspectival utterances, e.g. "Peter is that guy; the present time is
5:53 pm, June 14, 2014."
 In general, non-perspectival information is parasitic on perspectival information: the latter generates the former. And non-perspectival utterances are parasitic on perspectival utterances: the latter generates the former.
 Science aspires to produce non-perspectival information---and rightly so, since natural laws are mind-independent. But scientific (nonperspectival) knowledge is painstakingly extracted from perspectival knowledge, and there is no way to acquire scientific knowledge except on the basis of perspectival knowledge. Consequently, there is no way to articulate science-critical data except on the basis of perspectival language and a fortiori no way to articulate the hypotheses that model that data.
 
 
Why indexical-free languages cannot express perspectival information (continued)
 
Also, the mind falls within the scope of science, and the same is therefore true of the subjective and the perspectival. It is a fact that perspectives exist, and science must model data-sets whose elements are perspectival perceptions and thoughts.
Also, if a language contains no indexical expressions, it is impossible to use that language to give names to people, places, and dates. Given a language in which is no equivalent of "that" or "now," there is no Ltranslation of:
 

	* That person is named "Jack"
 
or
 

	* Today will hereafter be referred to as "Martin Luther King Day."
 
In order to assign names in L to hitherto nameless entities, it is necessary to have use context-sensitive expressions. (If person x, wishing to name hitherto nameless person y, grabs y and repeatedly says "Jack," x is creating ad hoc a context-sensitive expression that does what his language, lacking as it does the requisite indexicals, is unable to do. This shows that non-non-perspectival languages (languages that don't contain indexicalexpressions) are parasitic on perspectival languages and, consequently, are really proper parts of perspectival languages.
 
Why there are non-perspectival truths that an indexical-free language is ipso facto unable to express
 
Surely
 
1. x is identical x
 
is a law of logic.
 
But
 
A. "That guy is identical with that guy"
 
is false if the two occurrences of "that don't co-refer.
 
Surely
 
2. If x has phi, then x does not not have phi
 
is a law of logic.
 
But
 
B. If that particle is at this exact moment in position p, then that particle is not not in position at this exact instant,
 
is false, for almost any given possible referent of either of occurrence of "that particle."
 
 
Surely
 
3. If xRy and yRz, then xRz
 
is a law of logic.
 
But
 
C. If Mary is currently further from the building than Larry and Larry is currently further from the building than Jerry, then Mary is currently further from the building than Jerry
 
is false, assuming, as we legitimately may, that not all three of the
occurrences of "currently" co-refer.
 
 
Why there are non-perspectival truths that an indexical-free
language is ipso facto unable to express (continued)
 
 
The so-called 'laws of logic' are not bona fide laws; they are
(supposedly) law-schemata. In other words, they are open-sentences that are (supposedly) true under interpretations of their constants. Put yet another, the so-called laws of logic are sentence-forms such that (supposedly) there no false instances of those forms, i.e. such that (supposedly) no sentence having one of those forms is false.
 But we have seen that there are false instances of those forms. For we have seen that context-sensitive sentences having those forms may be false.
 This does not necessarily mean that x=x and P→P are not laws (or law-schemata). It means that sentences of natural language do not validate those particular law-schemata (if that is in fact what they are); it means that, if K is a class of expressions whose members validate those (supposed) lawschemata, then the elements of K are not sentences of natural language; and it further means that the elements of K do not contain context-sensitive components.
 The elements of K: The expressions belonging to K cannot be sentences of natural language, since those are all context-sensitive. Those expressions could be expressions belonging to artificial languages. But if that's the case, then the discipline of logic studies artifacts: the subject-matter of logic has to be created post hoc to validate the so-called findings of logic. Other disciplines are responses to pre-existing subject-matters; logic's subject-matter is a response to it.
 Propositions do conform to the laws of logic. If taken to concern propositions, as opposed to linguistic expressions, each of the following is true:
 
(P→(P→R))→((R→Q)→(~Q→~P)),
(x)((y)(Fy)→Fx),
For all x, x=x,
For no x, Fx and not-Fx.
 
 The problem is that a system of logic is supposed to tell us how to manipulate linguistic expressions, and propositions are not linguistic expressions.
 Summary: It is not easy to find interpretations of the so-called laws of logic, which, in actuality, are law-schema, if there are models of them, and mere open-sentences, if there aren't. Supposing this true, the purpose of mathematical logic is to figure out how meaningless expressions can be combined in accordance with meaningless rules into larger meaningless expressions.
 
 
 
Chapter 12 Why Empirical Theories are not Formal Calculi (2014)
 
 
There are two different kinds of disciplines: empirical (observationbased) and strictly conceptual (or a priori). Biology, physics, psychology, economics are empirical. Mathematics, logic, and philosophy are strictly conceptual.
Empirical disciplines obviously avail themselves of the intellectual instruments created by strictly conceptual disciplines. Indeed, they are heavily dependent on such instruments.
But what even the most mathematics-heavy branch of physics is doing is fundamentally different from what is done by any given branch of any given non-empirical discipline. The objective of even the most mathematics-heavy branch of physics is to explain otherwise anomalous redistributions of mass-energy.
This is not the objective any given branch of any given non-empirical discipline. The objective of any given non-empirical discipline is to identify purely logical relations among concepts: it is to identify rules of inference.
 
 
Rules of inference identical with conditional propositions
 
Rules of inference have the form: if such and such is the case, then thus and such must also be the case. Thus, mathematics, logic, and philosophy (philosophy quite as much as the other, incidentally) identify truths of the form: it is incoherent to suppose that P is true and Q is false. Such disciplines do not assert that P is true, only that it cannot coherently be asserted that Q is false supposing that P is true.
Be it noted that, in this context, 'coherent' has a logical, not psychological meaning. Logically, the proposition that there are no continuous functions that cannot be differentiated at any point is neither more nor less coherent than the proposition that there are three-sided pentagons. For each is 100% incoherent, as each is conceptually false, in the sense that its own structure prevents it from being true. But given how obviously incoherent the second proposition is, no one would who was coherent in the psychological sense would bother to affirm it, even though an utterly sane person might very well affirm, as Kant did, that a continuous function is necessarily differentiable at all of its points.
 
 
What empirical scientists mean by the word 'theory'
 
Empirical scientists use the word "theory"; and mathematicians/logicians also use the word "theory"---but not in the same way as empirical scientists.
In the empirical sciences, a theory is given by a proposition that is intended to be explanatory and general.
P is an explanation of Q if the following conditions are all met:
 

	* Each of P and Q is an empirical proposition;

	* Q is known to be true;

	* P is not known to be true;

	* Q is an anomaly, i.e. it is a mystery why it is the case;

	* Supposing that P is true, Q is no longer an anomaly;

	* Supposing that P is false, Q is an anomaly;

	* P is compatible with what we know to be true, i.e. we do not have any reason to believe P to be false.
 
 
Not all explanations are theories. Suppose that, in order to explain the fact that all of the money in my wallet is gone, I correctly hypothesize that Larry, my unprincipled roommate, stole said cash. I have put forth an explanation; but that explanation is not a theory, at least not in the sense in which psychoanalytic theory/relativity theory/evolutionary theory are theories. Scientific theories are general: when correct, they explain entire categories of phenomena and, for that reason, correctly identify some structural fact about (some sector of) the universe.
It is not in general possible to explain an entire category of phenomena without positing entities (particles, forces, causal liaisons) not previously believed to exist. In order to explain the disappearance of my cash, I did not have to posit the existence of anything whose existence I did not already grant.
But in order to explain why a sealed vessel containing hot liquid is ceteris paribus more likely to burst than a sealed vessel containing cold liquid, it is necessary to posit such entities; for it is necessary to suppose that, contrary to first appearances, liquids consist of discrete particles. Supposing that liquids do in fact consist of discrete particles and that those particles obey the same physical laws that we know to govern other entities, the justmentioned fact is explained in the very same way as the fact that ceteris paribus more damage is done to a fortress by a million hammer blows than by 10 hammer blows.
 
 
What logicians/mathematicians mean by the word "theory"
 
When mathematicians/logicians use the word "theory," they are not referring to propositions that are need be either explanatory or general. In fact, they aren't even referring to propositions: they are referring to interpreted calculi.
A calculus is given an ordered pair (V,G), where V is a class of expressions and G is a grammar with respect to V. G is a grammar with respect to V if:
 
 

	* Given any sequence of members of V, G categorizes that sequences as acceptable (grammatical) or unacceptable (ungrammatical); and
 

	* G is recursive, meaning that it contains provisions making it possible to generate new admissible strings out of pre-existing such strings.
 
Bear in mind that the expressions in V do not mean anything: they are just ciphers (e.g. "x," "y," "z," "phi," "psi," and so forth); and, consequently, the rules belonging to G are completely arbitrary.
Thus, (V,G) is an uninterpreted calculus, meaning that the expression-strings belonging to it are meaningless, in the sense they are neither true nor false. ("x has phi" and "x bears R to y" are neither true nor false; each is an open sentence or, what is the same, a sentence-schema.)
An interpretation of a calculus is a function that assigns significances to the expressions of that calculus in such a way that the strings belonging to it are either true or false.
An interpreted calculus is therefore given by an ordered triple (V,G,M) where "V" and "G" are defined as before and where "M" refers to a function that assigns significances to the strings belonging to (V,G) in such a way that any given such string is either true or false.
An uninterpreted calculus is an inductively (recursively) defined class of expressions that are neither true nor false; an interpreted calculus is an inductively defined class of expressions that are neither true nor false; an interpreted calculus is an inductively defined class of expressions that are either true or false.
A 'theory', as logicians and mathematicians use this term, is simply an interpreted expression class. Such a class needn't be true or explanatory or general, even though it is hoped in many cases that it has all three virtues.
An example of such a theory is (P,A,R), where P contains the expressions "number," "successor" and "0: A contains the Peano Axioms (due to Dedekind); and R contain Russell's definitions of "0", "successor" and
"number."
Peano’s Axioms are:
 

	1. 0 is a number.

	2. 0 is not the successor of a number.

	3. Any given number has exactly one successor.

	4. The successor of a number is a number.

	5. If 0 has φ, and n+1 has φ whenever n has ϕ, then m has φ, where m is an arbitrary number.
 
 In 1-5, “0” and “successor” are variables, denoting, respectively, an undetermined entity and an undetermined relation. According to Russell, “0” and “successor” are to be defined as follows:
 
 

	* 0 is the empty set,

	* For all n, n is the smallest class that contains all n-tuples, and

	* n+1=m means that, given a class k such that k ∈ Kn, where Kn is the smallest class containing every n-tuple, if x ∉ k, then k ∪ {x} ∈ Kn+1.
 
 1-5, coupled with (i)-(3), constitute an adequate theory of arithmetic.
 
Empirical theories as interpreted formal calculi
 
Soon after Russell and Dedekind conducted their investigations into axiomatics, and because of those investigations, it was suggested that empirical theories were interpreted calculi.
Here is the idea. The just-mentioned theory, relating observable heatrelated phenomena to hypothetical molecular phenomena, is given by the ordered triple (V,G,M), where
 
 

	* V contains expressions (e.g. "molecule," "phase space,"
"Avogadro's number") that have no meaning independent of that theory;
 

	* Given a strings of expressions belonging to V, G says whether or not that string is admissible: In this case, G says that "a liquid's constituent molecules accelerate when the liquid is heated" is admissible; and G says that "a liquid's constituent molecules become less massive when the liquid is heated" is inadmissible;
 

	* M contains propositions that link the strings generated by (V,G) to observable phenomena; thus, M contains propositions such as "liquids and gasses consist of discrete particles that obey Newton's laws of motion (basically, the laws of ballistics)", which, if true, would indeed account for the relevant data.
 
According to proponents of this view, the statements in M are meaning-postulates: they assign meanings to otherwise meaningless theoretical terms.
As advocates of this view know full well, not all meaning-postulates assign theory-constitutive propositions to sentence-schemata. So they describe those meaning-postulates that do carry out such assignments as "bridge principles" (or, alternately, "correspondence rules"), so as to distinguish them from other meaning-postulates.
Be it noted that the term "bridge principle" is itself a theoretical term. If this analysis of what theories are is correct, then "molecule" and "electron" and other theoretical terms are given meaning in the just-described way, in which case there is such a thing as a bridge principle. But if that analysis is false, that is not how such expressions are given meaning, in which case there is no such thing as a principle, just as there is no such thing as phlogiston.
 Though untenable (see below), this analysis is not without merit. It is self-evident that observation-reports (e.g. there is an elephant in the room, there is a pencil on the desk) are meaningful. It is not self-evident that statements about forces (gravity, electricity, unconscious urges) are meaningful. The just-stated analysis, supposing it correct, solves this problem.
"Molecule," "id," "gravitational field," etc. are meaningless pending identification of the relevant bridge principles. Since those bridge principles establish relations of synonymy between various theoretical statements (e.g. "X's mean kinetic energy increased during a given interval," where X is the gas in some container C) and various observation-statements (e.g. "C's pressure and temperature increased during the interval in question").
 
 
Why this analysis is not tenable: First reason
 
Suppose for argument's sake that indeed
 
(T) Theoretical expressions and expression-strings are indeed meaningless, except in relation to such bridge principles. \
 
The propositions assigned to such strings by such principles are observation-reports. Statements about electron-jumps, molecular velocity, and unconscious longings are merely shorthand for statements about spectrumemission, pressure increases, and various conscious events and observable behaviors.
If this is the case, then it is not by positing states of affairs of which we do not knowledge that theories account for those states of affairs of which we do have knowledge. If this analysis is correct, theories merely organize statements about observable phenomena; they do not, contrary to first appearances, posit states of affairs that are distinct from observable phenomena and, since causation holds only between distinct entities, capable of causing them. T is false since T is inconsistent with this truth.
 
Second reason
 
 The observable consequences of a given hypothetical (theoretical) phenomenon are not fixed. As technology changes, they change; as circumstances vary, they vary. The technologies now available are distinct from those available in 1950. Consequently, the observable manifestations of an electron-jump are not what they were in 1950.
In general, if S is a theoretical statement, there is no finite list of nontheoretical statements S*1…S*n, such that S is equivalent with S*1…S*n (taken jointly). The list of non-theoretical statements corresponding to S is infinitely long; and there is no way to identify the members of that list except in terms of S itself. Thus, pace T, meaning flows from the theory-level to the observation-level, not vice versa.
 
Third reason
 
But the main problem with T is that it fails to distinguish between two senses in which a statement can be "meaningful."
On the one hand, a statement can be meaningful in the sense that it says, of some object x, that x has phi, for some property phi. ("There are elves living on the dark side of the moon, and these elves vanish without a trace whenever there is any chance of detecting them." This is a meaningful statement: for if it weren't meaningful, it wouldn't be ridiculous, since a ridiculous statement is one that has an obviously false meaning.)
On the other hand, a statement S can be meaningful in the sense that,
from a scientific perspective, it is worth considering. (Statements about moonelves fail this test. Statements about electrons pass it.)
T is false since it embodies a failure to distinguish between these two disambiguations of the word “meaningful.”
 
Fourth reason
 
If T is correct, then, given some data-set d1…dn, any hypothesis H that models d1…dn is ipso facto correct. For according to T, there is no difference between H’s being true and H’s modeling the data.
Given the presumption that there is a difference between H’s being true and H’s being merely data-consistent, it follows that T is false.
Given that this presumption can reasonably be questioned, the juststated argument is therefore not cogent. But that argument is cogent given the fact that, unless H is true, H will not be consistent with arbitrary enlargements of d1…dn. Any given finite data-set is consistent with infinitely many theories, since co-extensive finitary models need not be co-intensive. But non-finitary models cannot be co-extensive without being co-intensive (or, to be precise, without being co-hyperintensive: “x is a closed planar figure of uniform curvature” and “x is the area bounded by the class of all co-planar points that are equidistant from a given point” are co-intensive, meaning that α satisfies the one exactly if it satisfies the other, but they are not co-hyper intensive, meaning only that α is a closed planar figure of uniform curvature is not trivially equivalent with “α is the area bounded by the class of all co-planar points that are equidistant from a given point”).
 
Fifth reason
 
Given an empirical statement S, T correctly assumes that S’s being an observation-report is sufficient for S’s being meaningful, but incorrectly assumes that it is also necessary.
The statement
 
(S*) What we cannot perceive affects what we can perceive
 
cannot be true without ipso facto failing to be synonymous with any observation-report or class of observation-reports.
In fact, this truth is implicit in any given observation-report. I am not seeing (or otherwise sense-perceiving) X except to the extent that my psychological condition is the end-result of a causal series Σ initiated by some X-involving state of affairs. I cannot, while having a perception of X, senseperceive Σ, since I would then be perceiving Σ, not X.
But my observation-report has no bearing on the external world unless the observation in question is the result a Σ-similar series. In fact, Σsimilar series are inherently unobservable. Observations of such series, were such observations possible, would themselves be the final installments of such series. Owing to the consequent interference-effects, such observations would be inaccurate, and we could not possibly know on strictly observational grounds exactly how inaccurate.
Thus, implicit in any observation-report OR is the assumption that OR itself is inaccurate unless some other statement NR is accurate, where NR is not an observation-report and, moreover, NR cannot possibly be justified on strictly observational grounds.
We may conclude that T is false and in fact deeply incoherent.
 
 
Chapter 13 Numbers as Ordered Pairs (2014)
 
Abstract: According to Frege, n=Kn, where n is any cardinal number and Kn is the class of all n-tuples. According to Von Neumann, n=Kpn, where Kpn is the class of all of n's predecessors. These analyses are prima facie incompatible with each other, given that Kn≠Kpn, for n>0. In the present paper it is shown that these analyses are in fact compatible with each other, for the reason that each analysis can and ultimately must be interpreted as being to the effect that n=Cn, where Cn is the class of all ordered pairs <Kn#,Rn#>, where Kn# is an arbitrary class and Rn# is an arbitrary relation such that a class k has n-many members exactly if k bears Rn# to Kn#.
 
 According to Frege, the cardinal number n is Kn, where Kn is the class of all n-tuples. (Thus, Ø=0; K1=1; K2=2; and so on.) According to Von Neumann, the cardinal number n is Kpn, where Kpn is the class of all of n's predecessors. (Thus, Ø=0; {Ø}=1; {Ø,{Ø}}=2; and so on.)
 These analyses seem to be incompatible, given that Kn≠Kpn, for n>0. At the same time, each analysis is viable, given that the content of any statement of the form "…n…" is perspicuously represented---i.e. represented in such a way that its inferential properties can be read off of its syntax---by some statement of the form "… Kn…" and also by some statement of the form "…Kpn…". We thus have a paradox: Kn≠Kpn and yet n=Kn and n=Kpn.  In an attempt to deal with this paradox, some philosophers have taken the desperate measure of saying that numbers, and therefore relations among numbers, do not exist mind-independently. Those authors who have rejected this position have failed to identify an entity with which a given cardinal number both can and must be identified.
 We will now identify just such an entity.
 Frege's analysis can be interpreted as being given by the proposition that, for any cardinal n, n=<Kn, ∈ >, where ∈ is the relation between classmember and class; and Von Neumann's analysis can be interpreted as being given by the proposition that n=<Kpn,≈>, where ≈ is the relation between set and equipollent set. Thus, if KJ is the class of John's cars, then Frege's analysis maps (i) John has exactly one car onto (ii) KJ ∈ K1, whereas Von Neumann's analysis maps (i) onto (iii) KJ≈Kp1.
 This suggests that, for any cardinal n, n can be identified with the class Cn of all ordered pairs <Kn#,Rn#>, where Kn# is any class and Rn# is any relation such that a class k has n-many members exactly if kRn#Kn# (read: k bears Rn# to Kn#). Thus, 0=C0={<K0#,R0#>│(k) (kR0#K0#↔k ∈ K0)}, where K0={k│(x) (x ∈ k↔x≈Ø)}; 1=C1= {<K1#,R1#>│(k) (kR1#K1#↔k ∈ K1)}, where K1={k│(x) (x ∈ k↔x≈{Ø})}; 2=C2= {<K2#,R2#>│(k)
(kR2#K2#↔k ∈ K2)}, where K2={k│(x)(x ∈ k↔x≈{Ø, {Ø}})}; and so on.
 Given an ordered pair< K,R>, let us use the notation <K,R>n to indicate that <K,R> is an n-pair, meaning that a class k is an n-tuple iff kRK. For example,< K,R>2 ↔(k≈Kp2↔kRK). ("<K,R> is a 2-pair exactly if k's bearing R to K is necessary and sufficient for k's having two members.") For any cardinal n, Cn is the smallest class containing every n-pair. Each of <Kpn,≈> and <Kn, ∈ > is an n-pair, and there are obviously others. What each Cn-member <x,y> has in common with each of <Kn, ∈ > and <Kpn,≈> is that <x,y> represents n's structure and is thus, as we might put it, an n-isomorph.
Since nothing that isn't in Cn is an n-isomorph, membership in Cn is both necessary and sufficient for possession of the structural properties, and therefore of all of the properties, that are individuative of n. Therefore, a given cardinal n not only can but must be identified with Cn. Therefore, n=Cn={<x,y>│<x,y>n}.
 For any cardinal number n, n=Cn. This analysis is consistent with the fact that any n-pair adequately represents n's structure and also with the fact that any adequate representation of n's structure is an n-pair. But unlike the analyses of Frege and Von Neumann, our analysis is consistent with the presumption that there is only one entity that can be identified with n. [12]
 
Chapter 14
Alan Turing’s Analysis of Computation and its Significance for
Psychology (2014)
 
 
 
The mind is an information-processing system. An informationprocessing system is anything that converts information into information. Through our eyes, ears, and other sensory organs, we upload information about the external world. Our central nervous system processes this information. It then outputs beliefs, which in turn eventuate in worldtransformative action.
Your PC is an information-processing system. Information is uploaded, converted, and then downloaded. The same is true of all computers. To that extent, computers are not so different from the human mind.
But the similarities end there. All computers are informationprocessing systems, but not all information-processing systems are computers. The human mind is an information-processing system that is not a computer.
No one did more to demonstrate this than Alan Turing. And yet no one had a greater role than Turing in the development of the modern computer. These two achievements of Turing’s are tw o sides of the same coin, as we will see.
This paper is divided into two parts. In the first part, we will describe Turing’s analysis of computability. This analysis is the foundation of contemporary computer science. In the second part, we will discuss the bearing of Turing’s analysis on the question: Are we computers?
 
 
Part 1: Turing’s Analysis of Computability
 
 
 
Turing did not himself create a physical computer; nor did he create a computer program. What he did was much more important. He created a meta-program---a blueprint for creating programs---known as the Universal Turing Machine. The Universal Turing Machine is really just a very precise description of what it is to compute the solution a problem.
Not all cases of finding a solution are cases of computing a solution. A solution that is known on the basis of intuition or informal reasoning is not computed. To compute a solution is to use an algorithm to identify it.
An algorithm is a mechanical procedure. In elementary school, you learned rote procedures for adding and multiplying multidigit numbers. These are examples of algorithms.
The algorithms for multiplication and addition are concerned not with numbers or mathematical operations, but with physical inscriptions---not with the number 5 or the operation of addition, but with instances of the corresponding expressions. According to these algorithms, whether a given inscription or inscription-sequence is permissible is a function of its shape, not of its meaning. Thus, the ability to carry out such an algorithm has to do with sensitivity to symbol- shape, not with sensitivity to symbol-meaning. For this reason, machines can implement them and, in so doing, solve arithmetical problems.
All algorithms are concerned with the geometrical or otherwise strictly physical properties of objects; none are concerned with their semantic properties. For this reason, algorithms can be implemented by machines.
In the early 20th century, algorithms were invented for deducing statements from other statements. Thus was created the discipline of mathematical logic, the purpose of which is to mechanize the drawing of inferences. Computer science grew out of mathematical logic. With the advent of computer science, there arose questions, both practical and philosophical, as to the similarities, or lack thereof, between minds and computers.
By producing a precise and rigorous analysis of the concept of computation, Alan Turing made it clear how to resolve many of these controversies. The essence of Turing’s analysis can be stated in one sentence: If a problem can be solved in a mechanical fashion, the solution is the output of a recursive function.
We will start by saying what this means. Then we will say why it is true. Finally, in Part 2, we will discuss the bearing that it has on the question: Are we computers?
 
 
Explaining Turing’s Analysis
 
Let us start by defining the term “recursive function.” First of all, a recursive function is a mathematical function. A function in the mathematical sense is a rule that assigns outputs to inputs. Consider the function F of x=x+1. This function assigns 2 to 1, 3 to 2, and so on. In other words, 2 is the output if 1 is the input, and 3 is output if 2 is the input.
A function need not assign numbers to numbers. In fact, the great innovations in mathematical logic underlying computer science were made possible by the discovery that some of the most important functions have nothing to do with numbers. The functions dealt with by Boolean Algebra fall into this category, as do the functions dealt with by the propositional calculus.
Both disciplines are indispensable to computer science.
A function cannot assign different outputs to a given input.
Otherwise, there are no limitations as to what a function may assign to what.
A recursive function is one that is defined for each of its own outputs. Consider the series: 2, 4, 16, 256, 65,536…This series is generated by a recursive function, namely: F of 1=2 and F of n+1=(F(n))2. This function assigns a 2 to the number corresponding to first position in the series---this number being 1, of course---and, if it assigns n to the number corresponding to a given position in the series, then it assigns n2 to the number corresponding to the subsequent position.
For reasons that will emerge, all series of infinite length are generated by recursive functions. For example, the series 0, 1, 2, 3,… is generated by the function: F of 1=0; F of n+1=n+2.
A recursive function is defined by (1) a rule that explicitly assigns a certain output to an initial input, along with (2) a rule for generating the output to any given input, apart from the initial input, on the basis of the output to the previous input.
Arithmetic is based on the following recursions:
 
(1) n+0=n and n+(m+1)=(n+m)+1 (2)n×0=0 and n×(m+1)=(n×m)+n (3) n0=1 and nm+1=nm×n.
 
Given enough time, any sum, product, exponent can be computed. If 0 is one of the operands, the answer is explicitly given. Otherwise, the answer is obtained by repeating the rule contained in the second part of the relevant recursion.
Thanks to (1)-(3) arithmetic requires no thought at all. It is therefore possible to create machines that solve problems of arithmetic as unthinkingly, but also as unerringly, as those that create hubcaps.
Wherever there is a recursive function, there is a mechanical decision procedure.
According to Turing, the converse also holds: wherever there is a decision-procedure, there is a recursive function. In other words, if the problem can be solved in a mechanical fashion, the solution is the output of a recursive function.
 
Evaluating Turing’s Analysis
 
The justification for Turing’s claim lies not in a formal proof, but in considerations of a philosophical nature, which we will now state.
First of all, a list of true arithmetical statements, e.g. “5+3=8” and
“72=49”, is not a decisionprocedure. Such a list presupposes an existing way of acquiring the relevant sort of knowledge. Therefore, to the extent that such a list is available, a decision-procedure cannot add to what we know. But a decisionprocedure that cannot add to what we know is no decision-procedure at all.
More importantly, a decision-procedure is of its very nature general. A list of truths is a record of pre-existing knowledge. Since a decisionprocedure is a way of acquiring new knowledge, no list of truths is a decision-procedure. It follows that a decision-procedure must apply to infinitely many cases that it does not explicitly mention. And this means, as we will now see, that any given decision-procedure must contain conditional information: information to the effect to the effect that if such and such holds (e.g. if n is even, n+1 is odd).
There are two ways of acquiring new information. One is by using our senses, that is, by observing the world. The other is by reasoning, that is, by drawing conclusions from what we already know. In using one’s senses to acquire knowledge, one obviously isn’t using a decision- procedure. Therefore, the first way isn’t relevant in this context, it being the second way that that we must consider. The second way necessarily involves knowledge of conditional truths: truths of the form if such and such is the case, then thus and such is also the case.
So far as decision-procedures enable us to add to what we know, it is by virtue of embodying conditional truths.
But decision-procedures cannot be strictly conditional, since they tell us that thus and such is the case, and not merely that thus and such is the case if such and such is the case.
To the extent that a given decision-procedure applies to infinitely many cases, it must be conditional. (Consider the second part of (3).) To the extent that it applies to any cases at all, it must be non-conditional. (Consider the first part of (3).) This means that, in order for a decision- procedure to work, it must contain non-conditional information.
It is therefore inherent in what a decision-procedure is that any such procedure contain two components:
 
 

	* A base-clause to the effect that such and such is the case; and

	* A conditional clause (usually referred to as an inductive clause, “inductive” being a synonym of “recursive”) to the effect that, if such and such is the case, then thus and such is also the case.
 
Any statement having this two-part structure is ipso facto a recursion. Thus, where there is a decision-procedure, there is a recursion; and, as previously observed, where there is a recursion, there is a decision-procedure. So Turing is right. A problem can be solved in a mechanical fashion---the solution to it can be computed, in other words---if, and only if, the solution is the output of a recursive function.
 
 
The Concept of a Turing Machine
 
Let us now discuss Turing’s ingenious way of illustrating these rather abstruse points. Imagine an infinitely long ribbon of paper that is divided into squares. This ribbon passes through a machine, one square at a time. Some of the squares are blank; others have markings on them. When a given square is inside the machine, the machine scans it. If the square has a marking on it, the machine can either
 
 

	* Erase that marking,

	* Add another marking,

	* Do nothing at all, or

	* Move one or more squares to the right or the left.
 
 
If the square is blank, the machine can either
 

	* Write a symbol on it;

	* Do nothing; or

	* Move one or more squares to the right or the left.
 
 
The machine’s behavior is predetermined by its program. This program consists of instructions to the effect that, if a given square’s condition is such and such, then the machine should do thus and such.
The two significant facts about this hypothetical situation are, first, that the machine can do nothing unless it is given data; and, second, that machine’s behavior is a function only of the condition of the square that it is scanning at that time, coupled with its program.
The tape’s condition prior to being scanned corresponds to the baseclause of a recursion, and the machine’s program corresponds to the inductive clause.
Turing proved that, given any problem that we would intuitively regard as being capable of being solved by a decision-procedure, the justdescribed machine can solve it.
A machine of the just-described kind that is limited to one program is a Turing Machine.
Such a machine that can run any program is a Universal Turing Machine.
If a given problem can be solved mechanically, it can be solved by a suitably programmed Turing machine and is thus “Turing-solvable.”
 
The intuitive basis for Turing’s analysis
 
There is a decision-procedure for a class K of problems just in case:
 

	* There is some finite class of expressions such that every problemin K can be expressed in terms of some finite concatenation of those expressions; and

	* Each member of K can be solved on the basis of its geometricalproperties, so far as those geometrical properties are determined by the interrelations of the primitive expressions composing it.
 
The point of (ii) is that, if we think of members of K as shapes on a Cartesian plane, any given such member M consists of a finite number of points and there is only a finite number of computationally relevant facts about M’s shape.
If K satisfies these two conditions, every computationally relevant fact about any given one of its members can be represented by marks on a Turing-tape, and a suitably programmed Turing machine can therefore respond appropriately to those marks.
 
 
A Turing-unsolvable Problem
 
 
 
Turing proved that not every problem is Turing-solvable. Consider the question:
 
 (T) Is every problem Turing-solvable?
 
For argument’s sake, suppose the answer to be “yes.” In that case, there is a program P, capable of being run on a Turing Machine, having the following property: Given any program F and given any input I, P can determine whether a Turing Machine running F will “halt” if given input I.
Given the existence of P, it follows that there exists a program Q such that, for any program F, Q can determine whether or not F halts if F runs F itself.
Given the existence of Q, it follows that there exists a program R such that
 

	* for any program F, R runs forever if, according to Q, F halts if F runs itself;
 
and also such that:
 

	* R halts if, according to Q, F runs forever if F runs itself.
 
 
Suppose that R runs on itself. There are exactly two possible cases to consider.
 
Case Number 1: Suppose that, according to Q, R halts if R runs itself.
In that case, by (1), R runs forever.
Case Number 2: Suppose that, according to Q, R runs forever if R runs itself. In that case, by (2) R halts.
 
In the first case, R runs forever if R halts. In the second, R halts if R runs forever. Thus, if R runs on itself, it halts if, and only if, it does not halt. Since this is not possible, there cannot be such a program as R. Since R exists if Q exists, Q does not exist; and since Q exists if P exists, P does not exist.
There is thus no way to compute the solution to the “Halting Problem.”
This does not mean that there is no way to solve that problem, only that there is no mechanical way to do so.
 
 
Part 2: Philosophical Implications
 
 
 
A computer is, by definition, a mechanical problem-solver. To say that a problem can be solved mechanically is to say that no thought is needed to solve it. Thus, if a computer can do it, thought is not required to do it.
Mechanical problem-solvers are not thinkers; they are thinker- proxies.
“But if computers don’t think,” it will be objected, “then they don’t solve problems.”
Computers don’t think, and they don’t solve problems. A mechanical ‘problem-solver’ is a non-problem-solver whose behavior makes it easy for an intelligent observe to solve otherwise difficult problems.
Suppose that 3+5= is entered into a properly functioning calculating device. That device is so structured that, on the basis of the physical characteristics of that input, it outputs 8. If it were on the basis of the meaning of that input that it decided what to output, it wouldn’t be a calculating device at all. By the same token, since it is a device, it is blind to the meaning of both input and output. Therefore, it cannot possibly be aware of the fact that the output was meaning- appropriate to the input, and it therefore has not in any literal sense solved anything. What it has done is make it easier for someone who does understand input and output to solve the problem in question.
Turing himself was very aware of the distinction between beings, such as ourselves, that actually problem-solve and beings, such as Turing Machines, that merely simulate problem- solving behavior. In his landmark paper On Computable Numbers, of which Part 1 of this paper is a summary, Turing points out that, by a “computer”, he means a person who computes--someone who uses a decision-procedure to solve a problem.
Intelligence is needed to create algorithms, not to implement them. The very purpose of an algorithm is to render thought unnecessary. We use algorithms to do arithmetic precisely because we wish to think as little as possible about arithmetic.
A corollary of the fact that we can create algorithms is that we can evaluate them. Given an algorithm, we are able to determine whether or not it yields the right results. There is no program whose legitimacy we cannot question. A computer cannot question its own program; for a computer cannot reject its own program. A computer could do so only if its program allowed it to do so. But if a computer rejects its program on the basis of its program, it is following that program and therefore isn’t rejecting it.
This argument, it will be noticed, bears a certain resemblance to
Turing’s proof that not all problems are Turing-solvable. It is suggestive that
Turing included that proof in the same paper where he describes Turing Machines. To be sure, Turing had reasons of a strictly discursive nature for doing so. But his decision to include it may have reflected a desire on his part to make it clear that Turing Machines merely simulate thought. Had he expressed himself more explicitly on this matter, a half century of psychological research might not have been wasted on the tragically misconceived notion that brains are digital computers.
 
 
Chapter 15 The Raven Paradox (2014)
 
The Raven-paradox, discovered by Carl Hempel (1945) is this:
 
As a matter of logic, sentences that are logically equivalent must be confirmationally equivalent, but there are logically equivalent sentences that are not confirmationally equivalent (e.g. ‘all ravens are black’ and ‘all nonblack things are non-ravens’).
 
 
 S1 and S2 are logically equivalent iff S1 entails S2 and S2 entails S1. (n=4 entails n=3+1, and n=3+1 entails n=4. Therefore, n=4 is equivalent with n=3+1.)
S1 and S2 are confirmationally equivalent iff, given any datum D, D confirms S1 to degree n iff D confirms S2 to degree n. (D: Two days ago, Smith had no cars, but yesterday he won four cars on a game show. D confirms n=4 and n=3+1, and it confirms them equally.)
 For S1 and S2 to be logically equivalent is, by definition, for neither to entail anything not also entailed by the other. It follows, by an indirect proof, that logical equivalence entails confirmational equivalence. Suppose that S1 and S2 are logically equivalent but confirmationally non-equivalent. Since they are confirmationally non-equivalent, there is some proposition S3 that confirms S2 more than it confirms S1. It follows that S3 is relatively unlikely to be false if S2 is true and also that S3 is relatively unlikely to be true if S1 is true. Thus, S2 entails that S3 is relatively likely to be true and S1 entails that S3 is relatively likely to be false. Thus, there is some proposition that S1 entails that S2 does not entail and there is some proposition that S2 entails that S1 does not entail. Thus, S1 and S2 are not logically equivalent, contradicting our hypothesis. Thus, confirmational non-equivalence entails logical nonequivalence. Equivalently, logical equivalence guarantees confirmational equivalence.
 
The original Raven Paradox stated in full
 
R1: All ravens are black (if x is a raven, then x is black).
R2: All non-black things are non-ravens (if x is non-black, then x isn’t a raven).
 
R1 and R2 are equivalent. (That is, they are equivalent if read extensionally, i.e. as concerning only actual, as opposed to possible objects or, equivalently, as concerning what must be as opposed to what is. Hempel doesn’t acknowledge that R1 and R2 can be read either extensionally or intensionally. When expounding Hempel’s theory, we will follow Hempel’s example in this regard. When critiquing it, we won’t.)
The equivalence of R1 and R2 is easily verified using Venn diagrams. But there’s a problem. Consider:
 
R3: x is a pink piano.
 
R3 confirms R2, but not R1. The pinkness of pianos has nothing to do with the blackness of ravens. But R3 would confirm R1 and R2 equally if they were logically equivalent. Since it doesn’t, they aren’t. But they seem to be. A paradox.
 
Another such paradox
 
M1: Heated metal expands (if x is metal, then x expands when heated).
M2: Heated non-expanders aren’t metal (if x doesn’t expand when heated, then x isn’t metal).
 
The equivalence of M1 and M2 is easily verified using Venn diagrams. But there’s a problem. Consider:
 
M3: Cube steaks shrink when heated.
 
M3 confirms M2, but not M1: The deflationary tendencies of heated meat have nothing to do with the expansionary tendencies of heated metal.
But M3 would confirm M1 and M2 equally if they were logically equivalent.
Since it doesn’t, they aren’t. But they seem to be. A paradox
 
Hempel’s solution
 
R3 does confirm R1 and R2 equally. We think otherwise because, our background beliefs being what they are, we believe it impossible that pianos should be ravens. We wouldn’t believe this if our background beliefs were different, and we’d therefore see that R3 per se is equally confirmatory of each of R1 and R2.
 Similarly, M3 does confirm M1 and M2 equally. We think otherwise because, our background beliefs being what they are, we believe it impossible that cube steaks should be made of metal. We wouldn’t believe this if our background beliefs were different, and we’d therefore see that M3 per se is equally confirmatory of each of M1 and M2.
 
The problem with Hempel’s solution
 
We can’t learn anything about ravens by studying pianos. We can’t learn anything about metal by studying meat. Hempel’s solution implies otherwise and is therefore false.
 
The actual solution
 
There are two ways to interpret any given statement of the form:
 
(1) All phi’s are psi’s (if x is a phi, then x is a psi).
 
1 can be interpreted (or ‘read’) extensionally or intensionally.  Read intensionally, 1 means:
 
(1*) For reasons of natural law, all actual phi’s are psi’s.
 
Read extensionally, 1 means:
 
(1#) By coincidence, all phi’s are psi’s.
 
 Some statements, e.g.
 
(2) all of the coins in JM’s pocket are quarters
 
are usually to be to be read extensionally. So 2 is usually to be taken
to mean:
 
(2#) By coincidence, all of the coins in JM’s pocket are quarter.
 
 But if there were some natural law or mechanism that required coins in my pocket to be quarters, then (2) would have to be read intensionally and thus taken to mean:
 
(2*) For reasons of natural law, all the coins in JM’s pocket are quarters.
 
M is usually to be read intensionally and is thus taken to mean:
 
(M1*) For reasons of natural law, metal objects expand when heated.
 
Read extensionally, M means:
 
(M1#) By coincidence, all things that don’t expand when heated aren’t metal.
 
M1* is not equivalent with M2. M2 is to the effect that a thing’s failing to expand when heated implies that it already isn’t metal, and it therefore implies that its failing to expand when heated cannot possibly cause it not to be metal. So M1* entails the negation of M2 and a fortiori isn’t equivalent with M2. An analogous argument establishes the non-equivalence of R1 and
R2.
 
Chapter 16 Zeno’s Paradox (2015)
 
In order to travel a distance of n yards, it is necessary to travel a distance of n/10 yards. In order to travel a distance of n/10 yards, it is necessary to travel a distance of n/100 yards. In general,
 

	* one cannot travel any distance at all without already havingtraveled some smaller distance.
 
Consequently,
 

	* Any given motion presupposes a prior motion.
 
A consequence of (ii) is:
 

	* There is no such thing as a stationary object’s beginning tomove,
 
Another consequence of (i) is:
 

	* There is no such thing as an object’s ceasing to be in a givenplace.
 
A consequence of (iv) is
 
(v) Nothing moves.
 
(i) is true. (v) follows from (i). But (v) is false.
How to solve this paradox?
 
Eugene Mills’ solution to Zeno’s paradox
 
For any possible universe U, there is some distance D such that nothing in U can move at all without covering a distance of at least D.
Explanation: Zeno has established that if any given motion presupposes another motion, then nothing can even begin to leave the place that it is occupying at a given time. Therefore, (i) must be rejected.
Assuming that (i) is false, it is not possible for there to no minimum, short of nullity, to the amount by which a given object moves. Therefore, in any world where motion is possible, there is some finite distance such that anything that moves in that world moves by at least that distance.
 
Problems with Mills’ solution
 
If Mills is right, then any given universe U consists of discrete cells such that, for any occupant x of U, x moves by vanishing from one cell and then appearing in another. x cannot move from one cell to the next, since there would in that case not be a minimum distance that x had to travel in order to travel at all.
A consequence of Mills’ position is that nothing moves. The assertion that
 

	* x spontaneously appears in one cell and spontaneously reappearsin an adjacent cell
 
is equivalent with the assertion that
 

	* x spontaneously ceases to exist and an x-like object that is notidentical with x spontaneously appears in a cell adjacent to that occupied by x.
 
 
If you are obliterated and some person who is exactly like you appears a moment later right next to where you were standing, that person isn’t you. Let you2 be that person. Given that you2 came into existence spontaneously, there are no lines of transmission linking him to the past and thus no lines of transmission linking you2 to you. Therefore, you2 is not you; and youn (n>2) isn’t identical with either you or with youi (1≤i<n).
If n is a sufficiently high number and there is a sufficiently small delay between youi’s disappearance and youi+1’s appearance, it will certainly appear that you had moved from one place to another. But that is obviously irrelevant.
In a Mills-universe, nothing has a past and, therefore, nothing has a future. Everything that exists, exists for an instant and then vanishes. There is no possibility of mutual causal influence among the occupants of a Millsuniverse.
Such a universe is no universe at all, since any given occupant of such a universe is in the very condition that it would be in if it were in a universe all by itself. Therefore, a Mills-universe is a non-universe.
Also, relative spatial and temporal position are to be understood in causal terms. Events are simultaneous if neither can affect the other; otherwise non-simultaneous. Since there is no causation in a given Milluniverse U, no U-occupant x can have either a spatial or a temporal position relative to any other U-occupant y. Thus, a Mills-universe is one in which there are neither places nor times.
In conclusion, Mills has given us a heap of absurdities, not a solution.
 
Bertrand Russell’s solution to Zeno’s paradox
 
The sum of infinitely many positive numbers may be finite (e.g. 1+½ +¼+…=2), and any finite number can be represented as such a sum. Therefore, the sum of infinitely many non-null motions may be a finite motion, and any given finite motion can be represented as such a sum. It is therefore no more of a mystery that any given motion should follow an infinite series of motions than it is that 2 should equal 1+½+¼+…
 
Problems with Russell’s solution
 
This is not a good solution. Zeno is asking how a given object can take that first step. He is asking how an object that moves 2 inches can move inch, and then another ½ inch, and then another ¼ inch, and so on. Russell hasn’t answered that question. He has only made the irrelevant point that if a given object can move that first inch, then it can, after an infinite series of further motions, move a second inch.
“The first step is the hardest,” said Mao Tse Tung. Once an object moves that first inch, all of the remaining inches are a foregone conclusion. This is the conceit underlying both Russell’s solution and Mills’. But each of these solutions merely begs the question, given that the very thing Zeno is asking is how that first step can be taken.
 
The actual solution to Zeno’s paradox
 
All position is relative position. Therefore, changes in position are changes in relative position. If x is the only occupant of a universe U, it cannot be said that x moves or a fortiori that x moves by a given amount. For there is nothing in relation to which x’s position can change.
Nor can it be said that x exists at a given time or for a certain period of time. For there is nothing that x either follows or precedes or with which it is simultaneous.
Therefore, the universe occupied by x comprises no spatiotemporal positions, except such as are internal to x’s proper parts. So far as there are relative positions or changes therein, they are strictly x-internal. x can equally be thought of as the sole occupant of U or as U itself. In either case, it is x’s proper parts to which relative positions and therefore changes in relative position can be ascribed and it is therefore x’s proper parts to which positions of any kind can be ascribed.
The sole occupant of a universe is that universe. Contrariwise, a space-time manifold has no existence independently of its occupants.
Position and change therein are multiply relative. Given only two objects, x1 and x2, it can be said that x1 and x2 are now further from each other, or closer to each other, than they were previously. But it cannot be said that either of them has changed its relative position by this or that specific amount. This is because, just as position is relative position, so distance is relative distance. If, in addition to x1 and x2, there is a third object x3, the distance between x1 and x2 can be compared with the distance between x1 and x3, and it can be said that the one distance either equals or exceeds the other. But unless there is a fourth object x4, it cannot be said by how much the one distance exceeds the other.
The more objects there are in a given universe, the greater the number of distances with which a given distance can be compared. The more such distances, the higher degree of precision with which a given distance can be meaningfully described.
Therefore, if x1…xn are the occupants of a given universe, changes in xi‘s position are capable of being small to the extent that n is large. It is the value of n that sets the metric. What we think of as a case of motion on the part of a given object xi is really a change undergone by x1…xn collectively. Seemingly system-internal changes are systemic changes. Therefore, to say that motion is continuous is to make the correct, if trivial, point that the class of changes capable of being undergone by a universe whose sole occupants are x1…xn is, for any number m, a proper subset of the class of changes capable of being undergone by an otherwise identical universe whose occupants are x1…xn…xn+m.
So when it is said that xi must move ½ inch in order to move an inch, and ¼ inch in order to move a ½ inch, and so on, the point being made is this:
 

	* Given any displacement d, no matter how small, if the universewere better populated and otherwise more heterogeneous than it currently is but all other factors, in including the laws of nature, were held constant, it would be possible for there to be an even more smaller displacement d*.
 
Given that xi moved .n inches is really an abbreviated way of describing a change collectively undergone by all of the universe’s occupants. Therefore, the meaning of (1) is given by the truth that:
 

	* No matter how well populated and otherwise heterogeneous theuniverse is, the universe is capable of being even more populous and otherwise heterogeneous; and for this reason the class of possible states of the universe is a proper subset of the class of possible states of a more heterogeneous but otherwise identical universe.
 
 
Let us consider the following statement in light of (2):
 

	* Any given motion consists of other, smaller motions; there is no
minimal unit of distance
 
Given (2), it follows that (a) has nothing to do with the structure of motion, its real meaning being given by
 

	* If K is the class of possible states of the universe as it currently isand K* is the class of possible states of an otherwise identical universe that is more heterogeneous than others, K is a proper subset of K*.
 
There is nothing paradoxical about (b). It is a truism, in fact. And there is no analogue of Zeno’s paradox that holds in connection with (b).
Systemic changes are too complex for us to understand with any precision. It is only by conceiving of them as system-internal changes that we can have any understanding of them. We should therefore expect contradictions to arise if we take such approximations as bona fide truths.
 
Chapter 17 The Coin Paradox (2015)
 
There are infinitely many quarter-sized regions on a flat table-top. Thus, if N is the exact number of quarter-sized regions, then, given any specific quarter-sized region, there is a 1/N=0 chance that a quarter dropped on that surface will occupy that exact region. But there is some quarter-sized region R that the quarter will come to occupy. Thus, there is 0% chance that the quarter will occupy R, and yet the quarter occupies R.
 In this context, N is aleph-one, this being the number of real numbers, which is also the number of distinct subregions of a surface.
The solution: 1/N≠0/N. To say that there is a 1/N chance that the quarter will occupy R is to say that the likelihood of its doing so is minimal but not nil. In general, p(e) is minimal if equal to 1/N, and nil if equal to 0/N, where p(e) is the probability of e.
Probabilities are given by real numbers, not by cardinal numbers. Real numbers are limits. For any n, nC≠1R, is the cardinal number 1C and 1R is the corresponding real.
1C is a class-size. Thus,
 

	* K’s cardinal number is 1
 
means
 

	* K is non-empty and, for some x, nothing belongs to K that isn’tidentical with x.
 
And for any n,
 

	* K’s cardinal number is n+1
 
means
 

	* If x is not a member of a class K* whose cardinality is n, thenthe cardinality of K* ∪ {x} is n+1.
 
By contrast, 1R is a degree, not a class-size. Thus,
 

	* x has property to P to degree n
 
means
 

	* If each of m1, m2, m3,…is a possible measurement of x, mi+1 always being more precise than mi, then, for any ε, there is some k such that the difference between mk and n is less than ε.
 
 Thus, nR, for any n, is given by an infinite series a1, a2, a3 …that converges on n, meaning that, for any ε, there is some k such that the difference between ak and n is less than ε. p(e) is minimal, as opposed to nil, if p(e) is a given by a series a*1, a*2, a*3 …that converges on 0 such that a*i>0, for all i. p(e) is nil, as opposed to minimal, if p(e) is given by the degenerate infinite series 0,0,0,….
In the first case, e, though possible, could not possibly be less likely without being impossible. In the second, e is impossible.
 
Chapter 18 Vagueness
 
The word “indeterminate” has two meanings. The sentence:
 
(BW) “Bill’s whereabouts are indeterminate,”
 
can be taken to mean either:
 
(BW1) given the available information, it isn’t possible to arrive at a principled judgment as to where Bill is.
 
or
 
(BW2) there is no fact as to where Bill is.
 
 BW2 cannot possibly be true. At any given point in time, there some space-time region R is such that Bill is occupying R. Of course, half of Bill's body can be in the garage while the other half is in the drive way. But that’s because the region he is occupying is itself half in the garage and half in the driveway; it is not because there is no region that Bill is determinately occupying. The same points mutatis mutandis hold of any other proposition to the effect that the world per se is indeterminate in any respect. In any case, this is what the present author believes.
 But many disagree, and their reasons for doing so initially seem to be good ones. For there certainly seem to be cases of objects with vague boundaries. In fact, all spatiotemporal objects, it would seem, have vague boundaries. Given any person P, there are many particles x such that one cannot non-arbitrarily say that ‹x is a part P's body› is true or that it's not true. This apparent fact is one that has led many a philosopher to hold that there is objective indeterminacy.[13] But we'll now see that such philosophers haven’t considered all the possible ways of modeling our intuitions.
 
Non-epistemic indeterminacy
 
 Smith doesn’t have a full head of hair; but there are a few tufts of hair on his head, in between which there is fuzz of varying degrees of thickness and density. Bearing this in mind, consider the statement:
 
 (SB) “Smith is bald.”
 
Is SB true or false? Many philosophers, probably most, would hold that:
 
(OV) There is no fact of the matter; and that fact has nothing to do with ignorance on our part. Here’s what’s going on. There exists a certain property P that of baldness and a certain person x. (P = the property of baldness. x = Smith.) And x doesn’t exactly instantiate P, but x doesn’t exactly fail to instantiate P. There is no fact as to whether the proposition x has P is true. It isn’t that we don’t know whether it’s true; it’s that there is no fact of the matter.
 
 Here’s the problem with OV. For argument’s sake, suppose that it is objectively indeterminate whether Smith is bald. Suppose, in other words, that the proposition (not the sentence):[14]
 
(SB) Smith is bald, is true.
 And, so let us also suppose, the reason SB is vague is that it is objectively indeterminate exactly what conditions a given thing must satisfy to be bald.
 Given these suppositions, it is ipso facto indeterminate what exactly SB entails and what is entailed by it. If it is objectively indeterminate exactly what features a thing must have to be bald, then it is for that very reason indeterminate, for any x, exactly what entails, and also what is entailed by, the proposition (not—nota bene—the sentence):
 
(XB) ‹x is bald›,
 
for any x.
 Thus, a consequence of the supposition that SB is objectively indeterminate is that it is indeterminate what SB entails and also what is entailed by it.
 But the very idea of such a proposition is not a coherent one. Propositions are individuated by what they entail. Different entailment relations, different propositions. So until the entailment relations of some sentence-like string of verbiage have been fixed, no proposition has been identified to that verbiage; and all we have is, at most, a sentence-schema.
 
An objection to the argument just presented
 
 
 It is said that:
 
(ER) Propositions are not individuated by their entailment relations. The proposition that 1 + 1 = 2 obviously isn’t identical with the proposition that triangles have three sides. But a given proposition entails/is entailed by the one just in case it entails/is entailed by the other.”
 
 Obviously 1 + 1 = 2 and triangles have three sides are different propositions. But contrary to what ER assumes, they don't coincide in respect of their entailment relations. The way in which for some n, n + 2 follows from 1 + 1 = 2 differs—quite dramatically—from the way (or, rather, any one of the infinitely many possible ways) in which for some n, n + 2 follows from triangles have three sides. A corollary is that, until it is settled what the entailment relations are of a given sentence, it ipso facto hasn’t been settled which proposition is meant by that sentence. (This doesn’t mean that one has to know what all of those relations are. No one knows what all of the entailment relations are of “1 + 1 = 2.” But, the semantic rules of the English language being what they are, it is indeed fixed what those entailment relations are.)
 What a sentence says---or, to be precise, what is affirmed by a nonabortive indicative token of that sentence ---is a function of exactly two things: first, what follows from that sentence-token (supposing it is true); second, how those things follow from it (same qualification). Given a sentence-token S, once what it entails and how it entails it are fixed, there is nothing left to be said about what it means. By the same token, if it isn’t fixed what S entails or how it entails it, it has yet to be fixed what S means. Thus, a sentence such that there is no fact as to what it entails, or as to how it entails what it entails, is a sentence to which no one proposition has been assigned.
 Bearing these points in mind, suppose the following. P is a true proposition. There are propositions P1….Pn such that, for each i, it is objectively indeterminate whether P entails Pi. Thus, P ipso facto leaves it open whether Pi is true. But if P leaves it open whether Pi is true, then P determinately fails to entail Pi. That doesn’t mean that P entails the negation of Pi. (Snow is white doesn’t entail grass is green or grass is not green. A proposition may be compatible with another proposition and with its negation.)
 The believer in indeterminacy has but one way of dealing with this argument. He is forced to say that, although there is no fact as to whether P entails Pi, nonetheless P does not leave it open whether Pi is true. But this position is tautologously false.
 Here is a similar argument. Suppose there to be some propositions P* such that (i), for any given proposition, it is determinate whether P* entails that proposition and, therefore, that it is determinate, for any i, whether P* entails Pi but such that (ii), with that qualification, P* entails a given proposition iff P also entails it. Is P identical with P*? It cannot be. For P* has, whereas P lacks, the property of being such that there is a fact as to whether it entails Pi, for some i. Thus, P is distinct from any proposition P% such that P%, supposing it true, settles whether or not Pi is true. So P fails to settle whether or not Pi is true and thus fails to entail it or its negation. So the statement “P entails Pi” is determinately false.
 Were there indeterminate statements;, i.e., statements such that there was no fact as to whether what they affirmed was true, there would be pairs of statements such that there was no fact as to whether the one entailed the other (or, therefore, whether it entailed its negation). But given any such pair, the one ipso facto leaves it open whether the other is true and thus determinately fails to entail (the negation of the other), an immediate consequence being that there is a fact as to whether the one entails the other. So the concept of a proposition such that there is no fact as to whether it is true is an incoherent one, and the same is therefore true of the concept of objective, as opposed to epistemic vagueness.
 
Chapter 19 Three Different Kinds of Sorites Paradoxes (2010)
 
Consider the following paradox.
 
 
Paradox #1 (P1): A person with only one dollar is poor. If a person with n dollars is poor, then so is a person with n + 1 dollars. It follows that a person with a billion dollars is poor. But, obviously, a person with a billion dollars is not poor.
 
 
 For reasons that are of no philosophical importance and that, in any case, will soon become clear, P1 is an example of what is known as the “Sorites Paradox” (a.k.a., the “Paradox of the Heap," “Sorites” being the plural of the Greek word “soros," which means “heap”). There are three different kinds of Sorites paradoxes, P1 being an example of only one of those three kinds. We’ll now outline solutions to all three kinds, beginning with the kind instantiated by P1.
 Here is an outline of the solution to P1: Like most predicates, “poor” is a relational expression. Smith may be poor compared to Jones but wealthy compared to Green, or he may be poor relative to the standard set by some situation and wealthy relative to the standard set by some other situation. If Smith is a millionaire who needs to have a net worth of at least 50 million dollars to become a managing director of company X, he is poor relative to the standard of wealth that, given Smith’s desire to become a managing director of X, is the relevant one. So an utterance of ‘Smith is poor’ is correct if made in a context in which the relevant standard of wealth is set by Smith’s desire to become a managing director of X. For, in such a context, a "poor" person is one whose net worth is less than $50,000,000. For that very reason, it follows that, in such a context, there is a number n-- namely, 49,999,999--such that an utterance of ‹x is poor› is true if x has n dollars and false if x has n + 1 dollars.
 Bearing these points in mind, it’s clear how to solve each member of the infinitely large class of paradoxes to which P1 belongs. Consider the following paradox:
 
(P1#) If a person’s top running speed is 1 mph, then that person is slow. For any number, if a person whose top running speed is n mph is slow, then a person whose top running speed is n + 1 mph is also slow. Therefore, a person whose top running speed is 75 mph is slow.
 
A story, structurally similar to the one just told, will make it clear how to solve this paradox. At his best, Smith runs a 100 yard dash in 12 seconds. Smith tries to join track team X. In order to qualify for team X, one must run a 100 yard dash in no more than 10 seconds. Obviously Smith doesn’t make the team. Smith then decides to join team Y. In order to qualify for team Y, one must run a 100 yard dash in no more than 100 seconds. Smith obviously qualifies for Y.
 If made in a context in which the relative standard of swiftness is set by Smith’s desire to join X, an utterance of “Smith is fast” is false. But such an utterance is true if made in a context in which the relative standard of swiftness is set by Smith’s desire to join Y. In a context of either kind, there is some number n such that an utterance of ‹x is slow› is true if, at his best, x’s average speed when running the 100 yard dash is n and such that an utterance of “x is fast” is true if x is person whose average running speed when running 100 yards is n + 1.
 In a context of the first kind, n is any number such that if a person whose average speed when running a 100 yard dash is n and who, for that reason, runs the 100 yard dash in over 11 seconds but who, if his speed when running the 100 yard dash were n + 1, would run it in under 11 seconds. The same thing mutatis mutandis holds of contexts of the second kind.
 
These points generalized
 
 To generalize these points, we must note a fact about language— more specifically, about predicates.[17] Some predicates are binary. P is a binary predicate if the property it expresses is one that cannot be had to varying degrees; it is one that a given thing either has or doesn’t have. So “even” (as in “even number”) is a binary predicate. Sorites paradoxes always involve non-binary predicates (i.e., predicates that express properties that can be had to varying degrees), e.g., “fat,” “tall,” “smart.” A corollary is that Sorites paradoxes always involve properties that one thing can have to a greater extent than some other thing. One thing can be smarter than another.
 Bearing these points in mind, consider the following three sentences:
 

	* Smith is smart.

	* Smith is more smart than Jones.

	* Smith is smarter than Jones.
 
(ii) and (iii) are synonyms. In effect, (iii) is just an abbreviation of (ii). Surely, the occurrence of “smart” in (i) has the same meaning (picks out the same property) as the homonymous expression in (ii). This wouldn’t be possible if, in (i), the occurrence of “smart” picked out a binary (nonrelational) property. This shows that “smart” is always relational. This, in its turn, shows that tokens of (i) are elliptical for sentence-tokens that expressrelational propositions---sentence-tokens having the form:
 
 (i#) “Smith is smarter than___,”
 
 or perhaps:
 
 (i*) “Smith is smart enough for__.”
 
 So tokens of “Smith is smart” must be elliptical for sentences such as “Smith is smarter than Jones” and “Smith is smart enough to solve the puzzle.” Exactly similar points hold of other non-binary predicates. The meaning of “x is fast” is given by some sentence having the form “x is faster than y” (e.g., “Smith is faster than Jones”) or having the form “x is fast enough to satisfy standard S” (e.g., “that plane is fast enough to make it to Pittsburgh by 3:00 P.M.").
 
A confusion side-stepped
 
 Here I would like to head off a source of serious confusion. I am not advocating the view that at the level of semantics “Smith is smart," “Jones is tall," etc. express relational propositions of the just-mentioned kind. It cannot be assumed that the philosophical insights needed to solve puzzles that turn on facts about language are themselves encoded in the semantic rules of English (or of whatever language happens to be the relevant one). So the juststated analysis is not a semantic analysis; it is not an attempt to identify the semantic rules that assign meaning to sentences of the form “x is P," where P is an arbitrary non-binary predicate.
 It makes no sense to say that some number is more even than some other number. But this has nothing to do with language; it has to do with the property of being even. The sentence “6 is more even than 8," though absurd, does not run afoul of the semantic (or syntactic) rules of English. (Or, if it does, it is only because we have ex post facto projected our mathematical insights into syntactico-semantic rules of English. And were some mathematician to show that evenness came in degrees, it would come to be grammatical---if it isn’t already---to say ‹x is more even than y.›) Clearly, “two is even” is not semantically or otherwise elliptical for some sentences of the form ‹x is more even than y› or ‹x is even enough to satisfy standard S.› But unless we implausibly suppose that our knowledge that evenness doesn’t come in degrees is coded into the semantic rules of English---unless we implausibly endow the semantic rules of English, which can be mastered by somebody who wrongly believes that evenness does come in degrees, with our mathematical knowledge---then ‹x is even› is not, at the level of semantics, elliptical for “x is more even than y” (etc.).
 This reasoning mutatis mutandis shows that at the level of semantics ‹x is fast› isn’t elliptical for ‹x is faster than y› (etc.). For, were we to say otherwise, we’d be endowing the semantic rules of English with our (extralinguistic) knowledge of the fact that, indeed, swiftness comes in degrees. Given that those rules can, at least in principle, be mastered by somebody who has the idiotic belief that swiftness does not come in degrees, we mustn’t impute to the semantic rules of English our knowledge that swiftness does come in degrees; and we must therefore take the position, for which there is a vast amount of independent corroboration, that this knowledge of ours is nonlinguistic.
 That said, the way to solve P1 is to take the view that in some way or other---probably through pragmatic implicature, not necessarily through literal meaning---tokens of (e.g.) “Bob is smart” are elliptical for tokens of relational sentences of the previously described kind.
 
A different kind of Sorites Paradox
 
 Let us now move onto a different kind of Sorites paradox. Paradoxes
of this kind are much harder to solve than those of the kind just discussed:
 
P2: Let C be some cloud and let m be some water-molecule dead in center of C. Obviously m is a part of C. But let’s suppose that m migrates towards the periphery of C. For a while, m will still remain a part of C. But if m travels, say, two miles away from C, then m will definitely cease to be a part of C.
 But where’s the cut-off line? Suppose that, for a while, m whizzes around C’s periphery, sometimes bumping into molecules that are definitely a part of C, and never straying from C’s periphery---i.e., from what definitely either coincides with or falls within C’s periphery----by more than an inch. Under those circumstances, is m a part of C? What about if we continue to suppose that m intermittently bumps into C but we increase this margin from one inch to five inches? Is m still a part of C? And how infrequently can m collide with molecules that are clearly C-constitutive without itself definitely ceasing to be a part of C? If such collisions are frequent, we’re inclined to consider it a part of C, even during those periods when it’s not in contact with molecules that are clearly C-constitutive (provided that, during such periods, it doesn’t veer off by too great a distance). By the same token, if such collisions are infrequent, we’re inclined not to consider m a constituent of C, even if, in between such collisions, it remains fairly close to C. (The more frequent the collisions, the more m can travel away from C without ceasing to be a constituent of C.)
 But, once again, where is the cut-off line? Is it half an inch? Two inches? A foot? What is it? Any answer seems arbitrary. If I say: “it’s exactly 3 inches”, I’m making a stipulation; I’m not identifying a pre-existing fact. (Technically, the right question is: where are the cut-off lines? For, whether or not m is a member of C seems to depend both on its average proximity and on the frequency with which it comes into contact with bona fide Cconstituents. But, for simplicity’s sake, I’ve chosen to abstract from this fact.)
 So here, quite indisputably, we have a case of indeterminacy. But, more interestingly, this indeterminacy has nothing to do with the representations of the world that we, or creatures of any other kind, have of the world. There could (and probably would) be clouds even if there were no sentient beings; and, in the absence of such beings, there would, given just about any cloud C, be molecules that were definitely parts of C and others that definitely weren’t parts of C and, what is relevant, molecules x such that x is a constituent of C wouldn’t exactly be true and wouldn’t exactly be false--or, to make an equivalent point, such that x’s constituency in C would not itself exactly be a constituent of the universe and also wouldn’t exactly fail to be a constituent of the universe.
 
A correct conception of thinghood the key to solving P2
 
 The solution to P2 is similar to the solution to P1. But there are some significant differences; and to solve P2, we must first make some substantive claims as to what is meant by the words such as “thing” and “object.” (In this context, those terms are to refer only entities such as vases, rocks, windows, as opposed to abstracta such as numbers or possibilities.) For the reasons given in Sections 5.2-5.2.1 and now to be developed, I don’t consider it an option to say that the world per se is indeterminate. Whatever the word "cloud" means, we gave it that meaning. So the corresponding cannot possibly contain the information needed to answer substantive questions concerning cloud-composition, given that we didn't built such knowledge into it.
 Semantic rules cannot know more than we do. So it's understandable, if not inevitable, that there should be arrangements of molecules that determinately don't deserve to be characterized either as "clouds" or as "non-clouds." and it's understandable, if not inevitable, the word "cloud" should fail to pick out any one property.
 We cannot expect our linguistic conventions to "cut nature at the joints." to use Francis Bacon's expression; we cannot expect them to be hewed to exactly those properties in terms of which the constitution of the world is to be delineated. A slight detour through legal theory will help make this clear.
 Laws created 200 years ago necessarily fail to address issues relating to the disposal of motor-oil. There's nothing mysterious about this, and it's obviously no reason for saying that the world is intrinsically vague. The same holds of semantic rules that were created over 200 years ago. And semantic rules, like laws, must be updated if they are to do what we want them do. So it isn't hard to make sense of the idea that semantic rules should sometimes be silent.
 But it is hard to make sense of the idea that properties should be indeterminate. What does it mean to say that the property of being a cloud is indeterminate? To which property are we referring? "The one had by those billowy things in the sky." Yes, but there are other objects that this person is not currently indicating. So, when confronted with some new object, by what criterion do we decide whether it is of the same ilk as those billowy things? Even if we could see the microstructural properties of those objects, we wouldn't necessarily know in virtue of which facts about their microstructures they fell into the same category as those billowy things.
 Until we can answer these questions, we don't have an answer to our original question, namely: which property is the relevant one? The information we have limits what a viable answer to that question could be. But it still leaves us with an infinitely large class of distinct properties to choose from.
 To sum up: attempts to identify properties that are objectively indeterminate can be interpreted as cases where no one property has been identified, suggesting that so-called cases of objective indeterminacy are nothing more than projections into the external world of the platitude that open scientific questions are not to be solved by studying semantic rules.
 
A correct conception of thinghood the key to solving P2 (continued)
 
 In any case, P2 arises because we think about things in the wrong way. We think of things as being more thing-like than they really are! Right now I’m looking at the pen on my desk. Let x be one half of my pen (the segment that includes the pen's tip and whose length is half the pen's), and let y be some region of the table immediately adjacent to x. Finally, let Z be the "entity", for lack of a better word, whose only two parts are x and y. Z is not a ‘thing.’ If we were to list all the things in the world, my pen would be on the list, and so would the table on which it rests. But Z wouldn’t be on the list. Why not? Because Z lacks the dynamic cohesiveness, and concomitant predictive and explanatory usefulness, that is had by the pen or the table or any other bona fide object.
 Of course, tables don’t last forever. They can be broken and burnt; and they all come to an end, in one way or another. But it is never by virtue of being a table that a thing ceases to exist. Qua table, a thing can be depended on and its behavior predicted. The fact that poorly constructed tables are not thus reliable only confirms this point; for, in virtue of being poorly constructed, and, for that reason, lacking causal and explanatory integrity, a thing fails as a table. This only confirms that it is never as a table that a thing lacks causal or predictive usefulness.
 These points mutatis mutandis hold of all objects. Things are ipso facto prediction- and explanation facilitators. One thing can be more prediction- and explanation-conducive than another. Because of its relatively high degree of causal integrity, a house made of bricks and mortar is more explanation- and prediction-conducive than a house of cards. We are independently inclined to say that, other things being equal, brick house is more of a thing, and thus more “thingy," than a house of cards. We now know what it is that we’re saying when we say this. We’re saying that a brick house ceteris paribus has more structural integrity a house of cards. Thus, our analysis that things are prediction-/explanation-facilitators is consistent with our pre-theoretic intuition that (to switch examples) clouds, though things in some sense of the word, are less thingy than houses.
 
A consequence of this analysis
 
 One consequence of our analysis is that a given aggregate of molecules may be a thing in one respect and fail to be a thing in some other respect. In a context where the interactions holding among molecules m1…..mn facilitate prediction and explanation, m1….mn constitute a thing. In a different explanatory context, one where they don’t have the aforementioned virtues, they don’t constitute a thing. A galaxy is a vast object. But a galaxy does, in some contexts, function as a single object; it has the requisite causal integrity and predictive fertility that, when trying to answer certain questions, one does well to consider the various microparticles of which a galaxy consists as constituting a single object. In other contexts, one is ill-advised to do this, for the same reason mutatis mutandis.
 To be sure, we believe that some aggregates of molecules (e.g., vases, rocks, pens) are just things; we believe, in other words, that their having the status of thing isn’t relative to the dialectical context. This viewpoint reflects prejudices that, in their turn, reflect idiosyncratic facts about our lives. Supposing that m1…..mn are the molecules composing the vase on your coffee table, if we were much smaller, so that vases were to us what, in actuality, galaxies are to us now, whether m1…..mn constituted a single object would be a function of the explanatory context. Similarly, if we were much bigger and the rate at which we uploaded and processed information were much slower, we might see galaxies in much the same way that, in actuality, we see vases—we might seem them (wrongly) as being as unconditionally thingy, since, relative to what we’d need to know under such circumstances, it would (given certain additional assumptions as to what our interests and needs would be, were we such slow-thinking giants) only be in hypothetical or, at least, rather exotic contexts that they lacked the properties requisite for thing-status.
 
The solution to P2
 
 These facts about the concept of thinghood help us solve P2. It’s meaningless to ask "how far can m stray from C’s periphery---i.e., from the outermost layer of molecules that are definitely constitutive of C---without ceasing to belong to C?" The reason it’s meaningless is that whether m is, or is not, a part of C depends on the explanatory context. Relative to certain questions about C, m would definitely fail to qualify as part of C were it so much as one tenth of an inch outside of the aggregate of molecules that definitely qualified as being identical with, or very close to, C’s surface. (We’ll henceforth refer to that molecule-aggregate as “CS”—short for “C’s surface.”) In other contexts, m would definitely be a part of C if it were separated by a distance of 10 inches (or less) from CS. (Remember that, in this context, we’re assuming, as to simplify the discussion, that m’s distance from S is the only thing that matters, so far as m’s being a constituent of C is concerned. In all likelihood, other things would matter, such as the manner in which m was moving, the frequency with which it collided with indisputably C-constitutive molecules and the manner in which such collisions occurred, and so on. But analogues of the points we’re making hold with respect to the questions “how often must m collide with molecules that are clearly Cconstitutive?," “with how much force?," in what exact manner?,” and so on.)
 In contexts of either of these two kinds, there would be some number n such that, if m’s distance from S were n or less, m would determinately belong to C and such that if m’s distance from S were n + 1, m would definitely fail to qualify as a member of C. In contexts of the third kind, this would not be the case. But that is because, in such contexts, “C” would have no definite referent. It is not because, owing to some “objective” indeterminacy---some gap or blank in the world---there was no fact as to whether or not m was a part of C. The real reason would be as follows.
 
An objection to this solution
 
 “But aren’t there contexts," will asked, “where, relative to the question whether m was or was not a constituent of C, it wouldn’t matter by exactly how much m was separated from CS? And, supposing that such contexts exist, which they presumably do, doesn’t that show that there is objective indeterminacy?”
 Each of these questions is to be answered with a “no.” Let m be some molecule that is on the periphery of some cloud C. We'll draw a blank if, without having any other questions in mind, we ask ‹is m a part of C?›. The reason: the question is meaningless. Questions of the form: ‹is x a part of y?› are seldom to be decided on strictly geographical grounds. Such far as such questions seem to be of a strictly geographical nature, a thing's causal liaisons to other things---what it affects, and is affected by, and in what manner---is obviously dependent on where it is. But, when we think that of the former ‹is x a part of y?› is a strictly geographical one, the reason is almost certainly that, given where x is, it's clear that each of many different questions as to x's dynamic relations to other entities is inevitably to be answered in the affirmative. It is only in very artificial contexts that the question ‹is x a part of y?› is to be answered on strictly geographical grounds. And given such a context, the question is meaningless unless the relevant geographical criterion is specified. But once it's specified, the question clearly admits of an affirmative or negative response.
 Whether x is a part of y depends what sort of organization y is and on how x contributes to that organization. My body is an organization. That's why an object lodged deeply in my body isn't necessarily a part of it. A penny that I've accidentally swallowed isn't a part of my body; it doesn't contribute to that organization in the right way. The United States is an organization. That's why a non-American can be in Delaware and an American can be in Nepal. He does little for the people of Nepal, and vice versa, and he expects little from them, and vice versa. Any responsibilities that he has towards them, and any expectations that he has of them, are likely to be of an ad hoc nature. Their laws don't protect him; his soldiers don't protect them. It's somebody in Washington who signs his paycheck and decides whether, this next year, he'll still have a job and, if so, what job will be.
 We naturally think of clouds as paradigm cases of things that are not organizations. So, given some molecule m and some cloud C, we assume that the question ‹is m a part of C?› isn't remotely comparable to questions, such as "is Smith a U.S. citizen?" and "is Smith's right leg a very realistic looking prosthetic (in which case, it is not a part of his body) or is it actually his leg (in which case, it is a bona fide body part of his)?," the answers to which clearly depend, not just on the relative locations of two objects, but on the ways in which the objects in question interact. We therefore tend to believe that:
 
(PP) Instances of such relationships involve more than one object's being a part of another. Pure parthood is a strictly spatial relation. If x's being a so-called "part" of y involves x's being part of an organized system of entities, then x's relation to y isn't one of mere parthood. Consequently, an organized systems of entities is ipso facto such that its constituents cannot possibly bear that relation to it. Thus, anything whose constituents do bear this relationship to them is ipso facto nothing more than a disorganized heap or aggregate of entities.
 
 But PP is antithetical to the truth. Not only can organizations have parts, contrary to what PP alleges: they are the only things that have parts. The relation of parthood is always to be understood in organizational terms. Whether object x can fit into organization y often depends on where x is in relation to y. (Hence the illusion that parthood is sometimes a purely spatial relation.) But it's only if x's bearing a certain spatial relation to y suffices for its being appropriately integrated into y that x's location relative to y suffices for its being a part of y.
 So supposing that R is the space-time region occupied by some cloud, and some golf ball entered that cloud and, by some miracle simply hovered there for the duration of the cloud's existence, it would never cease to be a foreign object. The reason: the golf ball's structure doesn't permit it to behave in ways in virtue of which R's occupant interacts with other objects in distinctively cloud-like ways.
 Thus, even clouds aren't mere heaps of molecules. Nothing is a mere heap. Any group of objects that is organized in one respect is disorganized in some other. The very people who compose a highly organized law firm may compose a highly disorganized comedy troupe. The same particles that make up a highly organized work of art may make up a highly disorganized floorboard.
 There's nothing paradoxical about this. From a strictly syntactic standpoint, "organized" is a one-place predicate and thus denotes a property, not a relation. But, from a logical standpoint, "organized" a two place predicate and thus denotes a relation, not a property. For Smith to be organized when it comes to his responsibilities to his employer and disorganized when it comes to his responsibilities to his children is for Smith to bear some relation to the desiderata one must satisfy to be a good employee that he fails to bear to the desiderata that one must satisfy to be a good father.
 Before closing the argument, let's sum up. A moment ago, we saw that x's being a part of y consists in y's being a system of into which x has been integrated. But we just saw that "organized" is a relative term. A group of objects cannot just be organized; it must organized in this or that respect, a corollary being that a group of objects that is organized in one respect is necessarily disorganized in some other.
 So before we ask whether x is a part of y, there are three questions that we must answer:
 

	* What kind of organization are we taking y to be?

	* What conditions a given object must satisfy to belong to such anorganization? How must a given object interact with a group of objects composing such an organization if it is to be one of them?

	* Does x interact with the objects composing y in the requisiteways?
 
 
 These questions may be hard to answer. But they're answerable, at least in principle, and once they're answered there cannot possibly remain any reason to hold that there is no fact as to whether x is a part of y.
 
 
A third kind of Sorites Paradox
 
Let us now discuss, and attempt to solve, the so-called “Paradox of the Heap.”[19] Here is that paradox:
 
 
P3: A single grain of sand is not a heap of sand. If n grains of sand don’t jointly constitute a heap, then neither do n + 1 grains of sand. In other words, adding a grain of sand to a non-heap won’t yield a heap. Therefore, a billion grains of sand don’t constitute a heap.
 
 
 As it stands, P3 isn’t really a paradox. First of all, a billion grains of sand, even when taken jointly, don’t necessarily constitute a heap. If a million grains of sand are dispersed through space---if they are ‘scattered’---they don’t constitute a heap. So for a given multiplicity of grains of sand to constitute a heap, any given grain must be (relatively[20]) contiguous with at least one other member of that multiplicity. But even though, for a multiplicity of grains of sand to form a heap, it is necessary that they fulfill that condition, it isn’t sufficient. For a billion grains of sand that are arranged in a straight line, each contiguous with its neighbors (or, if it’s the first or last grain, with its one neighbor) isn’t a heap. For a multiplicity of grains of sand to qualify as a heap, it is necessary and (ultimately) sufficient that they satisfy the following requirements:
 
 

	* each member of that heap must be contiguous with at least oneother such member;

	* taken jointly, those grains of sand must form a 3-D entity; and

	* the entity in question cannot be a structure, at least not in the
same sense as a building or a ship in a bottle.
 
 
 (i) and (ii) are self-explanatory, but (iii) requires clarification. A sand-castle is not a heap of sand. What is the relevant difference? “Sandcastles are products of human artifice, whereas heaps of sand are not.”
 First of all, heaps of sand are often products of human artifice; second of all, there are structures (e.g., plants) that are not the products of artifice that are definitely heaps and wouldn’t be heaps if, other things being equal, they were made of sand. The difference between a heap of sand and a sand-castle seems to lie in the fact that there are quite strict conditions that a grain of sand must satisfy to become part of a sand-castle, whereas there are no conditions, apart from some very generic ones, that a grain of sand must satisfy to become part of a heap of sand. To become part of a given sandcastle, a given grain of sand must be affixed to the sand-castle in such a way that it either (a) provides extra support for the walkway connecting the two towers or (b) completes some otherwise incomplete decoration on the castle, etc. But to become part of a heap of sand, a given grain of sand need only be adjacent with one or more of that heap’s existing constituents.
 These points make it clear how to solve a paradox that is similar to P3 and that is to be solved in much the same way:
 
(P3#) A single grain of sand is not a heap. If n grains of sand, no matter how they are arranged, don’t jointly constitute a heap, then adding another grain to those grains won’t yield a heap, no matter how that extra grain is added to that heap.
 
 What makes it seem that (P3#) is hard to solve is that the word
“heap” hasn’t been defined. I don’t mean that it hasn’t been precisified[21], but that it hasn’t been disambiguated. If a “heap” refers to a structure, as opposed to an amorphous mound, of a certain kind, then, depending on what sort of structure that is, adding one more grain of sand to a structure consisting of n grains of sand quite definitely will turn a non-heap into a heap.
 If by a “heap”, we mean an amorphous mound of some kind, then, given a few fairly innocuous points about language that we’ve already made, we’ve already solved P3. Let us (speaking as logicians, not as semanticists) regard “heap” as a noun form of the adjective “heapy.” There are obviously degrees of heapiness---just as there are degrees of intelligence, tallness, etc. Whether a given mound of sound sand is “heapy” is relative to the operative standard. Let A and B consist of n and n + 1 grains of sand, respectively, but otherwise be qualitatively identical. To an ant whose objective is make it over mound A, A may not be heapy---meaning that the ant can make it over. But B may be heapy to that same ant, given that, because B contains that extra grain of sand (as to whose position in B I am making definite assumptions, clearly), B is not surmountable. So relative to the ant’s objectives (and also, perhaps, relative to the ways it can think of surmounting a heap), B is, whereas A is not, heapy.
 In conclusion, P3 is dealt with in two steps.
 

	* Replace “heap” with the corresponding adjective.

	* See that adjective as having (hidden) relational structure.
 
 
 
Chapter 20 The Theory of Types (2010)
 
 
 
Consider the statement[1]:
 

	1. Smith has all of the properties of a typical Frenchman.
 
Suppose that Smith is the only Frenchman who has all of the properties of a typical Frenchman. Let phi be the property of having all of the properties of a typical Frenchman. Since possession of non-phi is typical of Frenchman, and since possession of phi is decidedly atypical, 1 seems to entail
 
N1. Smith does not have all the properties of a typical Frenchman.
 
Now consider the statement:
 

	1. Every assertion (past, present, future) is false.
 
2 seems to entail that:
 
N2: Given that 2 is true, not every assertion ever made is false.
 
 According to Russell, the problem with each of 1 and 2 is that they require the existence of predicates that fall within their own scope, and he said that such predicates cannot occur in a meaningful statement. Some more examples will help us understand, and evaluate, Russell's reasoning.
 Let us say that a predicate Px is 'impredicative' iff Px is not true of Px. Thus, "long" is impredicative, since "long" is a short word. ("Short", on the other hand, is predicate.) "Is an expression of German" is impredicative, since it is not itself a German expression.
 Next example: The class of men is not a man and thus doesn't belong to itself. The class of abstract objects is an abstract object and thus, presumably, belongs to itself. Let K be the class of classes are not members
of themselves. Consider the statement:
 
3. K is a member of K.
 
3 seems to entail that
 
N3. K is not a member of K.
 
Consider:
 
4. "Impredicative" is impredicative.
 
4 seems to entail that
 
N4: "Impredicative" is not impredicative.
 
Russell’s Solution
 
 Russell's solution (henceforth “ATT”, short for ‘argument for type theory’) to this problem is as follows:
 
No significant assertion entails a contradiction. So each of 1-5, though seemingly significant, isn't. In each case, the existence is being assumed of a higher-order set S such that
 

	* sets of a lower order than S are among S's members and
 

	* S itself is such a member.
 
 
 Let S1 be the class of all first-order properties typical of a Frenchman. Let S2 be identical with S1, except that one of the members of S2 is the property of not having all of the properties of a typical Frenchman. Consider:
 
1#: Smith has all the first-order properties of a typical Frenchman--all the properties that are members of S1
1# does not entail a contradiction.
 
Let S1 be the class of all first-order assertions, and let S2 be identical
with S1, except that S2 contains 2. Consider:
 
2#. Every first-order assertion ever made---i.e. every member of S1--is false.
 
2# does not entail a contradiction.
 
 Let K* be the class of first-order classes are not members of themselves. Because 4 posits the existence of a class that is of the same order as its members, 4 entails a contradiction, and is therefore to be presumed meaningless. By contrast,
 
3.* K* is a member of K.
 
 is simply true, not both true and false, since K* is not a self-member;
and
 
3. K* is a member of K*
 
is simply false, not both true and false.
 Finally, "impredicative" is a second-order predicate---a predicate of predicates. Let S1 be the class of all first-order predicates P such that P does not have the property it itself expresses. Being a second-order predicate, "impredicative" isn't a member of S1. Unless "impredicative" is redefined, so as to exclude the possibility that it falls in its own extension, 3 entails a contradiction and is therefore meaningless. If "impredicative" is so redefined, then 3 is false, not both true and false, and there is no contradiction.
 
The Theory of Types evaluated
 
 Here, then, is the theory Russell's Theory of Types.
 
(TT) Given any s is a significant statement, either open or closed, of order n, s attributes a property to a given entity x only if x is of order m<n.
 
Let M1 be the class of all meaningful statements. If TT is true, it's meaningful. If it's meaningful, it's a member of M1. If it's a member of M1, it's a counterexample to itself, since, according to TT, a statement of order n cannot concern any entity of order m≥n.
 If it is said that (as it has been, by Russell himself, among others):
 
(TT#) There are infinitely many Theories of Type, one for order 1 (TT1), one for order 2 (TT2), etc. For each n, if Sn-1 is the class of all meaningful statements of order n-1 or lower, then TTn correctly describes Sn1. Thus, TTn concerns the class of significant statements of order n-1 (and lower); and TTn+1 concerns the class of all significant statements of order Sn, of which TTn is a member. For any given m, TTm+1 is concerned only with the class of meaningful statements of order m or lower.
 
 But TT# itself violates TT#.
 
More problems with The Theory of Types
 
If TT is right,
 
(i) There is no one law of excluded middle (LEM): There is LEM1,
LEM2, etc,
 
the same being true of each other law of logic.
 A consequence is
 

	* There is no such thing as truth: there is truth1, truth2, etc., where truth is a property of statements of order m<n.
 
 But (ii) self-contradicts, since. For, supposing (ii) true, it is true simpliciter, as opposed to true1 or true2… TT also entails:
 

	* There is no one number 3. Rather, there is 31, 32….3n…
 
where 31 is the class of all triples of individuals, 32 is the class of triples of first-order classes; and so on. Thus, the statement "I have 31 shirts" is meaningful (true or false), because shirts are individuals, not classes. But "I have 31 pairs of shoes" is meaningless, because pairs are classes.[2]
 In addition to being unacceptably revisionist, (iii) self-contradicts.
For, supposing (iii) correct, it says of the number 3---as opposed to 32, 33 …--that, for any n, 33 is class of all third-order triples and, in general, that n3 is the class of third-order n-tuples. Given that TT has false consequences and, in addition, is excessively revisionist, an alternative to it must be found.
 
The Theory of Types unnecessary
 
 Judicious parsing of 1-4 makes it clear that TT is unnecessary.
 
The problem with 1 ("Smith has all of the properties of a typical Frenchman"). Let p1, p2...pn be the properties of a typical Frenchman. (Thus, p1 might be the property of speaking French; p2 might be the property of being cultured; and son.) Let S1 be the set that includes each of p1…pn. Let S2 be the set of all properties had by Smith. The meaning of 1 is:
 
1$: S1 is a subset of S2.
 
 So 1 doesn't attribute a property (that of having all the properties of a typical Frenchman) to Smith. 1 attributes a property to a set. It attributes the property of belonging to S2 to S1.
 Linguistic surface structure often falsely suggests that what are in fact statements about classes are statements about individuals. Consider:
 
JF1: "Jones plays tennis well."
 
JF1 attributes a property---that of being good--to Smith's tennisplaying. But:
 
JF2: "Smith plays tennis often"
 
does not attribute a property to Smith's tennis-playing. There is no x
such that x=an instance of Smith's playing tennis such that x can be described as "often." Rather, JF2 says that, if K is the class of Smith's tennis-playing episodes, K is well-populated. So JF2 is not, except indirectly, about Smith, and 1 is not, except indirectly, about Smith. Given this fact, there is no need to impose limits on what it is that can fall into the class of properties of a typical Frenchman.
 
The problem with 2 ("Every assertion is false")
 
We must distinguish between propositions and the speech-acts by which they are affirmed. If I say nothing, the proposition
 
P1: I am saying nothing
 
is true.
 So P1 isn't self-refuting; its truth doesn't entail its falsity. There are many occasions on which I am indeed saying and on which, therefore, the proposition I am saying nothing is true.
 Suppose I say "I am saying nothing." In that case, the following proposition is true:
 
P2: I am saying that I am saying nothing.
 
P2 doesn't self-refute. It can be the case that a person says that he isn't saying anything. (I can do it right now, by uttering the words: "I am saying nothing.") There is many a possible situation in which P2 is true.
 Even though each of P1 and P2 is coherent (capable of being true), they cannot jointly be true, i.e. the following proposition is false:
 
P3: I am saying nothing; moreover, I am saying that I am saying nothing,
 
The one conjunct is incompatible with the other. There is no world in which it is true; so there is no world in which it is false because it's true; nor any world in which it's true because it's false.
 These points are easily mapped onto 2 ("every assertion is false").
Let W be a world in which the one thing that is asserted is that the Earth is flat. In W, the following proposition is true:
 
(*) No true proposition is affirmed.
 
So the proposition meant by "every assertion is false" doesn't selfrefute.
 Suppose that in a world W2, otherwise identical with W1, somebody affirms (*). In that case, in W2, the following proposition is true:
 
(**) It is affirmed that no true proposition is affirmed.
 
(**) isn't self-refuting If I say "no true proposition is affirmed," then (**) is simply true, not true and false; and if nobody says "no true proposition is true," then (**) is simply false, not false and true. So (*) is neither selfrefuting nor otherwise incapable of being true. What is incapable of being true is:
 
(***) No true proposition is affirmed; moreover, it is affirmed that
no true proposition is affirmed.
 
since each conjunct (***) is incompatible with the other.
 If I say
 
(2) "Every assertion is false",
 
the proposition that I am affirming---the proposition P that is the
meaning of my words---is (**). (**) is perfectly capable of being true. In virtue of the fact that I am affirming P, a further proposition---namely, (***)--is true. But (***) is not being affirmed. What I am affirming is (*), not (**); and (*) is capable of being true. The proposition that I am affirming is inconsistent, not with itself, but with the fact that somebody is saying it. More explicitly: (*) is inconsistent, not with itself, but with (**). But (*) doesn't entail (**), and (**) doesn't entail (*). So we don't have any selfrefuting proposition on our hands. All we have is a proposition whose truth is dependent on its not being stated.[3]
 There are infinitely many numbers n such that, for some true
proposition P,
 
P: it is true that 2<n, and it is never said that 2<n.
 
 Obviously, for any such P, P can never be affirmed. But P doesn't entail that it is affirmed. Nor does P otherwise self-refute. So there is nothing paradoxical about P. For much the same reason, there is nothing paradoxical about 2; and there is therefore nothing about 2 that makes it necessary to impose limits on the scope of the occurrence therein of "every."
 
The problem with 3 ('K is a member of K')
 
 Any pronoun of the form "__self"---e.g. "himself," "ourselves," "itself"---is a so-called anaphoric pronoun. An anaphoric pronoun is one that serves as a surrogate for an antecedent referring term. Thus, "the cat likes itself" means "the cat likes the cat," the occurrence in the former of "itself" being a stand-in for "the cat." And "the class of spoons is not a member of itself" means "the class of spoons is not a member of the class of spoons," the occurrence of "itself" in the former being a stand-in for "the class of spoons."
 If a given occurrence of "itself" doesn't refer to anything if it isn't functioning as a stand-in for an antecedent referring term. Therefore, an occurrence of "itself" doesn't refer to anything if it is a stand-in for an expression that does not itself have a referring term. "It doesn't belong to itself" is synonymous with "it doesn't belong to it," and the occurrence of "itself" in the former therefore has no referent unless the antecedent occurrence of "it" has a reference.
 

	1. "The class of classes that are not members of themselves"
 
means:
 

	1. "The class K of classes k such that k doesn't have p, for some
property p such that x has p iff x is a member of K."
 
And:
 

	A. "The class K of classes that do not belong to themselves does not
belong to itself"
 
means:
 

	A. "If K is the class of classes k such that k does not have p, for someproperty p such that x belongs to k iff x has p, then K does not have p."
 
 The occurrence of "p" at the very end of B is the fourth occurrence of "p" in that sentence. But none of the preceding occurrences of "p" refers to anything. Two of those occurrences are internal to the quantifier "for some property p such that x belongs to k iff x has p": those occurrences of "p" obviously don't refer to anything. The remaining occurrence of "p" is bound by the aforementioned quantifier, and it therefore doesn't refer to anything. The fourth and final occurrence of "p" is a free variable. Therefore, that occurrence doesn't refer to anything and B---containing as it does a freevariable---is an open-sentence and thus not a true sentence at all. Since B is synonymous with:
 
C: K is not a member of K.
 
C is simply a sentence with a free-variable in it, and thus an opensentence as opposed to a bona fide sentence, that being why there is no proposition that it affirms. Being a consequence of the fact that it contains a free variable, C's failure to affirm a meaningful proposition has nothing to do with the fact that some class's membership is insufficiently restricted.
 
The problem with 4 ("'impredicative' is impredicative")
 

	1. "Impredicative" is impredicative
 
means
 

	1. "Does not fall within its own extension" does not fall within itsown extension.
 
2 means:
 
3. "is a thing x such that x isn't true of x" isn't true of x.
 
The final occurrence of "x" in 3 is free. Thus, the reason 3 is neither true nor false is that it contains a free variable. 3 is a perspicuous rendering of 1. So 1 contains a free variable; and that's why it's false. Its falsity has nothing to do with some predicate's being allowed to have too large an extension.
 
Conclusion
 
 According to Russell, each of 1-4 is both true and false, if it's either true or false. And the reason for this, says Russell, is that, in each of 1-4, some class S is allowed to have members to have members that are of the same order as S. We have seen that, for each 1-4, this is false. Each of those sentences, when duly parsed, is either true or false (cf. 1); false (cf.2); or, because it contains a free variable, neither true nor false (cf. 3 and 4). None of 1-4 warrants the position that predicates (both open and closed, open predicates corresponding to classes, closed predicates being sentences and thus corresponding to propositions) may range only over entities that belong to orders lower than do those predicates themselves. Also, such a restriction on predicate-ranges makes it impossible to express obvious truths, e.g. the class of spatiotemporal entities is not itself spatiotemporal.
 1-4 are but some of the many paradoxes that Russell put forth in support of TT. It would be desirable to have a proof to the effect that each such paradox involves a solecism similar to each of those thus far considered.
 
 
Chapter 21 Set Theoretic Characterizations of Truth and Meaning (2007)
 
Abstract: By identifying propositions with sets of properties, and a proposition’s being true with its properties’ being jointly instantiated, we make it possible to establish a data-consistent correspondence between propositions and the sentences that represent them. Further, without running afoul of Kripke’s important (1980) semantic insights, we avoid the desperate measures (e.g. saying that “Socrates was tall” has a proposition, albeit a non-existent one, for its meaning) taken by post-Kripkean semanticists (e.g.
Salmon, Soames) in their efforts to assimilate said insights into a coherent theory of meaning.
 
Introduction
 
 Propositions are the things we affirm and deny. In any case, that is how the word “proposition” will be used in this paper. In English, propositions may be denoted by expressions of the form “that such and such,” as in, “that snow is white.”
 Some deny the existence of propositions. In this paper, we’ll assume, if only for argument’s sake, that they do exist.[22]
 Given this assumption, two questions arise: “what are propositions?” and “what is it for propositions to be true?”[23] We’ll give answers to those questions that don’t have the defects of any of the other answers given to them and that are independently plausible.
 An outline of our findings: Propositions are sets of properties; and for a proposition to be true is for the members of the set with which it is identical to be jointly instantiated. Truth is instantiatedness. (More precisely, truth is identical with the property of being a set (of a certain kind) all of whose members are instantiated.) Aside from a few brief remarks, I will leave it open whether all sets of properties qualify as propositions (hence the parenthetical hedge in the last sentence). But a case will be made that only sets of properties are propositions.
 What we’ll say applies both to atomic and to molecular propositions (viz. quantified generalizations (or their propositional counterparts, rather) and compound sentences (same qualification).) But, simply for reasons of space, I must publish the section on molecular propositions separately. (In my (2005) book Literal Meaning & Cognitive Content, I show how the necessary extensions of the forthcoming analysis are to be made.)
 
1.0 The Argument
 
 Consider the proposition:
 
1. Tommy is smoking.
 
 Intuitively, this proposition seems to consist of at least three
components: first, Tommy (or, in any case, something individuative of Tommy: perhaps a property he uniquely instantiates or a concept under which he and he alone falls); second, the property of smoking; and, third, some kind of “synthesis” of the two – some complex constituent that involves Tommy’s smoking. (We will try to state precisely what this synthesis involves.)  If 1 is true, then:
 

	A. The property of being identical with Tommy,
 
 is instantiated, and so is:
 

	A. The property of smoking.
 
 But, of course, those two properties could be instantiated in a world where Tommy is not smoking – in a world where, for example, Larry is smoking and a non-smoking Tommy is playing golf. We thus need a third property – a property such that, if a set S contains that property along with A and B, then 1 will be true just in case all of S’s members are instantiated. That third property is not hard to identify. It is:
 

	A. The property of being identical with something that is smokingand is identical with Tommy.
 
 Before moving on, let’s look at the apparatus that we’ve been developing. Once again, let S be a set that contains all and only A, B, and C[24]; and remember that we have identified S with 1 (the proposition that Tommy is smoking).
 First of all, if C is instantiated, so are B and A. Further, if C, and therefore B and A, are instantiated, then, and only then, is 1 true. It follows that 1 is true if, and only if, each of A, B, and C is instantiated. This is consistent with, and even corroborates, the thesis that 1 is S that and that 1’s being true is S’s members’ being jointly instantiated.
 Of course, that does not by itself show that 1 can be identified with S or that 1’s being true can be identified with S’s members’ being jointly instantiated. After all, there are infinitely many distinct sets of properties such that 1 is true just in case their members are instantiated. For example, let Z be the set containing the following properties and nothing besides: the property of being identical with a smoking Tommy; the property of being an even number; the property of being three sided if a triangle. The second two properties are instantiated in every possible world, given that even numbers necessarily exist and given that triangles cannot fail to have three sides. But surely Z cannot be identified with 1, the reason being that Z’s membership cannot, at least not in a sufficiently natural manner, be aligned with what we know about 1’s constituency.
 But S’s membership does so align, as a brief look back makes clear. S’s members are (or at least include) A, B, and C. 1’s constituents are (or at least include):
 

	* Something individuative of Tommy,

	* the property of smoking, and

	* something that combines those two things.
 
 Obviously A is individuative of Tommy. (Only Tommy can have that property; and, what is more, he must have it.) So far, so good. (ii) and B are identical. So far, still so good.
 What about C? That property is instantiated exactly if A and B are both instantiated. So, in a very clear sense of the term ‘combine,’ that property combines the property of smoking with (something individuative of) Tommy. (In the relevant sense of the term ‘combine,’ one property ‘combines’ n other properties exactly if the first is instantiated exactly if the other n properties are jointly instantiated.) And we know that, in some way or other, 1 combines (something individuative of) Tommy with the property of smoking. In at least one respect, then, C’s relationship to A and B is suggestively similar to 1’s relationship to its parts. Moreover, C ‘dominates’ each of A and B in a way suggestively similar to the way in which 1 dominates its constituents. A’s being instantiated is necessary but not sufficient for C’s being instantiated, the same being true of B’s being instantiated. Tommy’s existing is necessary but not sufficient for 1’s being true, the same being true of somebody’s being a smoker.
 While none of this demonstrates definitively that 1 is identical with S or that 1’s being true is identical with S’s being instantiated, we have, I believe, found enough of a match between 1/1’s being true and S/S’s members’ being instantiated to warrant looking into the idea that they might be one and the same.
 
2.0 The unity of the proposition
 
 How does 1 combine Tommy with the property of smoking? According to Frege, Tommy (or some concept thereof) saturates that property (or some concept thereof). (Henceforth, I’ll omit the qualification ‘or some concept thereof.’) But this doesn’t help at all. For, as Davidson (1967) observed, the term “saturate” is just another label for the operation in question. So while the Fregean statement:
 
(FR) “1 is the result of Tommy’s saturating the concept of smoking,”
 
may well be correct, we don’t know what it means.
 We are in a position to give the meaning of FR and to say what this mysterious ‘saturating’ amounts to. We’ve argued that 1 is a set whose members include the property of being Tommy, the property of smoking, and the property of being a smoking Tommy. 1 is the result of Tommy’s ‘saturating’ the property/concept of smoking in the sense that 1 is identical with a set S that consists of those three properties.
 For any proposition X, to say that X is the result of Y’s ‘saturating’ Z (for some Y and Z) is to say that X is a set whose members are the property of being identical with X, and Z itself, and also the property of being identical with something that is identical with X and also has Z.
 
3.0 More on the decomposition of propositions
 
 It is indisputable that 1 is true just in case C is instantiated. So why not just identify 1 with C, and 1’s being true with C’s being instantiated? Why go through the rigmarole that we went through? Why bother with A and B and, in general, any other properties other than C? Because if we identify 1 with C, and 1’s being true with C’s being instantiated, our theory won’t accommodate the very reasonable presumption that 1 has discrete parts corresponding to Tommy and to the property of smoking.
 Consider an instance of the property of being a smoking Tommy. Obviously that instance will involve Tommy smoking. But it will not, at least in any obvious way, contain a discrete part corresponding to Tommy or a discrete part corresponding to smoking. And what is true of an instance of that property is, quite possibly, true of the property itself. It cannot be taken for granted that C has a discrete part corresponding to Tommy or to smoking or to anything else. In fact, being a non-spatiotemporal entity, C won’t have discrete parts in any straightforward sense at all.
 The impression that C is part-less, or at least lacking in the right kind of parts, is reinforced when we look at what an instance of C is like. Such an instance is, to use Kenneth Taylor’s (1998) apt expression, a “ripple in the quantum”: (re)distribution of mass-energy. Of course, that mass-energy is (by hypothesis) sufficient for the existence of Tommy and of smoking and, indeed, of a smoking Tommy. But you would have a devil of a time isolating some part of that distribution that corresponded to Tommy, then distinguishing that from some other part corresponding to smoking, and then finding a third that fused those two, otherwise discrete, entities into a discrete instance of a smoking Tommy.
 By contrast, the proposition:
 
1. Tommy is smoking,
 
is, of its very nature, neatly parsed into Tommy, the property of
smoking, and a third constituent that synthesizes the two just mentioned. The neat articulations found in 1 are found, in some form, in S. Those
articulations, though found in S’s membership has a whole, are not found in C taken by itself, making S, but not C, a suitable mirror for the decompositional structure of 1.
 As Ian Hacking (1975) said, States of affairs (or ‘facts’, as they are sometimes called) do not have the same kinds of “articulations” as propositions. The quantum-ripples on which the truth of a proposition supervenes don’t have anything like the structure of that proposition. Whereas the proposition Tommy is smoking clearly has a unique, and relatively simple decomposition into Tommy (or some property/concept individuative thereof), the property of smoking, etc., the state of affairs in which Tommy’s smoking consists – the confluence of psychological, physiological, and, ultimately, sub-atomic disturbances – obviously doesn’t uniquely decompose into Tommy and the property of smoking. In fact, it seems a stretch to suppose that it even has one such decomposition.
 
3.1 A corollary
 
 Consider the proposition:
 
2. Tommy is snoring.
 
Let D be the property of being a snoring Tommy. It is obvious that:
 

	1. Tommy is smoking,
 
and:
 

	1. Tommy is snoring,
 
have much in common. They have in common the constituent Tommy (or, in any case, something corresponding thereto). They have in common the functions (or, if you prefer, properties) the property of being Tommy who is doing something and the property of being a something that is doing something.
 In light of this, consider some instance of D. In other words, consider the kind of property-instance, the kind of mass-energy distribution, on which the truth of 2 supervenes. That instance will, of course, suffice for the existence of Tommy, as will an instance of C. But will those instances, in virtue of that fact, have some discrete part in common? Unlikely. In neither case do we have Tommy simpliciter. We have Tommy smoking (while sweating profusely and worrying about his algebra test and his nascent nicotine addiction, all the while talking with his cousin Albert); in the other we have Tommy snoring (while having terrible dreams about his future as a second string pitcher on a mediocre team). There is no such thing, in either case, as Tommy simpliciter. There is only Tommy doing this or that, having this or that property. A corollary is that two situations that comprise Tommy do not, in virtue of that fact, have in common some discrete, isolable entity. So while it is true that C and D both comprise Tommy, the one does not, in comprising him, have a discrete constituent in common with the other.
 But now we must consider what we’ve said about the composition of 1 and also what follows about 2, by obvious extensions of what we’ve said about 1. 1 is a set S whose members are:
a: the property of being Tommy b: the property of smoking
C: the property of being a smoking Tommy
 
And by similar reasoning, 2 is a set S* whose members are:
 
a: the property of being Tommy, b*: the property of snoring, and
D: the property of being a snoring Tommy.
 
S and S* do have well-defined, discrete parts in common. Indeed, they have in common precisely what is had in common by:
 

	1. Tommy is smoking,
 
and
 

	1. Tommy is snoring.
 
 If we were to be really precise about it, we’d say that each of S and S* comprised, not only a-c, but also:
 

	a. the property of being a Tommy that does something (i.e., theproperty being a Tommy that does something or, in any case, has some property),
 
and also:
 

	a. the property of being a something that does something (i.e., the
property being a something that does something or, in any case, has some property).
 
 Let’s look at 1 for a second. It immediately implies:
 
i Tommy smokes; ii something smokes; iii Tommy does something; iv Tommy exists; v something does something.
 
Indeed, 1 implies (i)-(v) in a manner that is naturally described as formal. (So, granting that the term “form”---as in “formal” entailment”--typically describes a property of expressions, we have, it seems, identified a propositional analogue of that property.) And 2 immediately implies:
 
i* Tommy snores; ii* something snores; iii Tommy does something; iv Tommy exists; v something does something.
 
Now let’s look at S and at S*. The members of S are:
 

	* The property of being Tommy.

	* The property of snoring.

	* The property of being a Tommy that snores.

	* The property of being a Tommy that does something.

	* The property of being a something that does something.
 
The members of S* are:
 
I The property of being Tommy.
II* The property of smoking.
III* The property of being a Tommy that smokes.

	* The property of being a Tommy that does something.

	* The property of being a something that does something.
 
 Having identified 1 with S and 2 with S*, everything we know about those propositions – about what they entail, about what their components are, and about how their higher-level components are “forged” out of their lower level components – is accounted for.
 
4.0 Another desideratum satisfied by this analysis
 Many semanticists today hold that Plato and Socrates are veritable objects are constituents of propositions that concern them. So according to Kaplan (1989), who is following and agreeing with Russell (1903), Tommy – the person, not some Fregean concept thereof – is a constituent of both 1 and 2. Other adherents of this view are Scott Soames (2003), Nathan Salmon (2005), and Robert Moore (1995). (Opponents are J. Searle (1983), M. Dummett (1973), and – with some very heavy reservations to be stated later – the present author.)
 There is a rather serious problem with this view. Consider, not 1 or 2, but rather:
 
 3. Plato snores.
 
At this point in time, Plato doesn’t exist. So if he’s a (necessary[25]) constituent of 3 – if, in other words, 3 exists only if Plato does---then 3 doesn’t exist. Salmon and Soames, both of them hardline direct referencetheorists, deal with this by taking a desperate measure, viz., by saying that 3 exists and that its existence constitutively depends on Plato’s existence and that these two positions can be reconciled with each other --- that, more specifically, they can be reconciled by saying that 3 exists, albeit as a nonexistent proposition.
 This is not necessary or plausible or helpful. 3 exists. Plato does not. But the property of being identical with Plato, whatever it is, does exist. What is it to be Plato? To be Plato is, perhaps, to be a causal sequence that is initiated by the fertilizing of a certain egg by a certain spermatozoa. To be Plato is, perhaps, to have a soul or mind of a certain kind. What we know is that, if something is Plato, it’s being Plato supervenes on something probably having to do with the mass-energy distribution in the cosmos – on its mode of origination, on the quotient of spiritual energy in the particle-interactions that constitute it, on who knows what. In any case, even though Plato does not exist, the property of being identical with Plato does. That’s why I can meaningfully, not to mention correctly, say “I am not Plato” or, equivalently, “I don’t have the property of being identical with Plato.” And it’s also why we can meaningfully, and presumably correctly, say that Plato does not exist. For, in making such a statement, we aren’t picking out a non-object---which would, having been picked out, ipso facto cease to be a non-object – and then saying of it that it doesn’t exist. We are saying of an existing property, that of being identical with Plato, that it is uninstantiated.
 But our analysis is still consistent with the heart of direct-referencetheory, this being the idea that, for some x such that x is identical with Plato, the proposition meant by “Plato snores” is true just in case x snores, it being completely irrelevant what properties (other than being a snorer) x has. (The Fregean indirect-referentialist holds that for “Plato snores” to be correct it is necessary that, for example, a unique great philosopher to write The Parmenides snore.) It is clear why our analysis is consistent on this matter with the viewpoint of the direct referentialist. According to our analysis, 3 is true exactly if the following properties are instantiated:
 

	a. The property of being identical with Plato.

	b. The property of snoring.

	c. The property of being a Plato who snores.

	d. The property of being something that snores.

	e. The property of being something that does something (or has some
property).
 
 It is readily seen that, on our analysis, there is some x, such that x is Plato and such that 3 is true exactly if x snores, it being irrelevant what other properties x has. This is exactly what the direct-referentialist holds. At the same time, our analysis guarantees the existence of the proposition that Plato snores -- after all, the property of being Plato exists, even though it is now uninstantiated. So our analysis of Plato snores gives the direct-referencetheorist the truth-conditions that he wants and that (given certain compelling arguments due to Kripke, 1980; and Soames, 2003, 2004) he deserves. At the same time, our analysis doesn’t put the direct-reference-theorist in the awkward, logic-bending position of having to say that the proposition that Plato snores exists despite the failure of existence of entities on whose existence its own existence is constitutively dependent.[26]
 
 
 
 
 
 
 
 
 
 

	* I am borrowing Russell's own example.

	* [I am not sure about the following point, that being why I amputting it in a footnote.] Another consequence of TT, and of (iii) in particular, is that it cannot meaningfully be said that the cardinality of the continuum is greater than that of the cardinals.
 Cardinal numbers are classes of classes.
 Rationals are ordered pairs (two-membered classes) of cardinals, and therefore classes of classes of classes.
 Reals are classes of rationals, and therefore classes of classes of classes of classes.
 Let P be the property of having the cardinality of the class of real numbers or, equivalently, the classes of all classes having the same cardinality as the class of real numbers. Being a property/class of classes of classes of classes of classes, P is a fifth-level property/class. Therefore, if "n" is any number-expression such that "the class of reals has n members," then "the class of cardinals has n members" is meaningless (neither true nor false), for the same reason that, given TT, "I 31 have pairs of shoes" is meaningless.
[3] I.e. what we have is a case of a Moore-paradox. If say "nobody ever says anything,"
 
what I am saying---the proposition that I am affirming—is:
 
P: No one ever says anything.
 
P could obviously be true. It was true in our world before language was invented.
P is obviously inconsistent with the supposition that:
 
P*: Somebody says P.
 
But P doesn't entail P*, and P doesn't otherwise self-refute.
 If I say "snow is white, but I don't believe that snow is white," what I am saying—the proposition I am affirming---is:
 
Q: snow is white, and I don't believe that snow is white,
 
which could obviously be true. (When I was six weeks old, each
conjunct was true.) Q is inconsistent with the supposition that
 
Q*: I sincerely utter (and therefore believe) that snow is white; and
snow is white; and I don't believe that snow is white.
 
But Q doesn't entail Q*, and Q doesn't otherwise self-refute.
 .
 
 


	* Incidentally, LEM and LNC are LC-equivalent, meaning that (i)LEM entails that LEM is equivalent with LNC, and LNC entails that LNC is equivalent with LEM.
 

	* Or, by more careful authors, such as Quine (1970), as statementforms that are 'true under all reinterpretations of their variables' Quine (1970): Philosophy of Logic. Also see Quine (1966): The Ways of Paradox. Both are essential reading, given your interests.

	* In this context, "sentence" may be taken to mean either sentence and sentence-form, and "statement" may be taken to mean either statement or statement-form.

	* It worth asking---though it has not been asked, so far as I know---whether all modal operators can be defined in terms of them. The answer, in any case, is "no." One reason is that "probable" (and 83% probable and, for any n, n% probable) cannot be defined in terms of the box and diamond.

	* This was stated previously, but it bears repeating.

	* In this context, the word "theory" doesn't have the meaning that ithas in empirical science. But the word "theory" is not therefore ambiguous; rather it is polysemous. "Blue" is polysemous because, even though it can refer to very different colors (light blue, dark blue, aqua), its various referents are, as it were, all members of one family. The word "theory," as logicians use it, is not a way of modeling empirical data and, to that extent, doesn't have the same meaning that it has when physicists use it. But oftentimes when logicians produce theories (axiom-set-created statement-sets), they do so because there is some scientific (empirical) theory that they wish to axiomatize; those empirical theories constitute intended interpretations of those axiom-sets. To be sure, logicians often produce axiom-sets with the intention of axiomatizing branches of mathematics, which is a non-empirical discipline. But even though mathematics per se is non-empirical, if a given domain of mathematical reality is judged to be worth investigating, that is because there is an empirical theory that, unless that branch of mathematics is understood, will be deficient. Calculus: Invented to study the trajectories of projectiles. Set theory: Invented to study heat conduction. Model theory: Invented to study artificial intelligence. Trigonometry: Invented to measure land-masses and to build to minimize the amount of work needed to redirect water from rivers to arid lands. Information-theory (what I do): Invented to minimize the amount of hardware needed for computers to function. Negative numbers: invented to keep records (of amounts owed). Irrationals: Invented to normalize (render consistent) the results of length-measurements. Vectors: Invented to accommodate the Parallelogram Law and, more generally, to compute the effects on a given object of more than one force. Every extension of arithmetic had a very specific practical justification. And the hyper-theoretical and---as branches of mathematics go---quite useless investigations of Dedekind, Russell, Skolem, Tarski, and the other great logicians of the early to mid 1900s were de rigueur, given that, were it not for their results, those extensions of arithmetic would introduced incoherencies into the structure of mathematics and, technically, would have rendered the discipline defunct, given that there is no statement, and thus no falsehood, that isn't a logical consequence of an inconsistent body of statements. (The inconsistencies in question wouldn't have had an effect on physics-minded mathematicians, e.g. people concerned with missile guidance systems, but it would----I would suggest (though I do not know this)---that it would have vitiated the labors of Kolmogorov and other researchers in the area of artificial intelligence.

	* F1 and F2 are 'alphabetic variants' of one another if they areexactly the same except that, wherever the one contains occurrences of one kind of variable, the other contains occurrences of a different variable. So "either P1 or not Q1" has the same truth-value as "either P2 or not Q2," but not necessarily the same truth-value as "either P1 or not P1." The first two are alphabetic variants of each other; neither is an alphabetic variant of the third, owing to the fact that the third is not the result of a uniform-replacement of free-variables in either of the first two. And "Rx2y2 and Gz2" is an alphabetic variant of "Rx4y4 and Gz4" and also of "Rx4y2 and Gz3", but not of "Rx2x2 and Gx2," since the last formula is not mutatis mutandis the same as the other three, the variables in it are not distributed in the same way as in the other three.
 

	* 8 is different from each of 1-7. 8 is stated in a meta-language,unlike others. Also, 8 is not one axiom; in fact, it isn't an axiom at all: it is an axiom-schema, each of whose infinitely many instances are constitutive of the axiom-set in question.
 Thus, technically speaking, an axiom-set can contain infinitely many members. But the operative term is "technically speaking." There must be a finitary way of specifying the axioms of a theory. When it is said that a given theory comprises infinitely many axioms, what is being is that at least one of the axioms of that theory cannot be expressed in that theory and, moreover, licenses infinitely many distinct (though structurally analogous) transformation-rules. In practically all axiomatizations of arithmetic, there is an axiom-schema to the effect that every n has phi if O has phi and, moreover, the successor of anything having phi has phi. No such inductionaxiom-schema qualifies as a well-formed formula in the language to which the sentences generated by that axiom-set belong. And this means that with respect to that language such an induction-axiom(-schema) represents infinitely many distinct axioms. But in actuality it is obviously just one axiom. So, ultimately, axiom sets must be finite. The belief to the contrary has to do with an attitude of alarmism among logicians relating to potential violations of type-theory, which we'll discuss later on.

	* Thus, given how vague the term "Important" is and also howunclear it is whether a given axiom-set---or hypothesis or model---will some day be important, it follows that the term "formal truth" has to be used with extreme care, lest it have no meaning.
 

	* This is Benacerraf's (1965) position.

	* See Benaceraff (1996), Hale and Wright (2002), Jubien (1977),and Salmon (2006).

	* Bibliography
 
Benacerraf, Paul (1965) "What Numbers Could Not Be", The Philosophical Review, Vol 74, pp. 47-73.
Benacerraf, Paul (1996) "Recantation or Any old ω-sequence would do after all", Philosophia Mathematica, Vol. 4, pp. 184-189.
Hale, Bob and Wright, Crispin (2002) "Benacerraf's Dilemma Revisited", European Journal of Philosophy, Vol. 10, pp. 101-129.
Jubien, Michael (1977), "Ontology and Mathematical Truth", Nous, Vol. 5, pp. 133-150.
Salmon, Nathan (2006). Metaphysics, Mathematics, and Meaning. New York, Oxford University Press.
 

	* Parsons (2000) is an example of such a philosopher. Keefe (1997)contains many articles, by various philosophers, advocating the view that there is objective vagueness. In his unpublished (UCLA) dissertation, which was supervised by Kit Fine (himself an advocate of the view that there is objective vagueness), Paul Hovda (2000) argues that there is objective vagueness. (His argument is simply that it’s implausible to suppose that the world is articulated into objects all of which have sharp edges. He doesn’t consider the argument presented here.)

	* “SB” is short for “Smith is bald.”

	* “ER” is short for “entailment relations.”

	* Or, more precisely, any given one of the infinitely many possibleways.

	* Examples of predicates are “tall," slow," and “prime.” Predicatesare typically defined as “expressions that pick out properties.” But this definition, though decent enough for some purposes, won’t do as it stands. For there are non-predicates, e.g., “the property of being tall," that pick out properties. It is not easy to come up with a viable definition of predicate; for any such definition will presuppose the truth of substantive theoretical claims. In any case, here is (what I believe to be) a viable definition of that term. A predicate is an expression E such that E is elliptical for an open sentence that has the form “x is an instance of the property of being P” and that, because it has the form, yields an actual sentence when the variable is replaced with either a referring term (e.g., “John”) or a quantifier (e.g., “some penguin”). So “tall", according to this view, is a predicate because it is elliptical for (a grammatical variant of) the expression “x has the property of tallness," which, when the variable is replaced with a referring term or quantifier, yields a bona fide sentence (e.g., “John has the property of tallness"). The resulting sentence is abbreviated into one that, at the level of orthography, has the form “x is P.” (So, for example, “John has the property of tallness” is abbreviated into “John is tall.”) This theory—though artificial in some ways---does explain how exactly predicates (e.g., “tall”) differ from the corresponding noun-phrases (“the property of tallness”) and, so far as I know, is otherwise consistent with the data.

	* "PP" is short for "pure parthood."

	* The paradox of the heap was first Sorites paradox to come to theattention of philosophers.

	* I say “relatively” because I don’t wish to rule out that if, givensome multiplicity of grains of sand, the distance between any given two of those grains of sand is sufficiently small, that multiplicity could still constitute a heap. If the distance between any two grains is small enough that, as far as the physical behavior of that heap is concerned, those two grains might as well be contiguous, that multiplicity would constitute a heap. That said, to my knowledge, it isn’t physically possible for a multiplicity of noncontiguous grains of sand to have the dynamic properties of a multiplicity of contiguous grains of sand. More importantly, it could be argued that, if a multiplicity of grains of sand behaved as though its constituents were contiguous with one another, then they ipso facto would be contiguous with another---that the forces binding the grains of sand together, whereby those grains of sand jointly constitute a single object, make those grains of sand be contiguous, at least by one legitimate metric.

	* For a definition of this term, see Chapter 6, Section 4.2.

	* Wittgenstein (1958) and Quine (1960) are among those who denytheir existence.

	* In this section, we won't discuss molecular propositions
(propositions that have other propositions as proper parts; e.g., snow is white and grass is green) or quantified generalizations (propositions that, for two classes C1 and C2, answer the question "to what extent, if any, do C1 and C2 overlap?,”; e.g., "no dogs play poker,” which answers the question "how much does the class of dogs overlap with the class of poker-players?" The non-abbreviated versions of these answers are found in Chapter 3 of my book Analytic Philosophy.

	* For expository simplicity, we’re leaving aside niceties relating totense-markers and place-indicators.

	* “Necessary constituent” is a pleonasm---hence the parentheses---since a proposition surely couldn’t possibly have a structure other than the one it in fact has

	* Bibliography
 
Armstrong, David. 1989. Universals: an Opinionated Introduction.
Boulder, CO: Westview Press.
Armstrong, David. 1992. Properties. In Steven M. Cahn (Ed.), Philosophy for the 21st Century (pp. 181-193). New York: Oxford University Press.
Austin, J. L. 1961. Philosophical Papers. New York: Oxford University Press.
Ayer, Alfred Jules. 1952. Language, Truth, and Logic. New York: Dover Publications.
Barwise, Jon. 1989. The Situation in Logic. Palo Alto, CA: CSLI Publications.
Barwise, Jon, & Perry, John. 1983.Situations and Attitudes. Palo Alto, CA: CSLI Publications.
Benacerraf, Paul. 1965. What Numbers Could Not Be. Philosophical Review, 74, 47-73.
Blackburn, Simon. 1984. Spreading the Word. Oxford: Clarendon.
Bonjour, Laurence. 1998. In Defense of Pure Reason. Cambridge, U.K.: Cambridge University Press.
Brandom, Robert. 1994. Making it Explicit. Cambridge, MA:
Harvard University Press.
Burge, Tyler. 1979. Individualism and the Mental. In A. Pessin and S. Goldberg (Eds.), The Twin-Earth Chronicles, (pp. 125-141). Armonk, NY:
M.E. Sharpe.
Burge, Tyler. 1982. Other Bodies. In A. Pessin and S. Goldberg
(Eds.), The Twin-Earth Chronicles, pp. 142-160). Armonk, NY: M.E. Sharpe.
Burge, Tyler. 1986. Individualism and Self-knowledge. In A. Pessin and S. Goldberg (Eds.), The Twin-Earth Chronicles, (pp. 342-354). Armonk, NY: M.E. Sharpe.
Cappelen, Herman, & Lepore, Ernie. 2005. Insensitive Semantics: A defense of speech act pluralism and semantic minimalism. Oxford: Blackwell.
Carnap, Rudolph. 1932. The Elimination of Metaphysics through Logical Analysis of Language. In A.J. Ayer (Ed.), Logical Positivism, (pp. 60-81). New York: The Free Press.
Carnap, Rudolph. 1937. The Logical Syntax of Language. Routledge & Kegan Paul, London.
Carnap, Rudolph. 1956. Introduction to Symbolic Logic. New York: Dover.
Church, Alonzo. 1958. The Ontological Status of Women and
Abstract Entities. Lecture delivered at Harvard, available online at:
http://www.cs.nyu.edu/pipermail/fom/2005-September/009079.html
Churchland, Paul. 1984. Matter and Consciousness. Cambridge, MA:
The MIT Press.
Cresswell, Max. 1985. Structured Meanings. In J. Garfield and M. Kiteley (Eds.), Meaning and Truth, (pp. 446-452). St. Paul, MN: Paragon Press.
Davidson, Donald. 1967. Truth and Meaning. Synthese 17, 304-323.
Davidson, Donald. 1980. Inquiries into Truth and Interpretation.
New York: Oxford University Press.
Davidson, Donald. Truth and Predication. Cambridge, MA: Harvard University Press.
Dennett, Daniel. 1975. Eliminative materialism and the propositional attitudes. In In D. Rosenthal (Ed.), The Nature of Mind, (pp. 502-507). New York: Oxford University Press.
Dennett, Daniel. 1978. Brainstorms. Cambridge, MA: The MIT press.
Donnellan, Keith. 1958. Reference and Definite Descriptions. In A. P. Martinich, (Ed.), The Philosophy of Language (pp. 235-247). New York: Oxford University Press.
Donnellan, Keith. 1966. Reference and Definite Descriptions. In A. P. Martinich (Ed.), The Philosophy of Language, (pp. 235-257). Oxford: Oxford University Press.
Donnellan, Keith. 1974. Speaking of nothing. The Philosophical Review 74, 3-31.
Dretske, Fred. 1982. Knowledge and the Flow of Information.
Cambridge, MA: The MIT Press.
Ducasse, C. J. 1969. Truth, Knowledge, and Causation. London:
Routledge & Kegan Paul.
Dummett, Michael. 1973. Frege: Philosophy of Language. Cambridge, MA: Harvard University Press.
Dummett, Michael. 1978. Truth and Other Enigmas. Cambridge, MA: Harvard University Press.
Einstein, Albert. 1962. The Principles of Relativity. New York: Dover.
Einstein, Albert, & Infeld, Leopold. 1961. The Evolution of Physics.
New York: Simon & Schuster.
Evans, Gareth. 1982. The Varieties of Reference. Oxford: Clarendon Press.
Evans, Gareth. 1985. Collected Papers. Oxford: Clarendon Press.
Falvey, Kevin. 1994. Externalism, Self-Knowledge, and Skepticism. Unpublished Dissertation. Department of Philosophy. University of Minnesota.
Falvey, Kevin, & Owens, Joseph. 1994. Externalism, SelfKnowledge, and Skepticism. Philosophical Review 103, 107-137.
Field, Hartry. 1977. Logic, Meaning, and Conceptual Role. Journal of Philosophy 69, 378-408.
Fodor, Jerry. 1968. Psychological Explanation. New York: Random House.
Fodor, Jerry. 1975. The Language of Thought. New York: Thomas
Y. Crowell
Fodor, Jerry. 1981a. Methodological Solipsism Considered as a Research Strategy in Cognitive Psychology. In D. Rosenthal (Ed.), The Nature of Mind, (pp. 485-498). New York: Oxford University Press.
Fodor, Jerry. 1981b. Representations. Cambridge, MA: The MIT Press.
Fodor, Jerry. 1983. The Modularity of Mind. Cambridge, MA: The MIT Press.
Fodor, Jerry. 1987. Psychosemantics. Cambridge, MA: The MIT Press.
Fodor, Jerry. 1987b. Individualism and Supervenience. In A. Pessin and S. Goldberg (Eds.), The Twin-Earth Chronicles, (pp. 192-218). Armonk, NY: M.E. Sharpe.
Fodor, Jerry. 1990. A Theory of Content and Other Essays.
Cambridge, MA: The MIT Press.
Fodor, Jerry. 1994a. Fodor. In S. Guttenplan (Ed.), A Companion to
the Philosophy of Mind, (pp. 292-300). Oxford: Blackwell
Fodor, Jerry. 1994b. The Elm and the Expert: Mentalese and Its Semantics. Cambridge, MA: The MIT Press.
Fodor, Jerry. 1998a. Concepts. Oxford: Clarendon Press.
Fodor, Jerry. 1998b. In Critical Condition. Cambridge MA: The MIT Press.
Fodor, Jerry,& Lepore, Ernest. 2002. The Compositionality Papers. New York: Oxford University Press.
Fodor, Jerry,& Pylyshin, Zenon. 1988. Connectionism and cognitive architecture: a critical analysis. In S. Pinker (Ed.), Connections and Symbols, (pp. 3-72). Amsterdam: Elsevier.
Frege, Gottlob. 1879. Concept-Writing. In Michael Beaney (Ed.), The Frege Reader (pp. 181-193). Oxford: Blackwell.
Frege, Gottlob. 1891. Function and Concept. In Michael Beaney (Ed.), The Frege Reader, (pp. 130-148). Oxford: Blackwell.
Frege, Gottlob. 1892a. On Sinn and Bedeutung. In Michael Beaney (Ed.), The Frege Reader, (pp. 151-171). Oxford: Blackwell.
Frege, Gottlob. 1892b. On Concept and Object. In Michael Beaney (Ed.), The Frege Reader, (pp. 181-193). Oxford: Blackwell.
Frege, Gottlob. 1918. Thought. In Michael Beaney (Ed.), The Frege Reader, (pp. 325-345). Oxford: Blackwell.
Grice, H. P. 1957. Meaning. In A.P. Martinich (Ed.), The Philosophy of Language, (pp. 72-78). Oxford: Oxford University Press.
Hahn, Hans. 1933. Logic, Mathematics, and Knowledge of Nature. In A. J. Ayer (Ed.), Logical Positivism, (pp. 137-163). New York: The Free Press.
Hale, Bob, & Wright, Crispin (Eds.). 1997. A Companion to the Philosophy of Language. Oxford: Basil Blackwell.
Hempel, Carl G. 1965. Aspects of Scientific Explanation. New York:
The Free Press.
Hempel, Carl G. 1966. Philosophy of Natural Science. Englewood Cliffs: Prentice Hall.
Jackson, Frank. 1998. Mind, Method, and Conditionals. London:
Routledge.
Kaplan, David. 1968. Quantifying In. In A. P. Martinich (Ed.), The Philosophy of Language (pp. 362-391). New York: Oxford University Press.
Kaplan, David. 1989a. Demonstratives. In J. Almog, et al.(Eds.),
Themes from Kaplan (pp. 481-563). New York: Oxford University Press. Kaplan, David. 1989b. Afterthoughts. In J. Almog, et al. (Eds.),
Themes from Kaplan (pp. 565-614). New York: Oxford University Press.
Katz, Jerrold. 1972. Semantic Theory. New York: Harper and Row.
King, Jeffrey C. 1995. Structured Propositions and Complex
Predicates, Nous, 29(4), 516-535
King, Jeffrey C. 1996. Structured Propositions and Sentence
Structure, Journal of
Philosophical Logic, 25: 495-521.
Kripke, Saul. 1979. A Puzzle about Belief. In A. Margalit (Ed.), Meaning and Use. Dordrecht: D. Reidel.
Kripke, Saul. 1980. Naming and Necessity. Cambridge, MA: Harvard University Press.
Kripke, Saul. 1982. Wittgenstein on Rules and Private Language.
Cambridge, MA: Harvard University Press.
Lewis, Clarence I. 1946. An Analysis of Knowledge and Valuation.
Cambridge, MA: Harvard University Press.
Lewis, Clarence I. 1952. The modes of meaning. In L. Linsky (Ed.), Semantics and the Philosophy of Language, (pp. 50-66). Chicago: University of Illinois Press.
Lewis, David. 1975. Language and Languages. In A. P. Martinich (Ed.), The Philosophy of Language, (pp. 489-508). New York: Oxford University Press.
Lewis, David. 1983. Philosophical Papers, Volume 1. New York:
Oxford University Press.
Lewis, David. 1984. On the Plurality of Worlds. Oxford: Blackwell.
Lewis, David. 1987. Philosophical Papers, Volume 2. New York:
Oxford University Press.
McDowell, John. 1994. Mind and World. Cambridge, MA: Harvard University Press.
McDowell, John. 1998. Meaning, Knowledge & Reality. New York:
Oxford University Press.
Montague, Richard. 1974a. The Proper Treatment of Quantification in Ordinary English. In Richard Thomason (Ed.), Formal Philosophy. New Haven, CT: Yale University Press.
Montague, Richard. 1974b. Formal Philosophy: Selected Papers of Richard Montague. New Haven, CT: Yale University Press.
Moore, Robert C. 1995. Logic and Representation. Palo Alto, CA:
CSLI Publications.
Putnam, Hilary. 1975. The Meaning of “Meaning.” In A. Pessin and S. Goldberg (Eds.), The Twin-Earth Chronicles, (pp. 1-52). Armonk, NY:
M.E. Sharpe.
Putnam, Hilary. 1996. Introduction to The Twin-Earth Chronicles. In A. Pessin and S. Goldberg (Eds.), The Twin-Earth Chronicles, (pp. xv-xxii). Armonk, NY: M.E. Sharpe.
Pylyshin, Zenon W. 1984. Computation and Cognition. Cambridge, MA: The MIT Press.
Quine, Willard van Orman. 1940. Mathematical Logic. Cambridge, MA: Harvard University Press, pp. 139-151.
Quine, Willard Van Orman. 1951. Two dogmas of empiricism. In A.
P. Martinich (Ed.), The Philosophy of Language, (pp 26-39). Oxford: Oxford University Press.
Quine, Willard van Orman. 1953a. Reference and Modality. In W. V. O. Quine (Ed.), From a Logical Point of View (pp. 139-151). Cambridge, MA: Harvard University Press.
Quine, Willard van Orman. 1953b. From a Logical Point of View.
Cambridge, MA: Harvard University Press.
Quine, Willard van Orman. 1960. Word and Object. Cambridge, MA: The MIT Press.
Quine, Willard van Orman. 1966. The Ways of Paradox and Other Essays. Cambridge, MA: Harvard University Press.
Quine, Willard van Orman. 1970. Philosophy of Logic. Cambridge, MA: Harvard University Press.
Quine, Willard van Orman. 1977. Ontological relativity and other essays. New York: Columbia University Press.
Quine, Willard van Orman. 1981. Theories and Things. Cambridge, MA: Harvard University Press.
Russell, Bertrand. 1903. Principles of Mathematics. Cambridge, U.K.: Cambridge University Press.
Russell, Bertrand. 1905. On Denoting. In A. P. Martinich (Ed), The Philosophy of Language, (pp. 203-211). The Philosophy of Language.
Oxford: Oxford University Press.
Russell, Bertrand. 1912. The Problems of Philosophy. London:
George Allen Unwin.
Russell, Bertrand. 1917. Mysticism and Logic. London: George Allen Unwin.
Bertrand, Russell. 1918. The philosophy of logical atomism. In R.C.
Marsh (ed.), Logic and Knowledge, (pp. 175-282).
Salmon, Nathan. 1986. Frege’s Puzzle. Cambridge, MA: The MIT Press.
Salmon, Nathan. 2005. Metaphysics, Mathematics, and Meaning. Philosophical Papers II. New York: Oxford University Press.
Salmon, Nathan. 2007. Content, Cognition, and Communication:
Philosophical Papers II. New York: Oxford University Press.
Searle, John. 1969. Speech Acts. Cambridge, U.K.: Cambridge University Press.
Searle, John. 1979. Expression and Meaning. Cambridge, U.K.:
Cambridge University Press.
Searle, John. 1983. Intentionality: an Essay on the Philosophy of Mind. Cambridge, U.K.: Cambridge University Press.
Soames, Scott. 2003. Philosophical Analysis in the 20th Century.
Volumes 1 and 2. Princeton, NJ: Princeton University Press.
Soames, Scott. 2005. Reference and Description. Princeton, NJ:
Princeton University Press.
Stalnaker, Robert. 1976. Modality. In J. Garfield and M. Kiteley (Eds.), Meaning and Truth (pp. 467-477). St. Paul, MN: Paragon Press.
Stalnaker, Robert. 1984. Inquiry. Cambridge, MA: MIT Press.
Stalnaker, Robert. 1999. Context and Content. Oxford: Clarendon Press.
Strawson, Peter. 1969. “Meaning and Truth.” In A. P. Martinich (Ed.), The Philosophy of Language, (pp. 91-101). Oxford: Oxford University Press.
Stroud, Barry. 2001. The Quest for Reality. Oxford: Oxford University Press.
Watson, John Broadus. 1924. Behaviorism. New York: Norton.
			Wittgenstein, Ludwig. 1922. 	Tractatus Logico-philosophicus. London: Routledge, Kegan & Paul.
 
 
