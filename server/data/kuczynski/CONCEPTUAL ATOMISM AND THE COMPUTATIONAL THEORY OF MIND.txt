Conceptual Atomism and the Computational Theory of Mind: 
A Defense of Content-Internalism and Semantic Externalism




Introduction 


        A doctrine known as “content-externalism” is widely taken to provide a correct analysis of mental content. A doctrine known as the Computational Theory of Mind (CTM) is widely taken to provide a correct analysis of mental operations. These doctrines support each other. 
      The present work is divided into two parts. In Part I (Chapters 1-12) it is argued that content externalism is false, but that a related doctrine known as “semantic externalism” is correct. An alternative to content-externalism is  proposed.
       In Part II (Chapters 13-25) xxx it is argued that CTM is false. Special attention is paid to the concept of syntactic form. It is seen that CTM involves a misunderstanding of this concept, and that this misunderstanding is embedded in misunderstandings that are reinforced by content-externalism.         


Part I A defense of Content-internalism and a Descriptivist theory of Concepts


Chapter 1 Basic concepts


Content-externalism 


           Let W and W* be two different possible worlds satisfying the following conditions. In W, Max sees rock R at time t. In W*, Twin-Max sees rock R* at the same time. R is numerically distinct from R*. But apart from that, there are no differences between W and W*. (It follows that Max and Twin-Max are numerically identical.) So even though R and R* are numerically distinct, they nonetheless look the same, and have the same mass, shape, and so on. And even though Max is looking at one rock, whereas Twin-Max is looking at some other rock, the physiological disturbances that result in the one case are qualitatively identical with those that result in the other. 
            Of course, Max and Twin-Max do not have exactly the same relational properties. For example, Max’s visual experience at time t is caused by R, not R*, and Twin-Max’s corresponding experience is caused by R*, not R. Nonetheless, Max and Twin are obviously extremely similar. So long as we consider the regions of space-time occupied by their bodies, there is nothing that distinguishes Max from Twin-Max. If there is an electron-jump in the region occupied by Max, there is a qualitatively identical electron-jump in the region occupied by Twin-Max. 
          According to a widely held doctrine, Max’s perceptions and subsequent thoughts don’t have the same contents as Twin-Max’s corresponding perceptions and thoughts. Here is the reasoning behind this claim: 


      Max’s visual perception is veridical exactly if R has certain properties, it being irrelevant whether R* has those properties. And Twin-Max’s visual perception is veridical exactly if R* has certain properties, it being irrelevant whether R has those properties. Similarly when Max thinks that rock is lovely, his thought is correct exactly if R is lovely, it being irrelevant whether R* is lovely. And when Twin-Max thinks that rock is lovely, his thought is correct exactly if R* is lovely, it being irrelevant whether R is lovely. Therefore Max’s R-perception and subsequent thoughts don’t have the same truth-conditions, or therefore the same contents, as Twin-Max’s R*-perception and subsequent-thoughts. 
         Leaving aside facts about the origins of their conditions, Max and Twin-Max are qualitatively identical. So it is solely in virtue of the fact that they xxx are embedded in different environments that they have perceptions and thoughts with different contents. Thus, in at least some cases, a mental state’s content is fixed, at least in part, by facts about the origins of that state. Two brain-states can be qualitatively identical, leaving aside facts about their causal origins, and yet have different contents. What a person (or creature) is thinking is constitutively dependent on facts about his environment, the same being true of the information encoded in his sense-perceptions.[1] 
       
        The doctrine just described is known as “content externalism.” The present work is concerned with content-externalism (among other things). We will argue that it is false.      
        Content-externalism must at all costs be distinguished from another doctrine that we will refer to as “semantic externalism.” 
  
Semantic externalism 


       A continuation of our story about Max and twin-Max will help us define the term “semantic externalism.” Max later tells people about R, referring to it as “Rocko.” Because Max is an eminent person, “Rocko” becomes part of the English language. So people who have never seen R sometimes refer to it as “Rocko.” They say things like: “the rock in your backyard is smaller than Rocko” and “Rocko is the most beautiful rock I have ever seen.”  Thus, in W, “Rocko” refers to R. Everything that we just said about Max is true mutatis mutandis of Twin-Max. So, in W*, “Rocko” refers to R*.
        Here is what semantic externalism says about this situation. In W, an utterance of “Rocko weighs over five lbs” is true exactly if R weighs over five lbs, it being irrelevant whether R* weighs over five lbs.  In general, for any predicate phi, an utterance in W of ┌Rocko has phi┐ is true exactly if the same is true of the singular proposition R has phi, it being irrelevant whether R* has phi. For exactly similar reasons, an utterance of ┌Rocko has phi┐ in W* is true exactly if R* has phi, it being irrelevant whether R has that property (Salmon 1986, Kaplan 1989, Soames 2001, 2004). 
      Content-externalism and semantic-externalism are distinct doctrines.[2] The first is a doctrine about what people think. The second is a doctrine about what our words mean. As we will see, a failure to distinguish between these two doctrines has led to much confusion in contemporary thought. We will find that semantic-externalism is unqualifiedly true, even though content-externalism is (so I will argue) unqualifiedly false. 
        There are many well-known apparent problems with semantic-externalism. For example, if semantic-externalism is right, then “Hesperus=Hesperus” has precisely the same literal meaning as “Hesperus=Phosphorous.” But surely these sentences must have different meanings, given that one of them is trivial whereas the other is non-trivial. 
         We will find that this problem, and others like it, vanish when we take a few basic facts into account – in particular, the fact that one must always exploit background semantic and non-semantic knowledge to compute the meanings of sentence-tokens that one encounters. 
       
Some apparent problems with content-externalism 


        As we have already seen, there is much to be said for content-externalism. It is a datum that, notwithstanding their similarities, Max and Twin-Max are seeing, and subsequently thinking about, different rocks. So it seems a datum that the contents of Max’s mental states are, to that extent, different from the content’s of Twin-Max’s mental states. Finally, there is no way to explain these differences except in terms of the fact that Max’s mental states don’t have the same origins as Twin-Max’s. These differences have no intra-cranial basis, and must therefore be sought in what is extra-cranial, i.e. in what is external.
        But there is a problem. So long as we confine ourselves to the regions occupied by their bodies, there is nothing that distinguishes Max from Twin-max. It immediately follows that they are physically identical. And unless we take the dubious measure of saying that their minds engulf remote regions of space larger than those encompassed by their bodies[3], it also follows that they are psychologically identical.[4] So to the extent that it must be understood along content-externalist lines, mental content is without any psychological significance:  what a person is thinks, believes, and doubts is irrelevant to how that person is psychologically. But it would seem to be a truism that two people differ psychologically if they differ in respect of what they believe, think, or doubt. As we will see, some authors reject this supposed truism on the grounds that it conflicts with content-externalism. But it is prima facie to the discredit of that doctrine that it has such a revisionist consequence.
      Before moving on, we should consider a possible externalist rejoinder to the argument just given: 


    You say that Max’s mind is confined to his cranium, and that to think otherwise is “dubious.” But in saying this, you are simply begging the question. The essence of content-externalism is that some facts about Max’s mind are fixed by extra-cranial facts. So if that doctrine is correct, it is not absurd to say that someone’s mind literally encompasses some remote region of space-time; and it is thus not absurd to say that Max and Twin-Max have qualitatively different minds. So I don’t see that you’ve made any headway here against content-externalism.[5] 


      
       It is easy to show that this response has consequences too revisionist to accept. Because light travels at a finite speed, one often sees stars that went out of existence long ago. Given this, suppose that, instead of being nearby rocks, R and R* are qualitatively identical, but numerically distinct, stars that went out of existence 100 million years ago. In that case, the objector’s response amounts to this: at least some portion of Max’s mind was around 100 million years ago. But that is straightforwardly false. There were no human minds back then. 
      This point can be generalized. One sees states of affairs, not objects. You don’t just see Smith. Rather, you see a dated situation that has Smith as a component. Because light travels at a finite speed, anything that you see has since ceased to exist, and anything that is contemporaneous with your visual perception is, at most, a successor or continuation of the state of affairs that you are seeing. Since content-externalism makes the thing you are seeing into a veritable constituent of the content of your perception, it follows that the objector’s response drains all of your perceptions of any content. Given that our perceptions obviously do have content, we may conclude that Max and Twin-Max are psychologically and physically identical, contrary to what the objector says. 
   
Some apparent problems with content-externalism (continued) 


      Suppose that Max does, whereas Twin-Max does not, believe that there is a nearby ATM machine that is spitting out hundred dollar bills. There will be an immediate difference between Max and Twin-Max in regards to what they feel, what they want, and what they do. Max will, whereas Twin-Max will not, experience a crisis of conscience (“should I take money that is not mine?”). Max will, whereas Twin-Max will not, repress his feelings of guilt at taking the money. Max does, whereas Twin-Max does not, develop a feeling of self-loathing, which is defensively cloaked under a veneer of excessive self-confidence. And so on.
       In this case, we have a situation where Max’s mental content clearly differs from Twin-Max’s. That initial difference quickly ramifies into others, and Max and Twin-Max forever cease to have parallel lives. 
        To see why this is a problem for the content-externalist, let us return to the previous scenario – the one where the only differences between Max and Twin-Max coincide with, or derive from, the fact that the one person saw R while the other saw R*. In that scenario, the alleged difference in content doesn’t lead to any lack of parallelism. Even if we concede to the content-externalism that Max and Twin-Max have different psychological contents, those contents are perfectly parallel. 
      For reasons of a purely methodological nature, that perfect parallelism is suspicious.  We are reminded of Poincare’s famous thought-experiment. Let W and W* be two different universes. (These needn’t coincide with the two homonymously named universes previously discussed.) At time t, everything in W undergoes a tenfold increase in size. Apart from that, W and W* are qualitatively identical. 
     Is there any difference between W and W*? Poincaré famously said “no”, and his answer was vindicated by later developments in both physics and logic. Because the changes that occurred in W were perfectly uniform, the relational properties of events in the one world remain identical with those of events in the other world. Thus, I am twice as tall as my niece in W iff I am twice as tall as she is in W*. If my pants are too tight in W, then they are too tight by exactly the same amount in W*. It is obvious that these points generalize without limit. There is thus no conceivable way of differentiating between W and W*, and the statement “I am in W, as opposed to W*” is thus without any explanatory or experimental significance. So we are guilty of making a distinction without a corresponding difference if we say that those worlds differ. It follows that the notion of absolute size, and therewith of absolute position, are empty.[6] 
       The differences between Max and Twin-Max are like those between the worlds in Poincare’s thought-experiment. Genuine differences destroy parallelism and disrupt relational facts. But the supposed differences between Max and Twin-Max are completely non-disruptive. Those two individuals remain in perfect lock-step (Fodor 1987, Jackson and Pettit 2004: 45-46).
      A content-externalist might respond by saying: 


     You are begging the question. Max and Twin-Max don’t remain in lock-step. Max has dreams about R, whereas Twin-Max has dreams about R*. Max wants to build a miniature replica or R, whereas Twin-Max wants to build a miniature replica of R*. And these differences do ramify into others. Given that both Max and Twin-Max believe that there are no square circles, Max comes to believe either R* weighs over five lbs or there are square circles whereas Twin-Max comes to believe: either R weighs over five lbs or there are square circles. So contrary to what you said, we don’t have one difference: we have a whole pattern of differences.[7] 
      
      The content-externalist wishes to show that, because Max’s perception results from R as opposed to R*, his mental content is qualitatively different from Twin-Max’s. All of the differences cited by the objector presuppose that this is the case. So the differences cited by the objector in defense of the content-externalist’s position presuppose the truth of that position, and thus don’t provide any independent support it. 


Content-internalism versus content-externalism 


       A theory is a way of modeling data. In philosophy, these data usually consist of intuitions. For example, we all have the intuition that killing infants is evil; and any viable ethical theory must either validate that intuition or it must show that, relative to intuitions of an even more fundamental kind, it can be explained away. 
      It is a datum that some of Max’s thoughts are made true by facts about R, whereas Twin-Max’s corresponding thoughts are made true by facts about R*. It is also a datum that there are certain apparent similarities between Max’s R-thoughts and Twin-Max’s R*-thoughts. Content-externalism provides one model of such data. Content-internalism provides a different model of that data.[8] (By “content-internalism” I mean the doctrine that content-externalism is false.)
       These days most philosophers believe that content-externalism is correct. In other words, most philosophers believe that, because of the differences between W and W*, Max and Twin-Max differ in respect of the identity of the information encoded in their sense-perceptions and subsequent thoughts. 
        For the reasons given a moment ago, it seems very reasonable to believe that there is a kind of representational content that Max and Twin-Max have in common, and that this common content is not affected by the differences between their two worlds. Following convention, we will refer to that kind of content (supposing that it exists) as “narrow content” (Loar 1985, Jackson and Pettit 2004c). So supposing that x and y are qualitatively identical, leaving aside facts about the origins of their conditions, x and y cannot differ in respect of the narrow contents of their perceptions and thoughts. 
      Of course, all content-internalists believe that there is such a thing as narrow-content, and so do some content-externalists. Such content-externalists are forced to advocate a “two-tiered” or “two-dimensional” conception of mental content. We will refer to this position as “soft content-externalism.”[9]
      A number of eminent content-externalists deny that there is such a thing as narrow-content. Of these, the most prominent are probably Tyler Burge, Gareth Evans, and John McDowell. We will refer to this position as “hard-line content-externalism.” 
        In this work I will argue that both forms of content-externalism are quite false. I will also argue that semantic externalism is entirely correct. We will see that many of the grounds for content-externalism vanish as soon as that doctrine is sharply distinguished from  semantic externalism.
       Jerry Fodor (1998) is a hard-line externalist who has proposed a very definite view as to the nature of conception, 666 and he has presented a number of powerful arguments for that view. Indeed, given an acceptance of hard-line externalism, Fodor’s analysis of conception follows (or so I will argue). 
       The essence of Fodor’s position is this. For x to have a concept of y is for some of x’s states to have been caused, in a certain way, by states of affairs involving y. xxx Fodor’s view can be understood in terms of the following scenario. I see Fred. This involves some state of affairs involving Fred causing me to have certain psychological states (various sensory experiences and attendant thought-processes). Xxx In their turn, those states lead to my being able to think about Fred, xxx i.e. they lead to my having a concept of Fred. Here we have a case where one thing’s having a concept of some other thing involves the second thing’s having some kind of effect on the first thing. xxx Since it is an obvious fact that there exist situations like the one just described, nobody denies that conception may involve a causal connection between subject and object. But Fodor goes a step further, saying that any instance of conception not only involves, but is identical with, an instance of the kind of causal relation just discussed. My having a concept of Socrates not only involves, but is identical with, my being on the receiving end of a causal chain that begins with some state of affairs involving Socrates.[10] Fodor attempts to show that my concepts of theoretical entities (e.g. muons) and also of abstract entities (e.g. the property of justice) can be explained along similar lines.[11] 
      Of course, this conception of conception is not an easy one to accept. But Fodor provides independent corroboration for it. More specifically, he successfully shows that each of three widely held and independently plausible doctrines implicitly presupposes the truth of his analysis (Fodor 1975, 1987, 1994, 1998). Those doctrines are the Computational Theory of Mind (CTM), the Symbolic Conception of Thought (SCT), and hardline content-externalism. SCT is the view that we think in symbols and thus in some kind of language. CTM is the view that mind is to brain what software is to hardware. In due course, we will say more completely what these doctrines are. 
      Given that each of these doctrines presupposes the truth of Fodor’s analysis, it follows that there is at least as much support for the latter as there is for the best supported of those three doctrines. Further, there is independent support for each of these doctrines. So even though Fodor’s analysis might initially seem counterintuitive, there is much to be said in support of it. 
 
Conceptual atomism and content-externalism
 
      As I will be using the word “concept”, x has a concept of y iff x can have thoughts about y. Because you are able to think about Socrates, you have a concept of the man.
      If correct, Fodor’s analysis warrants the acceptance of a doctrine that we will refer to as “conceptual atomism.” Let us consider your concept of Socrates. It would seem, on the face of it, that you can have that concept only because you already have various others. Let X be a creature that has no conception of spatio-temporal order, of causality, or of corporeality. Could X have a concept of Socrates? Most of us would say “no.” It seems absurd to suppose that a creature so totally lacking in cognitive wherewithal could possibly have a concept of Socrates. More generally, it seems absurd to suppose that an otherwise conceptless creature could have a concept of Socrates. It seems, therefore, that one’s concept of Socrates is not an “atom”, and is necessarily embedded in a network of other concepts. Some kind of conceptual non-atomism seems obligatory.[12] One of the purposes of this work is to argue that conceptual non-atomism is in fact correct.
      But if Fodor’s analysis is right, conceptual atomism is not only permissible, but de rigueur. According to that analysis, my having a concept of Socrates consists solely in my having a certain causal connection with Socrates. Whatever causal connection I have with Socrates could presumably be had by an otherwise conceptless being, e.g. a photographic plate. So Fodor’s analysis seems to allow that such a being could have a concept of Socrates. In general, it seems that if we accept a strictly causal analysis of conception, such as that advocated by Fodor, then we are committed to a dubious conceptual atomism. 
       Fodor recognizes this, and he accepts conceptual atomism. Fodor says that an otherwise conceptless creature could have a concept of Socrates – or of my desk or of justice or of the color green. Because he is keenly aware that many will disagree with this atomism, he attempts to find independent corroboration for it. The merits of these attempts will be evaluated in Chapters 15-17. 
          Fodor’s atomism is easily shown to be at least conditionally correct. (Here we will outline an argument that we will give in full in Chapter 13.) Suppose that content-externalism is correct. In that case, two people can be qualitatively identical but for the fact that one of them has one concept where the other has some different concept (or has no concept at all). According to the content-externalist, Max has a concept of R instead of a concept of R*, but apart from that, Max and twin-Max are qualitatively identical. If all concepts were constitutively linked with other concepts, then it wouldn’t be possible for two people (or creatures) to differ with respect to just one concept. So to the extent that content-externalism is correct, concepts come one at a time, and not in clusters. 
       Suppose that members of species X don’t have hearts, but that X’s are, in general, high-functioning creatures. In that case, it won’t be a biological possibility that members of that species are otherwise just like human beings. Members of that species must differ systemically from people – otherwise they would be in the same health-situation as a person without a heart, and would thus immediately go out of existence. 
        According to the non-atomist, what we just said about hearts is true of concepts. (I am going to choose an extremely tendentious example to illustrate my point.) If Smith has the concept of a conversion-reaction whereas Jones does not, then Smith must have other concepts that Jones does not. Jones’ acquiring the concept of a conversion-reaction involves his acquiring other concepts – e.g. the concepts of repression, of a punitive super-ego, and of unconscious activity. The non-atomist says that any acquisition of a single concept involves an acquisition of multiple concepts; and this is equivalent to the view, stated a moment ago, that conceptual differences between people cannot 666 be confined to a single concept. (We will develop this argument in Chapter 13.)
         So given content-externalism, Fodor’s atomism follows, as does his strictly causal conception of conception. According to the content-externalist, Max has a concept of R, and that is the one concept that Max has that twin-Max lacks. Max is causally connected to R, and that is the one thing that distinguishes Max from twin-Max. Of course, exactly the same points mutatis mutandis hold of twin-Max. The conceptual differences between Max and twin-Max supervene wholly on the differences in their causal liaisons. The fact that Max’s does, whereas twin-Max does not, have a concept of R is wholly a function of the fact that Max is, whereas twin-Max is not, causally connected to R in a certain way. So to the extent that the content-externalist account of mental content is the right one, it follows that differences in concepts are to be understood in strictly causal terms, and therefore that conception itself is so to be understood. So given an acceptance of content-externalism, Fodor’s atomism and his strictly causal conception of conception both follow.[13] 
        Thus, Fodor is simply being true to his own premises in accepting these two doctrines. Most other content-externalists have not gone so far as to say that conception is to be understood in purely causal terms, or that a strictly atomistic view of concepts is correct. But so far as this is the case, the systems advocated by those other content-externalists are not consistent ones.        


The relation of CTM to conceptual-atomism 


          But Fodor’s primary reason for accepting conceptual atomism is not that content-externalism demands it. His primary reason is that he accepts CTM and, as Fodor himself cogently argues, the truth of CTM depends on that of atomism. (Fodor (1968, 1975) accepted CTM before content-externalism even came into existence.) In Chapters 13-22 we will argue that CTM is not viable and that the arguments for it are fallacious. Let us briefly outline what we will say. 
        For the sake of argument, suppose that CTM is right. In other words, suppose that thinking does consisting in “computing.” A question immediately arises: What exactly does the word “compute” mean in this context? 
       Right now, I could compute a sum – I could add 134 to 397. But that kind of computation obviously presupposes various cognitive faculties, and thus cannot underlie cognition. 
       Fodor is aware of this, and he defines the word “computation” in a way that, he believes, does not render CTM viciously circular. A computation, he says, is a “formal operation on symbols” (Fodor 1987: 19). It is an operation that is causally driven by the forms, not the meanings, of the symbols involved. A machine can respond to the form of the expression “23+15” in such a way that it produces the right output. No thinking is needed to perform a purely formal operation. Given that computing is a purely formal operation, it follows that there is no vicious circularity in supposing that thinking is computing (Fodor 1981: 13-17, Fodor 1987: 18-20). 
         An immediate consequence of CTM – indeed, the very essence of it - is that thinking is not content-driven (Fodor 1987: 19). Of course, such a position initially strikes us as very odd.  I believe that Bill fell off of a tall building, and this leads me to believe that he is now injured or deceased. Surely this is an example of a content-driven sequence of mental states. So supposing that we do think in symbols, it is very hard to believe that the semantic properties of those symbols are causally inert. 
       But Fodor (1987, 1990) has produced an argument that, if cogent, shows why we mustn’t put too much stock in this particular criticism of CTM. The purely formal properties of symbols can be coordinated with their representational properties in such a way that all of the relevant phenomena are easily explained – e.g. the fact that, if I believe that Bill has seven cars, then I am likely to form the belief that Bill has a prime number of cars. True – this account does strip the mental per se of causal efficacy. But theories are to be evaluated in terms of their degree of concordance with the relevant data, not in terms of their concordance with our a priori conceptions. In this case, the relevant datum is that certain kinds of thoughts are likely to follow other kinds of thoughts. It is not a datum that semantics is what is causally responsible for these patterns.
 
The concept of syntax: an introduction


          There are a number of points to make in response to the argument just outlined. I will now only outline these points, since they will be discussed at length later on. 
        Supposing that a computation is understood to be a “form-driven” operation, we must ask: what is meant by the term “form”? Sometimes Fodor says that what he has in mind is syntactic form. So Fodor’s position becomes: a computation is a syntax-driven operation. Is this claim feasible?
         Before we can answer this question, we must note that the term “syntax” is ambiguous: what linguists mean by it isn’t what mathematical logicians mean by it.  Let us now see if either disambiguation of the term “syntax” validates Fodor’s position. According to a linguist, the sentences: 


(*) “John punched Fred” 


and 


(**) “Larry kissed Mary” 


have similar (or identical) syntactical structures. What does this mean? It means that they have similar derivation-trees. And this means, very roughly, that the way in which the one sentence is assigned the meaning that it has resembles the way in which the other sentence is assigned the meaning that it has. In general, the syntax of a sentence lies not in what it means, but in how it means what it means. Syntax is meaning-how. (Semantics is meaning-what.) The concept of syntax is therefore not a meaning-innocent notion.
        So supposing, as Fodor does, that thinking is an operation on expressions, syntax-driven operations are meaning-driven. They are driven by a sensitivity not to what the operands mean, but to how they mean what they mean. Sensitivity to meaning-how, no less than sensitivity to meaning-what, presupposes a heavy cognitive arsenal. It is therefore not tenable to suppose that syntax-driven operations could be cognitively foundational. 
        Let us give a different version of the argument just outlined. The term “wet” is not interchangeable with the expression “the property of wetness.” After all, “one shouldn’t drive on wet roads” is meaningful, whereas “one shouldn’t drive on the property of wetness roads” is not. If you know only that the term “wet” denotes or expresses a certain property, and do not know the syntactic properties of that expression, then you are ignorant of a crucial aspect of its meaning. 
          Syntax is combinatorial (or recursive) semantics. One knows the syntax of a complex expression when knows the combinatorial semantic properties of its constituents. Equivalently, one knows the syntax of an expression when one knows how its meaning is derived from those of its constituents – when, in other words, one knows its derivation tree. An operation is syntax-driven iff it is driven by a sensitivity to combinatorial semantics. Since such an operation can be carried out only where there is already an awareness of meaning, it is not an option to hold that such operations form the foundation of our cognitive lives. 
        The linguist’s disambiguation of the term “syntax” thus fails to validate Fodor’s position. Let us now see if Fodor’s position is validated by the mathematical logician’s disambiguation of that term. 
        First of all, how are the two disambiguations different? Most linguists would say that 


(1) “Bob is tall or Bob is not tall”


has the same syntax as 


(2) “Bob is tall and Bob is not tall.”


The linguist sees “or” as being in the same syntactic category as “and.” From his standpoint, (1) and (2) are no more syntactically different than “Bob is tall” and “Bob is short.” But the mathematical logician says that, because (2) has an “or” in the place where (1) has an “and”, those sentences are in different syntactic categories. What is the basis of this (apparent) disagreement?
       When a mathematical logician says that a sentence S, belonging to language L, is “syntactically true”, he means that it is a theorem or consequence of the semantic rules of L that S is true.[14] And when a mathematical logician says that two sentences S and S* have the same syntax, he means that they are interchangeable from a proof-theoretic standpoint. Equivalently, S1 and S2 have the same “syntax” iff….S1…is syntactically true iff the same is true of…S2….(So, for example, if there is some sentence S3 such that S1→S3 is a theorem and S2→S3 is not, then S1 is syntactically different from S2.) It is a theorem of the rules of English semantics that (1) is true, but not that (2) is true. Indeed, it is a theorem of those rules that (2) is false.  
       Even though the mathematical logician’s disambiguation of the term “syntax” is different from the linguist’s, the former poses the same problems for Fodor’s analysis as the latter. On both disambiguations, a sentence’s syntax lies in how it means what it means.
        Of course, the linguist and the logician don’t have quite the same thing in mind when they think about how a sentence is assigned the meaning that it has. The latter is concerned with non-psychological notions such provability; the former is concerned with psychological notions such as comprehension and learnability. But in both cases, a sentence’s syntax lies in a relationship that holds between the semantic rules of the relevant language and the sentence’s meaning. So given either disambiguation of the term “syntax”, syntax-driven operations are meaning-driven. This immediately entails that Fodor’s position is a non-starter        


Indexicality and the impossibility of a syntactic characterization of logical form 


      There is an entirely different reason why CTM is in trouble if “form” is identified with syntax. For CTM to work, it must be possible to coordinate syntax with semantics. But there is no disambiguation of the term “syntax” that makes such a coordination possible. A linguist would say that:


(^)  “Smith is ill because Smith doesn’t smoke.” 


 has the same syntax as


 (^^) “Smith is ill and Smith doesn’t smoke.” 


Given this sense of the word “syntax”, if some syntax-driven entity accepts each of “Smith is ill” and “Smith doesn’t smoke”, it is just as likely to transition to (^) as it is to transition to (^^). But this clearly doesn’t correspond to the transitions that a rational person would make. So the linguist’s definition of “syntax” fails to validate the idea that thinking consist in syntax-driven operation. 
       According to the mathematical logician, (^) and (^^) do have different syntactic structures. Indeed, from the mathematical logician’s viewpoint, the “syntax” of a sentence is by definition identical with its logical form. So it would seem that this disambiguation of the term “syntax” would validate Fodor’s analysis. 
       But this is not so. Relative to this reading of the term “syntax”, syntax tracks logical form only if the language in question satisfies conditions that would make that language useless in the way of mediating rational thought. In that sense of the word “syntax”, an utterance of “that [pointing to Smith] is identical with that [pointing to Jones]” has the same syntax as an utterance of “that [pointing to Smith] is identical with that [pointing once again to Smith].” So a purely syntax-driven entity wouldn’t be capable of registering the profound logical differences between these two utterances. Since it is obvious that human beings can do so, it follows that, in this sense of the word “syntax”, we aren’t syntax-driven entities (Kuczynski 2006b). 
      What we just said about “that” is true of “here”, “now”, “this”, “over there”, and any other context-sensitive expression. Syntax can be coordinated with logical form only where there is no context-sensitivity. So supposing that we think in a language whose syntactic structures are coordinated with their logical forms, it follows that those sentences have no context-sensitive component and that, consequently, one isn’t capable of thinking things like it is now 3:00 p.m. or that guy is Jones. Since we obviously do have such thoughts, our thoughts are not mediated by a language of the kind just described. 
              
Syntax as morphology 
      
         Sometimes when Fodor talks about sentential “form”, he is referring to the property of having a certain shape. He is referring to form in a purely geometrical sense (Fodor 1987: 18-20).  
        But this disambiguation of the word “form” doesn’t validate the contention that thought is syntax-driven or, therefore, that it is meaningfully described as computational. Syntax is not morphology. Syntax doesn’t supervene on morphology. Syntax is no more capable than semantics of being coordinated with morphology. (We will argue for these claims in Chapters 13 and 14.) So in direct opposition to what Fodor holds, thought is not syntax-driven, and is therefore not computational, to the extent that it is morphology-driven. 
         To be sure, there is a long tradition of identifying syntax with morphology. But that tradition is mistaken, and it involves erroneous views as to the meanings of expressions such as “syntax”, “algorithm”,  “mechanical procedure” , and “formal truth.”
       
The root-problem with CTM and content-externalism


        But there is a problem with CTM, and also with content-externalism, more fundamental than any thus far mentioned. Suppose that brain-state B realizes a condition of believing that Socrates was bald. There is no doubt that B has causal properties; it has a certain shape, a certain mass, and consists of particles with positive and electric charges, and so forth. But if content-externalism is right, then B’s having a certain representational content – its encoding the proposition that Socrates was bald – is causally inert. From the viewpoint of causation and explanation, B’s having that property is as irrelevant as its having the property of being a thing x such that x is either a circle or not a circle (Jackson and Pettit 2004: 46-48, Kuczynski 2006c).  
        Content-externalism threatens the very existence of mental content. Where the occupants of the spatiotemporal are concerned, existence and causality are practically indistinguishable. Fodor (1968) himself makes this point very clearly,[15] and so does Jaegwon Kim (1993: 348). A state of affairs that has no causal powers is no state of affairs at all.  Since content-externalism strips mental content of causal powers, it denies its existence. 
       John McDowell argues that content-externalism is compatible with the causal efficacy of the mental.[16] But McDowell’s argument is a straightforward non-starter, as we will see in a moment. 
       Fodor sees clearly that, if content-externalism is right, no brain-state has causal powers in virtue of its representational properties; i.e. he sees that content-externalism strips content of causal efficacy. (That is why, in his view, it is the “syntactic structures” of brain-states, not their semantic (representational) properties, that do all the causal work.) But Fodor seems not to see that this jeopardizes the very existence of representational, and therefore mental, properties. 
      Like McDowell, Frank Jackson and Phillip Pettit hold that content-externalism is consistent with the causal potency of the mental (Jackson and Pettit 2004-2004c). But their argument is very different from McDowell’s, and has considerably more merit. Their argument is based on a distinction between what they call “program-causality” and “efficient-causality.” They argue that content-externalism allows representational states of affairs (e.g. a brain-state’s being a belief that Plato was wise) to be program-causes, even though it doesn’t allow them to be efficient-causes. 
        I believe that the Jackson-Pettit analysis of causality is accurate and that the distinction between program-causality and efficient-causality is of the highest importance. But their worthy analysis of causality does not show that content-externalism is compatible with the presumption representational states of affairs have any causal properties; it no more allows mental states to be program-causes than it allows them to be efficient causes. This will be shown in Chapter 12. 


Thee key distinctions


         In this work, it will be argued that, so far as content-externalism appears plausible, that is because we are failing to make the following three distinctions:


(1) The distinction between what is literally meant by our expressions and the information that is imparted to us in the process of computing literal meaning. 


(2) The distinction between content and truth-maker. 


(3) The distinction between perceptual and meta-perceptual data (between what is encoded in our perceptions, taken by themselves, and what we infer from our perceptions). 


        Since much of Part I will be spent delineating (1)-(3), I will now only give an outline of what they mean. For the sake of argument, suppose that, as Kaplan (1989) holds, demonstrative expressions are “directly referential.” In that case, the proposition literally meant by a token of: 


(A) “that overbearing and generally unsavory man standing over there next to that atrocious painting is a professor of anthropology” 


is simply:


(B) x is a professor of anthropology, 


for some value of x. But obviously what is communicated by a token of (A) will not be so threadbare. What is communicated is (inter alia) that somebody is overbearing and generally unsavory and is also standing next to some painting that is atrocious. Thus, what is communicated by a token of (A) will involve concepts like painting, overbearing, unsavory that are quite absent from (B). How is this to be reconciled with Kaplan’s thesis that (B) is the literal meaning of (A)?
       There is no problem. We need only take into account the fact that people typically understand the expressions that they encounter on the basis of their knowledge of the semantic rules that assign them meaning. The semantic rule for the demonstrative expression “that overbearing and generally unsavory man standing over there next to that atrocious painting” is:


(C) For any context C, and any predicate phi, if somebody x in C is uniquely a salient overbearing and generally unsavory man standing next to a uniquely salient painting y, then a token in C of ┌ that overbearing and generally unsavory man standing over there next to that atrocious painting has phi┐ means: x has phi. 


The rule for (A) specifically is: 


(D)  For any context C, if there somebody x in C is a uniquely salient overbearing and generally unsavory man standing next to a uniquely salient painting y, then a token in C of “that overbearing and generally unsavory man standing over there next to that atrocious painting is a professor of anthropology” means: x is a professor of anthropology.
 
        When one hears a token of (A), one has to work through (D). Anyone who knows (D) will know that an utterance of (A) will not be true unless, in the context of utterance, somebody x is a uniquely salient overbearing and generally unsavory man standing next to a uniquely salient atrocious painting y, and x is a professor of anthropology. So even though what a token of (A) literally means is (B), and thus doesn’t involve the concepts of being unsavory or over-bearing, what such a token communicates to someone does concern these very concepts. Because of the information that one must work through in order to assign the right proposition to a token of (A), what such a token communicates is very different from what it literally means. 
      I will refer to information conveyed in this way as “pre-semantic implicature.” We will find that what we just said about tokens of (A) is true, to some degree or other, of all sentences. In connection with this, we will find that pre-semantic implicatures are exponentially more powerful than the post-semantic implicatures studied by Grice.  
        Let us now briefly say what is meant by (2) and (3). Consider the sentence: 


(S) “Somebody invented bifocals.” 


        This sentence is true because Benjamin Franklin invented bifocals. So Franklin’s inventing bifocals is the truth-maker of (S). But the meaning of (S) obviously isn’t: Franklin invented bifocals. After all, even though it is false, “somebody invented bifocals, but Franklin did not invent bifocals” is not self-contradictory.[17] What we just said about sentences is true of perceptions and thoughts. When I look at an ice-cube, what makes my perception veridical is that there are various H2O-molecules in a certain configuration in a certain region of space-time. So the truth-maker of my perception is given by some proposition having the form: in region R, there are various molecules consisting of hydrogen and oxygen atoms, and those molecules are interrelated in such and such a manner. But what my perception tells me isn’t given by such a proposition. So the content of my perception doesn’t involve the concepts molecule, oxygen, or hydrogen.  
       In his landmark work the Varieties of Reference, Gareth Evans put forth deep and original analyses of conception, semantic content, and the relationship between the two. I believe that, by combining Evans’ insights with (1)-(3), we are able to produce models of both semantic and cognitive content that satisfy two important requirements. First, those models enable us to hold onto all of the pre-theoretic intuitions that are prima facie inconsistent with consent-externalism. For example, those models enable us to hold onto our intuition that, in at least some cases, our beliefs about our own minds are characterized by a kind of certainty and incorrigibility that could not possibly characterize our beliefs about the external world. (As we will see, content-externalism has a hard time accommodating this datum.) Second, those models enable us to account for the important fact, stressed (but misunderstood) by content-externalism, that our concepts of spatiotemporal objects have an ineliminable causal component.
        Evans’ notion of a “cognitive map” is going to play a crucial role in our analysis of conception. We will also find important applications for Evans’ important distinction between “conceptual” and “non-conceptual” content.  Evans’ idea of a de re sense (Evans 1985: Chapter 10) – which came to have an important place in McDowell’s work (McDowell 1998: Chapters 10-13) – will also be discussed at length. We will find that it is an incoherent synthesis of a number of deep insights. 


McDowell on mental causality 


        I would like to end this introduction by substantiating a point made earlier. As previously noted, John McDowell argued that content-externalism is consistent with the fact that the mental is causally efficacious. Let w* be a world that is just like ours except that w* contains XYZ, instead of H2O. (In this context, take “world” to mean “planet.”) Let Smith be a person of our world, and let Smith* be Smith’s doppelganger in w*. In our world, Smith’s perception of a glass of H2O causes him to reach for that glass. In w*, Smith*’s perception of causes him to reach for that glass. 
       Here is what, according to McDowell, is going on. McDowell says that Smith’s perception has a different content from Smith*’s. There is some glass x such that the content of Smith’s perception does, whereas the content of Smith*’s perception does not, have x has a constituent; and there is some glass y such that the content of Smith*’s perception does, whereas the content of Smith’s perception does not, have y has a constituent. Further, there is some natural kind N – namely, H2O -- such that the content of Smith’s perception does, whereas the content of Smith*’s perception does not, have N has a constituent. Finally, there is some natural kind N* – namely, XYZ  -- such that  the content of Smith*’s perception does, whereas the content of Smith*’s perception does not, have N* has a constituent. 
     We’ve already seen some reason to believe that these contentions are wrong, and involve a conception of perceptual content that is rendered incoherent by its failure to distinguish a number of relevantly different notions – in particular, the distinction between data and meta-data, the distinction between literal and cognitive meaning, and the distinction between content and truth-maker. But let us leave that aside for now, and continue with McDowell’s analysis. 
        According to McDowell, it is patently obvious why content-externalism is consistent with the fact that the mental has causal powers. In virtue of having glass x, as opposed to glass y, for its content, Smith’s perception has causal powers not had by Smith*’s perception. Smith’s perception does, whereas Smith*’s perception does not, causes somebody to reach for glass x.  And in virtue of having glass y, as opposed to glass x, for its content, Smith*’s perception has causal powers not had by Smith’s perception. Smith*’s perception does, whereas Smith’s perception does not, cause somebody to reach for glass y. Similar remarks explain why, in virtue of having H2O, as opposed to XYZ, for its content, Smith’s perception has causal powers not had by Smith*’s perception 666.  
          But contrary to what McDowell says, the scenario just described is consistent with the idea that the causal properties of Smith’s perception are identical with those of Smith*’s. Imagine the following. Magnet A is attracted to magnet B. Magnet B happens to be green. But (ceteris paribus) if B were red or purple or orange, A would still be attracted to it. It is true that, because B is green, A is behaving in a way that it would not behave if B were some other color. (A is drawn towards a green magnet, instead of a red one.) But it doesn’t follow that B’s color has anything to do with A’s behavior. Ceteris paribus A’s behavior wouldn’t be relevantly different in a world where B were some other color. This shows that B’s being green has no effect on what A does, notwithstanding that, because B is green, A is doing something (namely moving towards a green magnet) that it wouldn’t be doing if B were red. 
       Similarly, given only that Smith’s behavior is caused by H2O, as opposed XYZ, it doesn’t follow that the glass’s containing H2O had any effect on Smith’s behavior and mentation that the glass’s containing XYZ would not have had. 
          Let C1…Cn be Smith’s causal properties. Given that Smith has those properties, it follows that he will act just like Smith*, if embedded in a situation exactly like the one that, in the scenario described a moment ago, Smith* is in. The same thing mutatis mutandis is true of Smith*. It would therefore be absurd to conclude from the differences between Smith’s and Smith*’s behavior (viz. that Smith reaches for a glass of H2O whereas Smith* reaches for a glass of XYZ) that they have different causal powers.  
        This argument is basically identical with one given by Fodor (1987b). Let S be the situation described by McDowell. Now suppose that Smith and Smith* switch places, but that otherwise w* and our world remain the same. Let S* be the situation that results. Obviously Smith and Smith* are going to act differently given that they are confronted with numerically different objects. But that doesn’t mean that one of them is causally different from the other. Two individuals are causally different just in case, were they to switch places but all other factors were held constant, they would act differently from how they in fact act. Smith and Smith* don’t satisfy this condition. Nor, for exactly similar reasons, do any two individuals who differ only in respect of how their current conditions originated. It follows that mental content is without causal powers to the extent that it is to be understood along content-externalist lines. And from this it follows that content-externalism strips content of causal potency and thus of existence itself.
          An object’s causal properties are to be understood not strictly in terms of its behavior in actual circumstances, but in terms of those aspects of its behavior that are invariant with respect to hypothetical or counterfactual changes in those circumstances (Fodor 1987b). McDowell’s argument involves a failure to appreciate this fact, and that is why it crumbles.
         McDowell’s analysis also involves a failure to distinguish causal properties from instances of such properties. On Monday, Jones beats Aaronson in a boxing match. On Tuesday, Jones beats Brown in a boxing match. Jones uses the very same boxing techniques on both days. So Jones’ boxing capabilities are instantiated on Monday, and those same capabilities are instantiated again on Tuesday. Of course, what Jones is doing on Monday is different from what he is doing on Tuesday: on Monday, he is defeating Smith, and on Tuesday he is defeating Jones. But this is because some one set of causal powers is instantiated in two different contexts.  
         Smith’s causal properties are instantiated in one context, and Smith*’s causal properties are instantiated in a qualitatively different context. But it obviously doesn’t follow that the properties being instantiated are different. Each of Smith and Smith* is behaving in exactly the way in which, were the two to switch places, the other would behave. This is consistent with their being identical in respect of their causal properties. So if, as the content-externalist alleges, Smith and Smith* differ in respect of the contents of their mental states, those differences have no causal significance. Once causal properties are distinguished from their instances, there ceases to be any temptation to say that Smith and Smith* are causally different.
         Content-externalism is the view two individuals may have different mental contents even though, leaving aside facts about the origins of their conditions, those individuals are qualitatively identical. But we’ve seen that those alleged differences in mental content are causally inert.  In other words, there are no differences in causal properties without differences in intrinsic properties. (How a given set of causal properties is expressed is a function of what is in the environment of the individual whose properties we are considering. But that is irrelevant, as we have seen.) Mental properties are not Cambridge properties; instance of them are not causally inert or explanatorily trivial. If they are anything at all, mental properties are causal properties. So a difference in mental properties must mean a difference in causal properties.[18] If Smith’s mental content really is different from Smith*’s, then Smith’s thoughts must be causally different from Smith*’s. So the supposed differences between Smith and Smith* turn out to be causally inert; and this means that they those differences don’t exist at all. 
        Differences in mental content are causally inert, and therefore non-existent, so far as they are to be understood along externalist lines. A corollary is that content-externalism is inconsistent not only with the causal potency of the mental, but with its very existence. 
        Stephen Stich (1978, 1983) sees that content-externalism is inconsistent with the presumption that instances of representational properties can do any causal or explanatory work. (As Stich puts it, content-externalism is inconsistent with the “autonomy of the mental.”) At the same time, Stich holds that content-externalism provides a correct analysis of the concept of representational content. On this basis, Stich concludes that we must reject the idea that our mental states are to be understood in terms of the concept of representation or in terms of any concept that presupposes that concept (e.g. the concepts of belief, hope, doubt, desire, and so on). Stich concludes that “folk-psychology” in its entirety must be thrown out and replaced with an entirely different kind of psychology. 
      Stich is right to say that content-externalism strips representational properties of any causal or explanatory significance. But Stich is guilty of a major non-sequitur in inferring from this that folk-psychology must be jettisoned. 666 For, as we will see, Folk-psychology is easily reconciled with content-internalism and thus with the fact that psychological properties are explanatorily important. 


Chapter 2 The Predicative Nature of Sense-Perception[19] 


      Let us begin by considering a statement made by Jon Barwise (1989: 26):
  
         When I look around I cannot see a single thing-it-itself, some sort of ideal physical object stripped of its properties and its relations with other objects. What I do see is a scene, a complex of objects having properties and bearing relations to one another. The properties and relations are every bit as important to what I see as the idealized thing-in-itself. In fact, what really counts is the whole complex of objects-having-properties-and-bearing-relations which constitutes the scene. 


     
         One sees states of affairs. One does not see objects simpliciter. This must be understood aright. Obviously one does see objects. That is a datum. But one sees objects by seeing the states of affairs in which they are embedded. You don’t just see Fido. You see an object with certain properties (e.g. it has a certain color fur and a certain number of legs), in a certain location. That location is, in its turn, visually represented to you in relational terms: Fido – or, strictly speaking, the state of affairs in which he is embedded – is given to you as being under the piano, next to Toonces the cat. 
      Everything that we just said about Fido is true mutatis mutandis of these objects. One doesn’t see Toonces. One sees an object with certain morphological, chromatic, and kinematic properties. One sees a four-legged creature with black with white spots, moving about in such and such a manner. 
      Before drawing what I believe to be some of the consequences of these points, I would like to make a distinction. Barwise rightly says that you don’t ever see a bare thing-in-itself: whenever something is given to you in visual perception, it is given to you as having various properties and standing various relations vis-à-vis other objects. But there are two ways to interpret this point. We can take it to mean:


(*) You see a bare thing-in-itself plus various instances of various properties and relations. 


Or we can take it to mean:


(**) You don’t see a bare thing-in-itself at all. Your seeing a given thing consists in instances of various properties and relations being given to you. It does not consist in your seeing some bare thing which is, so to speak, surrounded by various instances of properties and relations. 


(*) and (**) are inconsistent with each other. If there is any possibility of a thing’s being visually represented to one as a bare particular -- even as a bare particular that happens to be surrounded, so to speak, by various instances of properties and relations -- then it is ipso facto false to say that things must be represented as being propertied and interrelated. So if (*) is right, then (**) is false. Given that sense-perception is necessarily predicational, it follows that there is no prospect of a thing’s being visually represented as a bare particular and that (**) is therefore the right thesis. In perception you are not given a bare particular alongside instances of properties and relations. You are just given those instances. 
       Sense-perceived particulars are represented to you in terms of instances of properties and relations. When you see Fido, the content of your visual perception (so far as it can be put into words) is not given by a noun (“Fido”), but by a sentence (“at this point in time, in a certain place, there is a creature that has four legs and beige fur…”). For you to see Fido is for Fido to be described to you. Perception is description.
        Here an anticipation is in order. Later we will find that the content of a perception is not a proposition, even though the content of any perception can, at least up to a point, be given by a proposition. But this doesn’t affect the substance of our points about perception. The information encoded in any sense-perception is descriptive and existential in nature. The content of that perception is given information that affirms the existence of situations satisfying certain conditions and that, in so doing, describes objects. A consequence is that, so far as that information can be verbalized, it is given by existence-claims (“there is a four-legged animal with beige fur, sitting underneath the piano…”), and not by mere nouns (“Fido”). We will often refer speak of this information as consisting in “propositions.” But this is simply an expository device – the word “information” can always be substituted for “proposition”, provided the needed grammatical changes are made – and it mustn’t be supposed that we are taking it for granted that perceptual content is propositional in nature. On the contrary, we will go to great lengths later (Chapters 22-23) to show that it is not, and that this is one of the reasons why LOT crumbles.


Some consequences of the predicative nature of sense-perception 


      We’ve seen that perception is descriptive – that a perception of an object gives one a description of that object. This fact, taken in conjunction with a platitude of semantics, has far reaching consequences as to the nature of representational content. That semantic platitude is this: expression-types must be distinguished from expression-tokens. The expression-type “I” doesn’t refer to anyone; but any given token of it does refer (to the person who produced it). The expression-type “I am tired” isn’t true or false, but particular tokens of it are.
     Given these points, consider the following semantic rule: 


(S) Tokens of “Smith” directly refer to Smith. So in virtue of having the form “…Smith…”, a sentence-token is true exactly if Smith has the property…x…


At the moment, we may set aside the question whether natural languages in fact contain semantic rules like (S). (Our discussion of (S) will itself help us settle that empirical question.)
       The import of (S) is this. Tokens of “Smith” are not “connotative” or “descriptive.” For a token of “Smith is tall” to be true, it is necessary and sufficient that Smith be tall; and it is irrelevant whether Smith has any properties other than that of being tall. Put more formally, there is some x such that a token t of “Smith is tall” means is true iff x is tall. So, for some x, a token of “Smith is tall” encodes the “singular proposition” x is tall. 
        But we must distinguish (S) itself from one’s knowledge of (S). Unless people know (S), at least at some level, that semantic rule is of no use in helping people communicate with one another. After all, if people do not at some level know (S), then they cannot use that rule to produce and understand statements. 
        With these points in mind, let us ask a very basic question: How does one learn (S)? There are a few of different ways, and we will soon discuss all of them. But right now we may focus on the most fundamental one. 
       Smith is right in front of you. Your companion points to him, and says “that guy – the one right over there, standing next to the water-fountain – is Smith.” Here there is some x such that the semantic rule you are learning is simply this:


 “Smith” refers to x [or: tokens of “Smith” refer to x]. 


Now that you know (S), you can understand, and meaningfully produce, sentences of the form ┌…Smith…┐Your knowledge of (S) is thus implicated in your being able to understand and intelligently use expressions of that form. (By an “intelligent” use of an expression I mean one that embodies an understanding of what it means. People do, whereas parrots do not, intelligently say “it’s cold out today.”) 
        But here we come to a crucial point. In order for you to know (S), you have to know to be able to affix that label to the right person; you have to know who Smith is, at least on one delineation of that expression. Of course, you do know who Smith is, and you do know whom the word “Smith” labels. You know this on the basis of the ostensive definition discussed in the last paragraph: you saw Smith, and were told that “Smith” labels him. But what was the content of the visual experience through which Smith was represented to you? 
       For reasons that we discussed a little while ago, you didn’t just see Smith. You didn’t see a “bare thing in itself.” Of course, you did see Smith. But what was visually represented to you, in your seeing him, was not a bare thing-in-itself, but was rather an object having a certain morphology (e.g. he had a certain number of limbs, and the musculature of an athlete), certain kinematic properties (e.g. it was picking up a tennis-ball), certain (relative) spatio-temporal properties (it was next to a certain water-fountain in Topeka, Kansas, on a certain Saturday in April…). 
        So even though (S) itself is descriptively threadbare, the information through which (S) was made known to you was replete with descriptive articulations. Consequently, you must access (S) through such information. Semantically, “Smith” simply labels Smith. But you grasp (S) by having a mental state whose content given by some proposition like: 


(#) there is an individual x such that x had such and such morphological, spatio-temporal, kinematic…properties, and such that I saw x and such and such occasion, and such that “Smith” labels x. 


As (#) indicates, you know that, for some x, “Smith” is a mere label of x. But given the truth of (#), it follows that there is no x such that what a token of “Smith is tall” conveys to you is confined to the bare proposition x is tall. What follows, in fact, is that what such a token conveys to you is along the lines of: 


(##)  there is an individual x such that x had such and such morphological, spatio-temporal, kinematic…properties, and such that I saw x and such and such occasion, and such that “Smith” labels x; moreover, x is tall. 


       Let us put all these points together. For some individual x, what is literally meant by a token of “Smith is tall” is the bare proposition x is tall. But because of how you uploaded the relevant semantic rules, what such token conveys to you is at least approximately like (##). 


Why this analysis is consistent with our modal intuitions 


        For the sake of argument, suppose that, as I am proposing, (#) is what is communicated to you by a token of “Smith is tall.” That is consistent with the fact that you know that Smith – the person who in fact is named “Smith” -- might not have had of the properties in questing; he might not have been drinking from a given water-fountain at the relevant time. He might never have been in Topeka. He might not have been named “Smith.” 
       For some object x, both (#) and (##) are to the effect that “Smith” is a mere label of x. Notice that, in both cases, the occurrence of the word “labels” is well to the right of all the descriptive information regarding the circumstances relating to your first seeing Smith. Those propositions are to the effect that there is some x who in fact has these various properties, and that “Smith” labels x. Both of those propositions are consistent with the idea that x – the one who in fact is called “Smith” – might never have been near a drinking fountain in Topeka… Further, your knowing this last fact is consistent with the fact that you access S through (#) and also with the fact that you can access the meaning of a token of “Smith is tall” through (##).  


Mental content not object-involving


        Let us extend these points by telling a story. In terms of appearance, Mary and Twin-Mary are completely indistinguishable. (Here we are supposing that Mary and Twin-Mary are actual twins, and thus live in the same world.) Thus, to know that you were in the presence of the one as opposed to the other, you would either have to converse with her or study her behavior for an extended period of time. You are acquainted with both of them and thus have concepts of both. One day you see someone whom you know to be either Mary or Twin-Mary. There is, of course, nothing in your visual perception that tells you whether you are seeing the one as opposed to the other. But, let us suppose, the person whom you are seeing is in fact Mary.
       Here the content-externalist takes a bold position. He says that Mary herself is part of the content of your visual perception (Burge 1982, McGinn 1986, Kaplan 1989). Given this, suppose that, holding everything else constant, it had been Twin-Mary whom you were seeing. In that case, says the content-externalist, your perception would have had a different content. 
      Let us begin by articulating the reasoning behind the content-externalist’s position. Suppose that you see Mary (as opposed to Twin-Mary) sipping tea from a porcelain cup. Let V be this perception. V is veridical exactly if Mary has those properties, it being irrelevant what Twin-Mary or any other Mary look-alike is doing. Since pieces of information are individuated by their truth-conditions, it follows that any visual perception with different truth-conditions wouldn’t encode the same information as V, even if the two sense-perceptions were phenomenologically identical; and it also  follows that there is no perception with the same content as V* in any possible world where Mary doesn’t exist. Since mental states are individuated by their contents, it follows that V exists only in worlds where Mary exists. The relationship between V and Mary is constitutive. Mary is a constituent of V’s content and her existence is thus metaphysically necessary for V’s existence. V is no more capable of existing in a Mary-free world than water can exist in an oxygen-free world. This suggests that Mary herself – the flesh and blood object, not some Fregean concept thereof – is a component not only of the content of your visual experience, but of that experience itself. Given obvious analogues of this argument, it follows that anything of which one has a sense-perception is a constituent of the content of that perception and, indeed, of that perception itself. If we accept any form of externalism, McGinn (1986: 15) turns out to be entirely right: the mind is spread out all over the cosmos. 
         Here is what I will now argue. Mary is not a constituent of V’s content. Mary is described by that content, but she is not a component of it. V does exist in worlds where Mary does not. V occupies, at most, a sub-region of the region of space-time occupied by your cranium. 
         Etymologically, “content” means “contained in.” The word “content” is still used in this sense: “the contents of your carry-on bag must be securely in place before take-off.” But, of course, visual experiences and beliefs do not contain anything, at least not in the sense in which your wallet contains your cash. As it is used by philosophers, the word “content” is a technical term. 
        Let us start with a platitude that cuts through the vagueness and ambiguity of the term “content.” Whatever the word “content” means in this context, the content of an experience cannot be distinguished from what it tells you. (Of course, in this context, the word “tell” isn’t meant to have any linguistic overtones.) If your visual experience doesn’t tell you that p, then p isn’t part of the content of that experience. If your visual experience doesn’t tell you that Mary has phi, then Mary is no part of the content of that experience. 
       A corollary is that if what your visual experience tells you is no less consistent with Twin-Mary’s having phi than it is with Mary’s having phi – if Mary can be replaced with any phenomenal impostor without altering what your visual experience tells you – then we cannot say that Mary is any more a part of the “content” of that experience than Twin-Mary or any Mary-imposter. 
          Given only these points, we can begin to see cracks in the content-externalist’s position. Once again, consider V (your visual perception of Mary sipping tea). By itself, does V tell you whether you are seeing Mary as opposed to twin-Mary (or some other Mary-impostor)? No. V leaves that quite open, as a bit of fiction easily shows. While having V, you are told “you are seeing somebody who looks isn’t Mary but looks just like her.” You say in response: “given only what my current visual experience is telling me, I know that you are quite wrong.” Your response is a text-book case of fallacious reasoning. Given only what your eyes are telling you, you have no way of knowing the truth-value of what you’ve just been told. Of course, you are in fact seeing Mary: she is the one off of whom the relevant light-rays – the ones causing your visual perceptions – are bouncing. But by itself V is quite silent as to whether you are seeing Mary or Twin-Mary or some other Mary look-alike. 
        For you to know whether you are seeing Mary, as opposed a Mary-imposter, you need to consult information additional to that given you by V itself. You need to consider, for example, the fact that Twin-Mary hates tea and would never drink it; or the fact that Twin-Mary is now giving a lecture in Amsterdam (whereas you are now in Delaware); or that Twin-Mary, unlike Mary, has a medical condition which renders her incapable of holding a tea-cup. So by itself your visual experience doesn’t tell you that it is specifically Mary that is in front of you drinking tea. What tells you this is your visual experience plus background knowledge of the kind just described. 
      Of course, given V, you will probably not consciously have to go through an elaborate string of inferences to know that you are seeing Mary. Maybe that background knowledge operates by way of Chomskyan sub-personal inferences (this is my own view); maybe it does not (this is what McDowell (1998: Chapter 15), Searle (1994) and Evans (1985: Chapter 11) would say). What is certain is that, by itself, the information encoded in your perception is no less consistent with Twin-Mary’s being in front of you drinking tea than it is with Mary’s having those same properties. It wouldn’t be reasonable to deny that the relevant differential information is to be found outside that perception. 
       Suppose that we said that the relevant differential information were encoded into your perception. That position would involve our telescoping into your visual perception various pieces of information that quite obviously don’t belong there. We would have to telescope into that perception your knowledge that Twin-Mary is now in Amsterdam, that Robo-Mary is allergic to cats, and that Mary-7 has a medical condition that doesn’t allow her to sit down. It is clearly more reasonable to say that the relevant differential information interacts with the information that is encoded in your perception than it is to say that it is itself a part of that information. 
        Before moving on, we should address one possible misgiving that might arise with regard to the argument just given. Sellars (1963) made a compelling case that knowledge of the conditions of perception is needed assign a precise representational content to phenomenology. Given only the purely phenomenological aspects of your sense-perception, you could be seeing a square or a diamond, a patch of green or a patch of red, a small nearby object or a large distant one. It is your background that assigns a determinate content to this phenomenology: you know that you are looking at the object from above, and not from an oblique angle – that is why you see it as square, and not as a diamond. (The same point mutatis mutandis explains why the object appears red, not green; small and nearby, not large and far off; and so on.)[20]  So it might seem that, contrary to what I just said, background knowledge is telescoped into perceptual content – that, indeed, this is typically the case. If that is right, then the argument put forth in the previous paragraph implodes. 
        There is an obvious fallacy here. The kind of information of which Sellars is speaking is confined to facts about the conditions of perception. The fact that Twin-Mary takes a yearly trip to Amsterdam doesn’t fall into this category. Of course, Sellars’ insight does show that the information encoded in a perception isn’t neatly separable from background information. But blurry though the line between the two may be, it is clear that facts about Twin-Mary’s travel-habits are well on the other side of it.[21]     
         Taken by itself, what does your visual perception tell you? What is given to you in that perception is a person (or, at least, a person-shaped object) sitting next to a cat (or at least a cat-shaped object) on a sofa, a certain distance in front of you….In so far as the content of your perception can be “propositionalized”, that content is existential: there is an object x of such and such a shape sitting next to an object y of thus and such a shape…Perceptual content is existential.
       Here we must reaffirm a caveat that was stated earlier. To say that perceptual content is existential is not to say that perceptual content consists of propositions or any other para-sentential (or sentential) entities. Intuition resists the idea that the content of a perception can be exhausted by any series of propositions; and later we will find demonstrative support for our intuitions here. But given only that visual content isn’t necessarily propositional, it doesn’t follow that it isn’t existential. Plainly it is existential. You see that there is a man over, next to a car, near a tall building… 


Content-externalism and the content-internal character of entailment 


       Consider a world W* satisfying the following conditions. W* is just like our world except that, at the relevant time, it is Twin-Mary, and not Mary, who is sitting on the couch in front of you sipping tea. Let V* be the visual experience that you have under those circumstances. Given only this much, it would seem arbitrary to say that V and V* are numerically different visual experiences; for given only this much, it is perfectly possible that V* in the same way as V from the very same causal processes, and that (leaving aside what the content-externalist says about those perceptions), both are qualitatively in all respects. But the content-externalist is forced to say that V* is numerically different from V. After all, she says that V and V* have different contents, since the one does, while the other does not, have Mary as a part of its content. So given that content-bearing entities are individuated by their contents, the content-externalist compelled to adopt the dubious position that V and V* are numerically distinct. 
        It should be pointed out that no less an externalist than Tyler Burge (1982) insists that mental entities have their representational contents essentially and that it is therefore absurd to suppose that a perception could have a content different from the one it actually had. On this matter, I am in complete agreement with Burge. 
         The content-externalist’s position is inconsistent with basic facts about what it is for one piece of information to entail another. We’ve seen that the statement X and Y are the same information is equivalent with the statement for any piece of information Z, Z can be inferred from X in manner M iff Z can be inferred from Y  in manner M. V and V* satisfy this condition: nothing can rationally be inferred from V itself that cannot be inferred from V* itself (or vice versa); and nothing that can be inferred from the one is to be inferred in a different way, i.e. via a different series of deductions, from the way in which it is to be inferred from the other.  
       The content-externalist’s typical response to this sort of point is as follows: 


    If the content-externalist is right, V tells you that Mary is now sipping tea, whereas V* tells you that Twin-Mary is now sipping tea. So this last argument of yours simply begs the question against the content-externalist.


      But we’ve already seen why this point is a non-starter: it involves a failure to distinguish the information encoded in our perceptions from the information that, with the assistance of background knowledge, we derive from our perceptions.  
       The content-externalist’s position involves a failure to distinguish between content and truth-maker. V is a perception of Mary, as opposed to Twin-Mary, not because Mary is a constituent of V’s content, but because some fact about Mary is V’s truth-maker. As we’ve discussed, V tells you not that Mary is sitting in a certain place sipping tea, but that some woman (or, at any rate, some entity with the morphology characteristic of a woman) has those properties. There is indeed a woman satisfying that description and, under the present circumstances, that woman is Mary. But there are counterfactual scenarios where some fact about Twin-Mary would be the truth-maker of that same content. 
     
The relationship between causality and content 


       For a visual experience to be a perception of x, x must be part of the state of affairs that causes that experience. But given only that x satisfies that condition, it doesn’t follow that x per se is a constituent of the content of that experience. The content of a visual experience is, as we’ve emphasized, indistinguishable from what the experience tells you; and this, in its turn, is indistinguishable from what you can rationally infer from V, taken by itself. By itself, no visual experience can tell you that it is x specifically – as opposed to some x-look-alike – that caused it; there is no way that, by itself, any could perception could encode such differential information. This is easily established on generically logical grounds. 
        What your visual experience, taken by itself, tells you is going to be a function solely of facts about the physical properties of the situation right in front of you. (Indeed, it is going to be a function of a rather small subset of those properties.) So if one of constituents of that situation is replaced with something numerically distinct but qualitatively identical, there is no way for your experience to register that substitution. Suppose that x1, x2….xn are all qualitatively identical but numerically distinct objects. The character of your visual experience reflects only those aspects of the situation that are preserved in the light-rays that hit your retinas; and, for any i and any j, those aspects are invariant with respect to intersubstitutions of xi and xj. Your visual experience, taken by itself, cannot possibly register the fact that it is x3, as opposed to x24, that you are seeing.[22] 
      So given the nature of visual experience, there is no way that your visual experience, by itself, could discriminate between its being Mary in front of you and its being Twin-Mary in front of you. So if we plausibly identify the content of your visual experience with what that experience tells you; and if we plausibly identify what it tells you with what you may logically infer from it (or, at least, with a certain proper part of what you may logically infer from it); then we must say that Mary is no more a part of your visual experience than Twin-Mary or any other Mary-impostor. Given this last point, if we are to avoid theoretical arbitrariness, we must say that none of Mary or Twin-Mary or Robo-Mary…is a constituent of that content. All of this is consistent with the fact that your perception is of Mary specifically, and all of it is consistent with the fact that Mary – or, rather, some state of affairs involving Mary – is necessarily the cause of any perception of Mary. 


Content-externalism and disjunctivism 


       We can show how radical and counter-intuitive the content-externalist’s position is by following his own reasoning to its logical conclusion.[23] Once again, let V be a visual perception of Mary sitting on a couch holding a tea-cup. The essence of the content- externalist’s view is that Mary herself is a constituent of V’s content. But, of course, the same is supposed to be true each of the individual objects in the situation that is seen. So if that doctrine is right, the just mentioned sofa is a veritable component of V’s content, and so is the just mentioned sofa, and so is the cat sitting on that sofa – and so on. 
    Given this, let V1 be a perception that is just like V with this one qualification: the sofa represented by V (as defined a pages back) has been replaced with a qualitatively identical, but numerically distinct, sofa. Now let V2 be a perception that is just like V1 except that the tea-cup represented in V1 has been replaced with a qualitatively identical, but numerically distinct, tea-cup. Repeat this procedure until each of the objects represented by V – each bit of yarn, each carpet-fiber -- has been replaced with a qualitatively identical, but numerically distinct object, and let Vn be the resulting perception. 
      The similarity between V and Vn is not purely phenomenological. An artist who experienced V and painted what he saw would ceteris paribus produce a painting qualitatively identical with that produced by an artist who experienced Vn and then painted what he saw. Further, there is some one description D such that, in virtue of having either V or Vn, one would be warranted in affirming D. (D would be along the lines of: there is a woman with such and such properties sitting on a sofa holding a tea-cup…) It is clear that V and Vn a great deal of representational content in common.
        But content-externalism cannot accommodate this obvious fact. For the content-externalist, every one of the replacements we described would constitute a change in representational content. Numerically different objects, qualitatively different contents. A corollary is that V and Vn have the same content only to the extent that the objects represented by the one are numerically identical with those represented by the other. So, according to the content-externalist, V and Vn have no content in common. But intuition recoils at such a view; and, as we’ve just seen, it is demonstrably false. 
          John McDowell recognizes that, if content-externalism is right, then V and Vn have no representational content in common. Because he is a content-externalist, he accepts that V and Vn have no common content. This position, appropriately generalized, is sometimes referred to as “disjunctivism”, since it is given by the thesis content of the one perception is completely “disjoint” from the content of the other (McDowell 1998: Chapters 10-13). 
         Of course, McDowell concedes that V and Vn are identical in terms of phenomenology. But, in his view, that is where the similarity ends. McDowell does not address the fact that V and Vn have a great deal of existential information in common and that, consequently, the content of the one does at least overlap with that of the other. 
         A content-externalist might take the position that V and Vn do have some content in common: they have a purely “qualitative” or “general” content in common.[24] So each of them would be to the effect that some object having such and such properties is sitting on a sofa…But, at the same time, V would be to the effect that X is   sitting on a sofa Y, whereas Vn would be to the effect that  X* (≠X) is sitting on a sofa Y*(≠Y). So the general idea would be that representations have both a purely “qualitative” or “identity independent”, and that they also an “identity-dependent” content.[25]
         This view is either false or amounts to nothing more than a proposal that we make what would inevitably be a fruitless and confusing change in terminology. What the content-externalist is referring to as “identity-dependent content” is identical with what we have seen to be, not content, but meta-content. A related point is that the sort of “content” that V and Vn don’t have in common is a very different sort of thing from the content that they do have in common. The latter has inferential and causal powers that the former lacks. Consequently, the externalist is using the word “content” to denote two very different things.  
       I would like to address a possible objection not the analysis just outlined (I will put it in the voice of an imaginary spokesperson for content-externalism): 


      As you yourself have insisted, if a perception, or any other content-bearing entity, has content C, then it necessarily has that content. If B is someone’s belief that snow is white, then it is nonsense to suppose that B might have been a belief that 1+1=2. Given this point, it obviously follows that, if p is a perception of Mary, it is necessarily a perception of Mary. After all, in this context, it is a matter of simple semantics that the verbiage to the right of the word “of” denotes the content of the perception in question. In English, if I wish to indicate that X is a constituent of the content of some perception of mine, I say that I had a perception “of” X. Denying this would be like saying that “Socrates” doesn’t denote Socrates. For reasons you yourself have given, it follows that Mary herself, as opposed to some Fregean sense thereof, is a constituent of the content of that perception. 


    
      On a number of occasions, philosophers have drawn extravagant epistemological and metaphysical conclusions on the basis of epistemologically innocence facts about language.[26] This is one of those cases. 
        In almost all contexts, what is of interest to others, and even to yourself, is not what is encoded strictly in your visual experience, but is rather what you know on the basis of that experience. The vast majority of what we wish to communicate would be virtually impossible to communicate if our locutions were faithful to the division of labor characteristic of our information-gathering. Suppose that language forced one to make it clear exactly what was due to perception and what was due to extra-perceptual background knowledge. In other words, suppose that if one wished to explain how one knew that Mary had gone to the airport, one had to produce a statement of the form:


(#)  “I had a visual experience such that what was given to me in that experience was an individual x having a distinctively female morphology… and such that, given my background knowledge, it was evident to me that Mary uniquely satisfied the just stated existence claim.” 


In that case, one would need extreme cognitive and linguistic virtuosity to make and, to a lesser extent, to understand even the most pedestrian of statements. In narrow philosophical contexts, (#) is an informative and relevant statement. But in most contexts, the stratifications that (#) so faithfully preserves are of no interest. What we want to know is whether you have information about Mary (or Fred or Ethel…). The microstructure of the cognitive processes by which you attained that knowledge is irrelevant and, given the philosophical and psychological obstacles involved, would also be extraordinarily difficult to learn about in the first place. 
        For this reason, language does us a great service by telescoping (#) into “I saw Mary”, or “I had a perception of Mary”, and by effecting other, comparable condensations across the board. Were it not to do this, language could be used and understood only by a few prodigies, and could convey only in the most circuitous manner the information that all of us (including the aforementioned prodigies) typically wish to know. So given only that I must report what I saw by saying “I had a perception of Mary” (or, more idiomatically, “I saw Mary”), it doesn’t follow Mary is a constituent of the content of the visual experience itself. The primary purpose of language is to convey what is relevant, where relevance is to be understood in pragmatic, not philosophical, terms. Given this, there is no reason to expect that our locutions will always reproduce the delicate distinctions to which we must look for solutions to recherché questions of logic and epistemology. Indeed, given the practical nature of language, it is almost to be expected that language will obscure those distinctions.  




Chapter 3 Uniquely individuating descriptions 




We’ve already seen a number of reasons to accept the following three views: 


(1) Conception is essentially descriptive in character. 


(2) Expressions like “Socrates” and “Plato” are not descriptive to any degree: they are “directly referential.” 


(3) There is no difficulty reconciling (1) and (2) with each other. 


      In his landmark work Naming and Necessity, Kripke made a strong case for (2). (Like most contemporary philosophers, I believe that Kripke’s arguments are decisive.[27]) On this basis many have rejected (1), believing it to be incompatible with (2). I would like to show that (1) and (2) are not incompatible. 
       Let us start with a quick summary of some of the relevant points in Naming and Necessity. According to Russell (1918, 1948), “Socrates” is synonymous with a definite description; this might be “the greatest philosopher to have died of hemlock poisoning.” To understand the word “Socrates”, and thus to understand sentences of the form “…Socrates…”, one must obviously know the semantics of “Socrates; and one must therefore know that “Socrates” is synonymous with that definite description. Consequently, anyone who uses the word “Socrates” with understanding is able to produce a description that applies to Socrates and Socrates alone. 
        In general, if one knows the semantics of a referring term, then one knows some description that applies uniquely to the referent of that term. Supposing that x is the referent of “Gilgamesh”, if I understand what is meant by sentences like “Gilgamesh was wise” or “Gilgamesh lives a long time ago”, then I know of some description that singles out x. If I know of no such description, then I cannot really know what is meant by such sentences.
        Supposedly, Kripke demolished this view. Consider any description that Socrates uniquely satisfies. Here is an example: “the greatest philosopher to have died of hemlock-poisoning.” One can understand sentences of the form ┌…Socrates…┐ without knowing that the referent of “Socrates” consumed hemlock. One can understand “Socrates was wise” without knowing that “Socrates” picks out somebody who uniquely satisfies the description: greatest philosopher to have died of hemlock-poisoning. 
       This point holds for any description that singles out Socrates. Consider the description: “the person who figures as the protagonist in most of the platonic dialogues.” One can understand the sentence “Socrates was wise” without having the slightest idea that he was a protagonist in any philosophical dialogues. Given any description D that applies uniquely to Socrates, one can understand “…Socrates…” without knowing that D applies to the referent of “Socrates.”[28] 
      This point has many apparent consequences. Some of these are semantic in nature. Others are epistemological. 
        Here is one of the semantic consequences. “Socrates” is not synonymous with any definite description. Given any description D, one can know that “Socrates was wise” is true without knowing that somebody uniquely instantiated D and that any such person was wise. So it isn’t tenable to maintain that “Socrates” is synonymous with “the greatest philosopher to have died of hemlock-poisoning” or with any other definite description.      
      Here is one of the supposed epistemological consequences. One can think about Socrates without knowing of any description that singles him out – without knowing a uniquely individuating description (UID) of the kind just described. 
  
The causal theory of reference and conception 


       Kripke’s argument has other apparent consequences, both for semantics and epistemology. Let us start with a question: Why does “Socrates” refer to Socrates and not (for example) Plato? Russell’s answer was this: “Socrates” is synonymous with a description that is true of Socrates and Socrates alone. Kripke made a powerful case against this answer. So how does Kripke answer our question? His answer is that “Socrates” refers to Socrates because a certain kind of causal relation holds between tokens of “Socrates” and Socrates himself (or, more exactly, states of affairs involving Socrates).[29] 
       The following story will help us further explicate Kripke’s views on this topic. Somebody – let us refer to that person as  “Smith” -- saw Socrates. Socrates’ presence thus caused Smith to have certain visual experiences. Smith then gave a name to Socrates. (Let us idealize away from the fact that, for cultural reasons, that is probably not how Socrates was named.) Smith was able to pass that name along to people who did not themselves see, or otherwise sense-perceive, Socrates. Of course, for Smith to pass along that name to someone, that person had to be causally connected to Smith. The process just described is repeated over and over. Let us suppose that I am the 521st installment in a sequence of events like the one described.[30] 
          Smith’s original term for Socrates may well have undergone phonetic distortion. What I have been left with is the sound (or sound-type) “Socrates”, which may well probably very different in terms of phonetics from the term that Smith used. But that is not relevant here. What is relevant is that, when I produce instances of that sound-type, my words refer back to Socrates precisely because I am connected to Socrates by way of a chain like the one just described. When I say “Socrates”, my words refer to Socrates because they are causally connected to him in a certain way. In general, if an expression E refers to an object O, that is in virtue of the fact that tokens of E stand in a certain causal relation to states of affairs involving O.


Why the causal story is only a chapter in the descriptive story


       Let us now evaluate the various claims just put forth. How do you learn what a given word refers to? At first, there appear to be two ways: you can learn it by description or by ostension. (Soon we will see that there is a third.)
      Let us illustrate these points with a story. You are young, and have thus never heard the name “Socrates.” Somebody says to you: 


(*) “ ‘Socrates’ is the name of the most famous philosopher to die of hemlock poisoning.” 




Here the word “Socrates” has been defined for you in a descriptive manner. In effect, you were told: somebody O uniquely satisfies a certain description (viz. most famous philosopher to die of hemlock poisoning) and “Socrates” names O. 
       On the face of it, there seems to be a second, entirely distinct way of learning what a term refers to: you can be given an ostensive definition. Here is an illustration. You are in a crowded market place. You see a man haranguing a crowd. Your companion says: 


(**) “that person over there [pointing to the orator] is named ‘Socrates’.” 


   
       But, in a certain class of cases, one is able to acquire the ability to use a referring term without ever having been given either an ostensive or descriptive definition of it. Suppose that you and two other people (Smith and Jones) are talking. All of a sudden Smith and Jones start talking about somebody named “Argo.” They never say who “Argo” refers to. They never say: “Argo was the president of our fraternity back in college” or “Argo was my divorce lawyer; and by sheer coincidence he’s Smith’s racquetball partner.” They do not ostensively define “Argo, since he is not present.  Smith and Jones simply prattle on about “Argo”, and you are too polite to ask them who that person is. 
     Nonetheless, as Gareth Evans (1985: Chapter 1) pointed out, it seems that, even under these circumstances, you can use the word “Argo” in a meaningful way. You can say “it sounds as though Argo is a text-book case of somebody with borderline-personality disorder”; and you can ask questions like “did Argo mean to do that to you, or was it just an accident?” 
    So, on the face of it, it seems that you can acquire the ability to use “Argo” in a meaningful way without ever having been given an ostensive or descriptive definition of it. When you say “it sounds as though Argo is an evil person”, you are using the expression “Argo” with understanding; you are not in the same category as a parrot that mindlessly produces those same sounds. It thus appears that you can simply “pick up” the ability to use “Argo”, and names generally: there needn’t be an ostensive or descriptive definition.[31] 
   
     Let us take stock. There seem to be three ways that a proper name N can be inducted into one’s lexicon: 


(i) one can be given an ostensive definition of N; 
(ii) one can be given a descriptive definition of N; or 
(iii) one can just “pick up” the use of N.




         Given this, it is easily shown that that one’s learning what an expression refers to always involves one’s learning some description that singles out its referent. All of (i)-(iii) collapse into (ii). 
     Let us start by considering category (i). Suppose that somebody ostensively defines “Socrates” for me. I see somebody haranguing a mob. My companion says: “that person is named ‘Socrates’.” 
      Under this circumstance, I know that there is some individual x such that x uniquely has certain properties, and I know that “Socrates” refers to x. Ostensive definitions work by way of knowledge of uniquely individuating descriptions. Somebody points to some person (or object) O and says: “that guy is named ‘Fred’.” For the definition to work – i.e. in order for you to learn to what (or whom) “Fred” refers – you must have some way of singling out the person ostended. Suppose your companion points in a certain direction and says “that is Fred”, but there are thirty different equally salient objects. In that case, the definition won’t work, since you aren’t able to pick out the right object. 
       Now suppose that there are thirty numerically different, but (leaving aside location) qualitatively identical men in a certain place. Your companion Bob goes up to one of them, put his hand on his shoulder, and says: 


(*) “this guy is named ‘Fred’.” 


Even though the person just named is qualitatively just like many others, you know of some description that applies to him and to no one else. You know the following proposition to be true: there is some individual x such that x is uniquely a person whom Bob just picked out – such that x uniquely has the property that Bob just put his hand on x’s shoulder – and “Fred” names x. This time Bob’s definition works. It works only because you know of some existence claim that Fred, and Fred alone, satisfies. 
      The description is not one that tells you much about what kind of person Fred is. In fact, that description doesn’t tell you anything about how Fred is psychologically or (leaving aside facts about spatio-temporal location, and leaving aside also the information encoded in your perception concerning Fred’s appearance) physically different from other people. The description in question gives you enough information to cognitively single out Fred, and it gives you little beyond that. But that is neither here nor there. In this context, there is only one important point, namely: your knowing what “Fred” refers to depends essentially on your knowing the truth of some proposition of the form: somebody x uniquely has phi and “Fred” names x.     
      This is not to deny that your knowing what “Fred” refers to involves your having some kind of causal connection to Fred. You do have some kind of causal connection to Fred: you see him, and this involves your being causally connected to him. You acquire the ability to use the word “Fred” in consequence of (among other things, I will argue) this causal connection.  So your subsequent uses of “Fred” refer to Fred in virtue of this causal connection (among other things). 
      But the causal connection is a component of your knowledge of a uniquely individuating description. In the story just told, that description was (at least approximately): “there is some object x over there such that, a moment ago, Fred put his hand on x’s shoulder and said: ‘this guy is named “Fred”’.” The relevant causal connection between you and Fred corresponds to the context-sensitive terms in that statement. (These are the expressions in italics.) 
        We will see that in any case where a causal connection between X and Y is constitutive of X’s concept of Y, that connection is embedded in X’s knowledge of some description that Y uniquely satisfies; and if that description were verbalized, that causal connection would be expressed by one or more of the context-sensitive expressions in that verbalization. 
      Let us now deal with category (iii). We will soon see why we are skipping to (iii), and not dealing right away with (ii).
      Once again, consider the case where you are talking with Smith and Jones. Remember what we said earlier about that situation. Smith and Jones are acquainted with Argo, but you are not. At no point in the conversation do they ever say anything like “Argo was my divorce lawyer” or “Argo was the best man at my wedding.” They never enunciate a uniquely individuating description; they never give you a definite description that applies to Argo.
       Of course, given that they are producing sentences of the form “…Argo…”, it follows that you are, in effect, given many indefinite descriptions that he satisfies. Smith says “Argo is a real cad.” So here you are being given an existence claim of the form: somebody x is a cad and “Argo” refers to x. But, of course, many people are cads. So given only that you know the truth of this existence claim, it doesn’t follow that you know which to specific person – which specific cad – “Argo” refers. 
       But the truth is that, in virtue of the fact that you overheard Smith and Jones using the word “Argo”, you have been given a definite description that Argo uniquely satisfies, and you have learned some true proposition of the form: something x uniquely has phi and “Argo” refers to x. 
       We may show this through an extension of our story. Unlike you, Smith is personally acquainted with Argo. For reasons that we’ve already covered, Smith thus knows some true proposition of the form: some thing (or some person) x uniquely has phi and “Argo” refers to x. 
       Given this, let us take the next step in our argument. On each occasion where Smith or Jones says “Argo was a cad”, there was one person to whom Smith was referring by means of the word “Argo.” Suppose that, on occasion t, Smith says “Argo was a cad.” Obviously the description ┌x is a cad┐ is indefinite, and applies to many. But on that occasion, there was exactly one person whom Smith was describing as being a cad; and you know this merely by virtue of overhearing Smith’s statement. So just by virtue of being in colloquy with Smith, you do pick up knowledge of some claim like: on occasion t, there was exactly one person who Smith described as being a cad, and “Argo” refers to x. 
       We must be careful to distinguish between the following claims: 


(a) Exactly one person has phi. 
(b) Exactly one person is being described, on some particular occasion t, as having phi. 


        Your picking up the word “Argo” doesn’t involve your learning the truth of some claim of the form: exactly one person x is a cad, and “Argo” refers to x. Such a claim is false, given that there are many cads. Your picking up “Argo” involves your learning the truth of some claim of the form: on such and such occasion, exactly one person x is being described as a cad, and “Argo” refers to x.
        We must take care to make one other distinction. Smith himself never uttered an existence claim of the form:  there is some x such that x uniquely has phi and “Argo” refers to x.  Smith himself never uttered an existence claim of the form:   on occasion t, I (Smith) referred to somebody x as a cad and “Argo” refers to x. Smith said only “Argo is a cad.” But the information that you are given, by virtue of being in discussion with Smith, is not confined to what Smith himself says. When Smith says “Argo is a cad”, the information that is encoded in his words is quite threadbare. But even though what Smith was saying might have been minimal, the information you have about Smith’s saying it is enormous. You know when and where Smith performed that speech-act, and you have much other non-trivial information about it: and that information does suffice to give you the right kind of uniquely individuating description. 
      There is no vicious circularity in this account.[32] Smith personally met Argo. He learned the meaning of “Argo” through an ostensive definition. Maybe Smith himself gave Argo the name “Argo.” (For cultural reasons, this is not likely. But that is not relevant.) In any case, Smith saw Argo, and then learned (or possibly stipulated) that the person he was seeing was named “Argo”. 
       You meet Smith. You have a conversation with him.  On some specific occasion within that conversation, Smith says “Argo was a cad.” You thus know that, on that occasion, there is somebody x such that Smith is describing x and x alone as a cad, and that “Argo” is the term Smith is using to refer to x. The uniquely individuating description that you subsequently associated with “Argo” is not: the unique person x such that x is named “Argo.” Rather, it is: the unique person x such that, on such and such occasion, Smith was describing x as a cad.
      In the circumstance just described, you are only at one remove from somebody who was directly acquainted with Argo – with somebody to whom “Argo” was defined ostensively. But what we’ve said applies equally to the case where you are at five hundred removes from the referent of the word in question. Consider this scenario. Smith doesn’t personally know Argo. But Smith knows Brown, and Brown personally knows Argo. Smith is not given an ostensive or descriptive definition of “Argo”. But Smith overhears Brown saying “Argo is a cad.” On this basis, Smith is able to add “Argo” to his own lexicon. (We just described the principles governing such an addition.) You then overhear Smith saying “Argo is a cad”, “Argo is a mean person”, and so forth. You are not given an ostensive or descriptive definition of “Argo”. But on the basis of what you overhear, you are able to add “Argo” to your lexicon: the principles that govern Smith’s appropriation of “Argo” obviously apply to your appropriation of that name. The same principles would apply if you were five hundred removes from somebody who was actually acquainted with Argo. Invariably, what would enable you to use “Argo” to refer to Argo would be your knowledge of some existence-claim that Argo uniquely satisfies.[33] 
        Let us now consider category (ii). Here it is very easy to fall prey to a confusion. Imagine the following. You have never heard the word “Socrates” before. You are talking with your friend Charlie. He says “Seymour is second only to Socrates in philosophical ability.” You don’t know who “Socrates” refers to. So you ask: “Who is Socrates?” Charlie says: “Socrates was the author of the Nichomachean Ethics and the Posterior Analytics.” 
      Of course, Charlie is wrong. Socrates did not write either of those works, and “Socrates” does not refer to the author of either of those works. At the same time, in consequence of your having this exchange with Charlie, you can use the word “Socrates” to refer to Socrates. 
        Here it seems as though you are able to use the word “Socrates” to refer to Socrates, even though your only belief about him is wrong – even though the only thing you “know” about him isn’t true. But this appearance is misleading. What we have here is a case where you add a word to your lexicon in manner (iii). You do know some uniquely individuating description that applies to Socrates. But that description is not “the unique author of the Nichomachean Ethics and the Posterior Analytics.” Rather, it is: ┌the person to whom, on occasion t, Charlie ascribed the property of writing the Nichomachean Ethics and the Posterior Analytics┐, for some value of t. 
       In most cases where we seem to be appropriating a name in manner (ii), we are in fact appropriating it in manner (iii). But we can certainly construct a case where, unmistakably, we are appropriating a name in manner (iii).[34] 
      Suppose you and Charlie are having a conversation. Neither of you has any idea who invented the zipper. You and Charlie decide that, at least when speaking to each other, you will refer to that person, whoever it is, as “Julius.” (See Evans 1985: Chapter 7.) So you have no idea who invented the zipper. But you know that somebody did so, and you have stipulated that “Julius” is to refer to that person.  Thus you have added a semantic rule to English (or, at any rate, to a certain idiolect of English). It must be made clear what that rule is. The rule is given by the following: 


(Z) If x uniquely invented the zipper, then “Julius” refers to x. 


The descriptive information is given wide-scope with respect to the “refers to” operator. So if Smith was a unique zipper-inventor, then “Julius was a millionaire” means Smith was a millionaire. That sentence does not mean: somebody x uniquely invented the zipper and x was a millionaire. “Julius” is a name, not a quantifier. 
    You and Charlie don’t know who “Julius” refers to. But it does refer to somebody. On the face of it, it certainly seems as though you can use it significantly: you can, with understanding, say things like “Julius was probably a talented inventor” and “Julius must be worth a fortune”. 
       Some authors, e.g. Kaplan (1968) and Donnellan (1974), have said that, under the circumstances, you cannot say things like “Julius must be worth a fortune” and really mean them. This is controversial. (I will soon argue that it is true.) But what is clear is that if you and I can use the term “Julius” with understanding, it is only because we know some true claim of the form: somebody x uniquely has phi, and “Julius” refers to x. Here, of course, phi is the property of inventing the zipper. 
       I do not wish to be misunderstood. A case can be made (and soon will be made) that unless you know who invented the zipper, you don’t know which proposition is semantically encoded in “Julius must be worth a fortune”, or in any other sentence of the form ┌…Julius…┐ What you actually know is some meta-linguistic proposition like: for some object O, the sentence “Julius must be worth a fortune” is true exactly if O must be worth a fortune. Since you don’t know which exact person invented the zipper, you don’t know who “Julius” refers to; and you therefore don’t know which proposition is encoded in that sentence. But, at the same time, you have metalinguistic knowledge about “Julius must be worth a fortune” which, in some respects, simulates real understanding of it. 
       In everyday life there are many cases where we seem to be adding a name to our lexicon in manner (ii). Suppose little Timmy has never heard the name “Shakespeare” before. You say to him: “Shakespeare is the person who wrote Romeo and Juliet.” Here it seems that the three year old is appropriating the name “Shakespeare” in manner (ii); for what you are telling him is, in effect: there is some x such that x uniquely wrote Romeo and Juliet and “Shakespeare” refers to x. 
         But really little Timmy has appropriated “Shakespeare” in manner (iii). A Kripke-style argument shows this. After your conversation with him, little Timmy can make statements about Shakespeare. They may be wrong and ill-informed. But they are wrong and ill-informed statements about Shakespeare. Let us suppose that Timmy produces the words “did Shakespeare like French fries?”, and “Shakespeare must have been weird, because his writing is so funny.” (I say “produces the sounds”, instead of “asks” and “says”, so as not to prejudge the question whether Timmy is, in fact, saying or asking anything.)
        But suppose it turns out that, although he wrote Hamlet and King Lear and Timon of Athens, Shakespeare did not write Romeo and Juliet. Does that mean that little Timmy’s Shakespeare-statements were blanks? Does it mean that, in asking “did Shakespeare like French fries?”, Timmy wasn’t really asking anything? Does it mean he was merely simulating what is done by somebody who is actually asking a question? It seems not. It seems that little Timmy did manage to ask whether Shakespeare liked French fries.[35] 
     But if Little Timmy’s ability to refer to Shakespeare depended on Shakespeare’s having written Romeo and Juliet, then his statements would indeed have been abortive. Little Timmy couldn’t ask or say anything about Shakespeare if his ability to refer to that man depended on the truth of the statement: somebody uniquely wrote Romeo and Juliet and “Shakespeare” refers to x.
      What is going on here is that little Timmy added “Shakespeare” to his lexicon in manner (iii). He heard you refer to him. Thus, given what we said earlier, the existence- claim through which he added “Shakespeare” to his lexicon has the form: there is some x such that, on such and such occasion, Daddy said that x wrote Romeo and Juliet and “Shakespeare” refers to x.  That existence-claim remains true, even though the other one -- somebody uniquely wrote Romeo and Juliet and “Shakespeare” refers to x – turned out false. 
       Let us now talk about the existence-claim that turned out to be wrong. What role did this proposition have? Another piece of fiction will help us answer this question. 
       You see somebody at a party. You don’t know him. He acts as though he is very important. You ask your companion: “Who is that guy? What gives him the right to be so self-important?” You are told: “He is the dean.” Before you know who that person was, you were able to refer to him, and also to have thoughts about him. You were able to think that he is obnoxious and to wonder what gives him the right to be so haughty. But, despite this fact, there is still some sense in which you don’t know who he is. You can think about and refer to somebody without knowing who they are. When you say to little Timmy: “Shakespeare is the guy who wrote Romeo and Juliet”, you are telling him (or trying to tell him) who Shakespeare was: and this, as we’ve just seen, is different from transmitting to Timmy the ability to think about or refer to Shakespeare. (Of course, what we’ve said about “Shakespeare” is true of proper nouns generally.)
      Most “descriptive definitions” are really cases where one is learning who somebody is, or which object something is. They are not cases where one is acquiring the ability to refer to, or think about, that thing. Usually, but not always, the ability to refer to, and think about, the object in question seems to pre-exist knowledge of who somebody is or which object something is.  
        So while there may be cases where one is genuinely acquiring a name in manner (ii), they are not easy to produce, and they tend to be highly artificial. The only possible examples arise in connection with expressions like Evans’ “Julius.” 
       Let us summarize what we have found thus far. Any case of one’s adding a referring term to one’s lexicon involves one’s knowing some description that singles out the referent. For any name N, one’s adding N to one’s lexicon involves one’s knowing some true claim of the form: somebody x uniquely has phi, and N names x. This is true even in the case where one acquires the name through ostensive definition.
       The existence claims are not usually ones of historical moment; they are not ones like somebody x wrote Romeo and Juliet and “Shakespeare” names x. They are usually highly specific to the peculiarities of one’s own situation. But what is important is that knowledge of some such claim, trivial though it may be from a historian’s standpoint, is needed to use a name to refer to a thing. 


Neo-descriptivism untenable 


          Even though we learn what a name refers to through some existential-descriptive claim, the name itself is just a label. (In any case, this is what Kripke’s arguments strongly suggest, and we will continue to find confirmation for this position.) Semantically, “Shakespeare” simply labels Shakespeare. It doesn’t have any descriptive content.  But, as we’ve seen, one always learns which thing a name labels through some existential-descriptive claim. The semantics are not existential-descriptive; but the act of learning the semantics is existential-descriptive.  The semantic rule for “Shakespeare” must be given to you in some way or other. But what is given must be distinguished from how it is given.
         The following statement is false: 


(S1) The semantic rule for “Shakespeare” is this: somebody x uniquely wrote Hamlet and “Shakespeare” names x. 


S1 is false because “Shakespeare” refers to Shakespeare in worlds (that are identical with ours in respect of the semantic facts that hold in them) where Hamlet was never written. So the semantic rule for “Shakespeare” cannot have anything to do with Hamlet. 
       Unlike S1, the following statement is true: 


(S2) Somebody x uniquely wrote Hamlet and, and the semantic rule for “Shakespeare” is this:  “Shakespeare” names x. 


   The operator “the semantic rule for ‘Shakespeare’ is” must be given narrow-scope. Otherwise we end up committed to the kind of descriptivism that Kripke refuted. The name is just a label. For some x, the literal meaning of “Shakespeare was prolific” is simply: x was prolific. Nothing about the authorship of Hamlet is to be found in the literal meaning of that sentence.
    Though false, S1 doesn’t involve as many falsehoods as the following: 


(S3) The semantic rule for “Shakespeare” is this: for any predicate ┌…x…┐ ┌…Shakespeare…┐ means: somebody O uniquely wrote Hamlet and…O…


    
    What is literally meant by “Shakespeare was bald” is simply Shakespeare was bald, and is not: somebody x uniquely wrote Hamlet and x was bald. 
     To avoid running afoul of Kripke’s correct points, we must take care to give the relevant operators – ┌refers to__┐, ┌is the semantic rule for__┐ – narrow scope. We must make sure that they are safely to the right of potential descriptive, and therefore modal, contaminants. We’ve seen that whenever you learn the semantics of a name, it is through descriptive information. But you give the descriptive content wide-scope. That is why you don’t regard ┌N has phi┐ as analytic, or as true in all possible worlds. The semantic information is given narrow-scope; the epistemological information is given wide-scope; and that is why you have all the right modal intuitions. 
      Dummett (1973: 110-151) argues for wide-scope descriptivism. In his view, “Socrates was necessarily bald” means: there was some x such that x was a unique great philosopher to drink hemlock and necessarily: x was bald. It is pretty clear that this doctrine is false.[36] “Socrates was bald” doesn’t entail “somebody drank hemlock.” Dummett’s analysis deals with some of Kripke’s modal points, but not with Kripke’s compelling point that there is no analytic connection between “Socrates was bald” and “somebody drank hemlock.” 
      It is to be emphasized that (S2) is true only because, in it, the “the semantic rule for ‘Shakespeare’ is this:” operator is given narrow scope, so that no descriptive information falls within its clutches. By being careful about where we put that operator, we avoid any kind of descriptivism, and our analysis remains Kripke-friendly. 
 
The problem of forgotten start-up descriptions 


       There is a point that we must address. It will help if we first define a bit of terminology. Let 


(^) something x has phi


be a true proposition. Of course, what makes it true is that some particular thing O has phi. The truth of any generalization supervenes on the truth of some singular proposition. Let us refer to O as the “verifier” of (^). 
      Consider the claim “somebody is bald.” This is true because particular people are bald – because Bob and Fred are bald. Bob and Fred are verifiers of “somebody is bald.” An existence claim can have many verifiers. (False existence claims have none.) A true existence claim of the form “somebody uniquely has phi” has exactly one verifier. 
       With this terminology in place, we can easily state a formidable objection to our analysis. One typically forgets the existence-claim through which one added a name to one’s lexicon. One typically forgets the first time one heard “Shakespeare” or “Aristotle”; one often forgets one’s first meeting of a person. Given this, one is tempted to say: 


      You don’t necessarily associate any uniquely individuating description with “Aristotle” or “Smith” or “Jones.” Such a description may have been necessary to enable you to refer to those people, and to think about them. But once that ability is in place, the description drops out. At that point, there can be pure thought about the entities in question. You can just think about Aristotle and Smith; you don’t have to think about them through a uniquely individuating description.[37] 


        Obviously one does often forget the existential information that “started up” one’s conception of some objection – one often forgets such start-up descriptions. But we must not, on this account, accept the objector’s position. It is hard to believe that conception is as impoverished, as barren of descriptive content, as the objector makes it out to be. I thus propose an alternative view, namely: when one forgets a start-up description, what happens is not that one ceases to have knowledge of a uniquely individuating description, but rather that one replaces one such description with a related but distinct one. 
        Remember what we said earlier about “Fred.” If you add “Fred” to your lexicon in manner (i), i.e. through an ostensive definition, that involves your knowing some claim of the form: somebody x uniquely has phi and “Fred” names x. Given this, let us tell another story. You and a friend are at a party. You see somebody talking animatedly. That person is wearing a bowler hat. At time t, your friend points to that person and says “that is Fred.” Your adding “Fred” to your lexicon involves your knowing some existence claim – some proposition (or piece of information) that is at least approximately of the form: 


(e1) there is now somebody x such that I am now sense-perceiving and focusing on x, and who is wearing a bowler hat, and “Fred” names x. 
  
    Let us suppose that, a minute or so after “Fred” is ostensively defined for you, you go up to him and start talking. You now have a new uniquely individuating description of him. There are a number of reasons for this. First of all, the mere lapse in time between your current situation – your now talking with Fred – and the initial ostensive definition by itself guarantees that you will have a new uniquely individuating description of him. At time t, e1 was your uniquely individuating description. But because that time has now passed, e1 has been replaced. By itself, the mere passage of time replaces e1 with: 


(e2) there is somebody x such that I was sense-perceiving x a minute or two ago, and who was then wearing a bowler hat, and “Fred” names x.[38] 




      Notice that e2 “interlocks” with e1. The thing having the property specified in e2 is the same as the thing having the property specified in e1. Of course, the uniquely individuating description changes. But the new one is related to the old one in such a way that something x uniquely makes both of them true. The new one thus inherits the verifier of the old one. In a moment we will say more about this process of inheritance or transmission. 
       But things other than the mere passage of time force e1 to be replaced with a new uniquely individuating description. You are now engaged in conversation with Fred. You can see him more clearly. From afar he looked hale and strong, but you now see that he is puffy and out of shape. He is saying a number of things to you (he is talking about the national debt and the current administration). As a result, you generate a new uniquely individuating description of Fred. Your new one is (we may suppose): 


(e3) there is somebody x such that I was sense-perceiving and focusing on x a minute or two ago, and such that x was then wearing a bowler hat; and I am now conversing with x, who is now talking about the national debt, and who looks puffy and unhealthy, and who is named “Fred.” 


Notice that e3 and e2 interlock. e2 transmits its verifier to e3. 
     Now that you have e3, you can drop e2 and e1. You can completely forget them; and that will not jeopardize your ability to think about Fred. Suppose a moment passes; you have stopped talking with Fred. By itself, the mere passage of time replaces e3 with a slightly different claim: 


(e4) there is some x such that, a moment ago, x was talking about the national debt, and such that x looked puffy and unhealthy, and “Fred” names x. 




      Suppose that you have completely forgotten e1-e3. You still have some uniquely individuating description of Fred. This will continue to be the case so long as you are able to think about Fred. You go home at night. (e4) is now replaced with: 


(e5)  there is some x such that, several hours ago, at a party,  x was  talking about the national debt, and x looked puffy and unhealthy, and “Fred” names x. 


     This process can continue ad infinitum. One’s ability to think about and refer to something can only be started up by one’s acquiring knowledge of the right kind of existence-claim. Typically, that specific claim is forgotten. But it is replaced by another existence claim that interlocks with the first. That second one may, in its turn, be replaced by a third; the third by a fourth; and so on. Thus, contrary to what the objector says, the ability to think about, and refer to, an external object always involves possession of a uniquely individuating description that applies to it. 
       
The concept of recognition 


       The objector says that there can be “pure”, i.e. non-descriptive, conceptions of objects. But conception is surely not so innocent; and this becomes clear when we consider the phenomenon of recognition. 
         To recognize something is not, at least not merely, to register the truth of a bare identity proposition – a proposition of the form O=O. To register the truth of Smith is Smith is not, by itself, to recognize anything; and to recognize something is not (merely) to register the truth of O=O. 
         Recognition is obviously replete with knowledge of descriptive content. When you recognize the man in the distance as the man who insulted you at the restaurant, a great deal of descriptive, and therefore existential, knowledge is involved. You know that there is some x such that x insulted me at the restaurant…You also see that there is some y in the distance such that…Your recognizing the man in the distance as the man from the restaurant involves your “integrating” these pieces of information. You see that both descriptions – man in the distance and man from the restaurant – connect somehow; you see that there is some one thing such that both descriptions apply to it. In other words, you recognize the truth of some existential claim like: there is some x such that x is a man who insulted me at the restaurant and is also a man in the distance whom I am now seeing. 
       Once it is granted that recognition involves putting together different pieces of existential-descriptive information, it becomes highly plausible to see recognition as consisting in one’s registering the truth of the kind of existence-claim described a moment ago. The alternative is to see recognition as stripped of any descriptive content. But this is not psychologically (or, I think, epistemologically) plausible.
        These points about recognition confirm our analysis of conception. When you recognize something, what is happening is that two conceptions converge. Your recognizing the man in the distance as the man from the restaurant involves your putting together different pieces of descriptive information; it involves your realizing that some one conception (the awareness you are having now, of the man in the distance) and some other conception (the one you have of some lout whom you dealt with at a certain restaurant) both pick out some one thing. If conceptions were “pure”, i.e. were non-descriptive and therefore non-existential, then the just mentioned convergence of conceptions would be stripped of any descriptive content. Since descriptive information wouldn’t be involved, recognition would be reduced to the registering of some bare claim of the form O=O. But surely that is not what recognition is; surely your recognizing so and so at least involves your seeing that so and so has certain features or properties. Given the role that conceptions have in recognition, it thus becomes necessary to ascribe some of this descriptive knowledge to conceptions. It thus becomes necessary to see conceptions as being paved with descriptive-existential knowledge. This fact, combined with the fact that we often forget the description which starts up a conception, gives plausibility to the analysis we gave a moment ago regarding the sustaining of a conception: a conception is sustained by a series of interlocking existence claims.


The causal analysis as a component of the descriptive analysis


        None of this belittles the role that causal connections play in conception and reference. I am able to think about Fred precisely because I saw him; and, of course, seeing something involves being causally connected to it. 
        But how is the causal connection involved? What enables me to think about Fred is my knowledge of some uniquely individuating description (there is some guy whom I am now seeing and attending to, who is wearing a bowler hat, and “Fred” names that guy.) As we discussed earlier, my seeing Fred involves my being given a description that he uniquely satisfies. My being causally connected to Fred is involved in my being given that description. The causal connection is internal to the description. That causal connection is preserved if that particular description is forgotten and replaced with one that interlocks with it, in the manner described a moment ago. At any point, my conception of Fred is constituted by my knowing a description that is either identical with, or descended from, that encoded in a certain perception. Either way, what is doing the work is my knowledge of a uniquely individuating description of Fred. The causal connection, though essential, is a constituent of my knowledge of that description. 


Appendix to Chapter: 3  The similarities and dissimilarities between our analysis and Russell’s 


        According to Russell, for me to have a conception of O, I must know the truth of some existence claim of the form x uniquely has phi that O satisfies. So, like us Russell, advocates a strictly descriptive conception of conception (except where sense data and universals are concerned). 
        But Russell on the basis of this correct view, Russell put forth some doctrines that are highly questionable. The purpose of this section is to determine, in light of the points thus far developed in this work, just what is right about Russell’s position and also what is wrong about it.   
       Russell famously distinguished between knowledge by description and knowledge by acquaintance.[39] According to Russell, one’s knows something by description if one knows some existence claim that it uniquely satisfies; and one knows something “by acquaintance” if one has some kind of non-descriptive and, in generally, completely direct awareness of it. Russell thus concludes that one cannot be acquainted with any constituent of the external world. The only spatiotemporal entities with which one can be acquainted, according to Russell, are contents of one’s immediate consciousness (e.g. sensations, images).[40] 
      For this reason, Russell comes to the conclusion that it isn’t possible for anyone (with the possible exception of Socrates himself) to grasp propositions of which Socrates is a constituent. Russell believes that if x is an external spatiotemporal entity – a spatiotemporal entity that is not a constituent of one’s own consciousness -- then one cannot grasp any singular proposition of the form x has phi. Put another way, in Russell’s view, one cannot grasp any proposition that de re concerns Socrates or any other external object. I will argue that ultimately Russell is wrong. But the operative word here is “ultimately”; and the reasons why Russell is now generally held to be wrong have little or no real force against his views.


What is right about Russell’s view        
  
        Consider the singular proposition: 


(*) Socrates was bald. 


     To grasp (*), one must presumably grasp each of its constituents. So, in particular, one must have a concept of Socrates. But for reasons that we’ve already touched on, to have a concept of Socrates is to know some existence claim that he uniquely satisfies. So one grasps (*) by way of grasping some proposition of the form: 


(**) Something x uniquely has (or had) phi, and x was bald. 


There is no such thing as a “pure”, descriptively innocent grasp of anything external. It follows that (*) cannot be grasped except by way of (**). This is obviously similar to Russell’s view. Russell chose to express this view by saying that one cannot grasp (*). I choose to express it by saying that the way one grasps (*) is by grasping (**). But this difference is purely verbal.[41] 
         Russell made a point that has not been given its due in contemporary epistemology. There does seem to be a fundamental difference between the way I know about my own pains and tickles and the way I know about external objects. Suppose that I am having some pain x, and at that very moment, I believe the proposition x is unpleasant and I wish it would go away. It doesn’t seem possible that, if x were not to exist, I would be capable of having that very thought. After all, x is a constituent not only of the proposition I am grasping, but also of my grasping of it.  
        By contrast, an external object can never be a constituent of one’s awareness of it. This is the case even when one directly sees or otherwise perceives Socrates, as the following story makes clear. Tom is in possible world W1 and he sees Socrates. V1 is the purely psychological component of that perception. Socrates doesn’t exist in world W2. But W2 is otherwise just like W1. So supposing that V2 is Tom’s visual experience W2, it obviously follows that V1 and V2 are numerically identical. Of course, the distal cause of V1 is Socrates, whereas the distal cause of V2 is (let us say) some android who resembles Socrates. But the immediate biological antecedents of V1 are numerically identical with immediate biological antecedents of V2. More generally, both experiences are embedded in the same way in the history of the same organism. It would thus be highly counter-intuitive to deny that they were numerically identical.    
        Also, V2 and V1 are identical in respect of their phenomenologies and also in respect of their causal properties. (Some content-externalists would say that they have different causal properties. But we’ve already seen why that position is a non-starter.)    
         Let us now use the word “perception” to denote the kind of phenomenologically pregnant experience that if veridical would have a real-world object. So, in this context, a drunkard has “perceptions” of pink elephants no less than you are having perceptions of this book. 
       Given what we said a moment, it is easy to demonstrate the following two principles. First, given any perception P, if O is the “object” of that perception, there is a possible world where P exists even though O doesn’t. Second, given any instance A of some propositional attitude, if O is one of the objects of A (i.e. if O is one of the things that A is about), then (so long as O is not itself one of the mental or neurological entities composing A), there is a possible world where A exists even though O does not. 
        There is a third principle that falls out of our discussion. (It is, I believe, a tautological consequence of the previous two principles. But it is worth stating separately.) Let M be some awareness – it could be a perception or a thought – that, in actuality, concerns O, where O is not one of the neural or cognitive events that realize M. Being a spatio-temporal entity, M has various causal properties: certain things cause it to occur and it, in its turn, causes certain other things to occur. And being a spatiotemporal entity, M is obviously individuated by at least a certain subset of its causal properties. Given this, here is the just mentioned third principle. Let C1…Cn be the causal properties that, in actuality, are individuative of M. There is a possible world where O does not exist but where there is some entity M* has all of C1…Cn.  
        This last principle amounts to this: Let M be any mental entity that, in actuality, has object O. Supposing that O is not itself one of the events composing M, then there is a possible world where M exists and O does not and – what is closely related -- there is a possible world where O does not exist but where there exists something having all the causal properties that, in actuality, are individuative of M. 
      Put simply: unless the object O of an awareness A is actually a component of that same awareness, then A could exist in that absence of O. And the reason is that O’s existence is irrelevant to A’s having the causal properties that individuate it. 
      So if I am thinking about or seeing Socrates, there is no essential – no counterfactually resilient -- relation between my awareness and Socrates. That same awareness could exist in Socrates’ absence. 
      The externalist will respond to this by saying the following: 


       But that isn’t so. If you see Socrates, your perception encodes truth-evaluable information; it says something true or false. After all, if you say “that guy looks tired”, you are reporting what you see, and that report is either true or false. But suppose you say the very same thing upon having a hallucination qualitatively with the just mentioned perception. In that case, your words will be neither true nor false, the same being true of your perception. 




        Your hallucination does tell you something true or false. For it tells you something false. It says, to so speak: there is an individual over in that place, next to the piano…having such and such properties. Hallucinations are either false or coincidentally true. There is no blank, so to speak, in a hallucination in the place where there would be a filled space in a phenomenologically identical visual perception. 
        It is true, of course, that when, in an attempt to refer to some hallucinated man, the hallucinator says  “that guy looks tired”, his words don’t encode anything true or false, whereas those same words may encode a truth (or a falsehood) when uttered by somebody who has a phenomenologically identical perception. For, as Kaplan (1989) showed, given an utterance of “that guy looks tired”, the relevant semantic rule is: 


If there is a unique contextually salient guy, then a token t of “that guy looks tired” is true iff x looks tired. If there is no such an individual, then t is abortive, i.e. it doesn’t encode any proposition. 


But that is irrelevant in the present context, given the massive gulf between literal meaning and cognitive content. 
    Externalists are also likely to wage the following attack on our argument: 


    Perceptions, and awarenesses generally, are individuated by their objects. What could be more obvious? A perception of Socrates couldn’t be anything other than a perception of Socrates – anymore than Socrates himself could have been Plato or Napoleon. 


       We’ve already seen, at length, why this line of thought is not tenable. 
       Now we can see the power of Russell’s position. Let A be some awareness of mine, and let O be the object of that awareness. As we’ve been emphasizing, if O is not a component of A, then there is a counterfactual world where A exists but O does not. But if O is a component of A, then there is no counterfactual world where A exists but O does not. So, in that case, O’s existence is necessary for A to have the causal properties that make it what it is. 
       Given this, suppose that you are having a headache and you think to yourself: I wish this headache would go away. Let T be that thought (in this context the word “thought” refers to a certain kind of mental entity), and let H be the headache in question. It seems reasonable to say that T couldn’t possibly exist in a world where H did not exist. In connection with this, it seems that H is not only the object of T, but that it is itself a component of T. So given any world w there H doesn’t exist, there isn’t anything identical with T. Given any world where H doesn’t exist, there is nothing that is causally relevantly enough like T in respect of its to be T. 
       Now we can close Russell’s argument (or, rather, our extension of it). Spatiotemporal events are individuated by their causal properties – but not by all of those properties. Any two non-simultaneous ipso facto have some causal connections. Given any event E involving some brontosaurus, E has some causal relation to everything I do. (These causal relations are not of great explanatory value, but they still exist.) But there are epistemically possible worlds where E does not occur but where my life is exactly as it is here. So spatiotemporal states of affairs are individuated by a certain privileged subset of those causal properties. (I will not attempt to give a precise definition of that subset.) Let A be an awareness that has some external object O for its object; and let C1…Cn be the causal properties individuative of A. There is a possible world where O doesn’t exist but where something x has all of C1…Cn, i.e. there is a world where A exists but where O does not. So A’s existence is only extrinsically connected with that of O. Further, under the circumstances described, in a world where O doesn’t exist but A does exist, A will have exactly the same truth-conditions – the same content – that it has here. The context-externalist’s view to the contrary, as we saw, involves a failure to distinguish between (inter alia) the data encoded in A with meta-data about that data.
      But now consider an awareness A* that has an object O* such that O* is itself a constituent of A*. There is no world where A* exists but O* does not. An awareness has this sort of counterfactually resilient relationship to its object when, and only when, that object is a constituent of that awareness – i.e. when, and only when, that object is one of the neural or mental events constituting that awareness. Further, there is only one circumstance under which the object of an awareness is an actual constituent of that awareness: that object must itself be an item of consciousness – a tickle, a pain, an image. Finally, in any world where O* does not exist, there is nothing that has quite the same truth-conditions as A*. Under the circumstances described, it is reasonable – possibly even de rigueur – to hold that the data encoded in A* itself concerns O* and that, consequently, A* relationship to O* isn’t mediated through extraneous meta-data. 
       If the last two sentences are correct, then Russell’s position is quite correct. After all, on at least one reasonable understanding of the term “content”, the content of an awareness is internally related to that awareness. We’ve just seen that any perception of, or thought about, Socrates could exist, with its very same content, in worlds where Socrates does not exist. And, of course, we’ve seen that this point holds for any awareness A having an object O that is not itself a constituent of the consciousness realizing A. 
      Given this, Russell is right to say that the data encoded in one’s thoughts or perceptions never has Socrates per se as a constituent. After all, any thought that did have Socrates himself as a constituent obviously couldn’t exist in counter-factual worlds where Socrates doesn’t (or didn’t) exist. So, to rephrase the point just made, Russell would appear to be right to say that any thought about, or perception of, Socrates is not de re with respect to Socrates (except perhaps in cases where the thinker is Socrates himself).
       Further, given the points made in the second to last paragraph, another important conclusion follow. Let T be a thought that, in a suitably direct manner, concerns some constituent C of one’s current contents of one’s own consciousness. Nothing having the very same content as T, or therefore the very same truth-conditions, could exist in a world where C does not. And this is surely because C is itself a component of the truth (or falsehood) that is T’s content. So, once again, Russell is right to say that the proposition grasped by T is de re with respect to C.  
    
What is wrong with Russell’s view  


       Because the argument that will be given in this section is quite complicated, I would like to outline it before giving it in full. 
         First of all, by a “singular proposition”, I mean one that has a constituent of the external world as a component. The truth of any singular proposition supervenes on that of some purely general proposition. In other words, given any proposition that has some constituent of the external world as a constituent, the truth of that proposition supervenes on the truth of some proposition that is purely descriptive – a proposition whose only constituents are universals (properties and relations). One can be acquainted with a proposition of that kind. Therefore, one can be acquainted with a proposition whose truth depends on that of some singular proposition. Indeed, what we call “singular propositions” just are general propositions of the kind in question. So, ultimately, one can be acquainted with singular propositions. 
        For reasons that we will see, one is not often acquainted with such a proposition. In fact, acquaintance with such a proposition is probably a practical impossibility. It might even be a nomic impossibility, given interference-effects and the like. But, contrary to what Russell argues, it is not absurd to suppose that one might be acquainted with such a proposition. Let us now state the argument just outlined. 
        We have some inclination to think of objects – e.g. rocks, trees, people – as being the basic constituents of the spatiotemporal world. This viewpoint is encouraged, though probably not wholly caused, by the fact that expressions denoting objects are semantically simple. Among the ultimate, semantically simple expressions composing a sentence, one typically finds expressions like “Socrates”, “Plato”, and the like. And in cases where expressions denoting objects have semantic complexity – e.g. “that rock over there”, “the inventor of bifocals” – that semantic complexity serves the purpose of picking out the relevant individual, not of delineating its structure. So expressions denoting objects are either semantically simple or what they complexity they have has nothing to do with the structure of the relevant object. And this surely reinforces a pre-existing tendency to think in terms of, and cognitively divide the world into, objects. 
         But, of course, rocks, trees, and people are not the ultimate constituents of reality. To be sure, the term “ultimate constituent of reality” is a vague one, and whether x falls in its extension depends on what the relevant criterion of simplicity is. (Given any object, it may either be complex or simple, depending on how it is described and depending also on the explanatory context. This shows that complexity is ultimately a property of propositions or explanations, and not of objects.) But it can safely be said that, on any reasonable delineation of the term “ultimate constituent of reality”, Socrates doesn’t fall within the extension of that expression. Socrates’ existence supervenes on that of innumerable psychological and biological events. In their turn, those events supervene on innumerable cellular events which, in their turn, supervene on innumerable molecular events. And so on – until we reach the realm of the sub-atomic realm, where there are no objects, in any ordinary sense of the word (i.e. in the sense of something that has a certain persistence), but only displacements of minute quanta of mass-energy.[42]
       Of course, there are possible worlds where Socrates’ existence supervenes on those of events that are numerically, and even to some extent qualitatively, distinct from those on which his existence supervenes on this world. But there are surely no worlds of which Socrates is a fundamental constituent – even after we allow for the fact that the extension of the term “fundamental constituent” is, to a degree, a function of the dialectical context.[43] Consider the properties that are individuative of Socrates – that make him what he is. He falls into a certain biological category. In connection with this, he originated from certain biological events – on a certain occasion, a certain man and a certain woman created a certain zygote that developed by way of certain biological processes into an entity having certain biological, and psychological, characteristics. Anything remotely worthy of being classified as a fundamental constituent of the space-time manifold wouldn’t come close to being able to participate, in the relevant way, in biological processes like those just described. 666 Of course, what we just about Socrates is true (mutatis mutandis) of any biological entity. 666 In general, the objects in terms of which we are inclined to think  -- rocks, trees, vases, and so on -- are far from fundamental. 
         So what is fundamental? Socrates’ existence supervenes on facts about other objects – about organs, organelles, molecules, and so on. But everything we just said about Socrates is true (mutatis mutandis) of each of those other objects. Ultimately, then, Socrates’ existence must supervene on states of affairs that are not object-involving. The only states of affairs that satisfy this condition are those that consist of instances of properties, e.g. instances of a certain kind of charge. (Of course, some properties are such that any instances of them are ipso facto object-involving, e.g. the property identical with Socrates. So, in this context, when we talk about “properties”, we are considering only those that are not object-involving, i.e. we are considering only those properties P such that it is not the case that, if P is instantiated, some object, in any ordinary sense of the word, ipso facto exists.) Roughly speaking, Socrates is a series of instances of properties.[44] 
       Of course, this is not quite the right way of putting the matter. Let S be the series of property-instances that, in actuality, realized Socrates. So S comprises every single electron-jump involved in every atom that at any point constituted Socrates. Obviously there are possible worlds where Socrates exists but S does not. After all, Socrates didn’t have to be composed of the exact muon-displacements that, in fact, composed him. 
       But, as we discussed, given any possible world where Socrates exists, some series that is non-trivially like S exists. Given Kripke’s (1972) plausible points about the essentiality of origins, it seems reasonable to say that, in any world where Socrates exists, there is a series S* such that the earlier parts of S* are extremely similar to the earlier parts of S. It also seems reasonable to say that  the later parts of S* are not grossly unlike the later parts of S. We know, of course, that Socrates could have been different from how he was: he could have become a soldier as opposed to a philosopher; he could even have spent all of his years after the age of ten in a vegetative coma. But he could not have become a turnip or a cloud. We evaluate other people in terms of questions like the following: What do they do professionally? Are they in a coma? Have they written any books? Are they in jail? Relative to those benchmarks, Socrates might indeed have had a life very different from the life he actually had. But relative to benchmarks that that are less deeply rooted in our emotional parochialisms, Socrates could not have been all that different from how he was. In any world where Socrates exists, he is, for the duration of his existence, an entity that, in global terms, satisfies extremely narrowly defined genotypic and, to a much lesser extent, phenotypic conditions. He is not a philosopher in every such world. But there is no world where, from a strictly biological standpoint, the difference between how he is in that world and how he is in this world is more than infinitesimally small compared with the difference between how he is in this world and how, say, a carrot is in any world. So we may conclude that, in any world where Socrates exists, his existence supervenes either on S or on some series S* that, in the big scheme of things, is only slightly different from S. In any case, in any such world, Socrates existence supervenes on that of some series consisting, ultimately, of instances of states of affairs. 
        We must make one more point before we can see the epistemological consequences of this metaphysical discussion. As we saw earlier, given two people x and y who are molecule for molecule duplicates, and given any purely descriptive proposition P, x grasps P iff y grasps P. Whether one grasps a purely descriptive proposition supervenes on one’s non-relational properties. A corollary is that if one person x grasps some purely descriptive proposition P that some other person y does not grasp, then x necessarily has causal properties that y lacks. 
           Now we can close the argument. As we’ve just seen, for Socrates to exist in a world w is for some purely descriptive proposition P to hold in w. It follows that, contrary to what Russell maintains, we can, at least in principle, grasp a proposition P such that P is true in w only if Socrates exists in w. 
       But it doesn’t follow that the content-externalist is right. The content-externalist says that we in fact grasp propositions whose truth presupposes Socrates’ existence – that this is the sort of proposition grasped by somebody who understands sentences like “Socrates was wise.” But we have found that this is not the case. One’s concept of Socrates consist in one’s knowledge of some purely descriptive proposition that Socrates uniquely satisfies, and one is able to understand sentences like “Socrates was wise” only because one has such a concept. But the purely descriptive propositions in question are never anything like those described a moment ago; they are never propositions that state the sequence of property-instances on which Socrates’ existence supervened. Indeed, although they in fact have the property of being uniquely satisfied by Socrates, those propositions never, or at least seldom, necessarily have that property. 
       There is another reason why the content-externalist doesn’t benefit from our rejection of Russell’s claim that we cannot be acquainted with external objects. The externalist holds that we can grasp some proposition P such that P is true in a world w only if Socrates exists in w. That, we found, is actually correct, and Russell was wrong to deny it. But, as we have seen, any proposition satisfying this condition i8P is an existence-claim that is false if Socrates doesn’t exist in w. 666 Thus, P 666 doesn’t presuppose Socrates’ existence. Socrates’ existence in world w is a condition, but not a pre-condition, for P’s being true in w. A pre-condition for P’s being true is something that must hold if P is to be either true or false. A condition for P’s being true is not something that must hold for P to be either true or false. P is false in worlds where Socrates doesn’t exist; but it can be grasped such worlds. And this is because, pace the content-externalist, it is ultimately a purely descriptive proposition.    666  [Tidy up this paragraph?]


Chapter 4  Some semantic consequences or our analysis: tokens versus types, semantics versus pre-semantics            


           As we have emphasized, we what is literally meant by an utterance must be distinguished from the information that is uploaded or absorbed in the processing of computing  its 666 literal meaning. There is a closely related distinction that we haven’t yet discussed: the distinction between expression-types and expression-tokens. Given this distinction, it will be possible to refine and extend our findings. 


Expression-types versus expression-tokens


           The expression-type “you are tall” isn’t true or false. It is different tokens of it that are true or false. Where sentences containing indexicals are concerned, it is de rigueur to distinguish between type-meaning and token-meaning. (An “indexical” is a systematically context-sensitive component, e.g. “I”, “you”, “this”, “that”, “here”, “now.”)
          It follows that the distinction between sentence-types and sentence-tokens must be made universally. An utterance of “Smith is in kitchen” at t may be true while such an utterance at t* is false. This means that those utterances encode different propositions. But how his is this possible? After all,  “Smith is in kitchen” appears not to contain an indexical component. 
       That sentence is tensed, and because of the tense-marker what a token of it expresses is a function, in part, of the time of the tokening. Given any sentence-type containing a tensed verb – and this means any sentence-type belonging to natural language – the semantic content of that type is not a proposition, but is rather a function that assigns propositions to its tokens. 
         Of course, in some cases, tense is obviously irrelevant. The tense-marker in a token of “two plus two equals four” is idle. But this is easily explained along pragmatic lines: the tense-marker may be ignored, given the obvious mathematical (not semantic) fact that temporal considerations are irrelevant to the truth-conditions of arithmetical propositions.        Considerations of uniformity urge us to accept this explanation. It would be arbitrary, and also unnecessary, to say that the tense-marker in “two plus two equals four” has a different semantics from the tense-marker in “John swims every day.” 
      In artificial extensions of natural language, one may encounter tenseless sentences. At least arguably, a written token of “2+2=4” has no tense. But considerations of uniformity demand we see the expression-type as encoding, not a proposition, but a function that assigns a proposition to tokens of that type. Sentence-types are platonic entities; sentence-tokens are spatiotemporal. We’ve seen that, where natural language is concerned, it is sentence-tokens, not sentence-types, that bear propositions. Given this, suppose we said that the expression-type “2+2=4” had a proposition for its semantic content. In that case, we would be saying that the property of being proposition-bearing was sometimes a property of the spatiotemporal and other times was a property of the platonic. But such a proposal would bifurcate the notion of literal meaning, given how deep the division is between the platonic and the spatiotemporal. 
      We must also remember that a language is a means of communication. The things that are heard and spoken, read and written, are tokens. Those things can only be understood on the basis of the relevant semantic rules. Given this, those rules must assign propositions to sentence-tokens, and not sentence-types. 
       
Pre-semantic meaning as coinciding with type-meaning 


      Before moving on, let us discuss why the distinction between sentence-types and sentence-tokens is relevant to a work on conception. 
        Let T be a token of “that boorish uncultured man over there (the one who’s been dominating the conversation with his unfunny jokes for the last hour) is a spy”, and suppose that Smith is the man in question. Let T* be a token of “that erudite and illuminating gentleman next to the fireplace – the one who has been discoursing in such a brilliant, and yet unassuming fashion for the last ten minutes – is a spy.” As before, suppose that Smith is the man in question. 
        As we’ve noted, Kaplan (1989) argued compellingly that T and T* encode the very same proposition, namely Smith is a spy. So there is some individual x (namely Smith) such that, at the level of semantics, each of T and T* encodes a proposition that is true just in case x is tall. At first it seems as though Kaplan’s analysis must be wrong, given that T and T* communicate different, and non-equivalent, propositions. But in Chapter 1, we showed why Kaplan’s analysis is perfectly consistent with this fact.
        Notice that our explanation made heavy use of the distinction between type-semantics and token-semantics. One assigns the right meaning to T and T* on the basis of a knowledge of the relevant expression-types. So one works through type-meaning to ascertain token-meaning. As a result, what is communicated by a sentence-token is a function, at least in part, of type-meaning. A consequence is that two tokens that have the very same propositions for their literal meanings may communicate very different propositions. 
      As we will soon see, what we just said about sentence-tokens containing demonstrative-expressions is true of sentence-tokens containing definite descriptions and, indeed, of all sentence-tokens. If we keeping in mind the distinction between type-meaning and token-meaning, a number of otherwise unexplainable facts fall into place; and, as we will now see, if we don’t keep that distinction in mind, we are forced to adopt some counterintuitive and even incoherent views. 


Substitution-failures 


The sentence: 


(1) “Bill Gates is smart”


is what results when the definite description in:


(2) “the richest man in America is smart”


is replaced with a co-referring expression. Even though (1) and (2) have the same truth-value, they seem to have different meanings. So it certainly appears that substituting a referring term with a co-referring term can change meaning. But it also appears that such intersubstitutions can sometimes change truth-value: 


(s1) “Smith thinks that Bill Gates is smart”


 and


(s2) “Smith thinks that the richest man in America is smart”


certainly appear to differ in truth-value, and not only in meaning. 
         A related point is that: 


(3) “Bill Gates is Bill Gates”


is trivial, and therefore necessarily true, whereas 


(4) “Bill Gates is the richest man in America”


is non-trivial and also contingent. 
     Much of what is generally believed about substitutivity is in need of serious revision, given what we have said thus far in this work. 
       As we’ve seen, a token T of 


(5) “you are tall”


may have the same literal meaning as a token T* of 


(6) “that guy whom I saw yesterday, who was reading (or at least pretending to read) War and Peace while leaning against a statue of a dancing walrus, is tall”,


even though T and T*  communicate dramatically different propositions. We have already explained why there is no difficulty explaining this gulf between literal and communicated meaning. What we said about T and T* is easily extended to show that substitutions that appear to change literal meaning do not in fact do so. 
      Notice that there will (or could) certainly appear to be a difference in truth-value between a token sT of: 


(s5) “Smith thinks that you are tall”


and a token sT* of:


(s6) Smith thinks that that guy whom I saw yesterday (the one 666 who was reading, or at least pretending to read, War and Peace while leaning against a statue of a dancing walrus) is tall. 




      Such a difference will occur if Smith has no knowledge of any sculpture of a dancing walrus or of anything involving the novel War and Peace.[45] Obviously the apparent difference in truth-value between sT and sT* correlates with the apparent difference in meaning between T and T*. But the latter difference is merely apparent, as we saw. The same is therefore true of the former. Each of sT and sT* encodes the bare singular proposition: Smith thinks that x is tall. In any case, given the points made in connection with the apparent (but non-actual) differences in meaning between T and T* (and between t and t*…), there is no difficulty explaining why what is communicated by sT may differ in truth-value from what is communicated by sT*. 
      When we take into account the information through which one must compute the literal meanings of sT and sT*, it becomes clear why those tokens would inevitably convey very different propositions – that one of them would convey or suggest that the addressee knew of the existence of a dancing-walrus sculpture, while the other would not. Once we take pre-semantics into account, there is no need to assume any difference in meaning, or therefore in truth-value, between sT and sT*. Further, if we were to posit such a difference, in order to explain the apparent differences between in truth-value between those tokens, our explanation would be superfluous. Indeed, it would be in conflict with an incompatible, but adequate, explanation. 
       What we see, then, is that many apparent substitution-failures involve no change in literal meaning (or, therefore, truth-value), and are to be understood pragmatically. More specifically, they are to be understood in terms of pre-semantics. Let us extend now this line of thought by considering the controversial topic of definite descriptions. 
       Once again consider the sentence: 


(2) “the richest man in America is smart.” 


(2) certainly seems to have a very different meaning from: 


(7) “the first person to make a fortune by selling personal computers is smart.”


But, it would seem, (7) is what results when a referring term in (2) is replaced with a co-referring term. Similarly, 


(s2) “Smith thinks that the richest man in America is smart”


seems to have a different truth-value from: 


(s7) “Smith thinks that the first person to make a fortune by selling personal computers is smart.”


     In any case, (s2) and (s5) will have very different truth-values given certain reasonable assumptions about Smith’s beliefs, e.g. that Smith believes, first, that Jones is stupid and was also the first person to make a fortune from selling personal computers  and, second, that Bill Gates is smart. 
       Frege and Russell were keenly aware of the apparent differences in meaning just discussed, and they took them to be actual differences in meaning. Each explained these putative differences in different ways. Both explanations, we will see, have radically counter-intuitive consequences (especially Frege’s). Further, neither explanation is necessary. The problems that they are meant to solve can be solved without advocating theories that have any of the unpalatable consequences of their theories.  Let us start with Russell’s theory. 


Russell’s Theory of Descriptions 


      What is conveyed by (2) is different from what is conveyed by


(1) “Bill Gates is smart”,


and also from what is conveyed by:


(7) “the first person to make a fortune by selling personal computers is smart.”


And, of course, (1) and (7) differ in respect of what they convey. Let us now try to state more specifically what these sentences convey.
      The proposition conveyed by (2) obviously involves the concept richest man in America.  The word “the” connotes existence. (2) is not true if nobody is a richest man in America. (Suppose that there were no men at all in America. In that case, obviously, (2) wouldn’t be true. For exactly parallel reasons, (2) wouldn’t be true if there no richest man in America.) Further, unlike the words “four” and “some”, the word “the” connotes uniqueness. If there are a hundred equally rich richest men in America, then (2) fails to be true. So a necessary condition for the truth of (2) is that there be somebody who is uniquely is a richest man in America. Of course, if that person is not smart, then (2) is false; and if that person is smart, then (2) is true. So (2) is true exactly if the following proposition is true: 


(2P) There is somebody x such that x is uniquely a richest man in America; moreover, x is smart. 


      For exactly similar reasons, the proposition meant by (7) is identical, or at east equivalent, with: 


(7P) Somebody x is uniquely such that x was a first person to make a fortune selling personal computers; moreover, x is smart. 




       In general, ┌the phi has psi┐ is true exactly if the proposition something x uniquely has phi; moreover, x has psi is true. Thus, “the richest man in America” doesn’t refer to Bill Gates. It doesn’t refer to anything. Rather, as Kent Bach put it, it “contributes its quantificational structure” 666 to sentences in which it occurs. It is thus a quantifier, not a singular term.[46]  


Evaluating the Theory of Descriptions 


        The relevant data can be accounted for without accepting the dubious view that “the inventor of bifocals” doesn’t refer to the inventor of bifocals. For reasons that we’ve seen, we must distinguish types from tokens. Given this, suppose that the general semantic rule for definite descriptions were as follows: 


(*) a token T, that occurs at time t, of ┌the phi┐ is a singular term that refers to x exactly if, at t, x is a unique phi; and if there is no such individual at t, then T is semantically empty. 




        So supposing that x is a unique phi at a given time, a token at that time of ┌the phi┐ has individual x for its sole semantic content; and no concept of x -- no Fregean sense or Russellian description – is any part of what is literally meant by such a token. 
       If (*) is right, then a token of any sentence of the form: ┌the phi has psi┐ would either have the bare singular proposition x has psi (for the appropriate value of x), or it would fail to encode a proposition. It would mean x has psi if there were, at the time of utterance, a unique psi; and it would have no proposition for its literal meaning if there were no such individual. At the same time, for the reasons given earlier, such a token would convey the existence-claim: something x uniquely has phi; moreover, x has psi. So such a token would convey exactly the proposition that, according to Russell, is its literal meaning. The supposition that definite descriptions are singular, directly referential expressions is entirely consistent with the facts about cognitive significance that motivate Russell’s theory. In fact, that supposition explains those very facts, given the distinction between semantics and pre-semantics.[47]
       If (*) gives the general semantic rule for definite descriptions, then the semantics of “the richest man in America” will be given by the rule: 


(**) a token T, that occurs at time t, of “the richest man in America” is a singular term that refers to x exactly if, at t, x is a unique richest man in America; and if there is no such individual, then T is semantically empty. 




        Supposing that (**) is the correct rule, a token in 2006 of (7) has the bare singular proposition Bill Gate is smart for its semantic content, given that in 2006 Bill Gates is the richest man in America. But for the reasons we’ve discussed, such a token would still communicate the existential proposition: 


(7E) Somebody x is uniquely a richest man in America (at the present time); moreover, x is smart. 


For the sake of argument, let us suppose that occurrences of “the richest man in America” are singular terms. (This is what our pre-theoretic intuition strongly suggests.) The semantic rule for “the richest man in America” is obviously not going to be: 


(***) “The richest man in America” refers to Bill Gates.


The semantic rule for that expression must be general; it must not presuppose that this or that particular individual is the richest man in America or, indeed, whether there even is such a man. So that rule will necessarily be at least approximately like: 


If there is a unique individual x who is a richest man in America, then an occurrence (at t) of “the richest man in America” refers to x. 


      Anyone who has the linguistic knowledge needed to figure out what is meant by a token of (7), or any other sentence-token containing an occurrence of ┌the richest man in America┐, will know that a token of that expression refers to an object x just in case there is a unique richest man in America, and x 666 is that person. (Of course, this knowledge will be sub-personal, like a non-linguist’s knowledge of the rules governing when to say “me” as opposed to “I.”[48] My analysis does assume that there is sub-personal knowledge. We will discharge that assumption in Chapter 18. In any case, there is a vast amount of experimental and theoretical support for that assumption, granting that many philosophers are virulently opposed to it.) So anyone who can understand a token t of (7) will know that t is 666 true only if, at the time of tokening, somebody x is 666 a unique richest man in America. For similar reasons, that person will know that t is true 666 only if x is smart. So that person will know (albeit implicitly or sub-personally) that t is true exactly if, at the time of  tokening, somebody x is a unique richest man in America 666 and that, moreover, x is smart. 
      Here is another way of thinking about the matter. For the sake of argument, let us continue to suppose that occurrences of definite descriptions are singular terms, as opposed to quantifiers. In that case, the semantic rule for (7) is not going to be: 


(****) “The richest man in America is smart” means: Bill Gates is smart. 
 
Rather, it is going to be: 


If somebody x is uniquely a richest man in America at a given, then a token t (at that time) of “the richest man in America is smart” means (or is true iff) x is smart. 


    
    Anyone who understands such a token works through that rule. So such a person knows that, in order for a token of that sentence to be correct, there must (at the time of tokening) be somebody x who is uniquely a richest man in America and, further, that any such person must be smart. 
     So to explain why occurrences of (2) and (7) have the cognitive significances that they in fact have, it isn’t necessary to deny that occurrences of “the richest man in America” and other definite descriptions are singular terms; and it therefore isn’t necessary to suppose that such occurrences are quantifiers. So far as it seems necessary to take such a view, it is because 666 one is operating within a one-dimensional semantic system and 666 is therefore operating on the assumption that (***) and (****) are the relevant semantic rules.[49] 
          Let us sum up. Given the distinction between semantics and pre-semantics, and between token- and type-meaning, the thesis that occurrences of definite descriptions are singular terms is easily reconciled with the facts concerning what is conveyed by sentences containing such occurrences. 
        Given this, we can easily reconcile the supposition that definite descriptions are  singular terms with the apparent difference in truth-value between:


(s2) Smith thinks that that the richest man in America is smart 


and


(s7) Smith thinks that the first person to make a fortune by selling personal computers is smart. 


       For reasons that we’ve already covered, even if it is assumed that definite descriptions are singular terms, any token of the underlined parts will communicate a Russell-style existence-claims. More exactly, they will communicate 


(2P) somebody x is uniquely a richest man in America; moreover, x is smart. 


and 


(7P) Somebody x is uniquely a first person to make a fortune selling personal computers; moreover, x is smart. 




Given this, it is to be expected that tokens of s2 and s7 would communicate (but not semantically encode): 


(s2P) Smith thinks that somebody x is uniquely a richest man in America; moreover, x is smart. 


and 


(s7P) Smith thinks that somebody x is uniquely a first person to make a fortune selling personal computers; moreover, x is smart.




Of course, s2P and s9P could well have different truth-values. 
      It is well known that s2 and s7 have both “wide-scope” and “narrow-scope” readings.[50] s2 can convey that, without knowing who the richest man in America is or even whether there is such a man, Smith knows of that person that he is smart. This would hold in a scenario like the following. Smith lives next to Bill Gates. Smith knows that Bill Gates is smart, but not that Bill Gates is particularly wealthy. This is the narrow-scope (de re) reading, and it is given by the proposition: 


(s2NS) Somebody x is uniquely a richest man in America; and Smith thinks that x is  smart.




       Given that occurrences of 2 convey 2P, even on the assumption that tokens of definite description are directly referential, it is no wonder that s2 should be capable of conveying s2NS. There is no reason why the occurrences of “Smith thinks that” in tokens of s2 shouldn’t be capable of having different degrees of scope – no reason to think that, for reasons of pragmatics, those occurrences could be given either wide-scope or narrow-scope, depending on the specifics of the context of tokening. Indeed, it would be artificial to suppose that contextual-pragmatic factors didn’t have such an effect. So our analysis explains why occurrences of s2 can communicate s2NS, without having that for their literal meaning. 
     The “wide-scope” reading of s2 is given by s7P. We’ve already explained why tokens of s2 can convey s7P. 
      Incidentally, the reason that s2NS  is referred to as the “narrow-scope” reading is that, in it, the epistemic operator (“Smith thinks”) is given narrow-scope with respect to the existential quantifier. So the epistemic operator falls within the scope of the existential quantifier, and thus has a smaller scope than the latter. s7P is referred to as the “wide-scope” reading for the same reason mutatis mutandis. 
      There is thus no need to advocate Russell’s theory to explain the relevant facts about cognitive significance, i.e. about what is conveyed by sentence-occurrences of the form ┌…the phi…┐ This completely undercuts Russell’s theory, at least so far as that theory’s raison d’être is that it accounts for what is communicated by sentence-tokens containing definite descriptions.[51] 
       But not only is Russell’s theory unnecessary. It is demonstrably false. We must begin by distinguishing between semantic and conceptual analysis. A semantic analysis of an expression identifies its literal meaning. A conceptual analysis gives an analysis of that proposition itself, i.e. it identifies a proposition that is logically equivalent with the one that is literally meant, but is more perspicuous in respect of its inferential structure.[52]  
       Given this distinction, there are two possible interpretations of Russell’s theory. We can say that he is doing semantic analysis (identifying literal meanings) or that he is doing conceptual analysis. 
        Let us consider both interpretations, starting with the first. Consider the thesis that (2) is synonymous with (2P). For two sentences to be synonymous is, by definition, for them to have exactly the same literal meaning. It is not easy to find two distinct sentences that have precisely the same literal meaning. But “Smith is an enemy” and “Smith is a foe” are synonymous, or nearly so. Therefore a Southerner’s utterance of “Smith is an enemy” will be synonymous with a Northerner’s utterance of “Smith is a foe”, it being irrelevant that a Northerner’s accent is different from a Southerner’s. If two utterances are synonymous, the differences between them are innocuous (except in respects that are plainly irrelevant in the present context). 
        But the differences between ┌the phi has psi┐ and its Russellian paraphrase are not innocuous. Suppose that somebody asks you the following question: 


(Q) Is it true that there is a unique richest man in America? Or are there in fact several equal rich, richest people in America? 


If you answer by saying: 


(2) “the richest man in America is smart”, 


your answer displays a lack of linguistic competence. Granting that (2) conveys an answer to the question, no one who speaks English would think that (2) was a linguistically correct answer. A linguistically correct answer would be given by an utterance of “there is a unique richest person in America” or “somebody x is a unique richest person in America” or, therefore: 


(2P) “somebody x is a unique richest person in America; moreover, x is smart.”


In general, it is very clear that, in a context where an utterance of ┌the phi has psi┐ would show linguistic incompetence, its Russellian paraphrase (┌something x uniquely has phi; moreover x has psi┐) would show linguistic competence. And, of course, the very same argument mutatis mutandis shows that, in a context where an utterance ┌the phi has psi┐ would show linguistic competence, its Russellian analogue (┌something x uniquely has phi; moreover, x has psi┐) would show linguistic incompetence. 
      If (2) and (2P) were synonymous, then the differences between them would be as innocuous as the differences between a Southerner’s and a Northerner’s pronunciations of a given sentence. Alternatively, those differences would be as innocuous as the difference between “Smith is an enemy” and “Smith is a foe.” But (2) and (2P) are very much not interchangeable. In fact, it would be hard to think of a single context where the one would be appropriate if the other were. This cannot be chalked up to pragmatics since their non-interchangeability is rooted in facts about linguistic competence, and not in facts about sensitivity (or a lack thereof) to situational nuances.[53] 
       A story may clarify this last point. You say to an employee: “your performance here has been less than exemplary; and I think it would be a good idea if you started clearing your desk.” Of course, what you are conveying is: you’re fired. But the employee is so unintelligent that he takes your words literally. He responds to your statement by saying (he is not attempting to be ironic or humorous):


“You’re right, boss.  I probably should clear my desk – after all it’s pretty dirty. And, just as you say, my performance here has been bad. Thanks for telling me. I will now clean my desk and attempt to improve my performance.”


   
           The employee has shown a kind of incompetence. But it is not linguistic incompetence. He understood the literal meanings of your words perfectly well. But somebody who says (2) where (2P) is appropriate, or vice versa, is displaying linguistic incompetence. They haven’t mastered the relevant grammatical rules for those expressions. There are many contexts where  uttering the one sentence would be linguistically inappropriate – where it would show that the speaker needed to take more English-classes (supposing that he were  not intentionally flouting the rules of English semantics) – and where uttering the other would not. 
      Linguistic deficiencies are, by definition, non-pragmatic. Pragmatics is the interface of literal meaning and context. A “pragmatic deficiency”, such as that evinced by the employee, does not show a failure to have internalized the relevant literal meanings, but instead shows a failure to see how those meanings interact with facts about culture, psychology, and the like. Somebody who says ┌somebody x is a unique phi; moreover, x has psi┐ where the right statement is ┌the phi has psi┐, or vice versa, is showing grammatical-semantic incompetence. 
         It was brought up long ago (by Searle (1979) and also, I am told, by Kripke in unpublished lectures[54]) that the Theory of Descriptions is decidedly implausible when it comes to questions and imperatives. If Russell’s theory is right, then: 


(8) “tell the guy over there to call the fire-department” 


means either: 


(8NS) Make it be the case that somebody x is uniquely a guy over there; moreover, tell x to cal the fire-department 


or 


(8WS) There is somebody x such that x a unique person over there, and tell x to call the local fire-department. 


    Actually, if Russell’s theory is right, then (8) is multiply ambiguous, the reason being that it contains two definite descriptions. One of the disambiguations is: 


(8DWS) Make it be the case that there is exactly one local fire-department x, and make it be the case that there is exactly one guy over there y; and tell y to call x. 


     If we insist on eliminating all of the definite descriptions in (8), there are three other disambiguations of that sentence. But for our purposes, we can focus on (8WS) and (8NS). The problems for Russell’s theory that we uncover in connection with these two sentences apply with extra force to more strict Russellian paraphrases of (8), such (8DWS).
       As Searle (1979) observed, it is hard to believe that, on any disambiguation, an utterance of (8) expresses an order that you make there be somebody standing in a certain place. Further, there are obviously many contexts where an utterance of (8WS) would show a dearth of linguistic competence and where an utterance of (8) would show no such dearth. 
         For similar reasons, it is hard to believe that, on any disambiguation, (8) is synonymous with (8NS).  In uttering (8), you certainly don’t seem to be asserting that there is a unique man in a certain location. As Strawson (1951) said, you seem to be presupposing it, not affirming it. This is confirmed by the fact that an utterance of (8NS) would show a dearth of linguistic competence in contexts where an utterance of (8) would show no such dearth. It is therefore hard to believe that (8) is under any circumstances synonymous with (8NS). 
         Advocates of Russell’s theory argue that, so far as (8) strikes us as not being synonymous with (8NS) and (8WS), it is because we are mistaking pragmatic epiphenomena for literal meaning.[55] They argue that, after we root out the contextual factors that mediate between literal and understood meaning, Russell’s theory turns out to be in perfect accordance with the data.[56] 
        But given that synonymous sentences ipso facto have precisely the same meanings, it is hard to see how replacing  (8) with either (8NS) or (8WS) could be so far from innocuous; it is hard to see how doing so could turn a reasonable sounding utterance into an extremely strange sounding one, or how it could turn an instance of linguistic competence into one of linguistic incompetence. It is hard to see how replacing (8) with either of those other sentences is comparable to replacing  “enemy” with “foe” or “heather” with “gorse.” 
        To say that two expressions are synonymous is to make a very strong claim. Obviously intersubstituting synonymous expressions has phonetic consequences. (Tokens of “foe” sound different from tokens of “enemy.”) But it is hard to see how such differences could be semantically pregnant enough to sustain Russell’s theory in the face of the points that we’ve made. So it is not an option to suppose that Russell’s theory gives the literal meanings of sentences containing definite descriptions.[57] 
       Also, we have seen found that the negation of Russell’s theory is favored by a careful scrutiny of the contextual factors that mediate between literal and understood meaning. Of course, this directly contradicts what Russellians maintain.
        What about the idea that Russell’s theory gives, not literal meanings, but conceptual analyses, and thus logical equivalences? That idea is not tenable. There are two ways to see this. 
       If the literal meaning of “the richest man in America is smart” is not some quantified generalization, then “the richest man in America” is not a quantifier. If that expression is not a quantifier, then what could it be? The only reasonable hypotheses as to the semantics of that expression are, first, that it is a singular term and, second, that it is a Russell-style quantifier. So if “the richest man in America is smart” does not have a quantified generalization for its literal meaning, then “the richest man in America” is a singular term. In that case, Russell’s theory is false, since the essence of that theory is that definite descriptions are not singular terms. So we cannot assume that Russell’s theory merely gives logical equivalences without giving literal meanings. To make that assumption is to assume that no quantified generalization gives the literal meaning of (2). And it is a short step, if it is a step at all, from the latter assumption to the view that the definite description is a singular term. 
       This brings us to the second reason why Russell’s theory must be assumed to be an attempt to give literal meanings, as opposed to conceptual analyses. Suppose that (2)’s literal meaning is logically equivalent with some quantified generalization. In that case, presumably, that literal meaning is itself given by a quantified generalization. But if that is the case, then Russell’s theory does aspire to give literal meanings. But we’ve already seen why that theory does not give literal meanings.[58] 
     Let us develop the argument just given. Suppose that (2’s) literal meaning is logically equivalent with some quantified generalization. In that case, it is logically equivalent with: 


(i) “something x is such that anything y is a richest man in America just in case y=x; moreover, x is smart”


 or


(ii) “for some x, given any y, y is a richest man in America iff y=x; moreover, x is smart” or 


or 


(iii) “some object x has the property of being uniquely a richest man in America; moreover, for anything y, if y=x then y is smart” 


or some other, quantified generalization that is logically equivalent with each of (i)-(iii). But what we said about (2P) is true of each of these other sentences. Consider (ii), for example. Replacing an occurrence of (ii) with an occurrence of (2), or vice versa, would frequently produce a linguistically (and not just a pragmatically) inappropriate utterance where there was previously linguistically appropriate one (or vice versa). The same is true of (1) and (3) and of any other sentence that clearly expresses a quantified generalization.[59]
      
Frege’s view 


         Frege (1892) held that definite descriptions are singular terms. But Frege’s theory is less defensible than Russell’s. Russell’s theory happens to be false of English (or so I have argued), and is thus empirically false. But it is not an incoherent theory. The same cannot be said of Frege’s theory. 
         Frege (1892) rightly believed in what has come to known as the “principle of compositionality”[60]: the meaning of a complex expression is a function of the meanings of its constituents. A specific version of this principle relates to reference: the referent of a complex referring term is a function of the referents of its parts. (For the record, my view is that both principles are unqualifiedly correct.[61]) 
     Let us start with our paradigm: 


(2) the richest man in America is smart.


     According to Frege, the underlined expression is a singular term.[62]  At the same time, Frege also held that (2) is logically equivalent with: 


(2P) somebody x is a unique richest person in America; moreover, x is smart.


     This raises an important question. If the literal meaning of (2) is logically equivalent with (2P), why isn’t “the richest man in America” simply a quantifier? If Frege is right about (2), then (2) says nothing more and nothing less than (2P). In general, if Frege is right about ┌the phi┐, then ┌the phi has psi┐ is true exactly if phi is uniquely instantiated and any instance of it has psi. So any sentence of the form ┌the phi has psi┐ -- or, equivalently, of the form ┌….the phi…┐ -- answers the question ┌how many phi’s are psi’s? ┐ 
       But in that case, ┌the phi┐ is a text-book case of a quantifier. “No person is smart” answers the question “how many people are smart?”; so do “some person is smart”, “three people are smart”, and so on. That is why “some person”, “no person”, and so on, are quantifiers.[63] If Frege is right, then “the person over there is smart” answers that very same question. (It gives the answer: “there is exactly one person over there, and any such person is smart.”) So it isn’t clear how Frege’s position amounts to anything less than the idea that “the man” (or “the richest man in America”) is a quantifier.[64] 
        In any case, given a reasonable understanding of what a quantifier is, it is unclear why, on Frege’s view, definite descriptions are not quantifiers. Frege must deny the veritable truism a quantifier is an expression that, when conjoined with a predicate phi, answers the question ┌how many phi’s are there? ┐  It follows that Frege’s view is only as plausible as the denial of this truism.
       It is not hard to find support for this position. In the aftermath of Kripke, we have good reason to believe that, for some x (identical, let us suppose, with Bill Gates), the literal meaning of (2) -- or, strictly speaking, tokens thereof -- is simply: 


(2LM) x is smart. 


      In the aftermath of Kaplan (1975, 1989), we have good reason to believe that a token t of: 


(9) “that guy over there is smart” 


      encodes the very same proposition as (2LM), provided that the demonstrative expression refers to Bill Gates (or to whomever the richest man in America happens to be). 
      More generally, we have seen that a proper noun or demonstrative expression E refers to O exactly if, in virtue of having the form ┌E has phi┐, a sentence-token encodes a proposition that is true exactly if O has phi – it being irrelevant what other properties O has. So we have seen that, at least where proper nouns and demonstratives are concerned, reference is mere labeling. It isn’t describing or conceptualizing: it is mere picking out.  
     Given this, suppose that Frege is right. Suppose that  the occurrence in (2) of “the richest man in America” refers to Bill Gates, but that (2) is logically equivalent with (2P). Notice that Bill Gates is not a constituent of (2P). What is such a constituent is some concept that he uniquely falls under. Further, notice that Bill Gates is a constituent of the proposition literally meant by:  


(1) “Bill Gates is smart.”


    So if Frege is right about definite descriptions, then there are two fundamentally different kinds of reference. There is the kind where, in virtue of containing a referring term, 666 a sentence encodes a proposition that has the referent of that term as a veritable constituent. (This would be Kripke-Kaplan “direct reference.”) And there would also be the kind of reference where it is not the case that, in virtue of containing a referring term, 666 a sentence encodes a proposition that has the referent of that term as a veritable constituent. (This would be Frege-style “indirect” reference.”) If a sentence contained an expression E that  “referred” in the latter  sense to O, that sentence would, in virtue of that fact, encode a proposition had as a constituent, not O itself, but some concept C that O uniquely instantiated; and that proposition would be to the effect that C was uniquely instantiated. If E “refers” to O, in the Fregean indirect sense of “reference”, then there is some concept C such that O uniquely instantiates C, and the proposition meant by ┌E has phi┐ is to the effect that C is uniquely instantiated, and any instance of C has phi. So that proposition would provide the very information provided by the proposition that, according to Russell’s theory, is meant by ┌t666he C has phi. ┐ But, in that case, it is deeply unclear why E isn’t simply a Russell-style generalized quantifier. 
         For example, if Frege is right, then because it contains an occurrence of “the richest man in America”, (2) provides exactly the same information as (2P). But there would also be a kind of reference where this condition was not met. “Bill Gates” uncontroversially refers to Bill Gates. But (1) is not logically equivalent with (2P). The information provided by (1) is not is not the same as that provided by any quantified generalization. (This is subject to a qualification that we will discuss in a moment.) 
     At the same time, if Frege is right about definite descriptions, then (2) has a great deal in common with (2P). Both answer exactly the same question, namely: how many richest men in America are there and are they smart? Further, if Frege is right, the semantic rule for (2) is: “the richest man America is smart” is true iff there is exactly one richest man in American, and any such person is smart. That proposition is of course identical with the semantic rule for (2P). It is once again unclear how Frege’s view differs from the view that “the richest man in America” is a quantifier. 
      Frege uses the word “reference” (“Bedeutung”) to describe the relationship between “the richest man in America” and Bill Gates. But, leaving aside that purely verbal fact, Frege’s view is not meaningfully different from Russell’s. 
      In fact, Frege’s theory seems to be nothing more than a confused version of Russell’s theory.[65] Russell (1917: 152-167) held that if E actually refers to O, then in virtue of having the form ┌…E…┐ a sentence (or sentence-token) has O itself as a constituent, and not some sense or concept of O. Russell held that if “Socrates” actually referred to Socrates – if it were not a quantifier that, as Russell puts it, merely “simulated” reference to Socrates -- then for some x (identical with Socrates) ┌Socrates has psi┐ would encode the singular proposition: x has psi. Russell had the concept of what is now sometimes called “singular” or “direct” reference. The relationship between an expression that refers in this sense to Bill Gates is very different from the relationship that, according to Frege’s theory, holds between “the richest man in America” and Bill Gates. The latter relationship is such that what is meant by “the richest man in America is smart” is identical, or at least equivalent, with a quantified generalization of the form: something is uniquely a richest man in America, and any such thing is smart. The former relationship is such that, for some x (identical with Bill Gates), “Bill Gates is smart” means: x is smart, where “Bill Gates” is a hypothetical term that refers, in the strict Russellian sense, to Bill Gates. 
        Because Russell (1912, 1917: 152-167) saw this, he rightly held that the second kind of relationship has few or no meaningful differences from the kind of relationship that, if Frege’s theory is right, obtains between “the richest man in America” and Bill Gates. Russell clearly saw that Fregean “reference” – what would now be called “indirect” reference – is not significantly different from quantification.
          Russell agreed with Frege on one important issue. He held that each of “Socrates is smart” and “the richest man in America is smart” encodes a proposition identical, or at least logically equivalent, with one of the form: something uniquely has phi, and anything having phi is smart.  But Russell held that, for this very reason, “Socrates” and “the richest man in America” are quantifiers, as opposed to devices of reference; for he saw that describing them as terms that “referred” to Socrates and Bill Gates would obscure the important distinction between to be made between instances of quantification and instances of what are clearly reference. Russell’s theory of descriptions is thus a clear and coherent version of Frege’s theory. Unlike Frege, Russell does not describe as “reference” what is in fact quantification. He knew that the relationship that “Bill Gates” bears to Bill Gates has no meaningful similarities between the relationship that (if Frege’s theory is correct) either “the richest man in America” or “Bill Gates” bear to Bill Gates. And he knew that the latter relationship has many meaningful similarities with the relationship that, if his own Theory of Descriptions is correct, either “the richest man in America” or “Bill Gates” bear to Bill Gates. He thus saw that referring to the second relationship as one of “reference” would merely obscure a crucial distinction (that between singular reference and quantification), and would also hide a profound kinship (that between Fregean “reference” and quantification). So Russell used the term “quantification” where  Frege had used the term “reference.”  But apart from that, the semantics that Russell provides for proper nouns and definite descriptions is the same as that provided by Frege. In any case, it is hard to find any meaningful difference. 
        Russell’s conception of reference was entirely correct. His one fault was that he misapplied that conception. He thought that actual cases of reference were almost never found in everyday discourse. (In his view, one could refer to a content of one’s consciousness – by using a token of “this” or, conceivably, a proper noun of one’s inventing. But he thought that nothing apart from a content of one’s own consciousness could be the object of reference. In Chapter 9, we will discuss at great length how this view involves a misunderstanding of the concept of language. But it is noteworthy that Russell held that, if there are any genuinely referring expressions, certain demonstrative-expressions are among them. This is a striking anticipation of Kaplan’s (1989) theory.) 
        Accordingly, Russell denied that “Socrates” refers to Socrates, and he thought that the former was a quantifier. He thought that, in virtue of containing an occurrence of “Socrates”, a sentence-token encoded a proposition that had for a constituent, not Socrates himself, but rather some concept that Socrates instantiates. He held the same view with regard to “the great philosopher who drank hemlock.” These views, generalized to all proper nouns and definite descriptions, constitute Russell’s Theory of Descriptions. 
      We’ve seen why that theory is false, even though the conception of reference that underlies it is unexceptionable. We’ve also seen why Frege’s theory is not appreciably different from it. It follows that Frege’s theory is wrong for the same reasons as Russell’s. But we will now see that, because Frege conflated reference with quantification, his theory, unlike Russell’s, is incoherent, and not just false. 
         If Frege is right, i.e. if (2) and (2P) are logically equivalent, then (2) will be true in exactly the same circumstances as (2P). Of course, (2P) has a truth-value regardless of whether there is a unique richest man in America. If there is no such man, then (2P) is false, since it asserts that there is such a man. But according to Frege, (2) is without truth-value under that circumstance. This is flatly inconsistent with the idea that (2) is logically equivalent with (2P); and provides evidence in favor of our analysis. So far as you are affirming that such and such exists, you are not referring to it. Surely I am not referring to the number two in saying “there is a unique even prime x and x is even.” (In any case, I am referring to it only in the loose, vernacular sense of the word “refer.” I am not referring to in the strict, philosophical sense of the term -- the sense in which I would be referring to it if I were to say “the number two is even.”) Where there is an affirmation of existence, there is no reference, as Strawson (1950) made clear. If Frege is right to say that (2) and (2P) are logically equivalent, then an utterance of (2) is simply false – not lacking in truth-value -- if there is no unique richest American man; and the reason for this would be that, if there is no such man, then what (2) has affirmed is false. Given that affirming a thing’s existence is different from referring to it, it follows that “the richest man in America” is not a singular term if, as Frege holds, (2) and (2P) are logically equivalent. 
       Frege seemed to be aware, on some level, that referring and affirming existence are different things. That, presumably, is why he held that (2) is without truth-value if there is no unique richest man in America. But if 2 is without truth-value under that circumstance, then Frege’s other contention – that (2) and (2P) are logically equivalent – is simply false. Frege’s views on reference are thus incoherent. 
        Let us consider some objections to the argument just given: 


      You say that, if Frege is right about (2), then there are two totally different kinds of reference. But didn’t we already know that? There is “rigid” and “non-rigid” designation, to use Kripke’s (1972) terms. “Bill Gates” rigidly refers to Bill Gates, and “the richest man in America” non-rigidly refers to him. 


         Direct reference is not the same thing as rigid designation. Consider a demonstrative expression, e.g. “that man over there.” It refers to different people on different occasions. A fortiori it refers to different people in different worlds. It is thus a text-book case of an expression whose referent varies depending on the circumstances, and would thus seem to be a paradigm of non-rigid designation. But it is directly referential. 
         In response, one might argue that “that man over there” is a rigid designator, on the grounds that it refers directly. But this would either be a purely terminological move – and a confusing one at that – or a case of begging the question. The referent of “Bill Gates” is not context-sensitive. Given the rules of English semantics, its reference is fixed. “Bill Gates” is also paradigm-case of a rigid designator.[66] The referent of “that man over there” is context-sensitive. Given only the rules of English semantics, its reference is not fixed.[67] If we say that “that man over there” is a rigid-designator, then we are saying that rigidity and non-rigidity are not to be understood in terms of easily ascertained and uncontroversial facts about context-sensitivity, and that they are to be understood in terms of extremely controversial and hard to ascertain facts about the constituencies of propositions. If we say that “that man over there” is rigid, on the grounds that it is directly referential, then the terms “rigid” and “non-rigid” cannot be used without prejudging the outcomes of highly theoretical semantic and metaphysical debates, and they thus cease to have any descriptive utility. So it is not a reasonable option to define “rigid” as “directly referential.” “Rigid” must continue to be defined as “such that what it refers to does not depend on the context of utterance.” 
      But even if we set these points aside, it isn’t clear why “non-rigid designation” isn’t just a kind of quantification. Suppose that “the richest man in America” is a “non-rigid designator” and that Frege is right to think that (2) and (2P) are logically equivalent. In that case, given the arguments already presented, it isn’t clear why “non-rigid designation” isn’t just a form of quantification. In any case, as we’ve seen, “non-rigid designation” would have very little in common with any clear-cut case of reference, and it would have much in common with quantification. 
      As we saw, if Frege is right to hold that (2) and (2P) are logically equivalent, then the  relationship between “Bill Gates” and Bill Gates is very different from the relationship between “the richest man in America” and Bill Gates. It is not hard to extend the argument that we gave in defense of this. The proposition meant by (1) is true only worlds where Bill Gates exists. But the proposition meant by (2P) is true in worlds where he does not. The former is true in a world iff Bill Gates is smart in W. The latter can be true in a world W where Bill Gates is not smart. The relationship between “Bill Gates” and Bill Gates is indisputably a case of bona fide reference. But – supposing, with Frege, that (2) and (2P) are logically equivalent --  the relationship bears little resemblance to the relationship between “the richest man in American” and Bill Gates. 
        Of course, we might use the expression “designation” (or “reference”) to refer to both relations (with the qualification that reference was “rigid” in the one case and “non-rigid” in the other). But that would only mean that our terminology masked crucial semantic and logical differences. It would mean that “non-rigid reference” would denote a relationship that, as we previously saw, was virtually indistinguishable from quantification.[68] 
         Let us now state our second criticism of Frege. It will help if we begin by considering two other paradigms of ours: 


(s2) Smith thinks that the richest man in America is smart 
(s7) Smith thinks that the first person to make a fortune by selling personal computers is smart. 


         As we’ve discussed, Frege took it for granted for that definite descriptions are singular terms. Frege also took it for granted that (s2) and (s7) have different literal meanings and also that they have (or might have) different truth-values. Finally, and most importantly, Frege took it for granted that the underlined parts of (s2) and (s7)  refer to different propositions. (Given his other views, it was mandatory that he hold this.) 
       Here is where the problems begin. Suppose that we accept the principle of compositionality. In that case, the underlined part of (2) must co-refer with the underlined part of (7), supposing that the definite descriptions in them co-refer. So the underlined part of (2) must refer to the same proposition as the underlined part of (7). But according to Frege, the underlined parts refer to different propositions, that being why (s2) and (s7)  may differ in truth-value. Frege deals with this by saying that, in (s2) and (s7), the definite descriptions do not refer to Bill Gates (or any other individual), but rather refer to their “senses.” For exactly similar reasons, the underlined expression in: 


(10) Jones thinks that Smith thinks that the first person to make a fortune by selling personal computers is smart, 


refers not to Bill Gates, but to the sense of the customary sense of “the first person to make a fortune by selling personal computers.” 
       Frege’s view, appropriately generalized, is this. If a definite description (or proper noun) occurs in the context of an expression denoting a proposition, that definite description refers to its “sense.” So in 


(11) it is true that the first person to make a fortune by selling personal computers is smart,


the occurrence of the definite description does not refer to Bill Gates. Rather, it refers to what would ordinarily be the “sense” of that definite description (the concept first person to make a fortune by selling personal computers). Given obvious extensions of this reasoning, Frege’s view demands that the occurrence of the definite description in: 


(12) it is true that it is true that the first person to make a fortune by selling personal computers is smart, 


refer to the sense of the sense that it ordinarily has. 
       But, as Davidson (1980b: 93-108) points out, this view is deeply implausible. It seems ad hoc to suppose that the occurrence of “the first person to make a fortune by selling personal computers” refers to one thing in (12), a different thing in (11), and a third thing in (1).[69]
      There is another problem. What is the sense of the sense of the sense of “the first person to make a fortune by selling personal computers”? The sense associated with “the first person to make a fortune by selling personal computers” is not hard to identify: it is presumably the concept (unique) first person to make a fortune by selling personal computers. But the sense (or mode of presentation) of that sense (not to mention the 666 sense of that sense of that sense) is not so easy to identify.
       In fact, there is demonstrably no such thing as the sense of that sense (or of the sense of that sense). Any given spatiotemporal entity can be given through infinitely many different senses. As Russell (1905) put it, “there is no backward road from sense to denotation.”  If the same is true of concepts, then there is no such thing as the sense of the sense of sense associated with “the first person to make a fortune by selling personal computers.” Frege would then have to pick some specific sense out of these infinitely many. But it is hard to see how any such selection could be anything other than arbitrary, and could possibly correspond to some fact about English-semantics. 
        To block this, Frege would have to say either (a) that he was not concerned with the actual semantics of English or (b) that, given any concept, there is some one sense through which it must be grasped. Let us consider each option. 
        (b) is false. A given concept can be grasped in different ways, i.e. through different “modes of presentation.” In fact, this is a point that Frege himself emphasizes in the Foundations of Arithmetic (Frege 1884), and we may borrow one of Frege’s own examples to illustrate it. Consider the concept of the number zero. There are different ways of thinking about that concept. It can be thought of as the concept that is instantiated only by the predecessor of one or the concept that is instantiated only by the successor of negative-one, and so on. Also, given how hard it is to produce a correct analysis of that concept, it would be artificial to suppose that there were only one way of thinking about it. For if there were only one way of thinking about a concept, then presumably grasping it would be an all or nothing affair: one would either be oblivious to it or one would have complete insight into its structure. But, as Frege (1884) himself emphasized, one can typically learn more about a concept that one already grasps – just as one can learn more about the structure of a physical object that one sees. This suggests that concepts, like spatiotemporal objects, are given through indefinitely many different modes of presentation  If correct, this means that (b) is false. In any case, even if it turned out to be correct, the theoretical problems involved in establishing (b) are formidable, and (b) is thus not a very attractive option. 
       If option (a) is chosen, then Frege’s analysis is ex hypothesi irrelevant to what is meant by any actual (English or German or Japanese…) expressions, and is thus irrelevant to our hypotheses as to what such expressions mean. (This is not to mention that Frege does seem to saying quite explicitly that in the English sentence “Socrates is tall and Smith believes that Socrates is tall”, the two occurrences of “Socrates” do not co-refer, as one of them refers to a person and the other to a mode of presentation.)
       Russell’s theory does not have any of these problems. For any number n, if an occurrence of ┌the phi┐ is preceded by n operators, there is a well-defined rule saying how it parses out.[70] That rule is: ┌…the phi…┐ means, or is true iff, exactly one thing O has phi, and…O…Equivalently, that rule is: ┌the phi has psi┐ means, or is true iff, exactly one thing O has phi and O has psi. As we saw, if Russell is right, there will be cases where an occurrence of ┌the phi┐ parses out in different ways. (This will be the case whenever it falls within the scope of any operator that forms molecular propositions out of atomic ones, as Kaplan (1975b) point out.) So, to use our old example, if Russell’s theory is right, there are different ways that the definite description in (s2) can parse out. But this is not to the discredit of Russell’s theory since the propositions that are in fact conveyed by s2 correspond to those different ways of eliminating the definite description.
      But even though Russell’s theory doesn’t have the problems that we’ve just attributed to Frege’s, it does have other, non-trivial problems, as we’ve seen. At the same time, our theory does not have those problems, and it also appears to explain the relevant facts about cognitive significance. 


          
       
Chapter 5 Modality, intensionality, and a posteriori necessity 


           In the previous chapter, we saw how a failure to distinguish token-meaning (semantics) from type-meaning (pre-semantics) has led to some highly implausible semantic views. We also saw how reasonable alternatives to those views are generated if that distinction is taken into account. In this chapter, we will see how some erroneous theories about modality and conception result from a failure to distinguish semantics from what might be called “pre-pre-semantics.”
        Throughout this chapter we must keep in mind our point that it is always sentence-tokens that bear propositions, and that sentence-types never do so. The semantic content of sentence-type “Socrates is tall” is a rule that assigns a proposition to any given token of that type. That is why different tokens of that type can have different truth-values. (Of course, any two tokens of “one and one make two” have the same truth-value. But is to be explained in terms of the non-semantic fact that mathematical reality doesn’t change; it is not to be explained by supposing that the present-tense marker is semantically ambiguous between temporal and non-temporal meanings.[71]) 
         As we saw, Kripke (1972) made it clear that “Hesperus” and “Phosphorous” are not quantifiers and that they are not disguised descriptions. Kripke made a related point that we have not explicitly discussed, namely: proper names (e.g. “Hesperus”, “Socrates”) are rigid designators. In other words, given the semantics of English, it is fixed what those expressions (or, strictly speaking, their tokens) refer to. Let us develop this point. (To expedite discussion, I will speak as though expression-types refer. The inaccuracies created by this way of speaking are easily eliminated.) 
       Imagine a world W where Al Gore, as opposed to George W. Bush, is U.S. President in 2006. Given only that (in 2006) people in W refer to Gore as “the U.S. president”, it does not follow that there is a language in W whose semantic rules differ at all from those of English. But suppose that, in at least one of the languages in W, “Hesperus” refers to Mars, as opposed to Venus. In that case, we can conclude that there is some language in W that does not have precisely the same semantic rules as English.
         A language that is just like English except that, in it, “Plato” refers to Socrates and “Socrates” refers to Plato, does not have precisely the same semantic rules as English. Strictly speaking, that language isn’t English.[72] For exactly similar reasons, a language where “Hesperus” referred to Mars, not Venus, is not English, even though it may otherwise be just like English. 
         Of course, “Hesperus” and “Phosphorous” both (rigidly) refer to Venus. It follows that neither “Hesperus” nor “Phosphorous” can fail to refer to Venus in any language that has the same semantic rules as English. 
          Here is where matters become interesting. Obviously 


(1) “Hesperus is Hesperus” 


expresses a trivial proposition. But 


(2) “Hesperus is Phosphorous” 


expresses a non-trivial proposition. Frege and Russell dealt with this by saying that “Hesperus” and “Phosphorous” are quantifiers or disguised descriptions. “Hesperus” is synonymous with “the first celestial body to appear in the evening sky” and “Phosphorous” is synonymous with “the last celestial body to disappear from the morning sky.” So according to Russell, (2) means (or is logically equivalent with): 


(2R) Exactly one thing x is a first celestial body to appear in the evening sky; and exactly one thing y is a last celestial body to disappear from the morning sky; and nothing that has the property of being a first celestial body to appear in the evening sky lacks the property of being a last celestial body to disappear from the morning sky. 


      Frege’s position is not different from Russell’s, at least not in any way that is relevant in this context.[73] 
      We know from Kripke that Frege and Russell were wrong. “Hesperus” is not a description, and “Hesperus”, unlike “the first celestial body to appear in the evening sky”, rigidly refers to Venus. Of course, the same is true of “Phosphorous.” Each of the referring terms in (2) is a label; and the structure of the proposition encoded in (2) is not a quantified, Russell-style generalization. Rather, that proposition has the form x=y. 
       There is one last point to make before we can close Kripke’s argument. The relation of identity holds necessarily.[74] Nothing could possibly fail to be itself. Nothing could have been a numerically different object . This point can be established formally. Suppose that x is only contingently identical with y. Obviously x isn’t contingently identical with x. So if x is only contingently identical with y, then y has some property that x does not have (y has, and x lacks, the property of being contingently identical with x). So by Leibniz’s Law, x and y must be distinct. When it holds, identity holds necessarily. Any true statement of the form x=y is necessary.
        Let us now close Kripke’s argument. (2) expresses a true proposition of the form x=y. That proposition holds necessarily, given what we said in the previous paragraph. But (2) is obviously an a posteriori statement. It expresses a synthetic, not an analytic, claim. Empirical work was needed to establish the truth of (2). There are thus necessary a posteriori truths. Not all necessity is analytic (or a priori). 


A posteriori necessary truth: a re-assessment


           The argument just presented involves a major non-sequitur and is incorrigibly fallacious. We’ve seen good reason to believe that, for some x, an utterance of “Smith is tall” encodes the singular proposition x is tall. We’ve also seen reason to believe that what is communicated by any such utterance is much richer than that singular proposition. What is communicated by such a proposition is a function not (merely) of its literal meaning, but of the information through which one ascertains its literal meaning. That information, we saw, is existential. You cannot just see Smith. You must see a thing x that is embedded in a situation any perceptual representation of which is replete with descriptive content. And when someone speaking to you points to someone else and says “that guy is Smith” (or “that guy is named ‘Smith’”), the information that enables you to associate “Smith” with the right object has the form: there is some entity x such that x has such and such properties and such that “Smith” names x. Because “Smith” has narrow-scope with respect to the descriptive information (there is an entity having such and such properties), it is a mere label, and not (pace Russell and Frege) a description or quantifier. But, as we stressed, even though it has been semantically neutralized, by virtue of being given wide-scope in the relevant existence-claim, that descriptive-existential information still remains operative: you access the meaning of “Smith” through that existence-claim (or, at any rate, through some other existence-claim that “interlocks” with it in the way described in Chapter 3). For this reason, what an utterance of “Smith is tall” communicates to you will be an existence claim – it will have the form somebody x uniquely has such and such properties; moreover, “Smith” names x, and x is tall. (Of course, it is not always through ostensive definition that one learns what proper names refer to. But given what we saw in Chapter 3, it is clear how the points just made can be extended to deal with cases where word-reference is learned non-ostensively.) 
       Of course, what we just said about “Smith” is true of “Hesperus” and “Phosphorous.” For illustrative reasons, let us suppose that you learned the meanings of those terms ostensively. Your friend Jones point to a certain object in the morning sky, and says “that is Hesperus.” The object indicated is quite clearly the last celestial object (other than the sun) to disappear from the morning sky. (Of course, given only that some object is the last celestial body to disappear from the morning sky on one occasion, it doesn’t follow that it always has that property, i.e. it doesn’t follow that tomorrow, some other celestial body won’t have that property. But let us suppose that, on the basis of the experience just described plus your knowledge of astrodynamics, you correctly infer that the object indicated must be the last celestial body to disappear from every morning sky.) There is some x such that the semantic rule for “Hesperus” is simply: 


(HS) “Hesperus” refers to x. 


(More accurately, that rule is: tokens of “Hesperus” refer to x, for the appropriate value of x. This nicety is important, as we will see.) But (HS) is given to you through some claim having (approximately) the form: 


(HE) There is some object x such that x is a unique last celestial object to disappear from the morning sky, and “Hesperus” names x. 


A consequence is that if somebody says to you: 


(HL) “Hesperus is lovely”, 


what is communicated to you is not (merely) x is lovely, for some x, but is rather: 


(HLG) There is some object x such that x is a unique last celestial object to disappear from the morning sky; moreover, “Hesperus” names x, and x is lovely. 




For reasons that we discussed in Chapter 3, this doesn’t mean that you wrongly take tokens of (HL) to have (HLG) for their literal meanings. You know that the literal meaning of an utterance of (HL) is confined to the underlined part of (HLG). That is why you have the right modal and semantic intuitions; that is why you know that what is expressed by “Hesperus is the last celestial body to disappear from the morning sky” is not analytic; and that is why you know that “Hesperus might not have been the last celestial body to disappear from the morning sky” is not absurd, and does not describe an impossible situation. But it remains a fact that you access the meaning of tokens of (HL) through (HLG) and that such tokens thus communicate (HLG) to you. Given any predicate phi, exactly similar points hold with regard to what is communicated to you by ┌Hesperus has phi.┐
      Once again, you and Jones are gazing at the sky. He points to a celestial object and says “that is Phosphorous.” The object indicated is quite clearly the first celestial object to appear in the evening sky. For exact analogues of the reasons just given, what is communicated to you by a token of: 

(PL) “Phosphorous is lovely” 


will have approximately the form: 


(PLG) There is some object x such that x is a unique first celestial object to appear in the evening sky; moreover, “Phosphorous” names x, and x is lovely, 


even though (as you know) what is literally meant by such an utterance is confined to the underlined portion of (PLG). So while it is true that the semantics of “Phosphorous” is given by the rule: 


(PS) “Phosphorous” refers to x, 


the epistemology of that term is given to you through some piece of information like:


(PE) There is some object x such that x is a unique first celestial object to appear in the evening sky, and “Phosphorous” names x. 


As we’ve discussed, when we want to know what is communicated by statements, we must look not at the propositions that give their semantics, but at the propositions that give the epistemology of their semantics. 
       Given what we’ve said, it immediately follows that, for any phi, what a token of ┌Hesperus has phi┐ conveys to you is: 


(I) There is some object x such that x is a unique last celestial object to disappear from the morning sky; moreover, “Hesperus” names x, and x has phi. 




It also immediately follows that what a token of ┌Phosphorous has phi┐ conveys to you is: 




(II) There is some object x such that x is a unique first celestial object to appear in the evening sky; moreover, “Phosphorous” names x, and x has phi. 




Given (I) and (II), it follows straightforwardly that what a token of 




(2) “Hesperus is Phosphorous” 




conveys to you will be: 




(III) There is some object x such that x is a unique last celestial object to disappear from the morning sky; moreover, “Hesperus” names x; there is some object y such that y is a unique first celestial object to appear in the evening sky; moreover, “Phosphorous” names y; moreover; x=y. 




So what is conveyed by (2) will be exactly what Russell thought (wrongly) to be its literal meaning. What is conveyed by (2) is not a singular proposition of the form a=b. (I am switching variables for obvious reasons.) What is conveyed is a descriptively rich existence-claim. 
      But, for reasons that we’ve discussed, what is literally meant is confined to the underlined part of (III). And you know this. You know it for exactly the reasons that you know that the literal meaning of a token of “Hesperus is lovely” is confined to the underlined part of (HLG) – or, more exactly, that it is what is confined to a certain specialization of the propositional-form corresponding to the underlined part.
       Of course, that underlined part is necessarily true. As we discussed, any genuine identity claim holds necessarily, if it holds at all. But we don’t have any a posteriori necessary truth here. Astronomical work was needed  to ascertain the truth expressed by (III). That proposition is entirely contingent. 
        Tokens of (2) do indeed encode necessary truths. For what is literally meant by such tokens is a true proposition of the form a=b. But what is a posteriori is not what is literally meant by (2) or tokens thereof, but is rather what is communicated by such tokens. What is a posteriori is the information through which you access the literal meaning of tokens of (2). And that information is contingent. 
        The literal meaning of (2), on the other hand, is analytic. That literal meaning is given by a singular proposition of the form x=y. Because we are dealing with a singular proposition, we are dealing with a structure that comprises the object x and the object y. We are not dealing with a structure that comprises senses or descriptions of x or of y. Apart from the concept of equality, only x and y – the objects, not any concepts thereof – make it into that proposition. Since x is identical with y, some one object occupies the place that (in our notation) corresponds to the occurrence of the “x” and the occurrence of the “y.” And because, for the reasons just given, that object alone – without the accompaniment of any sense or description or concept – is what occupies that place, the proposition in question has the form x=x; and any proposition of that form is analytic. 
       Of course, empirical work is needed to grasp x, at least in this case. But for a proposition to be analytic is not for it to be such that no empirical work is needed to grasp its constituents; it is for that proposition to be such that, once grasped, no empirical work is needed to determine its truth-value. 
        So when we distinguish between semantics, on the one hand, and the epistemology of semantics, on the other, we don’t have anything that is both necessary and a posteriori. We have a strictly analytic proposition (corresponding to the underlined part of (III)) that is necessary; and we also have a contingent, a posteriori proposition (corresponding to (III) in its entirety). The idea that we have unearthed anything that is both necessary and a posteriori (or “synthetic”) embodies a failure to distinguish semantics from pre-semantics -- a failure to distinguish literal meaning from the information through which we access it. 
      The concept of necessary, a posteriori truth is a conflation of two concepts: the concept of literally meant, analytic truth and the concept of pre-semantically communicated (but not literally meant) contingent truth.
       Kripke provided an argument similar to that just considered that purports to show that what is meant by “water is H2O” and “light is electromagnetic radiation” express necessary, a posteriori truths. But what we just said about the case of 2 applies to these other cases. 
       This is not to say that there no instances of necessary a posteriori truth. But given only what Kripke says, it seems probable that the concept of necessary a posteriori truth is yet another expression of the failure to distinguish semantics from pre-semantics. 


Pre-semantics versus pre-pre-semantics 


        In the previous chapter, we saw how, where definite descriptions and demonstratives are concerned, a failure to distinguish semantics from pre-semantics had led to some questionable doctrines. In this chapter, we have seen yet another example of that phenomenon. But here it becomes important to distinguish two very different kinds of pre-semantics. 
        The semantics of the expression-type “that man over there is tall” is given by a rule that assigns the singular proposition x is tall to a token t of that expression, provided that t occurs in a context where somebody x is a unique contextually salient bald man. Because one must work through type-meaning to compute token-meaning, what is communicated is not (merely) x is tall but is rather: somebody x is uniquely a contextually salient bald man; moreover, x is bald. Because of this, many semantic theories – e.g. those of Frege and Russell – involve a failure to distinguish type-semantics from token-semantics. 
        But the rule for “Hesperus” has nothing to do with the kind of descriptive information encoded in existence-claims like: 


(HE) There is some object x such that x is a unique last celestial object to disappear from the morning sky, and “Hesperus” names x. 


      
        (HE) gives the information through which you grasp the semantic rule for “Hesperus.” As a whole, (HE) does not give the semantic rule for the type “Hesperus” or for its tokens. Only the underlined portion of (HE) does that. There is some x such that x is identical with Venus, and such that semantic rule for “Hesperus” is simply: 


(HS) “Hesperus” refers to x.


More exactly, there is some x such that semantic rule for “Hesperus” is simply: 


(HST) Tokens of “Hesperus” refer to x. 


We’ve already discussed why the expression-type “Hesperus” doesn’t refer to anything: for some x (Venus) its semantic content is a rule (a constant function) that assigns x to its tokens. Through the information borne by (HE), you learn the semantic content of the type “Hesperus.” That content is given by (HST). On the basis of your knowledge of (HST), you learn what is meant by specific tokens of “Hesperus” and, thus, what is meant by particular tokens of “Hesperus is lovely”, “Hesperus is a planet, not a star”, and the like. 
      So as a whole, (HE) doesn’t state the semantics of the expression-type “Hesperus”: only the underlined portion does that, as we’ve seen. Rather, (HE) states the information through which you learn the semantic content of the expression-type “Hesperus.” That content, in its turn, assigns a semantic content to tokens of that expression. So if token-meaning is semantics, and type-semantics is pre-semantics, then what you learn through (HE) is pre-pre-semantics. 
        Frege and Russell both thought that “Hesperus” had, for at least part of its meaning, some concept like last celestial object to disappear from the morning sky. This view involves several confusions. First, there is no such thing as “Hesperus” simpliciter. There is “Hesperus”, the expression-type, and there are tokens of that type. For some x, the semantic content of that expression-type is given by the proposition: tokens of “Hesperus” refer to x; and x itself is the content of such tokens. One must learn the semantic content of “Hesperus”, the expression-type, through some highly descriptive claim – some claim like (HE). As a result, what is communicated by a token of “Hesperus is lovely” is some descriptively rich existence-claim. So in terms of what it communicates, any token of “Hesperus is lovely” will, in virtue of containing an occurrence of “Hesperus”, communicate a proposition involving some concept like last celestial object to disappear from the morning sky. But that concept has nothing to do with the literal meaning of that sentence-token. Nor does it have to anything to do with the literal meaning of that sentence-type. So nothing having to do with that concept has to do with the semantics or even the pre-semantics of that token (at least not if, by “pre-semantics”, we mean what is meant by the corresponding type). Rather, that concept is part of the pre-pre-semantics of that token. The concept last celestial object to disappear from the morning sky is, at most, part of the pre-pre-semantics of “Hesperus”; and propositions identical or equivalent with something x  last celestial object to disappear from the morning sky, and x is lovely are, at most, part of the pre-pre-semantics of tokens of “Hesperus is lovely.” They aren’t part of the semantics of such tokens; and they aren’t part of the pre-semantics of that token (i.e. they aren’t part of what is literally meant by the corresponding type). Rather, they are part of the pre-pre-semantics of that token: they are part of the information through which one accesses the meaning of the relevant-type;  they are part of the information through which one accesses type-meaning (pre-semantics) and are thus pre-pre-semantic. 


Frege’s theory a conflation of three different concepts
 
           Here we need to qualify a point a just made. As we saw earlier, one often forgets the information through which one initially learned the semantics of an expression. I learn who “Smith” refers to under the following circumstance. At a certain time, in a certain place, I see a person with such and such properties; my companion points to Smith and says “that guy is Smith.” For reasons already discussed, what is relayed to me is not 666 some singular proposition of the form “Smith” names x, but is rather one of the form: at a given time and place, somebody x has such and such properties and “Smith” refer to x (or, tokens of “Smith” refer to x). Of course, I may forget that particular existence-claim and still be able to think about and refer to Smith. But so far as this possible, that is because my knowledge of that particular existence-claim has been replaced with a different one that interlocks with the first (or with a third one that interlocks with the second…). As we saw in Chapters 2 and 3, I must work through that existence-claim – that second or third or fourth…claim – to compute the meaning of “Smith is a professor” (or, by exactly similar reasoning, to computer the meaning of “Hesperus is a planet”). That existence-claim is, of course, no part of the meaning of a token of “Smith is a professor.” Nor, obviously, is it any part of the semantic content of the corresponding-type. That existence-claim constitutes the information through which I access the semantics of the corresponding type. (For some x, that semantics is given by the rule: tokens of “Smith is a professor” are true iff x is a professor.) And on the basis of my knowledge of that rule, I compute the meaning of a given xxx token of that sentence-type. So the concept person having such and such properties is no part of the semantics of any token of “Smith” or of the semantics of the corresponding type (so it is no part of the pre-semantics, in the strict sense, of such a token). Rather, that concept is, at most, part of the pre-pre-semantics of a token of “Smith” and it is, at most, part of the pre-pre-semantics of a token of “Smith is tall”, “Smith is a professor”, and so on. (I say “at most” because the concept person with such and such properties may not be a part of the pre-pre-semantics of “Smith”, depending on how one learns the semantics of “Smith.” If somebody points to a person with thus and such properties and says “that is Smith”, then the concept person with thus and such properties – as opposed to person with such and such properties – may end up being part of the pre-pre-semantics of “Smith”, at least for me.) Exactly similar remarks apply to “Cicero”, “Tully”, “Hesperus”, and “Phosphorous.” What Frege thus thought of as the sense of “Hesperus” is really the pre-pre-semantics of tokens of that expression. It isn’t part of semantics of tokens of that expression or of the corresponding type. It is part of the information through which one is given meaning of the corresponding type. It is thus at two removes from what is meant by expression-tokens. 
      Frege’s notion of sense is thus a conflation of three different concepts: token-meaning, type-meaning, and the non-semantic information through which one ascertains type-meaning.
     Kaplan (1989b: 568) writes: 


     Fregean sinn conflates elements of two quite different notions of meaning. One, which I called character, is close to the idea of linguistic meaning (and perhaps of cognitive content). Another, which I call content, is what is said by an expression in a particular context of use. The content of an utterance [i.e. a token] of a complete sentence is a truth-bearing proposition. Where indexicals are involved, the difference between character and content is quite clear. 


       Kaplan’s point contains a deep insight, and it is correct as far as it goes. But it doesn’t go far enough. Frege didn’t just hold that demonstratives and definite descriptions have sense; he didn’t just hold that “non-rigid” designators have sense. He held that proper nouns, like “Socrates” and “Hesperus”, have sense. The character-content distinction isn’t really applicable to such expressions. 
        In any case, even if it is applicable, it doesn’t explain why tokens of “Hesperus is Phosphorous” communicate non-trivial propositions. There is some x such that the semantic content of the expression-type “Hesperus” is tokens of “Hesperus” refer to x and such that the semantic content of the expression-type “Phosphorous” is tokens of “Phosphorous” refer to x. We could say that these rules are the “characters” of those expressions. But those rules are not sufficiently different to explain why tokens of ┌Hesperus has phi┐ convey propositions concerning the concept last celestial body to disappear from the morning sky or why tokens of ┌Phosphorous has phi┐ convey propositions concerning the concept first celestial body to appear in the evening sky. Those “characters” cannot even begin to explain the facts relating to the cognitive significances of such tokens. 
       So while Kaplan is quite right to say that Frege’s notion of sense conflates character and content – type-meaning and token-meaning – that is not all that it conflates. It false conflates the information through which one computes type-meaning with type-meaning. Thus Frege’s analysis involves a conflation, not of two, but of three different notions: semantics (token-meaning), pre-semantics (type-meaning), and pre-pre-semantics (the information through which one computes type-meaning and, on that basis, token-meaning). 
      To illustrate our criticism of Frege’s analysis, we chose to consider to a case where reference was learned ostensively. Of course, one doesn’t have to learn what “Hesperus” refers to through an ostensive definition; indeed, this isn’t likely to be how one learns that. But everything that we’ve said about cases of ostensive learning carries over to cases of non-ostensive learning. As we saw, it is always through a descriptive-existential claim that one learns what an expression E means: it is through some piece of information having the form: there is some object x having such and such properties, and tokens of E refer to x. Given this, everything that we said about cases where one learns the meaning of “Hesperus” ostensively holds in cases where one learns that meaning non-ostensively. Of course, everything that we just said about “Hesperus” is true of any other proper noun.) 
      Semantics is public. The expression-type “Hesperus” has a public meaning, and so do tokens of that type. But pre-pre-semantics varies from person to person. Depending on how I learn what “Hesperus” refers to, tokens of “Hesperus” might or might not connote the concept last celestial body…to me; and in virtue of containing tokens of “Hesperus”, sentence-tokens might or might not convey propositions containing that concept to me. This is consistent with the fact that semantics is public. After all, pre-pre-semantics is not semantics. It isn’t token-semantics or type-semantics. It is how people access semantics. 
      Given that pre-pre-semantics can vary from person to person, it might seem that our analysis threatens the possibility of interpersonal communication. The opposite is the case. Because of this variability, what one’s words literally mean is not in complete lock-step with what one is thinking: there is always a certain slack between the two. And it is because there is this slack that one person’s words can be meaningful to another person, even if the two people have had very different psycho-biographies. As we will discuss, if the literal meanings of one’s utterances were too close in content to the thoughts that precipitated them, those utterances would not be intelligible to others. Communication involves isomorphism, not identity, of the thoughts involved in the production and assimilation of linguistic expressions. We will investigate this in Chapter 9. 


Extensionality revisited 


        As we’ve seen, a token of “Hesperus is lovely” may convey a very different proposition from a token of “Phosphorous is lovely.” Given what Kripke (1972) and Soames (2001, 2003) say, it is probably not an option to hold that  those tokens differ in literal meaning. And it isn’t necessary to do so. It is necessary only to distinguish literal meaning from the information through which it is ascertained. It is necessary only to distinguish semantics from pre-semantics (and from pre-pre-semantics). 
          An exactly parallel line of thought reinforces the views on extensionality that we put forth in the previous chapter. A token of “John believes that Hesperus is lovely” may communicate a proposition that differs in truth-value from the proposition that is communicated by a token of “John believes that Phosphorous is lovely.” Given what Kripke and Soames say, it isn’t an option to hold that those tokens differ in literal meaning. And it isn’t necessary to do so: that difference in truth-value is to be explained along lines similar to those used to explain the apparent difference in meaning between “Hesperus is lovely” and “Phosphorous is lovely.” Yet another threat to extensionality turns out to involve a conflation of semantics and pre-semantics (and pre-pre-semantics). 
        Given what Kaplan (1989) says, a token of “he is tall” and “you are tall” have the same literal meaning if the occurrence of “he” co-refers with the occurrence of “you.” In Chapter 1, we explained why Kaplan’s view is consistent with the fact that those tokens convey very different propositions. A token of “John believes that you are tall” may convey a proposition that differs in truth-value from the proposition conveyed by a token of “John believes that you are tall.” But given obvious extensions of what we said in Chapter 1, that is perfectly consistent with the supposition that those tokens have the same proposition for their literal meaning. And given what Kaplan (1989) says, it is probably necessary to suppose that they have the same literal meaning. Yet another threat to extensionality is neutralized. 
         There is no shortage of authors who think that truth-value can be changed by intersubstituting co-referring definite descriptions, and who thus think that not all contexts are extensional.[75] The arguments in favor of that view are exact analogues of the arguments in favor of the view that truth-value by can be changed by intersubstituting two co-referring proper names or demonstratives. The latter arguments are fallacious, and the same is therefore true of the former. Further, as we saw in Chapter 3, the supposition that definite descriptions are directly referential is easily reconciled with the fact that the truth-value of what is conveyed can be changed by intersubstituting co-referring definite descriptions. In light of these points, it would be very artificial to suppose that intersubstituting co-referring definite descriptions changes truth-value. It thus appears that intersubstituting two co-referring nouns (or noun-phrases) never changes truth-value and that all contexts are therefore extensional.[76]
                  
Chapter 6  Cognitive maps and causal connections: why the causal story is an important part of the descriptive story
  
          It has often been said that to think about an object, one has to be causally connected to it. This has been held both by semanticists and philosophers of mind.[77]           
         This view seems to conflict with the fact that we can refer to things to which we have no causal connection. The famous example is Kaplan’s “Newman 1” (Kaplan 1975), which is defined thus: if there is an x such that x born before anyone else in the 3rd millennium A.D., let “Newman 1” refer to x. So if Brown has that property, then 


(N1) “Newman 1 will be a genius”


 semantically encodes the proposition: 


(BG) Brown will be a genius. 


          Some authors (Donnellan 1974, Kaplan 1989) hold both that we can refer to things to which we are not causally connected and that we must be causally connected to a thing in order to think about it. They have dealt with this situation by saying that we don’t grasp the proposition semantically encoded in N1. We are not causally connected to Brown, at least not in the right way. Therefore we cannot think about him, and thus cannot grasp the proposition that is literally meant by (N1).  
      Given what we’ve said in Chapter 3, this reasonable-seeming view should be reconsidered. (I say “reconsidered”, not “rejected”, because there is a certain truth in it, as I will try to show in this chapter.) 
      In many cases, our ability to think about a thing involves our having a certain causal relation to that thing. But we’ve seen that, in every such case, the causal connection between subject and object is simply an ingredient in the subject’s knowledge of the right kind of uniquely individuating description. Your acquiring a concept of Fred by seeing him consists in your acquiring knowledge of an existence claim of which Fred is the unique verifier. If you acquire a concept of Fred by being told about him, or by hearing about him, that too consists in your acquiring knowledge of an existence claim of which Fred is the unique verifier. In all cases, then, knowledge of a thing consists in knowledge of a uniquely individuating description that applies to that thing. In some cases, a causal connection between subject and object is an ingredient in that knowledge. But it is never the causal connection per se that constitutes conception; it is always knowledge of a uniquely individuating description. 
       Obviously we can know of a uniquely individuating description that applies to Brown (Newman1). So given only what we said in the last paragraph, it seems wrong, or at least arbitrary, to say that we can think about Socrates but that we cannot think about Newman 1. For the very thing that enables us to think about Socrates would seem to be present in the case of Newman 1.[78] 


Why the causal story is a necessary addition to the descriptive story 


      Nonetheless, there is a significant difference between the sort of concept that we have of Newman 1, on the one hand, and the sort of concept that we have of Socrates or of those with whom we are personally acquainted. Donnellan (1974), Evans (1982), and others are not entirely wrong to put those concepts in different categories. And Donnellan and Evans are right to see the relevant difference between them as lying in the fact that, in the one case but not the other, a causal connection between subject and object is involved.
        A proper understanding of this issue is to be found in an insight of Evans’. The argument I’m about to give is not exactly Evans’ own. But it owes much to his insights.[79]
        Evans (1982: 65) held that, in order for x to be able to have thoughts about y, x must have a “discriminating conception” of y. Unlike us, Evans did not hold that such knowledge consists in knowledge of a uniquely individuating description of the kind described earlier. But, like us, he rejected the idea that, by itself, a causal connection between x and y could possibly enable x to have thoughts about y. (He referred to the idea that, by itself, such a connection could realize conception as the “photograph model.”) And, like us, Evans held that, although such a causal connection has an important role within conception, it must be embedded within knowledge of a certain kind if there is to be any concept. 
         What, according to Evans, is the nature of that knowledge? Evans (1982: 143-191, 1985: 291-321) rightly says that spatiotemporal individuals are distinguished from one another by their locations (in both space and time). Of course, Socrates is not individuated by the fact that, at some specific moment, he is in some specific place. In other words, he is not who is he is in virtue of the fact that at time t he is in place p. After all, he might have been somewhere else at that time. (In fact, given any time t during which Socrates existed, if Socrates was at place p at t, Socrates might have been somewhere other than p.) But every spatiotemporal individual has unique space-time co-ordinates; and for this reason, and others, it seems reasonable to suppose that distinguishing one individual from the next consists in, or at least involves, having some conception of how such individuals differ in respect of their space-time locations. 
           Of course, if you see some object, you ipso facto know, at least relative to an egocentric frame of reference, how that object is spatiotemporally distinctive. So there is no trouble seeing how x’s perceiving y gives x the sort of discriminating knowledge of y that, in Evans’ view (and ours), endows x with a concept of y. Obviously seeing an object involves being causally connected with it. We saw earlier how this causal connection is a mere constituent of one’s being given a uniquely individuating description of that object. So if we confine ourselves to cases of sense-perception, it is clear how to reconcile the following two views (both of which we and Evans accept): first, in at least some cases, a causal connection between x and y is constitutive of x’s concept of y; second, x must have “discriminating knowledge” of y to have a concept of that object. 
       But, of course, most of our concepts are not acquired directly through perception. My concept of Socrates didn’t result from a perception of him. At the same time, that concept, like a visual perception of Socrates, has a causal component; and we have seen other similarities between conceptions that are derived from perceptual encounters with objects (e.g. my concept of my best friend) and conceptions are not so derived (e.g. my concept of Socrates). This suggests that it is possible to extend what said a moment ago about concepts of the first kind to concepts of the second kind. We will attempt to make that extension in this chapter. 
      A caveat is in order. It is, I will argue, only where spatiotemporal objects are concerned that a causal connection between subject and object is constitutive of conception. We will not attempt to show that what is true of my concept of my best friend or of Socrates is true of my concept of the number two or the concept of justice.[80] 
       But supposing that, at least where spatiotemporal objects are concerned, causality is constitutive of conception, we must ask why that is so. Why is a causal connection between x and y so important to x’s having a concept of y? Is it just a brute fact? Or, on the contrary, can we find some basis for that fact? 


Causality and spatiotemporal locatedness 


         I am going to give an Evans-inspired answer to this last question. (But even though it is Evans-inspired, my answer is not one that Evans himself provides. In fact, given his other views, it is not one that he could provide.) First of all, spatiotemporal relations are causal relations. E1 temporally precedes E2 iff there is a possible causal process (e.g. a light-ray) that begins with E1 and ends with E2  (Reichenbach 1958, Sklar 1974, Salmon 1984). Indeed, it would make no sense to say that two events were part of the same temporal order unless either (i) they were connected by a (possible) causal sequence or (ii) each of them connected by such a sequence to some third event. Further, it would make no sense to say that two events were part of the same space unless either (i*) they were connected by some (possible) causal sequence or (ii*) they were both connected by some sequence to some third event (Reichenbach 1958, Sklar 1974, Salmon 1984). 
        Although recent, and extremely sophisticated, developments in theoretical physics were needed to force these facts on our consciousness, it is hard to believe that we have not always known them at some intuitive level. Any person’s mind recoils at the idea of two events having temporal or spatial relations but being necessarily causally divorced both from each other and from any third event. Spatiotemporal relations are inseparable from causal relations. It seems reasonable to believe that, at some cognitive level, everyone has an awareness of the intimate connections between spatiotemporal location, on the one hand, and causality, on the other. Indeed, it seems reasonable, if not mandatory, to suppose that an awareness of this constitutes a vital part of our “conceptual scheme” – of our way of processing the disturbances of our sensory surfaces and, subsequently, of our way perceptually and cognitively the world. 
         Of course, this knowledge is not discursive, or even conscious.[81] But we wouldn’t expect it to be conscious, given that this knowledge is constitutive of the apparatus that generates perceptions and other contents of consciousness. This knowledge is part of our cognitive framework; it is not a cognitive production. Anything that is generated by consciousness, or a fortiori by discursive thought, presupposes that framework. So the knowledge in question is not to be found at the level of conscious or, more generally, personal mentation. 


The egocentric character of cognitive maps 


           We thus have three facts to work with. First, spatiotemporal relations are closely bound up with causal relations. Second, at some level, everybody knows this. Third, spatiotemporal individuals are distinguished from one another by their spatiotemporal co-ordinates. 
       Before we can close the argument, there is a fourth point to make. Ultimately, one’s cognitive “map” of the world is egocentric. In this respect, cognitive maps (so-called) are fundamentally different from the maps produced by cartographers and astronomers. While there is a sense in which maps of the latter kind are egocentric, it is entirely different from the sense in which cognitive maps are egocentric. 
       Right now let us say exactly how the maps produced by professional map-makers are egocentric. In a moment, we will see why the egocentricity of such maps is of a much more superficial kind than that characteristic of cognitive maps.  
        Even if you are an extremely knowledgeable geographer or astronomer, you must ultimately understand the location of a given country, or a given galaxy, in terms of something which is given to you ostensively (perceptually). The difference between somebody who is knowledgeable about geography and somebody who is not is that the former is able to put his concept of this place [the place where I, the knowledgeable geographer, am] into a much wider context than the person who doesn’t know anything about geography. Nobody understands the layout of Earth’s surface (or of the Solar System or of the Cosmos…) in completely non-egocentric terms. The astronomer (or geographer) can integrate his thoughts of the form …this place [the one I am occupying right now]…into a much wider body of information than the astronomically (or geographically) uninformed. But, in the end, the astronomer must begin with some kind of purely perceptual, and thus egocentric, interface with his environment. So every cognitive map of the world, no matter how panoramic it ends up becoming, begins with the egocentric phenomenon of sense-perception. Whenever one locates an event in space-time, one does so in terms that are ultimately egocentric.  
         From these points, it follows that an event’s (or object’s) spatiotemporal relations to one another are nearly enough indistinguishable from its causal relations to one (or, at least, from a certain subset of its causal relations to one). To locate an object in space time – to establish its spatio-temporal position relative to one – is to know of some causal connection connecting that event to one. 
         To perceive an object is to have an awareness of a very direct causal link between that object and oneself. Obviously, considerable scientific sophistication is needed to know the exact nature of the link. But, as previously discussed, if x perceives y, it is hard to believe that at every cognitive level x is oblivious to the fact that y is having a rather direct effect on his own experiences; and it is also hard to believe that x is entirely in the dark as to the nature of that causal relation. 
        Suppose that somebody shines a flashlight in your eyes. Perhaps you know nothing about the physics or neurophysiology involved in the processes mediating between, on the one hand, his turning the flashlight in your direction and, on the other hand, your subsequent painful and emotionally distressing flash-blindness. But you have a great deal of comparative knowledge with regard to this process. First of all, you know that a causal connection is involved: you know that the unpleasant state you are in is a consequence of the fact that a beam of light is pointing in your direction. Second, can certainly discriminate between that kind of causal process and others. You know that you are at the receiving end of something that is qualitatively different from a cool breeze or a lovely tune or a beautiful sunset. So, although you may have little or know theoretical understanding of the mechanics of these various processes, you are able to distinguish between them. You thus have a great deal of differential knowledge as to the nature of this process, granting that your theoretical or scientific knowledge of may be limited or even non-existent. 
     Similarly, somebody x who sees (or feels or hears…) something y must surely register, at some psychological level or other, the fact that y is causally responsible for his current condition, and must also have a reasonably good differential understanding of the nature of that process.[82]
       It is hard to believe that, when a cat sees a dog charging at him, there is no representation at all in the cat’s mind of some kind causal nexus between the cat’s current experiences and the occurrence of a certain kind of external phenomenon. Obviously the representation in question doesn’t consist in a discursive, theoretically articulated understanding of the sort that only our best scientists can produce. But it would be absurd to deny, on that basis, that at every cognitive level the cat is altogether ignorant of any relations of dependence of the sort just discussed. The behavior and cognition of animals would be inexplicable unless some allowance were made for some kind of awareness on their part of relations of causal dependence holding among the characters of their own states, on the one hand, and those of events in the external world, on the other. 
           Given these points, it is not hard to see why perception has such a distinguished and fundamental role in concept-formation. To have a concept of a thing is to be able to distinguish it from all other things. Ultimately, spatiotemporal individuals are distinguished by their space-time co-ordinates. Spatiotemporal distinctions are (nearly enough) causal distinctions. (Reichenbach (1958) argues cogently that they are causal relations.) All knowledge of spatiotemporal distinctions is ultimately egocentric. To perceive something is to have knowledge of a causal relation between that thing and oneself, and is also to have a great deal of (differential, not theoretical) knowledge as to the nature of that causal relation. So it is because it has a causal component that perception can give us the uniquely individuating knowledge of objects that is identical with our having concepts of them. So it is not a brute fact that perception is, at least in part, a causal phenomenon. That fact can be understood in terms of the fact that perception gives an understanding, albeit an egocentric one, one of the spatiotemporal locations of individuals and states of affairs. 
        It thus seems that for x to have a concept of y is for x to have some idea of y’s causal relation to one. (This line of thought is not meant to apply to our knowledge of abstract objects.) But the reason for this is not that a causal connection between x and y is a fundamental, inexplicable fact about x’s having a conception of y. What is thus fundamental is x’s having discriminating knowledge of y; and what is, or can be, fundamental to having such a conception is x’s having (egocentric) knowledge of y’s spatiotemporal location; and, finally, what is fundamental to that sort of knowledge is, or at least can be, a knowledge of y’s causal relation to x. 


Conception of an object as assigning a place to it in one’s cognitive map 


           Before we can close the argument, there are two more points to make. To have a cognitive map of the universe is (tautologically) to know how things are spatiotemporally distributed in it. A corollary is that, in some cognitively pregnant sense of the word concept, x has no concept of a thing y unless x has some way of fitting y into his (x’s) cognitive map. 
       We’ve said that at least part of what it is for x to have a concept of y is for x to know of some existence claim that y uniquely satisfies. Given this, suppose that x does know such a claim, but that x’s knowing this truth doesn’t involve x’s having any special causal connection to y. So suppose that E is not like the occurrence of 


(*) “this guy is named ‘Fred’” 
 
discussed in Chapter 3 (p. 47), but is rather like:


(**) somebody is a tallest spy 


Let us briefly recall what we said about (*). Let us suppose that Smith is the person referred to as “this guy” in (*). (We will set aside the issue of why is being referred to as “Fred.”) We saw in Chapter 3 that, in virtue of knowing the truth of utterance of (*), you (a) know the truth of some existence-claim that Smith uniquely satisfies; you (b) are at the receiving end of a very special kind of causal-process (one that Dretske (1982) would describe as “information-transmitting”) that begins with Smith; and, most importantly, you (c) have a concept of Smith. 
      (**) is not like this. Suppose that Smith is the tallest spy and that Jones knows the truth of (**). We would be reluctant to say, on those grounds alone, that Jones had a concept of Smith in virtue of knowing (**).[83] At the same time, in virtue of knowing E, x does know some claim that Smith uniquely satisfies. It is not the case that, in virtue of knowing (**), Jones is causally connected, in a significant way, with Smith. (He is not, to use Kaplan’s (1968) expression, en rapport with Smith.) But it is the case that, in virtue of knowing (*), one is causally connected with Smith. So the difference between having and lacking a concept can come down to down the presence or absence of a certain kind of causal connection.[84]
         But philosophers of an externalist turn of mind over-react to this. They say, or at least gravitate towards the position, that concepts are to no degree descriptive and are to be understood in strictly causal terms (Fodor 1998, Dretske 1982). They say that concepts are related to their objects in basically the same way that discolorations on a photographic plate are related to the events that caused those discolorations. In any case, the latter relationship is taken as a kind of model of the former. But we’ve seen why, in addition to being radically counterintuitive, this reaction is demonstrably false. 


Putting the causal story into context 


         The right reaction, I propose, is to say this. To have a concept of an object is not just to know the truth of some claim of the form something uniquely has phi that x satisfies. This is part of the story, but not the whole of it. The existence-claim in question must be such that in virtue of knowing it, one is able to integrate the verifier of that claim into one’s cognitive map of the world.  It is not the case that, in virtue of knowing (**), Jones has the kind of information about that thing that would enable him to integrate Smith into his cognitive map. That is why a knowledge of (**) does not give one a concept of Smith. It is the case that, in virtue of knowing (*) (or the relevant occurrence thereof), Jones has the kind of information about that thing that would enable him to integrate Smith into his cognitive map. That is why a knowledge of (*) does give one a concept of Smith.
      xxx In general, for x to have a concept of y is for x to know the truth of some existence claim E such that (i) y uniquely satisfies E and that (ii) x’s knowing E involves his being embedded in a certain kind of causal relationship with y and, finally, such that (iii) in virtue of knowing E, x is able to assign a location to y in his “cognitive map.”
       
How this analysis applies to objects that are not directly known through sense-perception


     Of course, there are cases where x’s concept of y is not derived from a perception of y itself. Consider my concept of Socrates. By itself, that concept gives me no information about Socrates’ spatiotemporal co-ordinates relative to me. So, by itself, that concept doesn’t tell me how Socrates fits into my cognitive map. 
         But this does not ultimately pose any problem for our analysis of conception. Suppose that my concept of Socrates consists in my knowing existence claim E*. For reasons we discussed in Chapter 3, E* will be such that, in virtue of my knowing it, I will be in a specific sort of causal relation to Socrates. I will be at the receiving end of what some philosophers refer to as an “information-transmitting”[85] sequence S beginning with Socrates and ending with myself. So even though my knowledge of E* does not by itself enable me to integrate Socrates into my cognitive map, in virtue of knowing E*, I nonetheless have the information I need to effect that integration. Because my knowing that description involves my being in a very specific sort of causal relation to Socrates – albeit one that may be very long and circuitous – my knowing that description puts me in a position to integrate Socrates into my cognitive map. 
       So, after a fashion, Kaplan (1968), Dretske (1982), and Fodor (1990) are right. To have a concept of Socrates, I do need to be at the end of a certain kind of causal process that begins with Socrates. But contrary to what Fodor holds, this is because my concept of Socrates consists in knowing some existence-claim E such that, first, Socrates uniquely satisfies E and such that, second, in virtue of knowing E, I am causally connected (in the just mentioned way) with Socrates. So my causal connection with Socrates is a mere constituent of my concept of him. My having that connection is a pre-condition for my grasping a certain description that Socrates satisfies; and my concept of Socrates is identical with my knowledge of that description, and not with that causal connection. The reason why a causal connection is necessary is that, without it, I cannot integrate any descriptive knowledge that I have of Socrates into my “cognitive map” of the world. Let me now define that term: the motivation for much of what was just said will emerge in the process of giving that definition.


The concept of a cognitive map 


       By a “cognitive map”, I am not referring to a theoretical distillation of scientific findings concerning the locations of individuals in the space-time manifold. Every creature having a minimum of cognitive sophistication – every creature capable of perception and action – is able to orient itself with respect to other individuals in its immediate environment, and is thus able to represent objects and states of affairs as having locations, in both space and time, relative to itself.[86] This ability is not the result of empirical inquiry. Rather, it is a pre-condition for such inquiry. Indeed, it is hardly distinguishable from a creature’s ability to have the perceptions through which empirical knowledge is acquired. Since the cognitive processes mediating perception are sub-personal, the same is true of the cognitive map in question. 
       There is a marked difference between, on the one hand, the cognitive maps that underlie our most basic dealings with the world and, on the other hand, the maps that cartographers and astronomers produce. Consider a map of the surface of the Earth. If that map is to give you any information, you must be able to correlate some item on that map with some location that is given to you directly. You must be able to have a thought of the form “this place [referring to the place one is occupying] is there on the map” (Evans 1982: Chapter 6). 
      In general, to interpret a map, you need some kind of a reference-point in your own perceptual experience. You need to have some independent grasp of at least one of the places represented by the map. Otherwise the map gives you, at most, the locations of the items depicted on it with respect to each other, but not with respect to you. And in that case, of course, the “map” in question isn’t a map at all, at least not from your viewpoint, since it cannot tell you where you are on the map. 
       So to understand any map – even one of the kind that cartographers and astronomers produce – you must be able to correlate at least some point on that with an indexical or “egocentric” understanding of your own. 
       Nonetheless, the maps of cartographers are fundamentally different from your cognitive map. The difference is that, notwithstanding what we just said, the former are fundamentally non-egocentric, whereas the latter is fundamentally egocentric. As long as you can correlate your present location with some point on (say) a map of the Earth’s surface, you will have no trouble understanding the map, and it is irrelevant which point that happens to be. Suppose you point to the dot that represents Topeka. If, while pointing to that dot, you can truthfully say “I am there”, then you are in a position to understand the map. Now replace the occurrence of “Topeka” in the statement just made with the name of any other place represented on the map. The point just made goes through. So while it is true that, in order to understand the map, you must relate it to a place that is given to you in egocentric terms, nonetheless the map itself does not have an egocentric character. The objective, non-egocentric character of the map is expressed in the fact that any place represented by that map will serve just as well as any other as a reference-point.
        In light of this point, consider some arbitrary map M with the following property. Suppose there is some place L such that, in order to understand M, L specifically must be your reference point. In that case, M distorts the mutual relations of the places depicted by it. More generally, to that extent some places on a map are better reference-points than others – to the extent that certain places on it more privileged than others -- that map misrepresents the relevant geographical area.
        A personal anecdote may help to bring out my meaning. I once owned a coffee-mug that said on it “A Washington D.C. resident’s map of the world.” Beneath the caption was a large picture of the Washington Monument, a smaller picture of the Empire state building, a tiny picture of the Eiffel Tower, a miniscule picture of the Taj Mahal, and so on. Of course, that map is not a good one. The reason is that, for that map to be at all useful to you, there is some one location L on the map such that you must be able to correlate your location with L. If you cannot correlate your actual position (the position referred to an utterance of yours of “this place” or “here”) with the part of the map depicting Washington D.C., then that map gives you little or no geographical information.     
      Of course, the maps produced by cartographers and astronomers are not like this. (At least not in so far as those maps are good ones. To simplify exposition, we will suppose that cartographers and astronomers produce good maps.) So the maps that cartographers and astronomers produce are, in an important sense, non-egocentric. Given such a map, there is no one point L on that map such that to understand that map, one must able to think truthfully, while pointing to L:  I am there. Such a map is egocentric only in the trivial sense that one must be able to truthfully think: I am there while pointing to some point or other on that map – any point will do.[87] 
     What we just said about a cartographer’s map is true, though usually to a lesser extent, of the body of geographical (and, more generally, spatiotemporal) knowledge that a cognitively normal person develops throughout one’s lifetime. One develops a map of the world, and to a lesser extent of the universe, that is objective, in the sense just described. 
        But what we just said about a cartographer’s map is not true of the cognitive maps the underlie perception and action. Those maps are fundamentally egocentric. Where such maps are concerned, there is only one viable reference-point. 
      Your current visual perception represents the locations and mutual spatial relations of various objects. It represents the place that is occupied by the star you are seeing, as well as the places occupied by the cactus, the horse,  and the barn; and that perception tells you (or tries to tell you) how they are spatially interrelated. Your perception is an ideographic representation of places, and is thus a kind of map. 
      But where that visual map is concerned, there is a privileged reference-point. There is some point p on that map such that ceteris paribus that map’s information about place x is more accurate than its information about place y exactly if, on the map, x is closer than y to p. This confirms what we said a moment ago: the cognitive maps embodied in one’s perceptual experience have a fundamentally egocentric character. 
         Of course, that cognitive map is a precondition for one’s acquiring empirical information and thus, in particular, for one’s creating non-egocentric maps of the sort discussed a moment ago. So the latter, non-egocentric maps have a relatively superficial place in our dealings with the world, whereas the egocentric maps associated with perception nearly enough are the cognitive apparatus through which we learn about, and orient ourselves with respect to, external reality. 
         Let us deal with an objection to this analysis: 


Suppose that  Smith is the person who satisfies the claim: 


(****) At 3:34 p.m. in the year 2323 A.D, somebody will be exactly one person wearing a hat at location L at 3:34 p.m., 2323 A.D.,  


for some given highly specific value of L. In the year 2006, Jones knows that (****) is true (let us set aside the question how he knows this), and Jones doesn’t does not know the truth of any other existence-claim that Smith satisfies. 
    In virtue of knowing (****), Jones has knowledge that would give him a maximally precise fix on the spatiotemporal location of some object and that, if the analysis just proposed is correct, would thus seem to qualify as a concept of Smith in the most robust sense possible. But under the circumstances, we would say Jones has no concept of Smith.[88] So, it would appear, your analysis falsely predicts that, under the circumstances described, Jones does have a concept Smith.  


         It is true that, in virtue of knowing the truth of (****), Jones has knowledge that would give him a maximally precise fix on the spatiotemporal location of Smith. But it is relative to the non-egocentric maps created by cartographers that Jones’ knowledge of (****) would give him this information. It is not relative to the egocentric map that is fundamental to our cognitive dealings with the world. Our analysis says that knowledge of (****) constitutes a concept of Smith only if, in virtue of having that knowledge, one can integrate Smith into one’s cognitive map. So this objection misses the mark. 
       
Why the causal story, rightly understood, does not help content-externalism 


      We’ve seen that, in at least some cases, a causal connection between x and y is integral to x’s concept of y. This might be seen as giving credibility to content-externalism. But this would not be the right reaction to have.     
     Suppose that, on some occasion, Jones sees Smith and, strictly on that basis, forms a concept of him. Let C be that concept. C is as clear-cut and extreme a case as there is to be found of a concept’s having a causal component; from a content-externalist’s viewpoint, C is a paradigm. Even in a situation where Smith doesn’t exist, Jones could have a mental state that is identical with C in respect of content and (what follows) in respect of causal properties. Jones could have C even if Smith didn’t exist. 
       We’ve already seen why. The content of C does not have the form: Smith has phi. It has the form there is something x having such and such properties over in that place…So the content of C is not object-involving with respect to Smith. That content is given by an existence claim which, under the circumstances, Smith uniquely satisfies. There is thus no reason why C couldn’t exist even if Smith didn’t. So even though, in virtue of having C, Jones is causally connected to Smith in a very specific way, C consists in Smith’s having knowledge of a description that Jones uniquely satisfies and that is not object-involving with respect to Jones. Of course, the kind of concept that, in the story just told, Smith has of Jones is, for content-externalist, a paradigm-case of a concept. So the falsity of content-externalism is evident even when we consider the concepts that best conform to its analysis. 
       
Chapter 7 Concepts as knowledge of series of interlocking existence-claims


         Our analysis of conception must be extended if it is to be entirely accurate. To see why it is inaccurate, and to see how to eliminate those inaccuracies, we need do little more than briefly revisit some points made earlier. 
      I meet Fred at a party. The existence-claim through which I initially lock onto him is (let us suppose): 


(1) there is somebody x over there standing next to the fire-place…


As a matter of psychological fact, people typically forget the existence-claims through which they initially lock onto objects. Second, even when do remember them, that memory is not capable of sustaining that cognitive lock-on. The next day, when I think about Fred, I obviously don’t do so by thinking (1). To think about Fred, I don’t have to be near somebody standing next to a fire-place, wearing a chalk-stripe suit, and so on. So (1) must be replaced with some other existence-claim, for example: 


(2) There was somebody x such that x is uniquely such that x was standing next a certain fire-place…


      Thus, for reasons of a strictly logical nature, the existence claim through which I  access Bob must change. The changes in question merely register the change in my chronological perspective, so to speak, on Fred – just as the changes in the sensory image through which I see the house register the changes in my spatial perspective on the house.[89] 
      There is another reason why one’s ability to think about x involves dropping certain existence claims and replacing them with others. As we discussed, one typically forgets the existence claim through which one initially accesses an object. I have absolutely no recollection my first encounter with my friend Larry or of the lamp I am now seeing. 
      As we saw earlier, one’s having a concept of an object involves having knowledge of a series of interlocking existence-claims. One’s knowledge of a given existence-claim can be dropped without destroying the concept, so long as that knowledge is replaced by knowledge of a new existence-claim that interlocks appropriately with the first. Here is an example. I meet Fred by learning the truth of (1). A few days pass, and my knowledge of (1) has thus been replaced with a knowledge of (2). I then see Fred and recognize him on the basis of this knowledge. This time Fred is wearing a loud sportcoat and an oversized bow-tie. So he is given to me through some existence claim like: 


(3) there is some individual x such that x is uniquely someone over there who is  wearing a loud sportcoat and an oversized bow-tie, and x is talking about current econometric theories…


Now that I can access Fred through (3), I can drop my knowledge of (2). 
       Here is where we must go beyond what we have previously said about concepts. We don’t want to say that I used to have one concept of Fred, and I now have a different one. Thus, we don’t want to say that my concept of Fred used to be identical with a knowledge of (2) and is now identical with a knowledge of (3). Such a view simply wouldn’t be true to our way of speaking. It would be like saying that I am not literally identical with the person I was yesterday, since I am now wearing different clothes. The concept I now have of Fred is numerically identical with the concept I had of him a few days ago. So, strictly speaking, a concept is not identical with knowledge of a uniquely individuating description of the sort previously described. 
       To have a concept of x is to have knowledge of a series of existence claims E1…En such that, for each i,  x uniquely satisfies Ei  and such that Ei+1 interlocks, in the way previously described, with Ei. In fact, even this is really only an approximation. To produce a more precise analysis of conception, we must begin to state the qualifications to which the analysis just proposed is subject. 
        First of all, as we’ve stressed, the relevant existence-claims cannot merely be such that they are satisfied uniquely by x. They must be such that, for each i, in virtue of knowing Ei, one has the kind of uniquely individuating knowledge that enables one to integrate x into one’s “cognitive map.” As we’ve seen, this means that, in virtue of knowing Ei, one has a mental state that is caused, in a rather specific way, by x (or, more accurately, some state of affairs comprising x). 
     Second, it obviously isn’t necessary that there be any time at which the subject knows all of E1…En. The whole point of our analysis is to accommodate the fact that one can know all but one of them while still having a concept of x. In light of these points, a more correct statement of our analysis of conception would be this: one has a concept of x at time t, iff there is some sequences of existence claims E1…En such that E1…En interlock in the way previously described; such that, at t, knows the truth of Ei, for some i; and, finally, such that, for each i, one’s knowledge of Ei arises, in the way previously described, out of a knowledge of Ei-1. 
      Here is the upshot of the last, rather difficult paragraph. A concept of x consists in one’s having “discriminating knowledge” of x, as Evans puts it. At any given point, such knowledge consists in knowing the truth of some existence claim of the sort earlier described. But any one’s knowledge of any given existence claim can, and probably will, be replaced with knowledge of another existence claim. The second existence claim will interlock with the first. This ensures that, even though there has been a change in the identity of the particular piece of knowledge through which one thinks about x, this change doesn’t create any sort of discontinuity within one’s concept of x. That concept evolves continuously, just as a person or a plant does. One’s concept of x is identical with, or at least supervenient on, a knowledge-stream of this sort. 


Frege’s paradox revisited


          Let us suppose that my concept of Fred begins with a knowledge of (1). And let us further suppose that this concept is sustained by my replacing my knowledge of (1) with a knowledge of (2), and by my eventually replacing my knowledge of (2) with a knowledge of (3), and so on. Let K1…Kn be the knowledge-series in question. (So K1 is my knowledge of 1, K2 is my knowledge of 2, and so on.) 
           Let us suppose that, one day, I meet a person in disguise. This person is in fact Fred, but I don’t know this. For many years hence, I keep on bumping into this disguised person. In fact, I form a friendship with him. I refer to him as “Barney.” Let K*1…K*n be the knowledge-series in question. So K*1 is my knowledge of some claim like: 


(1*) there is a unique person x over there wearing a strange disguise…


And K*2 is my knowledge of some claim that appropriately interlocks with K*1, for example: 


(2*) There is a unique person x such that I met x a week ago and x was wearing a strange disguise….


So in this case, there is some x (namely Fred), such that two different knowledge-streams enable me to think about x. That explains why, under the circumstances, I have two different concepts of Fred. 
    Of course, these two streams could converge. This would happen if I learned the truth of some existence claim Kn+1 that interlocked with both Kn and K*n. Here is an illustration. Suppose that, during my last encounter with “Barney”, he is given to me through the claim: 


K*n: there is some man x such that I’ve known x for several years and such that x is standing in front of me and is peeling off the odd mask he’s always worn over the years. 


And suppose that, during my last encounter with “Fred”, he is given to me through the claim: 


Kn: There is some man x such that I’ve known x for several years and such that x is standing in front of me and x has just peeled off the odd mask he’s always worn over the years, and x looks exactly like the person y I’ve referred to as “Fred” all these years and (because I know on independent grounds that nobody other than Fred looks anything like him) therefore is y. 


 In that case, Kn+1 will be along the lines of: 


Kn+1: There is some x such that x is standing in front of me and x is the person I’ve known as “Fred” all these years, and is also the person the person I’ve known as “Barney” all these years. 


So the two knowledge-streams that we’ve been discussing – namely, K1…Kn and K*1…K*n – converge in Kn+1. Recognition of the truth that would be expressed by a statement like “Fred=Barney” (or “Hesperus=Phosphorous”). 
      Of course, the sentences “Fred=Barney” and “Hesperus=Phosphorous” have for the literal meanings bare and trivial propositions of the form x=x. But here we are talking about the recognitions that would be associated, albeit non-semantically, with such utterances. We’ve already explained the nature of that association.  


Conception versus identification 


      We’ve seen that, in order to be able to think about x, one must be able to cognitively single x out, and this involves having “discriminating knowledge” of x, to borrow an expression of Gareth Evans. But having such knowledge is different from knowing x’s identity. I can have a concept of x without knowing who or what x is. Evans made this point clearly. Let us assimilate that point into the structure constituted by our analysis.  
        Suppose that, for five years, I live next a man whom I know as “Bob.” I am on good terms with Bob, and we occasionally have an amicable cup of coffee together. During such get-togethers, we exchange no substantive information, and I thus learn little about Bob.
         One day I am at the beach with a friend, and I see Bob. Pointing to Bob, my companion asks me “do you know who that person is?” In this context, the answer is “yes.” I recognize the man at the beach as my next door neighbor. 
         But a few weeks later, two stern-faced F.B.I. agents come to my door. They aggressively tell me that “Bob” is the head of the world’s largest drug-cartel and that he has also been selling weapons to various para-military organizations around the world. Of course, I didn’t know any of this, and I want to make it clear to the agents that I had no part in Bob’s malfeasance. So I say “I had no idea who he was.” 
       In saying this, I am telling the truth. I really had no idea who my next door neighbor was; I had no idea that he was such a evil-doer. So there is some x such that I am truthfully telling the F.B.I. agents that I do not know who x is. But how can this be? After all, when I was at the beach I truthfully said, pointing to Bob, “yes, I know who that is.” So, in that context, there is some y such that I am  truthfully telling my companion that I do know who x is.  The problem is that x is identical with y. So it would seem to follow there is some object z such that I do know who z is, and such that it is not the case that I know who z is. A paradox. 
       But there is no paradox. There is some x such that what I am telling the agents is that I had no that x was involved in these heinous enterprises. So there is some x such that I am telling the agents that I have no idea that x satisfies the description unique thing y such that y heads the  world’s largest  drug-cartel and y gives weapons to para-military organizations…And there is some y such that I telling my companion at the beach that I know that y has various properties – that y satisfies the description unique thing w such that w lives in the house to the immediate left of my house…
           The sentence “I know who x is” can be true in one context and false in another. This is because, in any context where it is appropriate to ask “do you know who x is?”, there is some description D such that, in that context, “I know who x is” means I know that x uniquely satisfies D; and given two different contexts, the description that is relevant to the one context may be different from the description that is relevant to the other. When I am talking with the agents, the relevant description is unique head of the world’s largest drug-cartel…When I  am talking with my companion at the beach, the relevant description is unique person who lives in the house to the left of mine… The concept of knowing-who (or knowing-what) is contextual. 
       But this brings us to a fundamental point. In each of the cases just discussed, my knowing who Bob is presupposes my having some concept of him. A pre-condition for my  recognizing the man at the beach is that I already have a concept of him. (You cannot recognize what you cannot already cognize.) I can fail to know of my kindly neighbor that he is a crime lord only because I can already have thoughts about him. So being able to have thoughts about x is different from knowing who or what x is, even after we allow for the contextual nature of the latter relation. Thus the discriminative knowledge discussed a moment ago – the knowledge needed to grasp singular propositions of the form x has phi -- is prior to a knowledge of x’s identity. 
         
Chapter 8 The problem of de re senses 


      Now we must broach a nest of issues relating to Gareth Evans’ important work on conception. Up to a point, Evans’ system coincides with ours. Evans is careful to distinguish semantics from epistemology. He is a direct reference theorist. In his view, there is some x such that “Socrates was bald” encodes the singular proposition x was bald. Like us, Evans believes that, at the level of semantics, “Socrates” is completely non-descriptive and is a mere label.
       At the same time, Evans is very aware that this singular proposition cannot be grasped in a vacuum – that it must be grasped through other information. He is aware this intermediary information is replete with descriptive content. In this respect, his system coincides with ours.
       There are other important similarities between our system and Evans’. Like us, Evans rejects the idea that conception can be understood in strictly causal terms. So he rejects the idea, advocated by Fodor, that concepts are related to their objects in more or less the same way that the discolorations on a photographic plate are related to the events that caused those discolorations. He thus rejects what he aptly refers to as “the photograph model” of conception.[90] 
        Like us, Evans believes that for x to have a concept of y (where y is a spatiotemporal individual) is to have knowledge of a certain kind. In Evans’ view, x must have “uniquely discriminating knowledge” of y. This means that x must know of at least one respect in which y is different from all other individuals. 
          But, at this point, Evans’ system diverges from ours in a number of important respects. First, according to Evans, it is not generally true that x’s having a concept of y consists in x’s having knowledge of such an existence claim. Evans concedes that, in some cases, this is what conception consists in. But he does not think that it always, of even generally, consists in this. 
        So Evans agrees with us that x’s having a concept of y consists in x’s being able to cognitively y distinguish from all other individuals. But Evans thinks that this ability does not, at least not as a rule, consist in x’s knowing some existence claim that y uniquely satisfies. 


Evans’ argument 


         Why does Evans think that, in general, a concept of y does not consist of knowledge of an existence claim that y uniquely satisfies? 
         First of all, he believes that demonstrative identification is not a kind of descriptive identification. His reasoning is best introduced through a bit of fiction. I am looking at Smith, and I am not looking at any other person. Prior to this, I had no concept of Smith. I am thus acquiring a concept of Smith from this perception. At this time, Smith is the sole person who is .00000565 light-years from me. Even though Smith satisfies the existence claim there some somebody x such that, at time t, x is .00000565 light-years from JM, I obviously don’t think of Smith in those terms – nothing having to do with light-years is any part of my concept of Smith. 
       Of course, Smith’s being that distance from me is an important fact about my concept of Smith; it is an important fact about my acquisition of that concept. But that fact isn’t represented within my concept, at least not in the sense that my concept incorporates knowledge of some existence claim describing that fact. 
         So, Evans concludes, when we distinguish facts about our concepts from facts about what is represented within them, we see that there is no warrant for a descriptivist analysis of concepts acquired through demonstrative identification. [91] 


Evaluating Evans’ argument 


          Obviously the basic distinction Evans is making is correct. Not every fact about a concept is represented within that concept. (My having a concept of Napoleon involves many facts involving electrons. But the concept electron is no part of the content of that concept.) 
         But Evans’ application of this truth seems incorrect. Look at some object – at (say) some tree in your vicinity. So far as it can be expressed in language, the content of that perception is not, as we’ve seen, given by any noun-phrase; it isn’t given by “a tree” or “that tree” or anything of the sort. So far as it can be put in words, that content is given by a sentence; and that sentence is existential in character. 
      We have seen that, in general, our perceptions make us aware of objects by apprising us of existence-claims that those objects satisfy. Given this fact, Evans’ argument immediately implodes. As we will now see, this fact also undermines some important component of Evans’ analysis of conception. 


Evans-style pseudo-thoughts


         Evans says that demonstrative-thoughts – the thoughts that prompt one to produce sentence-tokens like “that tree over there is lovely” and “you are a scoundrel” – are “Russellian” with respect to the objects that are demonstratively identified. (In this context, “thought” means “cognitive episode”, not “proposition.”) 
       What does this mean? It means that the content of the thought behind an utterance of “you are a scoundrel” that is addressed to Smith has Smith as a constituent, the same being true mutatis mutandis of the thoughts behind “that tree is lovely” and all other non-empty utterances containing demonstrative expressions. (By a “non-empty” utterance, I mean one that doesn’t contain any terms that are supposed to have a referent but don’t in fact have one, e.g. an occurrence of “that man over there” in a context where there is no man in the place in question.)
         Here it is important to make a distinction. We have argued that Smith himself is a constituent of the literal meaning of an utterance of “you are a scoundrel” that is addressed to him. Evans agrees with us about that. But we have also argued that Smith is not a constituent of the content of any thought that you have. Evans sharply disagrees with us about that. He is saying that, under the circumstances just described, Smith himself is a constituent of the content of a thought of yours. On the basis of this view, Evans draws an extraordinary and, I will argue, false view about mental representation. 
          Suppose you are looking at Smith and are thinking the thought that, under those circumstances, would lie behind an utterance of yours of: “that guy is tall.” Let T be that thought, and let S  be the situation just described. (T is not meant to be the proposition that is semantically encoded in an utterance that you would make in S. T is the thought behind such an utterance.)
         Now consider a hypothetical situation S* that is qualitatively just like S except that, in S*, you are hallucinating, and there is no man in the place at which you are looking. So in S*, you aren’t seeing Smith. Apart from some air molecules, the relevant part of space is completely empty. 
      According to Evans, in S*, you don’t have T. So, in S*, your mental state (leaving aside facts about its external causes) is just like your mental state in S 666, but in S you are having T, whereas in S* are not. So T is “Russellian” with respect to Smith: in any scenario where Smith doesn’t exist, T doesn’t either (Evans 1982: Chapter 6). Of course, in saying this, Evans is just being a garden-variety content-externalist. But he goes a step further.  
      According to Evans, there is a respect 666 in which, in S*, you are having no thought at all. In S*, there is a kind of cognitive blank where, in S, T would be (Evans 1982: Chapter 6). So in S*, you wrongly think that you are having a certain thought that you simply aren’t having. At the same time, you have exactly the same psychological properties in S* that you have in S.  
        This claim of Evans’ must be qualified if it is to have any plausibility. There is no denying that, in S*, you are having some kind of thought. You are having a visual experience that tells you, albeit falsely, that there is a man over in a certain place. If you didn’t have such an experience, then you wouldn’t be hallucinating; if a person doesn’t have perceptual experiences that tell him false things about the world around him, then he is not hallucinating at all. So if the claim of Evans’ that we identified in the last paragraph is to avoid being straightforwardly false, we must hedge it. What we must say is (at least approximately) this: 


(EVS) In S*, you are, in having your (hallucinatory) visual experience, having many thoughts. But, in S*, there is a kind of cognitive place, so to speak, where there is a blank or gap in your thoughts – a cognitive place that, in S, is filled with T. 




     In fact, (EVS) is Evans’ own position. But (EVS) is false. We’ve seen the reasons for this many times, and we don’t need to repeat them. 
      Given any situation where Evans would contend that a given thought is Russellian with respect to external object x, an argument exactly similar to the one just given shows that this contention is erroneous. We may conclude  that, contrary to what Evans says, demonstrative thoughts are not Russellian, even though demonstrative utterances are Russellian. 


Evans-style Russellian thoughts 


         Let us now discuss a corollary of Evans’ view. Let S** be a situation that is just like S except that, in S**, it is Brown you are seeing, not Smith. (So, in S**, you are not hallucinating.) Of course, given how we’ve set things up, it follows that, in S**, Brown appears to you in exactly the way in which, in S, Smith appears to you.
       Here is Evans* view. There is some thought T** such that, in S**, you are having T** and such that, in S, you are not having T**, where T** is a thought that is Russellian with respect to Brown. 
        For reasons exactly similar to those given in connection with S*, Evans’ view here is false. There is no thought that you are having in S** that you are not also having in S and also in S*.
         Why does Evans believe that demonstrative thoughts are Russellian? His argument is simple. Suppose you point to Smith and say “that guy is tall.” Let t be this utterance. Let us now state Evans’ premises. 


Premise 1: For various reasons, we know that the proposition semantically encoded in t is simply: Smith is tall. 


Premise  2: Obviously people can understand t. 


Premise 3: Understanding t consists in knowing which proposition it expresses. Knowing this involves grasping that proposition. So there is some proposition P such that you understand t only if you grasp P. 
     
Premise 4:   P is the proposition that one has in mind when looking at Smith and thinking of him that he is tall, i.e. P is the proposition that is the content of demonstrative-thoughts that one has when the relevant demonstratum is Smith.


Two things follow from these premises. First, Smith is a constituent of P; in other words, P is object-involving with respect to Smith. Second, the demonstrative-thought behind t is Russellian with respect to Smith. Of course, what we said of that thought is true of every demonstrative thought. (In the foregoing argument, t may be replaced with any token t* of a demonstrative-utterance, so long as the demonstrative in t* is not empty.) 
       Let us evaluate this argument. First of all, it is valid. Given premises 1-4, Evans’ conclusion follows. Further, the first two premises are obviously correct. The problem lies in the other two premises. Premise 4 is false. Premise 3 is ambiguous, and the argument fails on the relevant disambiguation. 
      We’ve seen why premise 4 is false. Let P* be the proposition that lies behind your utterance of t. So P* is a proposition that you grasp, and your grasp of P* is what motivates you to utter t. We’ve seen that P* is not a singular proposition of the form x is tall, and that P* doesn’t have Smith as a constituent. P* is some existential proposition that Smith satisfies, but of which he is not a constituent. 
       There is undoubtedly some sense in which premise 3 is true. But that premise is ambiguous. The reason is that, given any utterance, there are two different things it could mean to say that so and so “knows which” proposition is meant by that utterance.  This ambiguity corresponds to the distinction between knowledge by acquaintance and knowledge by description. Understanding a sentence-token  always involves having some kind of knowledge of the proposition which it encodes. But more often than not, that knowledge is knowledge by description, not knowledge by acquaintance. 
      Let Green be an arbitrary person. We’ve seen, time and time again, that if O is a constituent of the external world, Green can’t just think O. He can think about O only by way of his knowledge that some existence claim E is uniquely satisfied. (Of course, O must be the thing that satisfies E.) In Green’s case, let something x has psi be the relevant existence claim. So Green grasps O by knowing that something uniquely satisfies the claim something x has psi. In other words, Green grasps O by knowing the truth of the claim: something x uniquely has psi. 
       So far as Green can grasp the proposition O has phi, his grasping that proposition involves his grasping an existence claim. This clearly follows from what we was said in the last paragraph. It also clearly follows this claim will be: 


(#) Something x uniquely has psi, and x also has phi. 


       Thus, in so far as Green grasps the singular proposition O has phi, he grasps it by grasping some non-singular existence claim – some existence-claim that doesn’t presuppose O’s existence. At the same time, there is a clear sense in which (#) singles out or describes the relevant proposition. So there is a sense in which somebody who knows the truth of (#) grasps O has phi. 
      Given any true existence claim, the truth of that claim supervenes on the truth of some singular proposition. We might describe the latter as the “truth-maker” of the former. (This is consistent with our earlier use of this terminology.) O has phi is the unique truth-maker of (#). So somebody who recognizes the truth of (#) is thereby grasping, and also recognizing the truth of, (#). The sense in which such a person recognizes the truth of (#) is identical with the sense in which one recognizes the truth of some proposition about Socrates if one believes the proposition: somebody or other was a greatest philosopher to die of hemlock poisoning, and any such person believed in the existence of abstract objects. So there is a clear sense in which one can believe a proposition to be true without grasping exactly that proposition. Grasping a proposition involves singling it out. If one knows a proposition by description, one has singled it out. Thus, one needn’t be acquainted with a proposition to single it out.
        Let t# be an utterance of “that thing is green”, where t#  is accompanied by an ostension of O. The proposition encoded in t# is O is green. It is a datum that people can understand t# . Finally, it is a datum that this consists, at least in part, in associating that utterance with the right proposition. (So Green understands t# only because he can associate it with the right proposition.) Evans is right about all of this. 
      But Evans is wrong to think that understanding t# consists in being acquainted with O is green and then associating it with t#. It is possible to be acquainted with that proposition. It can only be known by description. 
      Here we need to head off a possible confusion. We saw earlier (in Chapter 3) that there is a descriptive proposition P such that one can be acquainted with P such that P is true iff O is green is true. Given this, it might seem that one can be acquainted with propositions that are object-involving with respect O. But, as we saw, P is not such that its existence presupposes that of O; and, consequently, it would be possible to grasp P even if O didn’t exist. So while it is true that understanding t# consists in associating it with its meaning, and while its truth this meaning is O has phi, one grasps this meaning, and effects this association, by way of some existence claim – by way of some claim that is not singular with respect to O. Evans’ argument is therefore fallacious. 


Evans-style cognitive hallucinations 


           A related position of Evans’ is similarly fallacious. Let W* be a world where Descartes never existed, but that is otherwise just like our world. So your condition in W* at time t is identical with your condition in our world at t, at least in so far as this possible given that Descartes never existed in W*. Now consider any one of the various beliefs that you have in this world about Descartes – e.g. your belief that he was French. Evans’ holds that, in W*, you simply cannot have that thought. So far as, in this world, your thoughts concern Descartes, you simply fail to have thoughts in W*.  So far as a mental event of yours in this world concerns Descartes, the corresponding mental event in W* fails to constitute a thought. 
          Of course, from a psychologist’s standpoint there would be no difference between those events (unless you implausibly hold that, in order to psychoanalyze someone, you need to know facts about early modern French history). Whatever intelligence, and xxx whatever neuroses or psychoses, were implicated in the one the one case would be equally implicated in the other. But, according to Evans, one of those mental events would be a thought, whereas the other would not. 
            Evans would not disagree with our contention that, from a psychologist’s viewpoint, your situation in W* would not (in virtue of Descartes’ non-existence there) be different from your situation here.[92] His position seems to be the category thought is not a psychological category. (This brings us an interesting general fact about content-externalist: it makes facts about representational content be causally, and therefore psychologically, irrelevant.[93] We will explore this in the next section.)
        Why does Evans hold that, for each Descartes-thought that you have in this world, you are shooting a blank – failing to think anything – in W*, even though your psychological condition here is identical with your condition there?  
         Evans’ argument for this is similar to the argument that he gives in connection with demonstrative-thoughts (here is a summary): 


Let t be an utterance of  “Descartes was French.” We know that, for some x, t’s literal meaning is the singular proposition x was French. (x is Descartes, of course.) Obviously people can understand t. Understanding t consists in associating it with the proposition that it means. Making this association involves grasping that proposition, i.e. in grasping x was French, for the appropriate x. A person who lives in a world where x exists, and who grasps the singular proposition x was French, may be psychologically identical with somebody who lives in a world where x doesn’t exist and who, consequently, doesn’t grasp that proposition. So those people are psychologically identical, even though one has a thought that the other does not. Xxx Counterintuitive though this conclusion may be, there is no way to circumvent it, given what it is to understand utterances like “Descartes was French.” 


  
       The truth is that there is a way to circumvent that counterintuitive xxx and (so I have argued) incoherent conclusion. As we saw in Chapter 3, one thinks about Descartes through the right kind of uniquely individuating description. And, as we also saw, this is perfectly consistent with direct-reference-theory, contrary to what has been widely been assumed.[94]
        
Psychology versus epistemology


      Our discussion of Evans brings to light an incoherence that lies at the center of content-externalism. 
        Let B be the brain-state or pattern of neural stimulation that realizes your belief that 13 is a prime number. In virtue of being such a belief, B has certain causal powers. For example, it has the power to generate a belief on your part that there is a prime number greater than ten. It is thus a matter of empirical fact that, in virtue of its having a certain content and thus in virtue of its being a thought of a certain kind, B has certain psychological properties that it would not otherwise have. Given this, it is not an option to deny that, in virtue of being a thought, B is a certain kind of component of one’s psyche. 
        It would be deeply implausible to say that my belief that 13 is prime is object-dependent with respect to some constituent of the external world. Surely a brain in a vat that was just like mine would be capable of having arithmetical thoughts. Surely an envatted brain that was an atom-for-atom duplicate of Gauss’s brain would have at least some mathematical intelligence, and would therefore be able to grasp mathematical truths. There thus doesn’t seem to be any possibility of there being a pseudo-thought that was psychologically just like my actual thought that 13 is prime; and this, for the reasons given a moment ago, means that content is causally potent, at least in some cases. 
      But, as Stich (1978) says, it seems deeply arbitrary to suppose that content sometimes has causal powers and sometimes doesn’t. That would be like saying that water is sometimes H2O and sometimes isn’t. Content-externalism is guilty of exactly this form of arbitrariness, given that content-externalism sometimes robs content of causal potency, and given that content at least sometimes has causal powers. 
      A content-externalist could give the following response to this: 


      You say that content is always potent if it is ever potent. But this is far from self-evident. Here is what I would propose, in light of the facts that you cited a moment ago. It is sometimes, but not always, the case that in virtue of having representational content, something x has causal powers that it wouldn’t otherwise have. In virtue of being a belief that 13 is prime, something x falls into a certain psychological category. But it is not the case that, in virtue of being a belief that Alpha Centauri is lovely, something x falls into a psychological category. 
       The motivation for this view would be as follows.  Let t be some Alpha Centauri-thought of yours. (So t is object-involving with respect to Alpha Centauri.) No thought with t’s exact content can occur in a world Alpha Centauri doesn’t exist. But in such a world, you could still have a thought t* that was causally just like t. The differences in content – the differences in respect of what kind of thoughts they were – between t and t* would thus be without causal or, therefore, psychological consequence. (After all, psychology is an empirical discipline, and psychological categories – like all categories employed in natural science – are causal.xxx) There would be no psychological differences between t and t*, even though they have different contents. 
    xxx So, to close the argument,  in some cases, a thing’s being a thought of a certain kind is psychologically pregnant, and in other cases it is not. In virtue of being a thought that 13 is prime, B falls into a certain psychological category that it wouldn’t otherwise fall into. But it is not the case that, in virtue of being a thought that Alpha Centauri is lovely, t falls into a certain psychological category that it wouldn’t otherwise fall into. Thus, xxx the property of being a thought sometimes is, and sometimes is not, a psychological property. 




          This view has an ad hoc quality. And there is no need to take it, since the data can be accommodated without it. We’ve already seen the reasons for this; but a brief review of those reasons may be appropriate.
        If one grasps Alpha Centauri, one does so by grasping some existence-claim that is available to be grasped in any world w, regardless of whether Alpha Centauri exists in w or not. Given any external object x, if one grasps x, one does so by way of some existential proposition that can be grasped in any world, regardless of whether x exists there or not. So we must consider the grasping of propositions of this kind – these purely qualitative, existential propositions -- when we wish to come to a conclusion as to what psychological properties a mental state has in virtue of having a certain content. 
        When we look at propositions of this kind, we discover the following important fact. In virtue of being a grasping of such a proposition, a mental state (or brain-state) does fall into this, as opposed that, psychological category. In other words, when we look at these propositions, we see that the property of being a thought of a certain kind is a psychological property – a property such that psychological explanation and classification is to be made in terms of it. 
      Let us put this more perspicuously. Let P and P* be any two proposition of the kind in question. (So P and P* are examples of the purely qualitative, existential propositions through which we grasp external objects.) xxx Suppose that P and P* are distinct propositions. In that case, we find that the psychological properties – the mental-causal properties --  that one has in virtue of grasping P are psychologically different from the psychological properties that one has in virtue of grasping P*. Now suppose that P and P* are identical. In that case, we find that the psychological properties that one has in virtue of grasping P are psychologically identical with the psychological properties that one has in virtue of grasping P*. 
       This is precisely what the externalist denies. Indeed, he denies it on two levels. First, as we saw earlier, the content-externalist is forced to say that, even if P and P* are different propositions, the psychological properties one has in virtue of grasping the one proposition may be indistinguishable from the psychological properties that one has in virtue of grasping the other. (To evade this, content-externalists have to take the tortured measure of saying that a correct psychological classification of a person’s mental states may involve knowledge of remote recesses of the cosmos.) 
        Second, the content-externalist is forced to make the following, equally counterintuitive claim. There are some propositions P of which the following is true. Two different people – say, Smith and Jones – both grasp P. But the psychological properties that Jones has in virtue of grasping P are different from the psychological properties that Smith has in  virtue of grasping P. 
        A short story will help make it clear why content-externalism is committed to this last claim. Apart from the differences about to be discussed, Smith and Jones are qualitatively identical. In the morning, Smith xxx sees Venus xxx and, in so doing, he acquires a concept of Venus. Of course, what Smith sees is a brightly lit object occupying a certain place in the morning sky. He forms the belief that the thing he is seeing is lovely. So, according to the externalist, there is some x, such that Smith now believes the singular proposition: x is lovely. 
        In the evening, Jones sees Venus xxx and, in so doing, he acquires a concept of Venus. Of course, what Jones sees is a dimply lit object occupying a certain place, different from the place just mentioned, in the evening sky. He forms the belief that the thing he is seeing is lovely. So, according to the externalist, there is some x, such that Jones now believes the singular proposition: x is lovely. 
       So, for some x, each of Jones and Smith believes the proposition: x is lovely. But it is obvious that Smith’s belief will be psychologically very different from Jones’ belief. In other words, those beliefs will differ in terms of their mental-causal properties (and also, for that matter, in terms of their garden variety causal properties). Supposing that both Smith and Jones are reasonably logical, Smith’s belief will lead him to believe that some object in the morning sky is lovely, even though the same is not true of Jones’ belief. Supposing that both Smith and Jones both have an ardent wish take a picture of a lovely object in the morning sky, Smith’s belief will lead him to form an intention to take such a picture, and will eventually lead him to buy a camera, and so on. Jones’ belief will lead to nothing comparable.
      So if content-externalism is right, then it appears that there is some proposition P such that the psychological properties that one person has in virtue of grasping P are entirely different from the psychological properties that some other person has in virtue of grasping that same proposition. 
       But this is incoherent, or at least close to incoherent. First of all, it violates the fact that (outside of the sub-atomic realm) qualitatively identical initial conditions lead to qualitatively identical outcomes – or, equivalently, that two initial conditions have qualitatively similar outcomes in so far as those conditions are qualitatively similar.  (Of course, this is, at least arguably, only approximately true. But the differences between Smith and Jones fall well outside the relevant margin of approximation.) 
        
Content-externalist 666  counter-responses


        Admittedly, the argument just given is less than probative; for the content-externalist has a compelling reply to it: 


       On the occasions described, Smith and Jones both form the singular belief x [Venus] is lovely. But that is not the end of the story. When Smith sees Venus, he not only forms the belief  x is lovely, but also various other beliefs, e.g. there is an object in a certain part of the morning sky having such and such color…And when Jones sees Venus, he not only forms the belief  x is lovely, but also various other beliefs, e.g. there is an object  in a certain part of the evening sky having such and such color…, where the color and the location just mentioned are different from the one’ s mentioned in the description of Smith’s belief. So contrary to what you said, the content-externalist is not in the position of having explain the differences between Smith and Jones in terms of some similarity between them – in terms of their both coming to believe x is lovely. For, in coming to believe that, they inevitably come to believe many other propositions, and the psychological differences between Smith and Jones are easily explained in terms of those other propositions. 


       First of all, in this passage, the content-externalist is really saying that nothing is to be explained in terms of the fact that Smith and Jones both grasp a certain singular proposition. The fact is, by the objector’s own admission, completely inert in terms of accounting for similarities or differences in their psychological or bodily properties. All of those differences are to be explained in existential-descriptive propositions, e.g. there is a lovely object in the evening sky…So there is no psychological, i.e. no mental-causal, expression of the supposed fact that either Smith or Brown comes to believe x is lovely. 
        Conceivably, a content-externalist might counter-reply as follows: 


 Consider the descriptive propositions in terms of which these differences are to be explained. Those descriptive propositions are themselves object-involving. For example, consider the proposition: there is a lovely object in that part of the sky…that proposition is object-involving with respect to a certain sky (a certain region of space). So you haven’t yet shown that a grasp of object-involving propositions is causally, and therefore, psychologically meaningless. 


       
       Yes, but an exact analogue the argument that we just ran with respect to x is lovely will apply to any singular proposition that is object-involving with respect to any external object. Consider the proposition: there is a lovely object in that part of the sky…Given a small amount of literary creativity, it is easy to hypothesize a scenario that demands that we say of that proposition exactly what we said of x is lovely. And in that second scenario, in order to explain the psychological differences between Smith and Brown, we will have to cite the fact that, on the relevant occasions, the sky was given to Brown in one way (i.e. via one descriptive content), whereas it was given to Brown in a very different way (i.e. via a different descriptive content). So, once again, when it comes time to explain the psychological differences between Smith and Brown, it is entirely irrelevant what singular propositions they come to believe concerning the external world. Those differences will have to be explained in terms of the fact that, on the relevant occasions, the one person did, whereas the other did not, come to believe in the truth of certain propositions that are not object-involving with respect to anything external. The differences will have to be explained in terms of the fact that they grasped different existential-descriptive propositions. If they grasped any propositions other than the purely descriptive one just stated, that fact is causally and explanatorily without consequence. Those other proposition-graspings, supposing that they exist, have no causal powers and no explanatory force. But this, of course, is tantamount to saying that those other proposition-graspings simply don’t exist. 
       Let us distill these points. The content-externalist has two choices. On the one hand, he can choose to be in the position of having to explain why two similar situations can lead to two disproportionately dissimilar situations. On the other hand, he can choose to say that, in some cases, one’s coming to believe something has absolutely no consequences at all in terms of that person’s psychology or, for that matter, in terms of any other portion of the spatio-temporal world. Of course, both options are incoherent, or nearly so. 
        
The notion of a de re sense 


     Given these points, we are in a position to evaluate some of Evans’ most important semantic and epistemological claims. Because these must be understood in terms of Frege’s (1892) semantic system, let us briefly review the relevant aspects of that system, along with our findings concerning it.
         “The inventor of bifocals is identical with the first post-master general” expresses something non-trivial, whereas  “The inventor of bifocals is identical with the inventor of bifocals” does not. Frege plausibly said that this is because definite descriptions have both sense and reference. 
        Frege held that the sense-reference distinction also applied to proper names. The sentence “Hesperus is Phosphorous” expresses something non-trivial, whereas the sentence “Hesperus is Hesperus” does not. Frege concluded that proper names, like (in his view) definite descriptions, have both sense and reference. 
       Kripke showed that Frege’s position is wrong as far as proper names are concerned. (We’ve also seen some reason to believe that it is wrong where definite descriptions are concerned.) Evans believes that Kripke’s arguments are cogent; so he believes that Frege’s analysis of “Socrates” and “Hesperus” is false. But Evans (1985: Chapter 7) believes that we could invent proper names with respect to which Frege’s analysis was correct. Evans holds that we could invent names – actual names, not quantifiers disguised as names -- that had, for at least part of the semantic content, Fregean senses. In connection with this, Evans’ argues there exist what McDowell would later refer to as “de re senses.” 
       On the basis of these semantic contentions, Evans’ puts forth a far-reaching and, if true, extremely important epistemological thesis, namely: there are de re modes of presentation. This thesis is a fusion of three different bodies of thought: first, Frege’s semantics and epistemology; second, Kripke’s work on proper names; and, third, content-externalism. 
           Here is what I now like to show. First, contrary to what Evans says, there cannot, even in principle, be proper names that have senses. The Fregean concept of sense is an incoherent amalgamation of semantics and epistemology. Evans’ belief that there are de re senses involves a similarly incoherent fusion of semantics and epistemology. But Evans’ view, unlike Frege’s, not only incoherently conflates semantics with epistemology: it conflates semantics with an epistemology that is itself incoherent. (Frege’s epistemology was not unlike that advocated in this work. Frege held that it is not objects per se that are the constituents of the propositions one grasps, but only senses or concepts of objects. That view, we have argued, is entirely correct. Frege’s projection of this view into his semantics – viz. names have senses, not objects, for their semantics contents – turned out to be false and, indeed, incoherent. ) 
       
 Evans’ argument for the existence of de re senses[95]


       Let us stipulate that “Julius” is to be defined as follows: 


(E1) If there is a unique thing x such that x invented the zipper, then “Julius” refers to x; and if nothing uniquely invented the zipper then “Julius” doesn’t refer at all. 
                
 So, by our stipulation, “Julius” is a referring term. At the same time, it obviously has a sense, this being the concept zipper-inventor (or perhaps unique zipper-inventor). On this basis, Evans arrives at two conclusions. 
        First, even though Frege was wrong with respect to actual proper names, the sense-reference distinction applies to invented proper names, such as “Julius.”[96] Second, there are de re senses.
       The idea behind the second claim is as follows. If somebody x uniquely invented the zipper, then “Julius was tall” is true exactly if x invented the zipper. In other words, given that x uniquely invented the zipper, the proposition encoded in that sentence is true in a world w exactly if x was tall in w. At the same time, as we saw in the last paragraph, “Julius” has a Fregean sense (unique zipper-inventor), and this Fregean sense is part of the proposition encoded in that sentence.  
       So, Evans concludes, if x uniquely invented the zipper, “Julius was tall” encodes a proposition that is object-involving with respect to x. At the same time, the reason why that proposition has x as a constituent is that it contains a concept that singles x out. For any predicate phi, an exactly similar line of thought shows that, if x uniquely invented the zipper, then ┌Julius has phi┐ encodes a proposition that has x as a constituent and that has x as a constituent because it comprises some concept that singles x out. 
         There is another fact about Evans’ proposal that must be pointed out. According to Evans, the proposition encoded in “Julius was tall” will vary from world to world. If Mary uniquely invented the zipper in w, then in w that sentence encodes a proposition that is true iff Mary invented the zipper. For this reason, says Evans, the kind of sense that “Julius” has isn’t quite the same as the senses of which Frege spoke. For Frege, the proposition meant by “the inventor of bifocals snored” doesn’t depend on who invented bifocals. This is because, according to Frege’s view, that person is not himself a constituent of the proposition meant by that sentence: only the sense of “the inventor of bifocals” makes it into the proposition. Matters are different with “Julius.” Even though that expression has a sense, the proposition meant by “Julius was tall” does vary depending on who invented the zipper. 
      The semantics of “Julius” can be understood in terms of Kaplan’s (1975) “dthat”-operator. If x is the unique phi, then by definition, ┌dthat [the phi] ┐ refers directly to x; and the proposition meant by ┌dthat [the phi] has psi┐ is true exactly if x has psi. So supposing that Franklin invented bifocals, the proposition encoded in “dthat [the inventor of bifocals] snored” is true in any world W where Franklin snored, it being irrelevant whether Franklin, or anyone else, uniquely invented bifocals in W.  “Julius” has same semantics as “dthat [the person who invented the zipper].” 
        Fregean senses fail to incorporate the things that they pick out into the propositions of which those senses are a part. The sense makes it into the proposition, but not the referent. But the sense of “Julius” does manage to incorporate the referent of Julius – the actual person – into the proposition. So Evans-style senses don’t merely describe,  although that is obviously part of what they do. They also seem to absorb the relevant objects into themselves. That is why – depending on whether it is Mary, Fred, or Ethel who uniquely invented the zipper -- the sense of “Julius” manages to make Mary herself or Fred himself or Ethel herself be a constituent of the proposition meant by “Julius was tall.” In general, Evans-style senses actually comprise the objects that they describe. “Julius” thus has a de re sense: a sense that actually comprises the object that it has as constituent. 
       It follows that what the sense of “Julius” is will depend on who invented the zipper. If Mary invented it, then “Julius” will have one sense. If Fred invented it, that expression will have a different senses. Those senses will be similar, but not identical. More exactly, they will be exactly alike except that, where the one has Fred as a constituent, the other has Mary as a constituent. In general, two senses might be exactly the same except that, in the place (so to speak) where one of them had external object x, the other had external object y.
       If cogent, the line of thought just discussed has two important consequence. First, even though the sense-reference distinction is not in fact true of actual proper names, it is true of possible proper names. Second, some senses (e.g. the senses of expressions like “Julius”) are de re with respect to external objects. 
      If correct, these two points would at least partially reconcile Frege’s semantics with the contemporary semantic view that, in at least some cases, the propositions meant by sentences have actual bits of the external world for their meanings. So given Evans’ views, we can hold onto some powerfully argued contemporary views about semantics, without foregoing Frege’s extremely plausible distinction between sense and reference. 


The epistemological underpinnings of the notion of a de re sense


        The view that there are de re senses is the semantic counterpart of an epistemological thesis. We’ve already discussed this thesis; but a brief summary of our findings may be appropriate. In the morning, you look at what is in fact Venus. In the evening, you look at what is in fact Venus. You don’t realize that the thing you saw in the morning is the same as the thing you saw in the evening. This is obviously because your morning-perceptions make you aware of Venus through one mode of presentation (one that, if verbalized, would be at least approximately: “last celestial body to disappear from the morning sky”), whereas your evening perceptions make you aware of Venus through a different mode of presentation (one that, if verbalized, would be at least approximately: “first celestial body to appear in the evening sky”). It is because these modes of presentation differ that you can coherently question whether you were seeing the same thing on both occasions.
      At the same time, content-externalism tells us that, in both cases, Venus itself is a constituent of the contents of your perceptions. So evidently the modes of presentation implicated in your perceptions not only presented Venus to you, but managed to assimilate Venus into themselves. Those modes of presentation – those descriptive contents – were therefore de re with respect to Venus. 
      
 Evaluating Evans’ argument 


        The notion of a  de re sense is incoherent, as is the notion of a de re mode of presentation. 
          Suppose that, in actuality, x uniquely invented the zipper. Let P be the proposition that, according to Evans, is encoded in “Julius was tall.” (Here we needn’t distinguish between types and tokens.) According to Evans, P is true in a world w exactly if, in w, x is tall. So P is identical, or at least equivalent, with x is tall. Obviously the concept unique zipper-inventor is no part of x is tall or, with a few irrelevant exceptions, of anything logically equivalent with x is tall.  
      Before proceeding, let me explain what these “irrelevant exceptions” are. Obviously x is tall is logically equivalent with either x was tall or a unique zipper-inventor was a square-circle. But that proposition isn’t what is meant by “Julius was tall”; and, for obvious reasons, the same is true of any other proposition that is both logically equivalent with x is tall and also has the concept unique zipper-inventor has a component.
       So, despite Evans’ own stipulation, the proposition meant by “Julius was tall” does not have the concept unique zipper-inventor as a component. That sense is nowhere to be found in that proposition. 
        What are we to say about the idea that P has as a component some de re mode of presentation -- about the idea that one of P’s components is a mode of presentation that actually has x as a constituent? 
      That idea is shown to be untenable by an argument similar to the one just given. Supposing that such a sense exists, there is no denying that at least part of the content of that sense is the concept unique zipper-inventor. But we’ve just seen that, with a few irrelevant exceptions, no proposition that has the same truth-conditions as P has that concept as a component. Thus, the concept unique zipper-inventor isn’t a component of any proposition that has the same truth-conditions as the proposition that by Evans’ own stipulation is the meaning of “Julius was tall.”  
        The concept unique zipper-inventor is no part what, by Evans’ own stipulation, is meant by “Julius was tall” and neither, therefore, is any concept that has the concept unique zipper-inventor (or zipper or inventor) as a component. So Evans has failed to identify any proposition that has a de re sense as a component. He has not shown that there are de re senses. 
        It is not hard to see what led Evans astray. Somebody who hears an utterance of “Julius snored” or “Julius was wealthy” must work through the semantic rule that assigns a referent to “Julius.” Supposing that Brown is the unique zipper-inventor, that rule is not: “Julius” refers to Brown. Rather it is: for anyone x who uniquely invented the zipper, “Julius” refers to x.  For reasons given earlier, this pre-semantic fact easily explains why “Julius snored” conveys the proposition some unique  zipper-inventor snored. But, by Evans’ own lights, the proposition literally meant by “Julius snored” is true in worlds where nobody invented the zipper. Consequently, that proposition has nothing to do with zipper-inventing. What does have to do with that concept is the proposition through which one computes the meaning of “Julius snored.” Evans is committing the now familiar error of conflating semantics with pre-semantics.[97] 
      
De re modes of presentation and Kripke’s paradox


          In the morning, you look at what is in fact Venus. You say sincerely say “that thing is lovely.” Let P1 be the proposition to which motivated this utterance. That evening, you again look at what is in fact Venus. You don’t know that, on both occasions, you were looking at the same thing. You say sincerely say “that thing is not lovely.” Let P2 be the proposition to which motivated this utterance.        
         It is a datum that, given only what we’ve said, you are not necessarily irrational. The reason is that the object in question was given to you in different ways – ways that are so different that you don’t know that you some one object as both “lovely” and “not lovely.” 
       But according to the content-externalist says that, for some, were thinking x is lovely in the morning and x is not lovely in the evening. Astonishingly, what content-externalists have done in response is to revise our conception of rationality: they respond by saying that one can assent to a proposition and its negation without being irrational. I can believe P and not-P without being irrational.[98]  
        Given what we’ve seen, there is no need to embrace this highly revisionist view. The content of your morning perception is an existence-claim that is satisfied by Venus, and the same is true of the content of your evening perception. But  Venus is not itself a constituent of your perception. There is no x such that (given only what we know about you from the story just told) you believe the singular proposition x is lovely and also the singular proposition x is not lovely. The semantic-externalist is quite right to say that you have affirmed both of those propositions. But we’ve already seen why this doesn’t entail that you believe both of those propositions. What you believe are the existence-claims that describe those singular propositions, not those singular propositions themselves. Those existence-claims are perfectly consistent. So we don’t need to jettison the age-old view that it is irrational to believe P and not-P. 


Refining our analysis 


      There is, admittedly, a problem with the view just presented. It is a problem that is easily be fixed, but it must be identified and dealt with: 


          You say that content-externalism is wrong because (this is one way of putting it) our perceptions give us knowledge by description, as opposed to knowledge by acquaintance, of their objects. But when we consider the descriptions that, in your view, perform this task, we find that they presuppose knowledge by acquaintance of certain objects. Consider what you just said in connection that the occurrence of “that part of the sky” in the sentence-token that expresses (*). (As before, let S be the part of the sky to which that occurrence refers.) By your own admission, the only reason that the perception in question is a perception of S, as opposed to something else, is that S causes you to have the visual experience in question. As you yourself (unwittingly) admit, S isn’t given to you by description. For if a perception that, in respect of its purely descriptive features, were just like the one you had of S, but were caused by something some other part of the sky S*, then that perception would be a perception of S*. So the reason that, in actuality, you are seeing S, as opposed to S*, is not that the content of your perception describes S as opposed to S*. The reason is simply that you have a causal, non-descriptive connection to S that you don’t have to S*.[99]




         This objection does have merit. But what it shows is not that my position is wrong. It only shows only that, in the initial presentation of my views, I chose to illustrate fundamental principles through examples that were vivid but slightly inaccurate, rather than through examples that were technically accurate but that, at that phase of the presentation of my theory, would have been very hard to understand. 
     In any case, the right response to the objector lies in a point made by John Searle (1983: 225-230). It is a point that we ourselves made earlier when discussing the relation between having a concept of an object and integrating it into one’s cognitive map of the world. 
        Consider the visual sensation involved your morning-perception of Venus. Let V be that sensation. Even a content-externalist will grant that V is partly descriptive. Even if V turns out to be a hallucination, it still tells you something – it tells you that there is a celestial body having a certain (approximate) location, and so on. A content-externalist would say that, if V is a hallucination, then there are gaps or blanks in its representational content where there would otherwise be objects. But he cannot plausibly deny that V tells you something, if only something false (or coincidentally true). Surely the hallucinator is told something false by his hallucinations. 
        In light of this, consider the existence claim: 


(**) There is some external state of affairs x such that x matches the description coded in V, and such that x caused V. 


       If V is caused by a blow to the head, or by consumption of a psychedelic drug, then it won’t be a perception of anything. The cause of V must be something which fits the description coded in V. It must be a brightly lit sky comprising a lovely luminescent planet. 
       But even this, though necessary, is not sufficient. In other words, for V to be a perception, it is not enough that V be caused by something x that fits the description coded in it. V must be caused in a particular way x. Suppose that a brightly lit sky causes Bob to punch you, which in turn causes you to have V. In that case, V wouldn’t be a perception, even though it was caused (albeit indirectly) by something which fits its content. So there is some specific mode of causation C such that, for V to be a perception, it is necessary and sufficient that V be caused in manner C by something x that fits the description coded in it. (It is a question greatly debated among epistemologists what C is. I will not attempt to answer this question. But it may reasonably be taken for granted that there is some such privileged causal modality.)
      Given this, let us replace (**) with: 


(***) There is some external state of affairs x such that x matches the description coded in V, and such that x caused V in manner C. 


Now suppose that SA is the state of affairs which uniquely satisfies (***). We’ve just saw that, in that case, V is a perception of (***). Of course, SA will comprise Venus, and it will also include various parts of the sky (among them the part of the sky to which we previously referred as “S”). Perhaps it will also include birds, trees, and so forth. 
        So V will be a perception of Venus, of S, and of those various birds and rocks. At the same time, none of those things will be a constituent of V’s content. Rather they will be described by it. The fact that you are seeing that particular bird, as opposed to some doppelganger, is indeed a function of the fact that you are causally connected to that bird in a way in which you are not causally connected to its doppelganger. But the connection is still a relation of description, not of acquaintance. That bird is, whereas its doppelganger is not, a part of the unique state of affairs which satisfies (***). (As before, let SA be that state of affairs.) Given what (***) is, in order to satisfy that existence claim, SA must be cause V (and do so in a quite specific way). At the same time, it is clear that (***) describes SA, and doesn’t have SA as a constituent. The reason you are seeing that particular bird and that particular planet, and not their doppelgangers, is that they are parts of SA, and SA is the thing which satisfies (***). So the reason that you see that particular bird is that you know of some description that it satisfies. At the same time, your knowing that description involves your having a quite specific causal relation to that bird. But, as we’ve seen, your epistemic relation to the bird is fundamentally descriptive, and the just mentioned causal connection is a mere component of that descriptive connection. 


Some virtues of this analysis 


        The model just proposed satisfies all the relevant desiderata. That, as I would now like to show, is why it is worth tolerating any counterintuitiveness that might characterize it. 
       We have completely descriptivized the content of perception. We have expelled external objects from the contents of our perceptions. On our model, such objects are described by those contents, but they are not actual constituents of those contents. Any analysis of perceptual (and cognitive) content must satisfy this requirement. This is because, so far as external objects are veritable constituents of our perceptual content, two perceptions or thoughts can have radically different contents without ipso facto having any differences in respect of their causal or their psychological properties.  
         Our analysis is consistent with the fact that what we are seeing and, more generally, thinking about is determined by our causal liaisons. So our analysis accommodates the datum that motivates content-externalism. 
         The problem with content-externalism is that confuses content with truth-maker. Supposing that x is a constituent of the external world (as opposed to a universal or a constituent of my own consciousness), for me to be thinking about x is not for x to be a constituent of the piece of information that I am grasping. Thinking about x typically involves having a descriptive fix on x. In many cases – indeed, in the cases that are cognitively central - that descriptive fix involves a causal component. (Our descriptivism is consistent with that fact, as we saw in Chapter 6.) But that causal connection is internal to a descriptive lock-on.  
           Notice that (***)  has a constituent of some person’s consciousness for a constituent. One of the constituents of (***) is a visual sensation, namely V. Notice (***) doesn’t describe V, but actually has it as a part. So (***) is object-involving with respect to some mental entity, but not with respect to anything external.[100] 


The Searle-McDowell debate 


         In light of these points, we can evaluate a criticism that John McDowell (1998: 260-274) makes of an analysis of John Searle’s (1983: 225-230). Like us, Searle advocates an internalist epistemology: he rejects the idea that external objects can be actual constituents of the contents of our thoughts. Searle also holds that concepts of external objects involve knowledge of truths that have items of one’s own consciousness as constituents. 
           McDowell’s rejects Searle’s position.[101] It is not hard to identify a criticism of our position that is an exact analogue of McDowell’s criticism of Searle:


        You grant that one can be aware of propositions that are object-involving with respect to one’s mental states – specifically with respect to the sensations that mediate one’s perceptions. So why not grant that we can be aware of propositions that are object-involving with respect to external objects? It seems arbitrary believe the one thing but not the other. So your grounds for advocating internalism are, in fact, grounds for accepting externalism.[102] 


   
         Suppose you grasp some proposition P about some sensation, e.g. some itch, that you are having. So P might be: I am having this itch because I am allergic to the shirt I am wearing. Let P* be a proposition that is just like P, except that, where P comprises that itch, P* comprises some other sensation, e.g. a tickle. A grasp of P has very different causal and psychological properties from a grasp of P*. So the substitution just described has psychological consequences – as opposed to consequences that can only be registered by a controversial theory of mental representation. Believing P leads you to believe that allergies cause itches, whereas believing P* leads you to believe that allergies cause tickles. It is obviously not the case that, ceteris paribus, a grasp of P is causally indistinguishable from a grasp of P*. No recherché arguments about causality are needed to establish this. Intersubstituting parts of propositions has very real psychological consequences when the parts in question are contents of consciousness, e.g. visual sensations like V. 
        Now let us a tell a different story. In our world, you are looking at Mary, and believing that she looks happy. Let T be the proposition that you believe true. Possible world w* is just like ours except that, in w*, you are looking at somebody who isn’t Mary, but looks exactly like her (i.e. looks exactly as Mary does in our world). In w*, you are thinking that this person looks happy. Let T* be the proposition that you believe true. In virtue of that difference, does your mental state in w* have causal properties not had by your mental state here? The answer is “no”, as we discussed earlier. But, according to McDowell, T and T* are different propositions, the reason being that, in the place where T has Mary as a constituent, T* has some other person as a constituent. By itself, intersubstituting parts of propositions has no psychological consequences when the parts in question are external objects.
       So, contrary to what McDowell says, it is not arbitrary to say that we can be acquainted (in Russell’s technical sense) with the contents of our own consciousness, while also maintaining that we are not acquainted (in that sense) with external objects. There are quite obvious reasons to believe that acquaintance with our mental states is not psychologically innocuous and also that acquaintance with external objects, if it existed, would be psychologically innocuous.  
      Of course, it would be foolhardy to deny that we are aware of external objects or that we do grasp propositions concerning them. But we’ve seen that we grasp such propositions descriptively. 
      There is a related point. Let P be some proposition that is object-involving with respect to Mary, and suppose that you grasp P. In other words, suppose that you have the just discussed knowledge-by-description of P that constitutes awareness of P. Suppose that we let somebody else take Mary’s place in P. To put it another way, let P* be a proposition that is just like P except that, in the place (so to speak) where P includes Mary, P* includes Bertha. 
      Obviously that intersubstitution can be psychologically significant. Your believing P* could be psychologically very different from your believing P. But if so, that is because that intersubstitution involved some kind of parallel change in the purely descriptive information through which you grasp the external world. If Bertha is qualitatively indistinguishable from Mary, then grasping P will be psychologically indistinguishable from grasping P*. But if Bertha is perceptibly different from Mary – if, for example, Bertha is wearing a green, round hat whereas Mary is wearing a red, square hat – then grasping P* will be psychologically different from grasping P. (We are assuming that you can see the colors and shapes of their hats.) But that is because, owing to these perceptible differences, the purely descriptive bodies of information through which you grasped P would be different from the purely descriptive bodies of information through which you grasped P*. In the one case, the relevant descriptive proposition would be: somebody x standing over there is wearing a red hat….The corresponding proposition in the other case would be: somebody x standing over there is wearing a green hat….
     So intersubstitutions of propositional components are not psychologically significant in cases where those components are external objects. When such intersubstitutions seem to be psychologically significant, it is because things other than external objects are being intersubstituted.  


Chapter 9 Publicity problems and the nature of linguistic communication 


       We’ve seen that understanding “Socrates”, or any other referring term, involves associating it with some description that its referent uniquely satisfies. But we’ve also seen that the descriptions that a person associates with such an expression are highly specific to the circumstances under which he first encounters it. A consequence is that any two people will almost certainly associate different descriptions with “Socrates.” But surely “Socrates” is useless as a device of communication unless people mean the same thing by it, and surely people cannot mean the same thing by it if any two people associate different descriptions with it. So our analysis seems to conflict with the fact that referring terms can be understood only in so far as the descriptions associated with them are shared.
       This is a point that Frege (1892) stressed: the “senses” of referring expressions must be public. If the sense that I associate with “Socrates” is great hemlock-drinking philosopher, and the sense that you associate with him is ironic main character in most of the Platonic dialogues, then what you mean by “Socrates was wise” will be different from what I mean by those same words. What you mean will be equivalent with: somebody x was uniquely an ironic main character in most of the platonic dialogues; and x was wise. And what I mean will be equivalent with: somebody x was uniquely a great hemlock-drinking philosopher; and x was wise. According to Frege, to the extent that people associate different senses with a given expression, that expression fails as a way of allowing people to express their thoughts to one another. 
       At the same time, it is a datum that we can use expressions like “Socrates” to make ourselves understood to one another. My analysis seems to be inconsistent with that fact. I believe that Socrates was a person of principle. The occurrence of “Socrates” in the last sentence expressed that belief. But if my analysis is right, how can that be? For what I mean by “Socrates was a person of principle” is one existence-claim, and what you mean by it, and thus take it to mean when hearing it from others, is some entirely different existence-claim. 
        I would now like to show why my analysis is consistent with the facts concerning the usefulness concerning “Socrates” and other expressions as devices of communication. Our analysis is consistent with the important points made by Frege concerning publicity and communicability. Indeed, I will go further than this. I will argue that what enables people to communicate with one another is precisely that there is a gulf between literal and cognitive content. Theories that don’t posit such a gulf make linguistic communication impossible. If the literal meanings of your words collapse into the contents of the thoughts that lie behind them, then I will never be able to understand what you are saying. This, at any rate, is what I will now argue.[103]
    
Speaker’s meaning versus linguistic meaning 


        Let T be a token of “Socrates was wise.” As we’ve seen, a given person – say, Smith -- accesses the literal meaning of the proposition literally meant by T through some proposition like the following: 


(TP) There is some x such that, for some occurrence y of “Socrates” such that Fred uttered y five minutes ago and such that, for some z, y uniquely refers to z, and “Socrates was wise” has for its literal meaning the proposition: z was wise. 


Obviously (TP) doesn’t say anything that is of general interest. It doesn’t say anything that historians or philosophers would find illuminating. 
     As we’ve seen, the thoughts through which you compute the meanings of utterances are of the same basic kind as the thoughts which prompt you to produce such utterances. Since there is no way for you to understand T except by way of your knowledge of some egocentric, contextual proposition like TP, knowledge of such a proposition must be what prompts you to utter T.  
      But this doesn’t entail that what you mean when you utter “Socrates was wise” is TP, or anything like it. For reasons that we’ve given, when you say “Socrates was wise”, you know that what is literally meant by yours words is confined to the underlined part. You thus know that, so far as your objective is to speak truly, your objective is met exactly if that operator-right proposition is correct. For you to mean that proposition by your utterance of “Socrates was wise” is simply for you to make that utterance with that objective. 
      It is true that you don’t directly grasp that proposition: you grasp it only in the indirect sense described earlier. But you can still mean that exact proposition by your words; you can mean exactly x was wise, for the appropriate x. You don’t have to mean some existence-claim, even though, ultimately, you are incapable of grasping anything other than such a claim. 
       To put these issues into context, let us briefly discuss what is probably the most famous analysis of the nature of linguistic meaning. That account is due to H.P. Grice (1957). 
        According to Grice, expression-meaning must be understood in terms of speaker’s meaning. “Snow is white” means snow is white in virtue of the fact that people mean snow is white by “snow is white.”  In general, our utterances mean what we mean by them.  
       Grice’s picture is not correct. Searle (1969: 43-47) put his finger on the basis problem with it. You cannot checkmate somebody in a context where the rules constitutive of the game of chess are inoperative; and you cannot even intend to checkmate somebody unless you believe that those rules are operative. Similarly, you cannot affirm that snow is white with the words “snow is white” in a context where the rules constitutive of the English language are inoperative; and you cannot even try to affirm that proposition with those words unless you believe that those rules are operative. A speaker cannot successfully affirm P with utterance S unless S already means P; and a speaker cannot even try to affirm P with S unless he xxx believes that S already means P.[104] So the concept of speaker’s meaning must be understood in terms of linguistic meaning, not vice versa. Speaker’s meaning presupposes conventional meaning, as Searle puts it.[105] 
              In Chapter 25, we will further discuss the problems with the Gricean view. But for now let us proceed on the reasonable assumption that it is false. (See Searle 1969: 42-50 for cogent arguments against the Gricean view.) 
         But Grice was surely right to this extent: what people think – what is going on in their minds – is obviously relevant to what comes to be meant by the noises and ink-marks they produce.[106] This must be understood aright. If I were to mean snow is white with the sounds “grass is green”, the latter would not come to mean the former. But the fact that “grass is green” means what it does is a reflection, albeit an indirect one, of what was going on in the minds of some people at some point in human history.  From this last fact, however, it doesn’t follow that speaker’s meaning – the phenomenon of a person’s meaning something by a sound or ink-mark -- is prior to semantic meaning. What follows is that speaker’s thinking is prior to semantic meaning. Xxx The Gricean model starts with the entirely correct point that what we think is at least partially determinate of what our words mean; but it conflates this truth with the falsehood that what we mean determines what our words mean.  
      The expressions of a language are public entities. Their occurrences are given to us through sense-perception, and the same is true of the activities which give them their meanings. How do you learn what “Hesperus” refers to? Somebody points to an object and says “that is Hesperus”, or you overhear somebody using that expression. In any case, it is always (ultimately) through sense-perception that you learn what that term refers to. 
      As we’ve discussed, for you to have a sense-perception of an object is for that object to be described to you. Given this point, along with the fact that it is through sense-perception that you learn semantic rules, it follows that those semantic rules are always described to you. 
       Of course, the perceptually encoded description through which a semantic rule is given to you will incorporate the idiosyncrasies of your particular situation, and will not have any basis in the semantic rule itself. Those idiosyncrasies are reflected in the information that is conveyed to you by utterances of sentences like “Socrates was wise” and “Hesperus is lovely.” As a result, there is categorically a lack of fit between the semantic rules themselves, on the one hand, and the contents of our thoughts, on the other. It thus of the essence of any public language that what its expressions mean not fit too snugly with the thoughts we have. 
      This does not mean that linguistic communication is not possible. It is a datum that people successfully transmit information through language, and that there is such a thing as using language to make oneself understood. What the preceding line of thought shows is that we must reanalyze what it is for someone to successfully communicate something. Let us now supply the needed re-analysis. 


The structure of linguistic communication 


           Suppose that Smith and Jones are both cognitively normal competent speakers of English. Both know what is meant by “Socrates is wise.” But, as we’ve seen, what Smith knows may be different from what Jones knows. What Smith knows has the form: 


(1) there is some x such that x has properties P1…Pn and “Socrates was wise” exactly if x was wise. 


And what Fred knows has the form:  


(2) there is some x such that x has properties P*1…P*n and “Socrates was wise” exactly if x was wise, 


where P1…Pn may be, and probably are, entirely different from P*1…P*n .
        But  (1) and (2) have the same truth-maker. The thing which satisfies (1) is identical with the thing which satisfies (2). So even though what Fred takes away from Smith’s utterance of “Socrates was wise” may be very different from the thought that prompted Smith’s utterance, there is still a significant sense in which a truth has been transmitted. Thanks to that utterance, Fred now has a thought that has the same truth-maker as Smith’s thought. 
        Another illustration may be in order. I see Brown for the first time at time t. But what I see is not just Brown; what is given to me in my perception corresponds to the existence-claim: over there, next to that tree, there is some man x such and x is unshaven and looks disheveled, and x just introduced himself to me by saying “I am Brown: please forgive my appearance – you see, I didn’t sleep well last night…” 
         Let us continue this story. You see Brown for the first time at time t*, and the content of your perception is given to you through the existence-claim: behind that podium, there is a clean-shaven, debonair fellow x such that x is giving a competent, but ultimately not very informative, lecture on the history of psychology, and such that I’ve been told that x’s name is “Brown”.  
       Suppose that you and I are together, and somebody tells us both: “Brown is a member of the libertarian party.”  What you will take away from that utterance is: 


(3) there is somebody x such that I heard x give a competent, but ultimately not very informative, lecture on the history of psychology; moreover, x is a member of the libertarian party. 


What I will take away from that utterance is:  


(4) a few days ago, next to the maple tree outside my house,  there was some man x such that x was unshaven and looked disheveled; moreover, x is a member of the libertarian party. 
 
     But even though (3) and (4) are very different, they both have the same truth-maker.   
     This point generalizes without limit. (We are continuing to confine our attention to cases where the people in question speak English and are cognitively competent.) If, ten days later, I say to you: “Brown just bought a new car”, the thought that motivated my utterance of that sentence will have the same truth-maker as the thought which that utterance leaves you with. So even though the thoughts that I have in connection with sentence-tokens of the form ┌Brown has phi┐ will always differ in significant ways from the thought that you have in connection with sentence-tokens, those two sets of thoughts will be coordinated in a very strict fashion. They will categorically have the same truth-makers. And this – nothing else -- is what is important to our being able to communicate with another through language.
          Suppose that, in order to communicate with each other, you and I had to associate exactly the same propositions with utterances of “Brown looks tired”, “there is no way that Brown can afford the BMW he just bought”, and so on.  In that case, communication would be impossible. Given the descriptive nature of sense-perception, and given the public nature of languages like English and Russian, there is no way that we could possibly have qualitatively identical thoughts in connection with “Brown looks tired” or, by reasons exactly similar to those just given, in connection with any other utterance. Communication is possible only because communication does not presuppose such a complete cognitive convergence between speaker and auditor. For communication to occur, only a limited convergence is needed: the speaker’s thoughts must have the same truth-maker as the auditor’s. 


Why our analysis accommodates the datum that linguistic communication is possible 


          Some would take these remarks to show that communication is impossible.[107] Some would say that, if indeed the proposition I associate with an utterance of “Brown looks tired” isn’t identical with the proposition that you associate with it, then we simply aren’t understanding each other: there is only an illusion of communication, fostered by a kind of parallelism between our thoughts. 
         Here is the view I would endorse. The line of thought given in the last paragraph is a purely terminological point, masquerading as one that is substantive. It is a datum that people make themselves understood through language. I say to you: “your mother is coming tomorrow.” Something has been communicated; and that is why you immediately start tidying your house, washing the bedding in the guest bedroom, and so forth. Verbal communication is an obvious and pervasive phenomenon. 
          The naïve model of this phenomenon is this: communicating involves the speaker and the auditor associating exactly the same propositions with the noises that are produced during their exchange; and so far as they fail to do so, they are not really communicating – even though they may feel as though they are. As we’ve seen, this position is a non-starter, given the public nature of linguistic symbols and given the formidable cognitive pre-requisites to internalizing and manipulating those symbols. This isn’t to say that there is never a convergence of the sort just described. But it would be false to say that communication categorically presupposed such an absolute convergence.  
       A more realistic model is the one proposed a moment ago. Communicating involves both speaker and auditor associating propositions that have the same truth-makers with the noises that are produced in during their exchange. Of course, if P and P* are the same proposition, then they have the same truth-maker. So our model is compatible with the possibility that, in at least some cases, communicating involves speaker and auditor associating the very same proposition with a certain sound or ink-mark. But our model, unlike the naïve one, is consistent with the fact that those two propositions are often distinct. What is necessary, according to our model, is that both propositions have the same truth-maker and are thus coordinated with each other. In general, linguistic communication involves a coordination, not an identity, of thought. Speaker and auditor must have parallel, not necessarily coincident, thoughts.
        Because linguistic communication involves identity of truth-maker, and not identity of proposition, people are able to communicate with each other despite what may be vast differences in their personal circumstances. 
       I have learned much from Aristotle’s words. This wouldn’t be possible if Aristotle’s communicating his insights to me involved my taking from his words exactly the thoughts that prompted him to produce them. It wouldn’t be possible if I had to associate with the word “Plato” exactly the description that Aristotle associated with the corresponding Greek word. It wouldn’t be possible if I had to associate exactly the same proposition with the sentence “Plato was a fine philosopher” that Aristotle associated with the corresponding Greek sentence. Given how different my life-history is from Aristotle’s, there is no possibility, even in principle, of such a complete cognitive convergence. 
        Language cuts through these biographical differences. This is because linguistic communication is about identity of truth-maker, and not of proposition. It is about what is external, and not about the internal processes through which we learn about what is external.  
        Of course, not all communication concerns what is external. One can tell people what one is thinking and feeling; I can tell you that I am happy or sad. But a precondition for my being able to do this is that linguistic communication not involve the strict cognitive convergence between speaker and auditor demanded by the naïve theory. 
        The word “sad” is a public entity. You learn what it means, at least in part, by seeing how it is used or, conceivably, by having it defined for you.[108] You learn what it means through, at least in part, sense-perception. You access that information through the biography-specific information embodied in your perceptions. Further, having uploaded that sensory information, you must then correlate it with your awareness of an internal state.[109] Given any two people who know what “sad” means, they will differ considerably as regards the specifics of that sensory information and also of the internal state correlated therewith. (Surely it cannot be taken for granted that everyone who knows 666 what “sad” means has exactly the same sort of sadness. I am not referring to garden-variety skeptical problems about other minds. I am referring to the fact that people are sad in different ways – just as objects can be blue in different ways: some are turquoise, some are azure, and so on.) 
         So when it comes to expressions that report inner-states, it is especially important that communication involve identity of truth-maker, and not of proposition. For where such expressions are concerned, there are two barriers to the kind of strict cognitive convergences demanded by the naïve theory. First there are the inevitable differences in the perceptual information through which any two people learn what a given word means. But there also are the inevitable differences in the exact phenomenologies of the inner states that are subsequently correlated with the information provided by those perceptions. So our model is 666 consistent with the fact that we can communicate our feelings and thoughts, and so on; and the competing model is inconsistent with that fact. 


Other reasons to accept this analysis


        According to the naive view, genuine communication occurs only to the extent speaker and auditor associate exactly the same propositions with the expressions used in their exchange.[110] I would now like to develop our criticisms of the naïve view
       You and I both speak English. Let S1…Sn be the set of English sentences that you and I both understand. As we’ve discussed, for practically any value of i, the proposition that I associate with a token of Si will be very different from the proposition that you associate with it. At the same time, the truth-maker of the one thought will be identical with the truth-maker of the other. So there is some x such that the singular proposition x was wise is the truth-maker of the proposition I associate with “Socrates was wise” and also of the one that you associate with it. This means that, even though you and I access the meaning of “Socrates was wise” through different bodies of information, we are nonetheless in complete agreement as to what state of affairs must hold for that sentence to be true.
      Of course, “Socrates was wise” was arbitrarily chosen, and what we just said of it is true of each sentence in S1…Sn. So what is true of “Socrates was wise” will be true also of sentences reporting evidence relevant to the truth of that sentence. Suppose recent historical research proves beyond a shadow of a doubt out that Socrates died when Plato was only ten years old. Given our model, there is some x and some y such that  the propositions that both of us associate with “Socrates died when Plato was only ten years old” are true exactly if the singular proposition x died when y was only ten years old is true.
        Thus, given our model of semantic competence, it follows that ceteris paribus you and I are in complete lock-step in regards to the evidential and, more generally inferential significance of any sentence of English. A corollary is that validity of the arguments literally meant by one’s words will perfectly mirror the validity of the argument that is grasped by the thoughts behind those words. What we just said about validity is true of truth, cogency, and every other logically significant property. 
         Our model thus accommodates the fact that sentences of English are capable of unambiguously transmitting information about the world, even though, at the same time, any two English speakers will access the meaning of practically any given English sentence through different bodies of information. 
      
Chapter 10 Content-externalism and self-knowledge 


         It seems clear that, within certain limits, we know with absolute certainty what it is that we are thinking. Right now, think about how much you enjoy reading Descartes’ works. (For the sake of argument, either suppose that you do enjoy reading his works or replace the proposition I like reading Descartes’ works with one that does befit your psychology, e.g. I do not particularly enjoy reading Descartes’ works or I want to go to Paris.) You know with unimpeachable (“Cartesian”) certainty what it is that you are thinking right now. Further, you know, with that same certainty, that you are in fact having a thought right now. In any case, our pre-theoretic intuitions give some credence to these assertions.
       We mustn’t confuse questions 666 concerning the range of things which we can know with Cartesian certainty with the question of 666 whether we can know things with such certainty. Freud, Chomsky, and others have argued that we are unaware of much of the mental activity that occurs within our own minds.[111]  But these discoveries don’t show that we don’t have any Cartesian certainties. They only show that we don’t have such certainties with respect to everything within our own minds.
        Right now think about the fact that you enjoy (or don’t enjoy) reading Descartes. Nothing that Freud or Chomsky say is inconsistent with the obvious truth that you know with Cartesian certainty that you are now thinking about that proposition. Freud may be right to say that many of your reasons for thinking 666 it are not known to you, and involve symptomatic conversions that are rooted in anxieties the grounds for which may never be revealed to your consciousness. Chomsky may be right to say that your being able to grasp that truth involves intricate performances on the part of some sub-personal cognitive apparatus that couldn’t possibly disclose itself to consciousness. Be all of this as it may, your knowledge that you are now thinking about the proposition I enjoy reading Descartes is characterized by a special and inviolable certainty – one that cannot attach even to the best substantiated beliefs about the external world. 


Why content-externalism seems to be  inconsistent with our intuitions concerning self-knowledge


         Given the information available to you, it is epistemically possible that Descartes didn’t exist. It could turn out that the relevant various historical records were forgeries, that the work attributed to him was actually written by someone else, and so on.
        The essence of content-externalism is that Descartes himself – as opposed to some description that happens to single him out – is a constituent of certain thoughts of yours (e.g. I enjoy reading Descartes).  If that doctrine is right, then there are various thoughts that you in fact have that you wouldn’t be having if turned out that Descartes had never existed. So supposing that you are now consciously entertaining the proposition I enjoy reading Descartes, an apparent consequence of content-externalism is that your knowledge that you are now having that thought is only as good as your knowledge that Descartes himself existed. This in turn means that you don’t know with any special certainty that you are having that thought. If content-externalism is right, then your knowledge of the contents of your own consciousness becomes as uncertain as your knowledge of early modern French history. (See Bilgrami 1992: 364-365, McKinsey 1991: 355-356.[112])  
     These remarks generalize without limit. Right now have the thought Alpha Centauri is more massive than my car. For reasons analogous to those just given, if content-externalism is right, then your knowledge that you are now having that thought is no more certain than your knowledge of some spatially and temporally remote region of the cosmos. 
       Of course, this seems quite wrong. If you are consciously having a thought about Descartes, you do (or at least can) know with a special certainty that you are having that thought. Even if we grant that one can be deluded as to the identities of the thoughts one is consciously having, there is no denying that there is a kind of certainty that can attach to our knowledge of what we consciously thinking that cannot possibly attach to our knowledge of what is going in the external world (McKinsey 1991: 355-356,Bilgrami 1992: 364-365). 
       Content-externalism has a closely related and equally counter-intuitive consequence, namely: you don’t know the identities of the thoughts that you consciously entertain with any more certainty than you know about the constitution of the external world. 
       As before, entertain the thought I enjoy reading Descartes. Let M be the mental process that mediates that thought. If content-externalism is right, then there is a possible world where M mediates the thought I enjoy reading Bentham or I enjoy reading Arnauld. After all, there are epistemically possible worlds – worlds consistent with the data that you have – where somebody other than Descartes wrote the Meditations and, in general, was the historical source of the various documents and evidences on which your beliefs about Descartes are (in actuality) based. Of course, given any external object O, what we just said about your knowledge of the identities of your Descartes-thoughts is true of your knowledge of the identities of your O-thoughts. 
        But this seems quite wrong. If you are consciously thinking I enjoy reading Descartes, you do know with a special certainty that you are thinking that thought as opposed to I enjoy reading Arnauld. 
       It seems to me that the two just mentioned consequences of content-externalism are equivalent. In other words, content-externalism entails that you don’t know (with Cartesian certainty) whether you are now thinking I enjoy reading Descartes iff it entails that you don’t know (with Cartesian certainty) that you are thinking I enjoy reading as opposed as opposed to I enjoy reading Smith or I enjoy reading Arnauld. But whether I am right to allege this equivalence is a subtlety that we can set aside, since nothing that we will say depends on it. 


Burge on self-knowledge 


          Tyler Burge (1986) is a content-externalist who is aware of this apparent problem, and has produced a brilliant way of dealing with it. In fact, I would go so far as to say that his argument is a masterpiece of philosophical workmanship. That argument is as follows: 


(TB)  Suppose that you are thinking: I enjoy reading Descartes. Let T be that thought. Now suppose that you are now thinking that you enjoy reading Descartes. Let T* be that  thought. 
    T* actually comprises T. So in thinking I am now thinking that I enjoy reading Descartes, you are necessarily thinking I enjoy reading Descartes. The very occurrence of T* thus guarantees its own truth. It is a self-fulfilling thought. 
    To be maximally clear, let us restate this argument. T* is a thought to the effect that T is occurring. T is a veritable component of T*. Therefore T* cannot possibly occur without being correct. Therefore, T* is grounds for its own truth. You cannot have T* without knowing T*
     So if you believe that you are thinking I enjoy reading Descartes, that belief is grounds for its own truth. You cannot have that belief without having logically adequate grounds for believing and, further, without in fact believing it on those very grounds. 
      Obviously this gives a certainty to one’s belief that one is thinking I enjoy reading Descartes that doesn’t attach to one’s believing some proposition about the external world. But, in addition, it gives a certainty to that belief that doesn’t even attach to one’s belief in the principles of logic or mathematics. 
       This last point is crucial. If you believe that 7+5=12, your belief cannot possibly be wrong. But your thinking 1+1=2 is not what makes that thought true. 7+5=12 is true in virtue of facts about the numbers and arithmetical operations. If you had to prove to somebody that 7+5=12, it wouldn’t be enough to say: “I just thought it; therefore its true.” You’d have to go through the sort of rigmarole that Whitehead and Russell went through. By contrast, if you think I enjoy reading Descartes, the grounds for that truth of that belief are simply that you had that belief.  
     For this reason, your thoughts about what you are (consciously) thinking have the sort of certainty that Kant described as “apodictic.” Nor 666 is it logically impossible that such thoughts should be wrong. Those occurrences provide the grounds for their own truth; and, in virtue of having those very thoughts, you are believing in their truth on those very grounds. So your having those thoughts guarantees that you recognize the reasons for which they are logically, and judge them to be true for those very reasons. So if you believe that you are thinking some thought, the certainty that attaches to that belief is of a higher order than the certainty which attaches to your belief that 7+5=12 or even that triangles have three sides. 
        There is one last point to make. The argument just given involves but one premise: in thinking I believe that I enjoy reading Descartes, one is thinking I enjoy reading Descartes. We’ve seen that, given that one premise, everything else follows. In using that premise, the content-externalist is in no way begging questions against his opponent. The truth of that premise is a kind of datum. In any case, its truth is known on grounds that are entirely independent of the truth of content-externalism or of any other doctrine. 
     So the argument just given is cogent. There is, at most, only an appearance of conflict between content-externalism and our belief that we can know our thoughts with Cartesian certainty.


      
             Let us evaluate this argument.[113] Just as Burge says, thinking 


T*: I am thinking that I enjoy reading Descartes 


does involves thinking 


T: I enjoy reading Descartes. 


      That is undeniable. There is no denying that, if it occurs, T* is necessarily correct. So if you manage to think T*, your belief is ipso facto correct. And, just as Burge says, the reason for this is that thinking T is a pre-condition for thinking T*.
       But the very thing that is in question is whether content-externalism allows that pre-condition to be met in the relevant contexts. It is easily shown that there are situations where content-externalism doesn’t allow you to have any thought at all but where, at the same time, it is clear on independent grounds that one is having a thought and, further, that one knows with Cartesian that one is having that thought. 
        Supposing that you have succeeded in having T, Burge’s argument does indeed show that you cannot be wrong to think that you have T. But if externalism is right, there are situations that are epistemically just like this one – situations where the neurons in your head are firing in exactly the manner in which they are firing here, where you feel exactly as you do here, have the same feelings of certainty, and so on -- but where you simply fail to have T. A fortiori you fail to have T* in such situations. At the same time, each of those situations is epistemically indistinguishable from your situation here; and it is therefore a datum that, in any one of those situations, you have the very same Cartesian certainties that you have here. So the worlds 666 where Burge’s assumptions are granted are not the worlds where one has the Cartesian certainties whose existence he is tethering to the truth of those assumptions.
      Let us develop this argument. Suppose that content-externalism is correct and, once again, think (or try to think) to yourself: I enjoy reading Descartes. So far as your mental state consists in your having that thought, your counterpart in a Descartes-free world w 666 is failing to have a thought. Now think: I am thinking that I enjoy reading Descartes. So far as your mental state consists in your having that thought, your counterpart in w is failing to have a thought. 
        Supposing, as we are, that content-externalism is correct, your counterpart is wrong. He attributes a thought to himself that he doesn’t actually have. In the place where you are actually having a thought, your counterpart is shooting a blank. In the place where, according to Burge, you know with Cartesian certainty that you are having a certain kind of thought, your counterpart is not having a thought and is thus wrongly believing himself to have a thought. This is equivalent to saying: for all you know – in other words, given your epistemic situation – you could be the one who is wrong; you could be mistaking some non-thought of yours for an actual thought. So your epistemic situation is consistent with your being wrong about whether you having a thought. A fortiori, in direct contradiction to what Burge maintains, your epistemic situation is consistent with your being wrong about which thought you are having. If you don’t know with Cartesian certainty that you are having a thought, you don’t know with Cartesian certainty that you are thinking some specific thought.
       Let us sum up our criticism of Burge (1986). An immediate consequence of content-externalism is that, even if you were in a world where your epistemic situation was identical with your actual epistemic situation, you could still fail to have many of the thoughts that you actually have. In particular, there are worlds where you cannot think I enjoy reading Descartes but where your epistemic situation is identical with your epistemic situation in our world. When we want to know whether content-externalism is compatible with what we know about the nature of self-knowledge, we have to consider worlds that are epistemically identical with ours. Therefore, we must not confine our attention to worlds where Descartes existed. After all, the set of such worlds forms does not exhaust 666 the class of worlds where your epistemic situation is exactly as it is here. 
        Burge’s argument is of the form: 


(*) Given that you are thinking I enjoy reading Descartes, such and such is true of any possible world where you attribute that thought to yourself. 


But, in light of how Burge and other content-externalists construe what it is to think about Descartes, (*) only takes into account the set of worlds where Descartes exists. It doesn’t take into account the entire 666 set of worlds where Descartes doesn’t exist but where your epistemic situation is exactly as it is here. So it doesn’t take into account all of the worlds in terms of which claims about self-knowledge must be evaluated. It only takes into account where Descartes has already been loaded, externalist-style, into your thoughts. 
        Thus, depending on how one chooses to look at it, Burge’s argument either begs the question, by restricting its attention to worlds where Descartes has been made a constituent of our thoughts, or it erroneously identifies the class of worlds that are epistemically identical with ours with some subset of the class of worlds where Descartes exists. Either way, the argument is fallacious. 
        
Another content-externalist stratagem 


    Our position is this:




      (CC)  If the content-externalist is right, there are worlds epistemically just like ours where, instead of thinking  I want to drink some water, I am thinking: I want to drink XYZ. Given that those worlds are epistemically indistinguishable from ours, it follows (tautologously) that I have no way of knowing that I am not in such a world and, therefore, that I have no way of knowing (at least with any special Cartesian certainty) that I am not thinking I want to drink XYZ as opposed to I want to drink water. But it is a datum – or at least a strong pre-theoretic presumption – that I do know with Cartesian certainty that, right now, I am thinking: I want to drink water. So content-externalism must be wrong, given that it has this false consequence. 




      We considered Burge’s response to (CC), and found it unsatisfactory. But other content-externalists have a different objection to (CC), to wit: 




(SK)    In this world, there is water (H2O), not XYZ. For obvious reasons of a generally logical kind, when you think: 


T*: I am thinking that I want to drink some water, 


you must also think: 


T: I want to drink some water. 


 Given this, suppose that you were in a world w that was just like our world except that, in w, there is XYZ instead of H2O. (It follows that your epistemic situation in w is just like your epistemic situation here.) So, just as you say, instead of thinking T, your counterpart in w thinks: 


S: I want to drink some XYZ. 


But this doesn’t render erroneous his beliefs about what he is thinking. For instead of thinking T*, your counterpart thinks: 


S*: I am thinking that I want to drink some XYZ. 


And, of course, S* is correct. So your counterpart is right, and content-externalism doesn’t violate his Cartesian access to his own conscious thoughts. 
      The general principle here is clear. Just as content-externalism says, what you think is constitutively dependent on facts about your environment 666. But your thoughts about your thoughts inherit those same constitutive dependencies. So your thoughts about your thoughts track your thoughts, ensuring that what you will know with Cartesian certainty in one world exactly what you know with Cartesian certainty in worlds epistemically identical with that world.[114]




        (SK) involves a failure to give due attention to distinctions of scope. Some background may help bring this out. 
        Let w be a world where there is XYZ instead of water, but that is otherwise just like our world. Let w1 be a world there is X1Y1Z1 instead of water, but that is otherwise just like our world; let w2 be a world there is X2Y2Z2 instead of water, but that is otherwise just like our world; and so on. So your epistemic situation in our world is identical with your epistemic situation in each of w1, w2, and so on. 
       Let us proceed. 666 Let T 666 be the thought: I enjoy drinking XYZ; let T1 666 be the thought: I enjoy drinking X1Y1Z1; 666 let T2 666 be the thought: I enjoy drinking X2Y2Z2;and so on. 666 Finally, suppose that, in our world, you are thinking I am currently thinking that I enjoy drinking water. 666
      Like everyone else, the externalist admits that we don’t know with Cartesian certainty that we are in a water-world, as opposed to an XYZ-world (or an X1Y1Z1-world…). At the same time, the essence of the content-externalist’s position is this: if I am in w, I am thinking 666 T; if I am in w1, I am thinking T1; if I am in w2,  I am thinking T2; and so on. 
        Given this, suppose for the sake of argument that (SK) is cogent. 666 In that case, if I am in w2, then there is some thought – namely T2 – such that 666 I am having T2 and such that I am attributing T2 to myself. But notice that, in the last sentence, the “there is” is given wide-scope with respect to the other operators – with respect to the expressions “attributing” and “having.” So if (SK) is cogent, then in w2, there is a thought that I am having and that I am correctly attributing to myself – but I don’t know which thought it is. I don’t know whether it is T1 or T2 or T3…
     Some fiction may clarify the structure of this argument. Because of some accident of genetic engineering, there are various people who look (and also dress and talk and act) exactly the same. These people are John1, John2...and John10. One day somebody who is in fact John4 is standing in front of me. Under these circumstances, I am in fact seeing John4 – and not John5 or John6 or any of the other Johns – but I don’t know this fact. All I know is (at most) that I am seeing either John1 or John2…or John10. 
      At the same time, there is somebody x such that I know that I am seeing x. After all, there is some person who is front of me such that I am seeing him and such that, in addition, I know myself to be seeing him. (This isn’t a case of blind-sight – of seeing without knowing that one sees.) What I don’t know is that John4 is that person. So in this scenario, there is somebody x such that x is John4 and such that I know I am seeing x. At the same time, I don’t know that I am seeing somebody x such that x is John4. 
      Let us close the argument with one more bit of fiction.  I am in w2. According to content-externalism, I am thus thinking: I enjoy drinking X2Y2Z2. But my epistemic situation in w2 is just like my epistemic situation here on Earth. If (SK) is cogent, then there is some thought x such that x is in fact identical with T2 and such that I know with Cartesian certainty that I am having x. But I don’t know with Cartesian certainty that there is some thought x such that x is T2 and such that I am now having T2. The only way I could know that fact with Cartesian certainty would be to know with Cartesian certainty the chemical structure of the liquid in bathtubs and swimming pools. But, as the content-externalist himself grants, I cannot know facts of that kind with that kind of certainty. 
       So if (SK) is cogent, then I indeed know with Cartesian certainty that I am having a thought that is in fact T2. But regardless of whether (SK) is cogent, I don’t know with Cartesian certainty that I am having T2 (as opposed to T3 or T4…) So even if (SK) is cogent, I don’t know which thought I am having – I don’t know which thought I am imputing to myself with Cartesian certainty.  
         Our intuition is that if I am consciously thinking: I enjoy drinking water, I know with Cartesian certainty that I am thinking I enjoy drinking water. Our presumption is not given by the claim: 


(WS) There is some thought x such that x is identical with I enjoy drinking water such that I know with Cartesian certainty that I am thinking x. 


Rather, our presumption is given by the claim:


(NS) I know with Cartesian certainty that I am thinking some thought x such that x is identical with I enjoy drinking water. 


So even if (SK) is cogent, it fails to establish that content-externalism is consistent with our presumptions about self-knowledge. In other words, (SK) is consistent with the view that content-externalism warrants some views about self-knowledge that are extremely revisionist and in conflict with hearty and plausible intuitions. 


Davidson on self-knowledge 


          Given what it is that we can know about ourselves, xxx and with what degree of certainty we can know it, content-externalism must be wrong.  In any case, we have seen some good reasons to accept this and no good reasons to reject it. But Donald Davidson rejects it, and he provides a bold argument on behalf of his position.[115] Let us now consider that argument. 
          From the viewpoint of a physicist, it is irrelevant whether you measure weight in pounds or kilograms. What matters is that you use some consistent system of measurement. My weight in pounds is 195. So far as there is a significant connection between the number 195 and my weight, that reflects the contingent and logically insignificant fact that a certain system of measurement has been adopted. Given any object O XXX, and given any number N, there is some viable system of measurement S such that, relative to S, O has mass N. It is only relative to some arbitrarily chosen system of measurement that there is any significant connection between any object’s mass and any number. 
        Suppose that Smith believes that water quenches thirst. In Davidson’s view, Smith’s relation to the proposition water quenches thirst is comparable to the relationship between my body-mass and the number 195. Relative to one viable system of measurement, there is a special connection between my weight and the number 195; and relative to others, there isn’t. Relative to one viable system of description, there is a special connection between Smith’s mental state and the proposition water quenches thirst; and relative to others, there isn’t. Just as it is useful, but not necessary, to measure weight in pounds, so it is useful, but not necessary, to describe mental events in terms of propositions. 666 [ADD MISSING PREMISE] Consequently, given only what is going on “in Smith’s head”, there is no reason to say that Smith believes that water quenches thirst. Thus, even if Smith has a complete knowledge of what is going on in his head, he doesn’t necessarily know that he believes that water quenches thirst.
       In light of a correct understanding of statements like “Smith believes that water quenches thirst”, it is clear that we don’t have any special knowledge concerning our own mental states. Content-externalism is consistent with this, and should therefore be commended, not rejected. 
           
Evaluating Davidson’s argument 


           Smith’s relation to the proposition water quenches thirst is not comparable to the relationship between my weight and the number 195. In the one case, we are dealing with an arbitrary convention (or, more accurately, with a non-arbitrary consequence of an arbitrary convention). In the other, we are dealing with a fact that has nothing to do with convention. Not many authors deny this. But even though Davidson’s view is not widely accepted, it is worthwhile to state explicitly why his view is wrong and what is wrong with his argument for it. 
         People are usefully described as having attitudes towards propositions. Why isn’t the same true of rocks and trees? The obvious answer is: “rocks and trees don’t have attitudes towards propositions; people do have such attitudes.” But this is exactly the position that Davidson is attempting to refute. 
         And there is much to be said for that position. If you subtract the representational from the mental, not much is left. Indeed, according to one school of thought, known as “intentionalism” 666, nothing mental is non-representational. Even phenomenal content is representational: given a difference in phenomenology, there is a difference in representational content. 
        I myself think that this is an overstatement. For reasons I have given elsewhere[116], I think that there are mental entities that are either non-representational or only derivatively representational. But what is indisputable is that representationality is a pervasive feature of the mental. It is also indisputable that non-derivative representationality is a sufficient, if not a necessary, condition for mentality xxx.
         Supposing that Davidson is right, there must be some way of identifying and describing mental phenomena that does not involve the concepts of belief, desire, and so on. But this doesn’t seem to be the case. Given that the concepts mental and non-derivatively representational are virtually interchangeable, it makes questionable sense to say that there could be a viable description of psychological reality that didn’t use concepts such as representation and proposition. Where human subjects are concerned, there doesn’t seem to be a neutral subject-matter that we may or may not choose to describe in terms of concepts like desire, fear, and so on.[117] Davidson’s argument assumes otherwise and is therefore fallacious. 
         One might make the following objection to this last point: 


         When we use terms like “belief” and “doubt”, we are describing what are in fact  neural events in mentalistic terms; and when we use terms like “glial cell” and “c-fiber stimulation”, we are discussing those same events in non-mentalistic terms. So contrary to what you say, there is a neutral subject-matter that may or may not be described in mentalistic terms. 


      
        In fact, Davidson himself makes this very point in his essay “Mental Events.”[118] There Davidson says that “events are mental only as described.”[119] The idea is that, just as a person may be described as a lawyer or father or soccer coach, so an event may be described as a pattern of electrical stimulation or as a surge of fear. Supposing that this is right, it seems to follow that psychological statements organize data that could just as well be organized in completely non-psychological terms. And it is exactly this view that underlies that Davidson’s views on self-knowledge.  
          But this line of thought is misguided, as a story may help show. I am suddenly overwhelmed by a number of complex feelings. I attempt to articulate them. (I say “I now realize that I should have become an actor, and that my decision to work on Wall Street -- though socially respectable and seemingly indicative of a mature acceptance of life’s exigencies -- was ultimately an attempt to avoid confronting the question that has been  haunting me since the age of five, to wit…”) Let S be the statement that results. Let us suppose that S is accurate. 
         Later that day, I am watching a film of the brain-event that realized the just described mental event. (That brain-event was recorded by a micro-camera inside my cranium.) I describe what I see, using the appropriate neuro-physiological terms. Let S* be the statement that results. Let us suppose that S* is accurate.
        The event in virtue of which S is true is identical with the event in virtue of which S* is true. But the data of which S is a correct synthesis is entirely different from the data of which S* is a correct synthesis. S* conceptualizes various visual perceptions of various discolorations on a certain video-monitor. That body of data doesn’t even overlap with the body of data conceptualized by S. There is no neutral data of which both psychological and non-psychological syntheses are possible.   
          A pang of remorse may be identical with some series of neural events. But the data correctly synthesized by a verbal expression of remorse is entirely different from the data correctly synthesized by any statement of the form ┌neural events of type PHI are now occurring.┐ Even though I have unexceptionable grounds for saying “I now feel terrible remorse over stealing my sister’s cookie”, I may have no grounds for making any statement involving terms like “neuron” and “glial cell.” So statements of the first kind do not organize data that is also correctly organized by neurological statements or, given obvious extensions of this reasoning, by non-psychological statements of any kind. 
        One last example. 666 Suppose that it is in virtue of the occurrence of neural events x, y, and z that I feel sad about Smith’s departure. The statement “I am sad about Smith’s departure” constitutes a correct synthesis of certain data. The statement “neural events x, y, and z are occurring” constitutes a correct synthesis of a very different body of data. (In the second case, but not the first, the data result from my doing, or at least learning about, various physiological researches.) Even though there is some event that is both psychological and neurological, there is not some one body of data that can be described in either neurological or psychological terms. 
        Given only that mental events are realized by neurological events, it doesn’t follow that the data organized by mentalistic statements can be organized by neurological or otherwise non-mentalistic statements. A failure to see this underlies Davidson’s view that psychological statements provide a way of organizing data that could in principle be organized along completely non-psychological lines. 
           This failure is indicative of a confusion that pervades Davidson’s analysis. Obviously Davidson is right to distinguish between the thing studied and our methods of studying it. We may use a blue tincture to stain some organelle, so as to make it easier to observe; and it would obviously be foolish to conclude on that account that the organelle was really blue. But concepts are not instruments. When I use a magnifying glass to look at an insect, I am interested in the insect, not the magnifying glass. The magnifying glass helps me generate the relevant data; but no fact about the microscope is itself a constituent of that data.[120] By contrast, when I talk about Bill’s fear of heights, I am not using the concept Bill’s fear of heights to identify some datum that XXX lies on the other side of that concept. The concept is a constituent of the data.  
         To be sure, the concepts that we use are not always constitutive of the data being studied. The phenomenon of heat is understood in terms of the concept molecular motion. But the latter concept is not constitutive of the data that a theory of heat must model. That is why one can grasp the concept of heat without grasping the concept of molecular motion. But the concepts that Davidson is discussing – belief, intention, doubt, and so on  – seem to be constitutive of the data that a psychological theory must model. I may or may not choose to understand Bill’s aversion to public places in terms of the concepts excessively punitive super-ego and conversion reaction. But if I eschew the concept fear of being in a public place, I obliterate the very data that I am trying to understand.[121] [122]
        
 
Why content-externalism should accept that it is inconsistent with our pre-theoretic intuitions about self-knowledge 


       It is ill-advised for proponents of content-externalists to attempt to reconcile that doctrine with our intuitions about self-knowledge. This is because content-externalism nearly enough is a denial that such intuitions are correct. 
       I look at Venus in the morning and sincerely say “that is lovely.” I look at Venus in the evening and sincerely say the same thing. But I don’t know that I was looking at the same thing on both occasions. 
        The content-externalist says that there is some one proposition such that I was sincerely affirming that proposition on both occasions. More explicitly, there is some x such that, on each occasion, I believed and affirmed the proposition: x is lovely. It is a datum – one that content-externalists don’t deny – that, under the circumstances described, I need not know this last fact. So the essence of  content-externalism nearly enough is that one doesn’t know what one is thinking. It would therefore seem ill-advised for content-externalists to try to show that their doctrine validates our intuitions about self-knowledge. 
        We can corroborate this by modifying the story just told. Consider a scenario that is just like the one just described, except in this one respect: In the evening, I sincerely say “that is not lovely.” According to this content-externalist, there is some x such that in the morning I believe the proposition x is lovely, and such that in the evening I believe the proposition x is not lovely. 
       It is a datum that, given only what we’ve just said, I am not necessarily guilty of irrationality – I am surely not to be compared with someone who sincerely says “I believe that Smith is French and that Smith is not French.” Most content-externalists admit this.[123]
      At the same time, it is clear that I would be guilty of irrationality if knew that, for some x, I was sincerely affirming x is lovely and also x is not lovely. So if content-externalism says that I xxx know with Cartesian certainty what it is that I am believing, then that doctrine is forced to part with the datum that I can coherently affirm both “that [pointing to Venus in the morning] is lovely” and also “that [pointing to Venus in the evening] is lovely.” So it is in that doctrine’s interest to ensure that our pre-theoretic claims about self-knowledge are wrong. 
       Also, although I myself believe that content-externalism is incorrect, I don’t think that, by itself, its irreconcilability with our pre-theoretic claims about self-knowledge is particularly to its discredit. Content-externalism says that there can be cognitive hallucinations in much the same way that there can be perceptual hallucinations. If the man I am “seeing” doesn’t exist, then I am not seeing a man and I am, to that extent, failing to have a perception at all. Perception decomposes into a psychological and non-psychological component: xxx there is no perception if either is lacking. Nobody regards it as puzzling that I can be wrong about who or what  I am seeing. I think that I am seeing Fred when I am actually seeing his twin. The fact that one can be wrong about the identity of what one is seeing is a straightforward corollary of the fact that perceptions have a non-psychological component. 
       Content-externalism plausibly (though incorrectly) says that, in a respect xxx similar to that just described, thoughts are like perceptions. A thought has both a psychological and a non-psychological component. If either is lacking, there is no thought. A corollary is that one can be wrong about the identity of what one is thinking. In any case, if we deny that this is a corollary, then we destroy the parallel with perception that forms the heart of content-externalism. 
         So the content-externalist’s best bet is to say that “think” is in the same category as “perceive” and that, consequently, one is no more authoritative with respect to the identity of what one thinks than one is with respect to the identity of what one perceives. 


Chapter 11 Why one’s mental content is fixed by one’s epistemic situation  


        If content-externalism is right, then two people who are in epistemically identical situations can have thoughts (or perceptions) with different contents. I am having a thought that has Smith as a constituent. But it is epistemically possible that I am having a thought that instead has Twin-Smith as a constituent. 
       In this chapter, I wish to argue that this is incoherent. To say that it is epistemically possible that I am thinking about Twin-Smith is to say that, given only the data at my immediate disposal, it cannot be ruled out that I am thinking about Twin-Smith. To say xxx that this isn’t ruled out by the data at my immediate disposal is to say that it isn’t ruled out by my mental content. So two people are in epistemically identical situations just in case their mental states have the same contents. I would now like to develop the argument just outlined. 
     The essence of content-externalism is this: 


(1) Given two people who are exactly the same, leaving aside facts about their respective environments, what the one believes may differ from what the other may believes.


This is equivalent with: 


(2) Given two people who are in different environments, what the one believes may differ from what the other believes, even if the two are in identical epistemic situations. 


X and Y are in identical epistemic situations iff, for any proposition P,  the grounds that X has for believing P are identical with the grounds that Y has for believing P.  
       (Actually, it would probably be even more accurate to say this: X and Y are in identical epistemic situations iff, for any truth or falsehood P, the grounds that X has for believing P are identical with the grounds that Y has for believing P. This definition, unlike the previous one, doesn’t involve the controversial (and, I will argue, false) view that all truths and falsehoods are identical with propositions – this is a topic we will discuss at length in chapters 22 and 23. But, in this context, solely for the purposes of brevity, we will use the term “proposition” as a shorthand for “truth or falsehood” or “piece of information.”)
          X has the same grounds as Y for believing some proposition P iff what X already believes has the same bearing on P as what Y already believes. For you to have good grounds for believing that somebody stole your car is for the propositions in which you already believe to have a certain relation (some kind of confirmation-relation) to the proposition somebody stole your car.  So X and Y are in identical epistemic situations exactly if, for any proposition P, the propositions in which X already believes stand in precisely the same relationship to P as the propositions in which Y already believes. Thus (1) is equivalent with: 


(3) Given two people who are in different environments, what the one believes may differ from what the other believes, even if, for any proposition P, the propositions in which the one already believes stand in precisely the same relationship to P as the propositions in which the other already believes. 


In order for the propositions in which X believes to bear on any proposition P in precisely the same way as the propositions in which Y already believes, it is necessary that X and Y believe precisely the same propositions.  
       Before closing the argument, there is a fact relating to the concept of analyticity that we must point out. Even if the propositions that X believes are analytically equivalent with the ones that X believes, there may still be some proposition P such that the exact way in which the former bear on the latter will differ from the way in which the latter bear on the latter. Suppose my one belief is that 1+1=2 and that your one belief is that each thing is self-identical. Of course, for any proposition P, the one proposition in which I believe entails P iff the same is true of the one proposition in which you believe. But the exact way in which the one proposition bears on  for some n, n+1=2 will obviously be very different from the exact way in which the other bears on that proposition. A derivation of for some n, n+1=2 from the one proposition will be extremely straightforward; in the other case, such a derivation will be extremely circuitous. In any case, those derivations will differ. Given obvious extensions of this reasoning, it is clear that if, for any P, X’s beliefs are to have exactly the same bearing on Y’s on P, X and Y must have precisely the same beliefs. So X and Y are in the same epistemic situation exactly if they have exactly the same beliefs. 
       Given what was said in the last paragraph, it follows that (3), and therefore (1), are equivalent with: 


(4) Given two people who are in different environments, what the one believes may differ from what the other believes, even if, for any proposition P, the propositions in which the one person 666 already believes are identical with the propositions in which the other already believes. 


But (4) is a blatant self-contradiction. It says that two people who believe the very same thing may not believe the very same thing. So content-externalism is given by a self-contradictory proposition. 
     To break this argument, the content-externalism would have to go down one of three paths. Either he 666 must deny: 


(A) for X and Y to be in epistemically identical situations is for X and Y to have the same beliefs, 


or he must deny: 


(B) rationality consists in seeing the bearing of propositions on other propositions (or, more generally, of information on other information), 666 [REMOVE THIS PREMISE?]


or he must deny: 


(C) Given only that X and Y are atom for atom duplicates, and that the mental supervenes on the physical, it follows that they are in epistemically identical situations. 




Indeed, a content-externalist might defend his denial of (C) on the following grounds: 


    
    Somebody who is in a world where there is ABC instead of H2O, but is otherwise just like you, is ipso facto in an epistemically different situation from you. Indeed, this is the essence of content-externalism; and in denying it, you have simply begged the question. 


     In fact, the position just stated is similar to one that McDowell (1998: Chapters 10-13) holds. 
       But each of (A)-(C) is a datum. Under the circumstances described in (C), X has no better reason than Y for believing that he is in an H2O world than Y, and Y has no better reason than X for believing that he is in an ABC-world. You are in an H2O world. Imagine a counterfactual scenario w such that, in w, you are in an ABC-world, but are otherwise exactly as you are now. So in w, you believe that you are in H2O world. Of course, that belief is wrong. But is it less rational than your actual belief that you are in such a world? Of course not. Your sensory surfaces are disturbed in exactly the same way as his. So the one set of disturbances cannot possibly differ from the other in respect of the extent to which it warrants a given belief. So for all the one knows, his condition is in fact identical with the others. In other words, the one person’s condition is epistemically just like the other’s. 
      Let us turn to (B). We must note that the content-externalist does (implausibly) deny (B). As we’ve seen, he says that, for some x, one can rationally believe x is lovely and x is not lovely. So it might seem that, in assuming (B), we have simply begged the question against the content-externalist.  But we have provided independent support for (B). 
       But have we begged questions in assuming (A)? The essence of content-externalism is that, even if X and Y are otherwise the same, differences in their environments amount to differences in what they believe and, therefore, to differences in their epistemic situations. So, it seems, our use of (A) begs the question.
        I would like to rebut this. According to the content-externalist, whenever X has a belief that is object-dependent with respect to H2O, Y has a belief that is object-dependent with respect to ABC. But the content-externalist will not say that X and Y differ in all of their beliefs. If X thinks 1+1=2, so does Y. They differ only with respect to a certain sub-class of their beliefs. Their beliefs diverge only when those beliefs are object-involving with respect to those features of their environments that are not common to both worlds. Since not every belief that one has is object-involving with respect to one’s environment, X and Y share some beliefs. 
        What is the nature of these shared beliefs? Every pro-externalist argument begins with something like the following: “Suppose that, in w, the relatively clear stuff that comes out of faucets and flows in rivers…is ABC, not H2O.” So, by the content-externalist’s own hypothesis, they both have the existential belief: “there is some relatively clear stuff x that comes out of faucets and flows in rivers and…” 
        In general, there is no way to motivate any pro-externalist argument without imputing a common core of existential belief to the doppelgangers in question. Consider Burge’s classic (1979) argument. In Smith’s world, “arthritis” refers to a disease of the joints. In Smith*’s world, it refers to some other disease, namely arthritis*, that doesn’t affect joints alone, but is otherwise just like arthritis. Apart from this difference, Smith and Smith* are exactly the same. Burge concludes that where Smith believes aspirin relieves the pain caused by arthritis, Smith* has the belief aspirin relieves the pain caused by arthritis*. 
       As Burge himself clearly sees, if this argument is to be cogent, it must be assumed that Smith and Smith* are both cognitively normal, linguistically competent, and so on. In order for somebody to know what an expression means, he must be in command of a rich body of knowledge. If it is a syntactically simple expression, he must have encountered certain occurrences of that term. If it is syntactically complex, he must have a command of the relevant features of his language; and this command in its turn presupposes that he already have a great deal of knowledge about his environment. So if either of Smith or Smith* lacks vast stores of knowledge, then neither will have any idea what is meant in his world by “arthritis”, rendering vacuously false any attempt to show that their respective usages of these expressions mediate different thoughts. 
       Further, the one person’s pre-existing knowledge must coincide, or at least overlap, with the other’s. Suppose that either of Smith or Smith* doesn’t know that there is some disease x such that x causes pain in one’s joints and is referred to as “arthritis.” In that case, as we just saw,  nothing resembling Burge’s thought-experiment is possible. Burge’s experiment thus presupposes that the descriptive beliefs through which Smith locks onto arthritis coincides with the descriptive beliefs through which Smith locks onto arthritis*. So in assuming, as xxx he must, that Smith’s epistemic situation is identical with Smith*’s, Burge is demanding that what Smith believes is identical with what Smith* believes. So Burge’s argument requires the truth of (A). The same is true of all pro-externalist arguments, and we thus haven’t begged any questions in assuming (A). 
       We may conclude xxx that content-externalism is given by a self-contradictory proposition: If X and Y are in qualitatively different environments, then what X believes may differ in content from what Y believes, even if X and Y are in epistemically identical situations, i.e. even if what X believes is identical in content with what Y believes. More simply: people who have exactly the same beliefs may, in virtue of that very fact, have different beliefs.   
       Let us illustrate this point by extending Burge’s thought experiment  Apart from the medical problems previously described, both Smith and Smith* are in perfect health. Also, each of Smith and Smith* knows himself to be the only person in Cleveland (or, at any rate, in his world’s version of Cleveland) whose phone number has four consecutive digits in it. 
       In light of this, suppose that Burge is right. In that case, there is some x such that x is a disease that affects only the joints, and Smith has singular belief: 


(S) there is exactly one person in Cleveland whose phone number has four consecutive digits in it, and that person has x and has no other diseases. 


And there is some y such that y is a disease that y doesn’t affect only the joints, and Smith* has the singular belief: 


(S*) there is exactly one person in Cleveland whose phone number has four consecutive digits in it, and that person has y and has no other diseases. 


     S and S* are incompatible. There is no possible world where they are both true. But apart from this belief in S, Smith’s epistemic situation is, by hypothesis, identical with Smith*’s. So the beliefs that Smith has apart from his belief in S are identical in content with those which Smith* has apart from his belief S*. 
       It is clear that Smith believes S in virtue of his having those other beliefs, the same being true mutatis mutandis of Smith*. So if, as Burge supposes, Smith believes S, that is in virtue of the fact that has various other beliefs, e.g. the belief that there is some painful malady x such that x is referred to as “arthritis” and I have been told that I have x. There is no possible world where Smith just believes S. A belief in S necessarily presupposes some more fundamental belief, such as the one just described. 
      That is why, in preparation of his thought-experiment, Burge himself takes pains to ascribe certain beliefs to both Smith and Smith*: they both have certain beliefs about language, about their own phenomenal states, about what physicians have said about how to ameliorate those states, and so on. As Burge surely knows, it would make little sense to say that Smith’s belief in S occurred in a vacuum of other beliefs. This is surely because those other beliefs are constitutively related to Smith’s beliefs about his medical situation. But that is very close to saying that he has the latter beliefs in virtue of having the former.   So it seems that, if Burge is right, two people have incompatible beliefs in virtue of having the very same beliefs. 
       To block this, Burge would have to say that it is not solely in virtue of having these various other beliefs that Smith believes in S, or that Smith* believes in S*. So even though Smith and Smith* share existential-descriptive beliefs like there is some malady x called “arthritis” that leads to excruciating joint-pain…their having these other beliefs is not the sole reason why they believe in S and S*, respectively. There is, Burge would maintain, an irreducible, causal component; and it is that purely causal, entirely non-descriptive component that makes all the difference. 
         The problem is that this causal connection operates by way of knowledge that Smith and Smith* have of the already discussed existence-claims. For example, suppose that having never before heard the term “arthritis”, or any synonym, Smith’s doctor says to him: “you are suffering from a disease known as ‘arthritis’, and that is why you are experiencing pain and stiffness in your joints.” In virtue of hearing this, Smith is indeed causally connected to an ailment (or, at least to instances thereof) to which Smith* is not connected; and, in virtue of having a corresponding experience in his world, Smith* is causally connected to a different ailment. But whatever causal connection Smith has to arthritis that Smith* lacks, that connection obviously operates by way of sense-perceptions of the sort just described,  and thus by way of Smith’s intake of purely existential information. It would make no sense to say that, apart from such perceptions, Smith had any kind of relevant causal connection to instances of arthritis. (Of course, exactly similar remarks apply to Smith*.) So once we take into account their purely descriptive beliefs, we have already fully taken into account any relevant causal connections to external objects that Smith and Smith* might have. There is no causal connection over and above descriptive beliefs to account for the supposed fact that Smith and Smith* have different thoughts.
       Thus, if we accept Burge’s belief in that supposed fact, then we are forced to say that they have different thoughts in virtue of having the very same existential-descriptive thoughts. But such a position, it may safely be said, could only be described as highly arbitrary. 
       
The debate between externalism and internalism not terminological 


      One might think that the debate between externalism and internalism is just a matter of nomenclature. We can choose to let the word “perception” refer either to a certain kind of purely psychological phenomenon or only to successful occurrences of that phenomenon. Similarly, we can choose to use the word “thought” to refer either to a purely psychological phenomenon or only to successful instances of that phenomenon. The externalist chooses the one option; the internalist chooses the other. 
       This is not a tenable position. A veridical perception decomposes into a purely psychological part and a non-psychological part. As we’ve seen, the non-psychological part is what is described by the purely psychological part. That is why the purely psychological part would have been a failure if the non-psychological part hadn’t existed.  
       Similarly, if thoughts decomposed into a psychological part and a non-psychological part, then the psychological part of a thought would be something which would be a failure if the non-psychological part didn’t exist, the reason being that non-psychological part would be what was described by the purely psychological part. So in order for thoughts to decompose into a psychological part and a non-psychological part, the purely psychological part must itself be a thought; it must itself be true or false. But this means that the thought would be purely psychological, and that what we were just describing as the non-psychological part of the thought wouldn’t be a part of the thought at all, and would instead be what made the thought true.   


Chapter 12 Jackson and Pettit on program-causality and content-externalism 


         Content-externalism is incompatible with the presumption that, in virtue of having such and such representational properties, a brain-state has causal properties that it would not otherwise have. In any case, this is what we have argued. McDowell (Evans 1982: 203-204) tried to show otherwise. But Fodor (1987b) showed quite conclusively that McDowell’s argument is a non-starter; and Fodor’s counter-argument provided positive support for the thesis that McDowell was attempting to refute.  
        But there is an argument for that thesis that is far more powerful than any thus far considered. That argument is due to Frank Jackson and Phillip. Working jointly, those authors have produced an original and compelling analysis of the concept of causal explanation. And they have argued that, given this analysis, there is no difficulty reconciling content-externalism with our presumptions concerning the causal potency of the mental. 
       I should begin by stating my position. I believe that what Jackson and Pettit say about causal explanation in general is important and correct and cogently argued. But, I will argue, the same cannot be said of their attempt to use these correct and deep insights to rescue content-externalism. In their attempt to save content-externalism, Jackson and Pettit have misapplied their own correct views.
      Jackson and Pettit have also attempted to use their insights into causation to defend functionalism against what appears to be a devastating objection to it. We will find that, once again, Jackson and Pettit have misapplied their own insights into causation; and we will also find that the aforementioned criticism of functionalism is in fact cogent. 




Why functionalism seems to be  incompatible with the causal potency of the mental 


         We have already seen why, supposedly, content-externalism is incompatible with the causal potency of the mental. So let us discuss why the same appears to be true of functionalism. 
       It will help if we begin by focusing on the fact that it is states of affairs, not objects, that have causal properties. The rock didn’t break the window. What did do was the rock’s having various properties, e.g. its having a certain mass and moving a with a certain velocity. Similarly, it is not brain-state β that does any causal work – it is brain-state β’s having such and such thermal (or morphological or electrical or representational or syntactical…) properties that does so. 
        Let B be the brain-state (or structure or series of events…) that realizes Smith’s belief that 1+2=3. According to functionalism, B realizes that belief entirely in virtue of what its causes and effects are. So B qualifies as such a belief because circumstances at least approximately like the following hold. Given that Smith already believes that 3 is an odd number, B’s existence leads Smith to believe 1 and 2 add up to some odd number. Given that Smith already believes that Jones has one car, and two motorcycles, and no other motorized vehicles, B’s existence lead Smith to believe that Jones has exactly three motorized vehicles. Given that Smith already believes that three is the successor of two, and that adding one to a number is the same as generating its successor, Smith (an English-speaker) says “three” when asked “what is 1+2?” 
        Of course, given only what we have said about Smith, he needn’t have a belief that 1+2=3. Smith’s possession of the dispositions just described could be explained without imputing such a belief to him. A closely related point is that Smith’s belief that 1+2=3 is not exhausted by his having just those three dispositions. But the idea behind functionalism is that Smith’s belief is exhausted by those three dispositions plus a large number of other dispositions of a similar kind. 
        According to functionalism, B’s being a belief that 1+2=3 is identical with its having a certain functional role. So B’s being such a belief consists in (inter alia) its leading Smith, under the right circumstances, to forming the belief that 1 and 2 add up to an odd number; it consists in  its leading Smith to forming the belief that Jones has three motorized vehicles. 
       If B’s being such a belief consists in its leading these states of affairs, then it cannot cause them to occur. But it is quite obvious that, under the right circumstances, B’s belief that 1+2=3 is a cause of his forming the belief that 1 and 2 add up to an odd number and that, under the right circumstances, it is a cause of B’s being a belief that Jones has three motorized vehicles.
        Another illustration may help. xxx You see a glass of water. Because you are violently thirsty – so thirsty that you no longer have any concern for matters of decorum and social propriety -- you grab the glass and drink its contents. B is the brain-state of yours that realizes your being in a state of thirst. Surely B’s being (or realizing) a state of thirst is at least one of the causal determinants of your grabbing the glass and drinking its contents. 
     But functionalism says that B’s realizing a state of thirst consists in its leading to your grabbing the glass; it says that B’s realizing such a state is constituted by its leading to such a state. Cause and effect must be distinct; no state of affairs causes itself or any constituent of itself. So B’s realizing a state of thirst cannot possibly be constituted by or consist in its leading to your reaching for the glass. Therefore functionalism is wrong,  given that B’s being a state of thirst obviously does (or at least could) cause you to reach for the glass. In general, by identifying content with functional role, functionalism strips content of the power to have any effect on functional role. 
       Functionalism says that, if B has the right consequences, then it is a desire for water (or a belief that 1+2=3…) This sounds perfectly reasonable, and it seems consistent with the fact that content is causally potent. 
       The problem is that it is meaningless to say that B does anything. What has causal consequences is not B. It is B’s having a certain morphology or temperature or representational content…(The rock doesn’t do anything. It is the rock’s having a certain mass and moving with a certain velocity that has causal consequences.) 
      Given this, functionalism becomes the position that B’s being a state of thirst (or belief that 1+2=3….) is identical with B’s leading to certain events (your reaching for the glass, your realizing that Smith has a certain number of cars…). But if B’s being a state of thirst is identical with these subsequent thoughts and behaviors, then it cannot cause them. 
      The moment we register the fact that it is B’s having this or that property, and not B simpliciter, that has causal powers, functionalism is revealed to strip the mental of its causal potency. 
               
The Jackson-Pettit response: causal relevance versus causal efficacy 


      Jackson and Pettit (2004, 2004c) argue that, despite the criticisms just made, content-externalism and functionalism are consistent with the presumption that the mental is causally potent. Let us now consider what Jackson and Pettit say. 
       Consider the following statement: 


(*) Pan P is hot at time t because, for the ten minutes preceding t,  there was a flame underneath P. 


Let us suppose that, in world W,  (*) describes an actual causal relationship, i.e. let us suppose that (*) is as true a causal statement as a lay-person (someone who has not mastered the subtleties of micro-physics) will ever produce. W is governed by the same physical laws that govern our world. (W may even be our world.) 
        Granting all of this, it was not, strictly speaking, the flame that caused the pan to heat up. It was not even the flame’s having a certain temperature. The only events that really did any work in the way of heating up the pan were various mass-energy displacements at, or vanishingly close to, the relevant surface of the pan. Let M1…Mn be the mass-energy displacements at the point of contact between the flame and underside of the pan. Now consider a scenario W* that is just like W, with just one difference: in W*, the flame in its entirety is absent except for M1…Mn. In W*, the pan will have he very same temperature that it has in W. It seems, then, that the flame didn’t do anything, except in so far as it comprised M1…Mn. This seems equivalent to saying that it was M1…Mn, and the flame, that heated the pan. If this is right, then (*) is false. 
        Leaving aside the causal statements made by a few microphysicists, what we just said about (*) is true mutatis mutandis of every causal statement has ever been uttered. Consider the statement: 


(**) Because it is square shaped, the peg could not fit into the round hole.[124] 


Suppose that (**) holds in world W, where W is governed by the same laws as ours. As Jackson and Pettit point out, it was not the squareness of the peg that prevented it from entering the whole; it was specific resistances generated by specific interactions of specific parts of specific surfaces. In order for those resistances to be generated, it isn’t necessary that the peg be square. The corners of the peg are not, in this context, doing anything: if we sawed them off, the peg still wouldn’t go into the hole (assuming, of course, that we sawed off only modest amounts); we’d be left with a heptagon that would fail to go into the hole for the very same reasons as the square. The forces that prevent the peg from entering the whole are invariant xxx with respect to infinitely many different possible alterations of the pegs shape and size, so long as those alterations fall within certain limits. Thus, it seems false to say that the peg’s squareness is what prevented it from entering the whole. Rather, what we must say is that specific forces (or mass-energy displacements or…) F1…Fn, occurring at contact points C1…Cm, are what prevented the peg from entering the whole. 
         But surely it wouldn’t be right say, without qualification, that (*) and (**) were false. It is a datum that (*) and (**) are (or can be) true. Leaving aside the utterances of a few microphysicists, not a single causal statement produced by anyone contains any mention of anything comparable to M1…Mn. If it is a datum that true and informative causal statements are almost always given by statements like (*) and (**); and, notwithstanding the points made a moment ago, it is therefore not an option to say, without some kind of heavy qualification, that they are false. 
              One last example. The pressure of the gas inside the container xxx is increased (because that gas is heated). The container subsequently bursts. What caused the vessel to burst was not, strictly speaking, the gas’s having (or suddenly acquiring) a certain pressure. Ultimately it was specific impacts of specific particles on specific parts of the surface of the container that led to the bursting of the vessel. Given a counter-factual scenario where those specific impacts occurred, but where the container was otherwise empty of gas, the container still would have burst. Given this, it seems that it is false to say that the gas (or the gas’s having a certain pressure) is what caused the vessel to burst. The gas’s having that pressure was completely innocuous, except in so far as it comprised the specific collisions just mentioned. At the same time, there is clearly some sense in which the gas’s pressure is responsible for the bursting of the vessel. If I say: 


(***) the container burst because the walls of the container couldn’t withstand the pressure put on them by the gas inside, 


   my statement is not in the same category as “the container burst because elves used their telepathic powers to make the container explode.” How is the putative truth of (***) to be reconciled with the fact  it was certain specific collisions K1…Kn, and not the gas’s pressure per se, xxx [comma inserted] that ruptured the vessel? How are the truth of (*) and (**) to be reconciled with the fact that, strictly speaking, it was E1…En and F1…Fn, and not the flame or squareness of the peg per se, that heated the pan and prevented the peg from entering the hole? 
        Jackson and Pettit deal with this problem by distinguishing between what they call “causal efficacy” and what they call “causal relevance.” It must be kept in mind that these are neologisms that are to be understood strictly in terms of the definitions that Jackson and Pettit provide. Their pre-existing meanings are to be set aside (except in so as those coincide with the meanings given to them by Jackson and Pettit). In connection with this, Jackson and Pettit distinguish between what they call “program causes” and what I will henceforth refer to as “effective causes.” (The term “effective cause” is my term. A state of affairs E is an “effective cause of” of E* iff E is causally efficacious with respect to E*. Any similarities between my use of the term “effective cause” and Aristotle’s are unintended and are to be disregarded.) Let us now define these terms – or, in any case, let us illustrate their meanings. 
         Consider statement (*). Events E1…En are causally efficacious with respect to the heating  of the pan. They are causes of the heating of the pan in the strictest possible sense. As we discussed, the flame itself is, from some viewpoint, quite inert as regards the heating of the pan, except in so far as it comprises E1…En. But, as we also pointed out, there is plainly a sense in which (*) is true; there is plainly a sense of the word “cause” in which the flame (or, more precisely, it’s having such and such properties) is a cause of the heating of the pan. The flame (or, rather, its having such and such properties) is, as Jackson and Pettit put it, “causally relevant” to the heating of pan. If one event is causally relevant, in the relevant technical sense of that expression, to another, then the first “programs for” the second or, equivalent, the first is a “program cause” of the second. So the flame is the “program cause” of the heating of the pan. Events E1…En are the “effective causes” of the heating of the pan. 
         Let us consider statement (**). F1…Fn, occurring at contact points C1…Cm, are what prevent the peg from entering whole. But it is a datum that (**) is (or could be) a true causal statement. If you ask me “why isn’t the peg going into the whole?” and I say “because the peg is square, and the xxx hole is round”, what I have said is not in the same category as “because the square is green and green objects are physically incapable of entering apertures of any size.” The squareness of the peg is causally relevant to its not being able to enter the hole; the former programs for, i.e. is the program cause, of the latter. F1…Fn, on the other hand, are the effective causes of the peg’s not entering the hole, i.e. the former are causally efficacious with respect to the latter. 
        The gas’s exerting a pressure on the walls of the container is causally relevant to, i.e. programs for, the rupturing the container; collisions K1…Kn are the effective causes of the rupturing of the vessel, i.e. they are “causally efficacious” with respect to that event. 


Precisifying the terms “program cause” and “effective cause”


           These remarks help to make it clear at an intuitive level what is meant by the terms “program cause” and “causally relevant.” Let us now try to convert that intuitive understanding into an explicit definition. 
        Although the flame per se is not causally efficacious with respect to the heating of the pan, the existence of the flame guarantees the occurrence of events that are thus efficacious. Let W^ any counterfactual scenario where E1…En do not occur, but that is otherwise just W (the world where (*) is true). Of course, in W^, the flame exists, and the relation that it bears to the pan in that world is comparable to the relation that it bears to the pan in W. Thanks to the existence of the flame, the pan will be heated in W^: it is guaranteed that, in W^, some micro-events will have the effects on the pan that, in W, are generated by E1…En. Under the circumstances, the flame’s presence thus programs for the heating of the pan: it constitutes a structure that, under the circumstances, renders inevitable the heating of the pan. Equivalently, the flame’s presence is causally relevant to the heating of the pan. (Remember that, in this context, the term “causally relevant” is being used in a neologistic sense.) 
     Analogous remarks apply to each of the scenarios discussed. Although the squareness of the peg per se is not efficacious with respect to the peg’s resisting being put in the hole, the squareness of the peg guarantees the presence of forces that are thus efficacious. Given any world where F1…Fn (the forces that, in actuality, prevent the peg from entering the hole) are absent, but is otherwise just like our world, the fact that the peg is square guarantees that some forces will prevent the peg from entering the hole. The squareness of the peg constitutes a structure that, under the circumstances, prevents the peg from entering the hole, even though this outcome is not generated by the squareness of the peg per se. 
       Under the circumstances, it is inevitable that the container will burst, given that the gas inside is exerting such and such a degree of pressure on its walls. The gas’s having  that pressure guarantees that, even if K1…Kn specifically are absent, some collisions or other will cause the container to rupture. Under the circumstances, the gas’s having that temperature programs for (or, equivalently, is causally relevant to) that outcome. 


How Jackson and Pettit apply the distinction between efficacy and relevance


     Let us now discuss how, given the distinction between causal relevance and causal efficacy, Jackson and Pettit attempt to show that content-externalism is in fact compatible with the presumed potency of the mental. Let W be our world, and let W* be a world that is just like ours except that it contains XYZ as opposed to H2O. In W, I see a glass of water (H2O) and, being thirsty, I decide to drink its contents. In W*, I see a glass of XYZ and, being thirsty, I decide to drink its contents. The content-externalist says that  the contents of my perception and subsequent intention in W are different from the contents of my  perception and subsequent intention in W*. In W, I see, and wish to drink, a glass of H2O. In W*, I see, and wish to drink, XYZ.  
      Here is what the internalist says in response. What does all the work is what is spatiotemporally local. What is remote does no work, except in so far as it leads to the right local states of affairs. So what is in the glass is irrelevant to what I think or do, except in so far as it leads to the right local events. Equivalently, given the right local events, it is irrelevant, so far as the generation of my ideation and conduct are concerned, what remote states of affairs obtain (or used to obtain). Thus, in so far as mental state’s content is a function of what is remote, its content is inert; a mental state’s content is not inert only in so far as that content is a function of what is local. Mental content does nothing, and thus has no effects, in so far as the content-externalist’s conception of it is correct. Given that mental content does have effects, the content-externalist’s position must be wrong. 
      Jackson and Pettit counter-respond by saying that this argument fails to distinguish between causal relevance and causal efficacy. My thinking about H2O is not causally efficacious with respect to forming an intention to drink the contents of the glass. But given that I am thinking about H2O, it is guaranteed, under the circumstances, that I will form that intention. True – my thinking about H2O does not supervene on what is local (intra-cranial). True – what is causally efficacious is confined to what is local. But it doesn’t follow that my thinking about H2O isn’t causally relevant to what I think and do. Just as the presence of the flame beneath the pan guarantees that the pan will be heated, so my thinking about H2O guarantees that I will generate an intention to drink from the glass. 
        The relationship between my forming an intention to drink H2O and my subsequent behavior is perfectly comparable, according to Jackson and Pettit, to the relationship between the presence of the flame beneath the pan and the subsequent heating of the pan. Outside the arena of microphysics, the latter is as robust an instance of a causal relationship as we will ever find. The same is therefore true of the first of the former relationship, given that the two relationships are comparable. So content-externalism by no means belittles the causal potency of the mental. 
       Remember our story in Chapter 1 about Max and twin-Max. Here is what Jackson and Pettit would say about that situation. Given that Max is thinking about R, it is guaranteed that he will think and act in certain ways,  just as, given the squareness of the peg, it is guaranteed that the peg will not enter the hole (even though the squareness of the peg is not causally efficacious with respect to the generation of that outcome). R’s being a constituent of Max’s mental content is as causally relevant to what Max thinks and does. Thus, content-externalism allows mental content to be as causally potent as the squareness of the peg or the temperature of the flame. 


Evaluating the Jackson-Pettit view


         First of all, the distinction between causal relevance and causally efficacy – between program causes and effective causes – is an entirely correct one; and it is, in my view, of the highest importance.[125] Explanation almost always consists in identifying program-causes, not effective-causes; and this is not simply because of we are not always in a position to identify effective-causes. Jackson and Pettit convincingly argue that one is typically given much more predictive, explanatory, and counterfactual information if one finds out what the program-causes of an event are than if one learns what its effective-causes are (Jackson and Pettit 2004d). Their arguments on this matter strike me as cogent, and I have nothing to add to them. 
          But we must regard as fallacious their attempt to show that, given the idea of a program-cause, content-externalism is consistent with the presumed causal potency of the mental. There are several reasons for this. 
           Suppose we want to know whether Max’s thinking about R has any causal powers at all – whether it is xxx either causally efficacious or causally relevant to anything Max thinks or does. Fodor has made it clear that the relevant question is not “given that Max is thinking about R, is there some kind of guarantee that he will do such and such?” Rather, the relevant question is: “given that Max is thinking about R, is there some kind of guarantee that he will do such and such that would be absent if he were thinking about R*?” More simply: “Does Max’s thinking about R have any causal properties that his thinking about R* would not?” The externalist says: “xxx yes – because he is thinking about R, not R*, he has a desire to take a photograph of R, but of R*; he has a surge of joy in response to R’s aesthetic properties, and not in response to R*’s.”
     But that answer, we have seen, is irrelevant. Remember what we said in Chapter 1. I quote:


Magnet A is attracted to magnet B. Magnet B happens to be green. But (ceteris paribus) if B were red or purple or orange, A would still be attracted to it. It is true that, because B is green, A is behaving in a way that it would not behave if B were some other color. (A is drawn towards a green magnet, instead of a red one.) But it doesn’t follow that B’s color has anything to do with A’s behavior. A’s behavior wouldn’t (ceteris paribus) be relevantly different in a world where B were some other color. This shows that B’s being green has no effect on what A does, notwithstanding that, because B is green, A is doing something (namely moving towards a green magnet) that it wouldn’t be doing if B were red. 
         
        For exactly similar reasons, given only that Max has a desire to take a picture of R, as opposed to R*, it doesn’t follow that his thinking about R has any effect on his thought or conduct that this thinking about R* would not. 
        The distinction between causal efficacy and causal relevance is irrelevant here. Ten minutes ago, the pan was cold. Now it is hot. I want an explanation. (To facilitate exposition, let’s suppose that I haven’t yet assimilated the fact that fire heats.)  I consider the various events that preceded the heating of the pan. I put on a green shirt (I was previously wearing a blue one). I played the piano. I turned on the light in the kitchen. I turned on the burner on which the pan was resting. I brushed my teeth. To figure out which of these events was responsible for the heating of the pan, I take a tour all those worlds that are just like this one, except that they don’t comprise one of the events just mentioned. (The epistemological equivalent of this tour could be accomplished through experimentation – through employment of Mill’s methods, or some such. We can see talk of this metaphysically impossible tour as a way of condensing a long and tedious description of highly possible experiments that could be conducted within a single world.) So in W1 I don’t put on a blue shirt; but otherwise W1 is just like our world. In W2 I don’t brush my teeth; but otherwise W2 is just like our world. And so on. Of course, I notice that in all but one of these worlds the pan is hot. The one where the pan is cold is the one that is just like ours except that, in it, I don’t turn on the burner. Let W7 be that world. 
        In W1, the pan does indeed have a property that it doesn’t have in our world – it has the property of being such that it is within ten feet of somebody who is not wearing a blue shirt. And in W2, the pan does indeed have a property that it doesn’t have in our world – it has the property of being such that it is within ten feet of somebody who hasn’t recently brushed his teeth. But this obviously isn’t enough to show that, in our world, my wearing a blue shirt or brushing my teeth is a program-cause of the pan’s being heated. Leaving aside the fact that, in W2, I haven’t brushed my teeth, the pan’s behavior there is identical with the pan’s behavior here. Let e1…en be the events described (so e1 is the event of my brushing my teeth; e2 is the event of my putting on a blue shirt; and so on); and let Wi be a world that is just like ours except that it doesn’t comprise ei. For each i, other than i=7, Wi is just like our world leaving aside the fact that Wi doesn’t comprise ei. This shows that e7 (the event of my turning on the burner) is the culprit. e7 is what is responsible for the pan’s heating. 
      Of course, e7 is a program-cause of the pan’s heating, i.e. the former is causally relevant to the latter, but not causally efficacious with respect to it. Given only that W7 is just like our world, except that it doesn’t include the event of my turning on the burner, it logically follows that W7 has properties not had by our world. For example, it logically follows that the pan has the property of not being such that, at a certain time, it is within a certain distance of someone who has turned on a certain kitchen appliance; and it logically follows that the pan has the property of being such it is either a square circle or that JM didn’t execute any intention he might have had to turn on a certain burner at a certain time. The reason that e7 is a program-cause of the pan’s heating is that leaving aside properties of the kind just mentioned, W7 differs from our world. 
         Causal relations are given by synthetic propositions. Logical relations are not causal relations – they are not relations of effective causality xxx or of program-causality. A corollary is that, in so far as statement P provides a logical guarantee of statement Q’s truth, P doesn’t provide a causal guarantee of Q’s truth. The statement at t, JM turned on the burner doesn’t logically guarantee the truth of the statement the pan heated up. That is why the first statement can, at least in principle, provide a causal explanation for the truth of the second. The statement at t, JM did something which would eventuate in the pan’s heating up logically guarantees the truth of the pan heated up, and thus provides no causal explanation for that truth. 
       To identify the cause (in any sense of the word) of an event, one considers situations that differ in some specific respect from the one that led to that event, but that are otherwise like the latter. But one must xxx set aside the strictly logical consequences of the differences just discussed. Given that, in W3, I am wearing a green shirt instead of a blue one, it logically follows that the pan is such that it is within the vicinity of a person wearing a green shirt. So given our description of that world, it is xxx indeed guaranteed that the pan has that property. But that guarantee is of an analytic, not a causal, nature. By contrast, given that, in W7, I don’t turn on the burner on, nothing concerning the pan’s temperature is logically guaranteed; and any outcome as to the pan’s thermal state is given by a synthetic, and therefore at least potentially causal, statement. 
         Jackson and Pettit are conflating the concept of a logical guarantee with that of a causal guarantee. Given how we’ve described Max’s and twin-Max’s respective worlds, it is indeed guaranteed that Max will behave differently from twin-Max. But that guarantee is logical: it is an artifact of the content-externalist’s description. It isn’t comparable to the guarantee provided by JM turned the burner on for the truth of the pan subsequently heated. 
       Let us close the argument. As before, let W be Max’s world – the world where he sees rock R. In a world W* that is just like W, except that W* doesn’t comprise R, it logically follows that Max will have many properties that he doesn’t have in W. For example, in W* will have the property of not being within a hundred feet of R at time t. If the content-externalist is right, another one of these properties is that Max will have the property of not being such that R is a constituent of his mental content. To establish that Max’s thinking about R is a program-cause of anything that he thinks or does, we need to show that leaving aside these differences – i.e. leaving aside the differences that follow analytically fro our descriptions of W and W* -- Max’s thought and behavior in W* is different from his thought and behavior in W. 
     But this is precisely what we find not to be the case. Leaving aside the (supposed) fact that, in W*, Max does not have R as a constituent of his thought; and leaving aside other differences between W and W* that follow analytically from our description of the differences between those two worlds; there are no differences between Max as he is in W and Max as he is in W*. So if R is a constituent of Max’s mental content, that is no more causally relevant to his thought or conduct than my putting on a blue shirt is causally relevant to the heating of the pan. 
        Another example may be appropriate. Given that I am seeing a dewy glass of ice-water, I will indeed do something that I wouldn’t do if (ceteris paribus) I were seeing a dewy glass of XYZ. Because I am seeing H2O, I will reach out an grab a glass of H2O. If (ceteris paribus) I were seeing XYZ, I would reach out and grab a glass of XYZ. But this doesn’t show that my seeing H2O is causally relevant to my thought or conduct. Given only our description of the XYZ-world, it immediately follows that I have many properties there that I don’t have here. For example, it follows that, in that world, I consist mostly of XYZ, as opposed to H2O. (That logically follows given our pre-existing knowledge that people consist mostly of H2O.) If the externalist is right, it also immediately follows that I have thoughts about XYZ in that world, but not in this one. But to show that my thinking about H2O is causally relevant to my behavior or thought, we need to show that, leaving aside those analytic differences, my thought and conduct in the XYZ-world are different from my thought and conduct in this world. 
        That condition is obviously not met. Jackson and Pettit contend that my having thoughts about H2O bears the same relation to my subsequently grabbing the glass that the presence of the flame bears to the subsequent heating of the pan. This contention is false. Given a world like ours, but that doesn’t comprise the flame (or the event of my turning on the burner), the pan will not heat: such a world will be different from ours even after we set aside the differences that logically follow from our description of it. That is why there is, or at least could be, a causal relation (albeit one of relevance, not efficacy) between the flame’s presence underneath the pan and the pan’s temperature. By contrast, given a world like ours, but where there is XYZ in the glass, I still reach out and grab the glass: such a world is not different from ours after we leave aside the differences that logically follow from our description of it.
      Let us suppose for the sake of argument that the content-externalist is right. In that case, the glass is a veritable component of my mental content. Given that the glass is such a component, it is indeed guaranteed that some events will occur that are causally efficacious with respect to my forming the previously described intention. But here we are dealing with different kind of guarantee from those previously discussed. As the content-externalist himself insists, the glass’s being a component of my mental states’ content does not supervene on what is local; it supervenes on what is remote – on what is, in fact, non-existent by the time that B1…Bn occur (or by the time that there occurs anything else that might be causally efficacious with respect to my forming an intention to grab the glass). The glass’s being a constituent of my mental states’ content therefore doesn’t comprise anything that could possibly be an effective cause of my forming that intention or, therefore, of the behavior that expresses that intention.  Therefore the glass’s being such a constituent doesn’t guarantee the formation of such an intention in a sense comparable to that in which the presence of the flame guarantees the heating of the pan. In the one case, the guarantee in question is an artifact of our description of the situation; in the other case, the guarantee holds in virtue of a causal nexus that has nothing to do with our descriptions.
          For the content-externalist, the glass’s being a constituent of my mental states’ contents consists in the glass’s having certain effects on me – it consists in the fact that some state of affairs involving the glass is (distal) cause of certain changes in my person. Content-externalism just is the position object X’s being a constituent of the content of mental state Y consists in its being the case that X (or, more accurately, some state of affairs involving X) causes Y. 
        So given an acceptance of content-externalism, it follow tautologously that, if X is a component of mental state Y, then X (or some state of affairs involving X) is what caused Y to occur. In particular, it follows tautologously that, if the glass is a constituent of the content of some mental state of mine, the glass is a cause of that state. 
      Thus, if we accept content-externalism, then statement “the glass is a component of the content of mental state M had by JM” tautologously implies the statement “N was caused by the glass (or, more exactly, by some state of affairs involving the glass).” Given that any neural state of mine will be causally potent, it follows that the statement “the glass is a component of the content of neural state M had by JM” guarantees the truth of some statement ascribing a causally potent state to me. 
      But this guarantee follows logically from the content-externalist’s position; it is a by-product of his way of describing the situation. And this is exactly the kind of guarantee that we don’t want in this context. For as we discussed earlier, when we want to assess whether the glass’s being a constituent of my mental states’ content has any kind of causal potency, the question to ask is this: 


Consider a world W^ where that particular glass is absent, and where some other glass has taken its place, but that is otherwise just like our world. Leaving aside the differences between W^ and our world that follow logically from our description of W^, is there any difference between how I think and act in W^ and how I think and act in this world?


         The answer to that question is obviously “no.” By hypothesis, the proximal causes in W^ of my thought and behavior would be identical with their proximal causes in our world. True – in W^, those proximal causes would lead to my grabbing glass X as opposed to glass Y. But given how we’ve described W^, it follows tautologously that it is X that I will reach for, and not Y. When we wish to assess causal potency – whether in the form of causal efficacy or causal relevance – we obviously don’t want to study the logical consequences of our definitions. Supposing that the content-externalist’s position is correct, it is indeed guaranteed that the glass’s being a constituent of my mental content has various effects on what I think and do. But the guarantee in question is of a logical, indeed a tautologous, nature; it is not a causal guarantee.  
       Another example may be appropriate. I am gazing at the heavens with my high-powered telescope. I see star X. Because X is so beautiful, I am filled with joy. Given this, let us suppose for argument’s sake that content-externalism is correct. In that case, X is a constituent of the representational content of my perceptual and cognitive states (in particular, of the aesthetic attitude just described). But, we may suppose, X ceased to exist millions of years ago. (I can see it because it took millions of years for the relevant light-rays to travel from X to my retinas.) 
        The externalist seems to have a problem – actually two problems. First, he is forced to say that X is a constituent of the content of my visual perception. Given that X doesn’t exist, it follows that, for the content-externalist, my perception does not have a complete content: it as a gap where there is supposed to be a star. But my perception does have a complete content, and content-externalism is therefore wrong. 
       It isn’t clear how the externalist is to respond to this, given that my visual perception has a content – a complete content, not one that has a gap in it where X is supposed to be.[126] But let us suppose that content-externalism can deal with this problem. Supposing that content-externalism is right, my thinking about X – i.e. X’s being a constituent of the contents of my mental states – supervenes on processes that went out of existence well before there were human beings. This makes it hard to see how X’s being a constituent of my mental-content could have any causal potency. After all, given the content-externalist’s position, X’s being a content of my thought supervenes on what is buried in the remote recesses of space-time. 
        Here is what Jackson and Pettit (2004) say about this. 


   X’s being a constituent of my mental content programs for, i.e. is causally relevant to, what I think and do. Admittedly, X’s being such a constituent isn’t an effective cause of my thoughts or deeds. But the flame isn’t an effective cause of the heating of the pan. So our position hardly downgrades the causal potency of representational content. 


        The flame is contemporaneous with the events are causally effective with respect to the heating of the pan; indeed, the latter are constituents of the former; and therein lies the nature of the causal relation between the flame and the heating of the pan. 
        But X ceased to exist millions of years ago. The same is true, of course, of the specific state of affairs involving X that is responsible for my perception (namely, X’s deflecting such and such light-rays in the direction of Earth, or some such). So nothing that is an effective cause of anything that I think or do could possibly be a constituent of any state of affairs involving X. Given this, it should be apparent that Jackson and Pettit are over-extending the term “program-cause” – that they are using it to denote two quite difference concepts. 
        Supposing that content-externalism is correct, X’s being a constituent of my mental content does indeed guarantee that there will be certain modifications of my neural (or mental) condition. But the nature of this guarantee is logical, not causal, and it is a tautologous consequence of the content-externalist’s position. That position is the view that X’s being a constituent of my mental content is identical with X’s being a cause (of some kind) of some current, and therefore causally potent, condition of mine. So given the content-externalist’s position: 


X is a component of the content of JM’s mental content =DF X (or, more accurately, some state of affairs involving X) caused some current, and therefore causally potent, modification of JM’s mind or nervous-system to occur. 


       By contrast, the connection between the presence of the flame and the heating of the pan – or between the temperature (pressure) of the gas and the rupturing of the vessel or between the squareness of the peg and its resistance to entering the hole – is entirely synthetic and a posteriori. This connection is given by a synthetic a posteriori proposition, and is therefore not a tautologous consequence of our definitions. 
        
What led Jackson-Pettit astray 


        As we’ve seen, the Jackson-Pettit analysis involves a failure to distinguish between logical and causal explanations (or between the logical and causal aspects of explanation). This is related, I now propose to show, to their not sufficiently distinguishing between: 


(a) X is a cause of so and so’s current condition 


and: 


(b) X’s being a constituent of so and so’s mental state is a cause of so and so’s current condition. 


There is an important difference between saying: 


(1)  Alpha Centauri (or some state of affairs involving that star) is a cause of Smith’s current thought and behavior. 


and saying: 


(2) Alpha Centauri’s being a constituent of Smith’s mental content is a cause of Smith’s current thought and behavior. 


      Here is an example of what I mean. Smith and Jones are both content-externalists. Smith is seeing star X. Because X is so beautiful, Smith experiences an aesthetic epiphany and thus decides to compose a poem celebrating X. Smith and Jones both know that X went out of existence long ago. Smith asks Jones: “How is X’s being a constituent of my mental content causally potent with respect to anything that I now think or do, given that X ceased to exist long ago and that everything that governs my conduct and mentation is in the here and now?” Jones answers by saying: 


(E) Components of the contents of mental (or neural) states are causes of those states. X is a component of the content of your mental state. Therefore X is a cause of your mental state. 






Supposing that E is true, it obviously follows that X is a cause of Smith’s current neural condition and thus with his current thought and behavior. (Nobody ever denied that.) But it doesn’t follow that X’s being a constituent of Smith’s mental content is a cause of anything having to do with Smith’s current thought or behavior. Given the content-externalist’s position, if X is to be a constituent of Smith’s mental content, it is logically necessary that some state of affairs involving X be a cause of (some aspect of) Smith’s current condition. So given the content-externalist’s position, the proposition: 


(A)  X is a constituent of Smith’s mental content 


logically entails: 


(B) X (or, more accurately, some state of affairs involving X) is a cause of (some aspect of) Smith’s current condition. 


So given the content-externalist’s position, and given that X is a constituent of Smith’s mental content, it is indeed guaranteed that some fact about X is causally responsible for what X now thinks and does. But what obviously doesn’t follow from (A) and (B) is: 


(C) X’s being a constituent of Smith’s mental content is causally responsible for what Smith is now thinking and doing. 


What obviously is causally responsible for Smith’s current condition is the fact that, millions of years ago, X deflected some light-ray in Earth’s direction, and that light-ray eventually collided with Smith’s retinas. So, quite obviously, some state of affairs involving X affects what Smith is now thinking and doing. But it doesn’t follow that X’s being a constituent of Smith’s mental content is one of those states of affairs. Further, it would make little to say X’s being such a state of affairs was one of the states of affairs involving X that had any kind of effect of Smith’s current condition. In fact, it makes little sense to speak of a “state of affairs” here at all.[127] There is no time during which both X and Smith exist. So it is hard to see how there could be any state of affairs, in any causally significant sense of the term, consisting of X’s being a constituent of Smith’s mental content. A fortiori it makes little sense to say that X’s being a constituent of the contents of those states has any effects on Smith. And even though it follows from the content-externalist’s position that some state of affairs involving X must have an effect of Smith’s current condition, given that X is a constituent of Smith’s mental contents, it does not follow, as we saw a moment ago, that X’s being such a constituent has any such effects. 
     Consider the flame. There are infinitely many times t such that, at t, we can truly say: the flame exists. That is why, for many times t, the flame is operational: it heats; it burns; it sooths; it torments. The same is true of the squareness of the peg, the temperature of the gas, and anything else that is a relatum of a true causal statement. There is no time t such that, at t, we can say: star X’s being a constituent of Smith’s mental is doing such and such. After all, there is no time at which X’s being such a constituent exists, given that X and Smith are separated by an interval of millions of years. Of course, if the externalist is right, the noun phrase “X’s being a constituent of Smith’s mental content” is not an empty one. But not every non-empty noun-phrase denotes a state of affairs, if by “state of affairs” we mean something of causal significance – something like the flame or the squareness of the peg. After all “the fact that there are infinitely many primes” is not an empty noun-phrase – it isn’t like “the man on the moon” – but it doesn’t denote the relatum of any true causal statement. 
       Jackson and Pettit were misled by their own examples. The examples that we have considered – the flame, the peg, the gas’s temperature – are among the examples used by Jackson and Pettit (or, in any case, are only trivially different from their own examples). But Jackson and Pettit give additional examples of what they describe as “program causes” (or as instances of “causal relevance”); and these other examples are not instances of the concept that we have been discussing. 
        Here is one of the examples in question. During a performance, the symphony-conductor becomes annoyed. Why? Because somebody coughed. Here is what Jackson and Pettit (2004: 55-59) say. Obviously the proposition (or statement): 


(SC) somebody coughed 


provides a perfectly good causal explanation of the fact that the conductor became annoyed. But (SC) doesn’t identify the effective cause of the conductor’s becoming annoyed. After all, it cannot just be somebody who coughed: it must be Smith, Jones, or Brown – it must be some specific person. There is no state of affairs – no causally significant entity – consisting in somebody’s coughing. If (SC) is true, that is parasitic on the truth of some singular proposition. But (SC) is still a correct causal explanation. Why? Because, given the truth of (SC), it follows that, for some x, the singular proposition x coughed is true; and x coughed does identify a state of affairs that led to the ripples in the quantum constitutive of the conductor’s becoming annoyed. 
       What is most significant in this context is what Jackson and Pettit don’t say about this example. Given the truth of (SC), it does indeed follow that, for some x, the singular proposition: 


(XC) 666 x coughed


is true. x’s coughing explains the conductor’s becoming annoyed in approximately (but only approximately: see below) the same way that the flame’s presence explains the pan’s becoming heated. x’s coughing is not causally effective with respect to the conductor’s becoming annoyed. What is thus effective are various neural events N1…Nn that are confined to the interior of the conductor’s cranium. x’s coughing (or, in actuality, some causal successor of x’s coughing) programs for the occurrence of N1…Nn. 
          In fact, what is going on is much more nuanced than Jackson and Pettit allow. First of all, it isn’t every aspect of x’s coughing that is responsible, on any delineation of the term “responsible”, for the conductor’s becoming annoyed. Rather, what happens is this. Among the mass-energy displacements constitutive of x’s coughing are various micro-events. Those micro-events lead to other micro-events. And so on, until we have some set of micro-events that lead to various micro-events that are constitutive of some physiological condition on the part of the conductor. That condition is related to the conductor’s becoming annoyed in the way that the presence of the flame is related to the heating of the pan. Among the constituents of that condition are various micro-events that effectively-cause the micro-events constitutive of the conductor’s becoming annoyed. 
      Jackson and Pettit say that (SC) is related to the conductor’s becoming annoyed in the same way that (*) is related to the pan’s becoming hot. In other words, they say that somebody’s coughing (not this or that person’s coughing, but just somebody’s doing so) is related to the conductor’s becoming annoyed in the way that the presence of the flame is related to the heating of the pan. But that is false for many reasons. First of all, unlike the presence of the flame, somebody’s coughing (as opposed to Brown’s coughing or Smith’s coughing) isn’t a state of affairs. As Russell (1903) said, you never just meet a person. You meet Bob or Mary or Jane. Similarly, you never just hear someone coughing; you hear some specific person doing so (even though you may have no idea who that person is). 
       It is true that (SC) does provide a perfectly good explanation as to why the conductor became annoyed. But the reasons for this are quite delicate and cannot be straightforwardly modeled on the relationship between (for example) the presence of the flame and the heating of the pan. Given that (SC) is true, it follows logically that (XC) is true (for some x). Given that (XC) is true, and given various causal laws, it follows that some state of affairs C holds, where C – not the non-entity described by (SC) – programs for N1…Nn. 
       As before, Jackson and Pettit are conflating the logical and causal dimensions of explanation. Given (SC), along with some principles of physics and psychology, it is guaranteed (or made probable) that the conductor will become annoyed. But not every guarantee is comparable to the guarantee that the flame’s presence  provides for the pan’s becoming hot. The guarantee provided by (SC) combines logical, effective-causal, and program-causal components. Given (SC), it logically follows that (XC) is true (for some value of x). The state of affairs described by (XC) effectively causes physiological condition C. C programs for N1…Nn, i.e. C is related to N1…Nn in a way that parallels the relationship of the flame to the heating of the pan. And, finally, N1…Nn effectively-cause the conductor to become annoyed. (N1…Nn effectively cause the brain-states that, supposing materialism to be correct, realize or are identical with the conductor’s being annoyed.) But somebody’s coughing isn’t related to the conductor’s becoming annoyed in remotely the same way that the presence of the flame is related to the heating of the pan. The flame is a state of affairs: it is right there, underneath the pan. Somebody’s coughing is not a state of affairs, and thus cannot be related to anything (e.g. the conductor’s becoming annoyed) in the way in which the flame is related to the heating of the pan. So given that the flame’s presence underneath the pan is a paradigm-case of a program-cause, Jackson and Pettit are hyper-extending the term “program-cause” in saying that it applies to somebody’s coughing. 
      Jackson and Pettit’s final example further over-extends the term “program-cause”. [128]Particles A and A* are qualitatively identical, and are in qualitatively identical circumstances (at least as far as their immediate vicinities are concerned). But they are thousands of miles from each other. At time t, particle B hits particle A, and particle B* hits particle A*. B and B* are qualitatively identical, and they hit A and A*, respectively, with the same degree of force. The result is that A is displaced by the same amount as A*. 
       Smith asks Brown why the following proposition is true: 


(AM) A and A* move by the same amount.


Brown answers by saying that: 


(SAF) A and A* were struck with the same amount of force.


Brown’s answer is obviously correct, and it provides a perfectly good causal explanation of the fact that Smith’s question concerns. But the cause of a xxx particle’s being displaced must be vanishingly close to that particle. The expression “the fact that A and A* are struck with the same degree of force” doesn’t refer to anything that is vanishingly close to either A or A*. In fact, it doesn’t refer to anything that has any spatio-temporal location. Given this, how can Brown’s answer be correct? 
        Here is what Jackson and Pettit say. Given the truth of (SAF), along with some accepted principles of physics, the truth of (AM) is guaranteed. Of course, Jackson and Pettit are right: (AM)’s truth is guaranteed. But the nature of that guarantee isn’t comparable to the guarantee that the flame’s presence provides for the heating of the pan. As Jackson and Pettit themselves point out, the fact that A and A* are struck with the same force isn’t a state of affairs. (The result of putting quotation marks around the italicized expression doesn’t pick out anything that has spatio-temporal boundaries, even of the most nebulous sort.) Brown is providing a good causal explanation. But that explanation is more akin to that provided by (SC) than to that provided by (*). Brown’s explanation combines logical and effective-causal components. 
       Let us start with (SAF). As a matter of logic, this entails that for some specific value of F, some singular proposition of the form: 


(AF) A is struck with F 


is true, and that some singular proposition of the form: 


(A*F) A* is struck with F 


is also true. 
     Of course, each of (AF) and (A*F) identifies some state of affairs (in the relevant sense). Given the laws of physics, A’s being struck with F is an effective cause of A’s moving by amount Q. And given those same laws, A*’s being struck with F is an effective cause of A*’s moving by amount Q. So given the truth of both (AF) and (A*F), the following xxx proposition follows: 


(BAF) both A and A* move by amount Q  


And given (BAF), (SAF) logically follows. 
      But what is important here is that there is no state of affairs consisting in the fact that A and A* are struck with the same force, and xxx there is no state of affairs consisting in the fact that A and A* are displaced by the same amount. 
       By contrast, the flame’s being beneath the pan at t and the pan’s having temperature T at t* are both states of affairs: they are spatio-temporally located entities; the expressions that denote them are not nominalizations of abstract relationships or generalizations over singular propositions. Thus, the relationship between (SAF) and (AM) is not comparable to that holding between the flame’s presence and the pan’s temperature.[129]  
       The problems with the Jackson-Pettit attempt to save functionalism can be distilled into the following argument. At time t, I have an intense desire to drink ice-water. Let B be the brain-state that realizes that desire. At that same time, I see a glass of ice-water in front of me. Because I am thirsty, I grab it and drink its contents. It is intuitively clear that, at t, it is my desire for ice-water that causes me to drink the contents of the glass. So my desire for ice-water is active at t. Thus B’s being a desire for ice-water is active at that time. If content-externalism is right, then B’s being such a desire supervenes on its functional role. (Let R be that role.) But B’s having such a role is not causally potent at t. The expression “B’s having functional role R” denotes an abstract property of a sequence of events. In this respect, it is less like the expression “the squareness of the peg” than it is like the expression “the fact that people gravitate towards extreme political positions in crisis-conditions.” Functionalism cannot accommodate the fact that, at t, my desire for ice-water is doing any work. 
       Of course, given that B has R, it is guaranteed that, at t, I will grab the glass and drink its content. Jackson and Pettit correctly point this out and, on this basis, hold that functionalism is compatible with the causal potency of the mental. But this response overlooks one crucial fact. The just-mentioned guarantee is logical, not causal. Given that B has R, it follows tautologously that I will drink from the glass. But causal relations are not expressed by tautologies. Given the statement there is a flame underneath the pan, it doesn’t follow tautologously that the pan will heat up; and that is why the first proposition provides a causal explanation of the truth of the second. By the same token, B has R provides no causal explanation JM drinks from the glass, given that the latter is an analytic consequence of the former. 


Summary of our findings thus far


        The concepts of a program-cause and of program explanation are of the highest importance. But for program-explanations, explanation would be impossible, outside of microphysics. (Also, for reasons that I haven’t given, but that Jackson and Pettit do give (2004d), explanations in terms of program-causes are in some ways more informative than explanations in terms of effective causes. Even though biological facts are realized by physical micro-facts, biology can capture principled regularities that micro-physics cannot.) 
        A paradigm of a program-cause is the case of the pan’s heating in consequence of the flame’s being put underneath it. The concept illustrated by this paradigm is an important one. This concept is instantiated by sequences of states of affairs such that the first states of affairs is literally composed of the events that effectively cause the second state of affairs. 
        But we render the term “program cause” ambiguous, or lacking in any coherent meaning, if we start using that term to denote relations that don’t hold between states of affairs. Noun-phrases – even non-empty ones -- don’t always denote states of affairs. The expression: 


(%)  “the fact that different cultures have always had different ways of indicating differences in social status and that, given any one culture, its ways of indicating differences in social have not remained perfectly constant in every respect over any period of more than one hundred years”


 is not empty. But (%) isn’t comparable to “the flame underneath the pan”, “the fact that the water is 112°”, or “the squareness of the peg.” In their attempts to reconcile content-externalism and functionalism with the causal potency of the mental, Jackson and Pettit use the term “program-explanation” to denote relations that don’t hold between states of affairs – they use it to refer to the relations that hold between “entities” like that denoted by (%). For that reason, those attempts are fallacious. 
       Of course, given only that Jackson and Pettit didn’t succeed in their efforts, it doesn’t follow that functional and content-externalism are in fact incapable of accommodating the causal potency of the mental. But we have seen that those doctrines do indeed have exactly that defect. For reasons already given, it follows that content-externalism is false; and this fact confirms the positive doctrines that we have put forth concerning mental content. 


Some additional objections to functionalism 


           Because functionalism is practically an orthodoxy among students of the mind, it is worth our while to state some additional arguments against it, so as to reinforce our conclusion that it is false. We will see that the objections to functionalism raised by these additional arguments are naturally understood as corollaries of the fact that functionalism is incompatible with the causal potency of the mental.
            Suppose that, because he has brain-state B, Smith says “three” when asked “what is 1+2?” Even though B is what mediates between perceptual input (his hearing the question “what is 1+2?”) and behavioral output (his saying “three”), it doesn’t follow that any arithmetical belief of his was involved. It could be that, because of B’s electrical properties, the sounds he heard triggered an involuntary laryngeal spasm which led to his producing the sound “three.” 
      An analogous point holds with regard to any other example of a case where B mediates between cause and effect in a way that is characteristic of a belief that 1+2=3. One day Smith learns that Jones has one car and two motorcycles, and no other motorized vehicles. For some reason, he finds this knowledge very exciting. This causes his heart to race. Given B’s electrical properties (not its representational properties), this causes Smith to form the belief Jones has three motorized vehicles. Given the input (Smith’s learning that Jones has two motorcycles and a car), B leads to the right output (Smith’s believing that Jones has three motorized vehicle). In other words, given the input, B leads to the same output as a belief that 1+2=3. 
        But we clearly don’t have a case where Smith’s believing that 1+2=3 led to his having the right belief. We have a situation where dumb luck simulated the operation of such a belief. In general, if B mediates between input and output in the wrong way, then B isn’t a belief that 1+2=3, regardless of whether B consistently assigns the right output to any given input.  
      The functionalist has a response to this: 


      I grant that freak accidents, such as the ones you’re describing, might happen. But if B always leads to the right output, the chances that B is anything other than a belief that 1+2=3 are vanishingly close to zero. 


      That is entirely correct. But we mustn’t confuse issues relating to what B is with issues relating to how we ascertain what B is. Supposing that B always produces the right output, that is excellent evidence that B is a belief that 1+2=3. But we’ve just seen that, given any instance where B generates the right output, B’s generating that output can, in principle, be explained without supposing that B realizes a belief that 1+2=3. Given any number of instances where B generates the right output, that fact can in principle be explained without having to suppose that B realizes a belief that 1+2=3. This means that the statement B mediates between input and output in a way characteristic of a belief that 1+2=3 does not analytically entail, and is not analytically entailed by, B is a belief that 1+2=3. 
        Of course, as we’ve noted, if B mediates between input and output in a way that is characteristic of such a belief, then refusing to characterize B as such a belief may be nothing more than childish skepticism. But given that such skepticism is not 666 incoherent and that it is not analytically false, it follows that B’s mediating between input and output in the right way is merely evidence of B’s being a belief that 1+2=3, and is thus not constitutive of its being such a belief. 
          There is another, similar argument against functionalism.[130] Suppose that B assigns the right output to a thousand different inputs. (For example, given that Smith has just heard “Brown has 1+2 bicycles”, B leads Smith to say “therefore Brown has 3 bicycles.”)  Given the evidence, it is likely that B is a belief that 1+2=3. But that same evidence is consistent with the hypothesis that B is a belief in some “bent” proposition, e.g. 1+2=3 – except when the objects being added are insects: in that case, 1+2=4. So as long Smith hears or reads anything having to do with insects, B will assign the same output to any given input as a belief that 1+2=3. But if Smith hears “there are two cockroaches in Brown’s room, and one ant, and no other insects”, Smith says “therefore there are four insects in Brown’s room.”[131] 
        In general, no matter how often B generates the right output, it is a possibility that B mediates a belief in some proposition other than 1+2=3. Given that this is even a skeptical possibility, it follows that B’s having the same functional role as a belief that 1+2=3 (i.e. its assigning the same output to any given input as such a belief) is not constitutive of B’s being such a belief and is at best good evidence to that effect. 
       This suggests that, if B really is a belief that 1+2=3, B’s assigning the right output to any given input is at most an effect of its being such a belief, and is thus not constitutive of its being such a belief. 
       Even if B produces the right output for any input, it doesn’t follow that B’s being a belief that 1+2=3 is involved. But so far as B’s being such a belief is involved, functional role is a veritable effect of content, and is thus not constitutive of it. Either B’s functional role is a causal consequence of content or B’s functional role is consistent with B’s being any number of beliefs distinct from a belief that 1+2=3. Both options are unacceptable.[132] 


Part II  Fodor, Conceptual Atomism, and Computationalism 


          In the preceding pages, we put forth some very definite views as to the nature of conception. The views put forth are incompatible with a powerfully argued analysis put forth by Jerry Fodor. In this Part, we will evaluate Fodor’s analysis. 
       Fodor’s work makes it clear that content-externalism has a great deal of independent support. So in order to prove the mettle of our own analysis, it is necessary that we consider Fodor’s alternative to it in detail. Doing so will give us some insight into a number of important questions: Are we computers? Supposing that we are, what does that entail? Does it entail, for example, that thinking consists in operations on linguistic symbols? Supposing that it does, what is the nature of those operations? Are those operations to be understood exclusively in terms of the purely formal properties of the symbols involved, or are they better understood in terms of their semantic properties? Or can they be fruitfully understood in both ways? (In other words, does the last question embody a false dichotomy of some kind?) These are but a few of the questions that we will address. 


Chapter 13 Content-Externalism and Atomism 


       We must begin by discussing a doctrine that we will refer to as “conceptual atomism.” Some background is needed before we can say what that doctrine is. 
        According to the view that we have put defended, for any spatiotemporal entity x, my having a concept of x involves my knowing some description that x satisfies. An immediate consequence of this view is that in order to have a concept of any spatiotemporal object, one must already have concepts. Where such objects are concerned, there is no possibility of conception in a vacuum of other concepts. 
           Of course, not everybody will agree that our particular view of conception is the right one. But what is generally, though not universally, accepted is that possession of one concept presupposes possession of others.[133] As we discussed earlier, it seems preposterous to assume that an otherwise conceptless creature could have a concept of Socrates or of the Washington Monument. It seems even more preposterous to assume that an otherwise conceptless creature could have thoughts about theoretical entities, such as electrons or neutrinos. There doesn’t seem to be any spatiotemporal entity x such that one could have a concept of x without having a concept of anything other than x. The idea that one’s x-concept could exist in isolation thus seems to be a non-starter (Berkeley 1934, Sellars 1963, Bonjour 1985, Peacocke 1992, Kuczynski 2003, 2004). 
     Concepts are not atoms; they are not self-contained units. Where there is one concept, there are many. Conceptual atomism is false, and conceptual non-atomism – conceptual molecularism or holism – must therefore be correct. In any case, this seems like a reasonable position; and our analysis is consistent with it, since it makes it a precondition for my having any concept of Socrates that I have a number of other concepts. 
         Here we must make a distinction. In this work, we have discussed what it is to have a concept of a spatiotemporal entity. We have not discussed what it is to have a concept of a non-spatiotemporal entity – of a property or a proposition. So we have left it open whether conceptual atomism holds with respect to our concepts of abstracta. We will discuss this problem at length in Chapters 22-23. We will find that non-atomism is no more true with respect to our concept of abstracta than it is of our concepts of spatiotemporal entities. (Actually, in those chapters, we will find that the distinction between those two kids of concepts is much blurrier than has thus far been generally assumed. For we will find that many so-called “constituents” of the spatio-temporal world – e.g. rocks, trees, vases – are more abstract than we are generally inclined to think.) 
       But independently of any theories that we will put forth, there are some obvious and compelling reasons to reject an atomist conception of conception. Could one grasp the concept of justice without grasping concepts like sentience, awareness, morality? And could one grasp any one of these concepts without grasping others? Surely one couldn’t have any conception of morality unless one understood what it was for an aspiration to be thwarted or for a living being to be otherwise violated. So a concept of morality would seem to presuppose concepts like animate being, purpose, and frustration. And to have a grasp of any one of these concepts, one must have yet others. To grasp the concept of frustration, one must grasp the concept of desire; and to grasp the latter, one must grasp the concept of an attitude in general.
          It used to be thought that, sooner or later, this regress would terminate in foundational concepts (Russell 1984[134], Wittgenstein 1922). But the attempts to find such foundational concepts have borne no fruit, and philosophy has generated a number of positive reasons for thinking them not to exist (Sellars 1963, Wittgenstein 1974, 1983, Kuczynski 2006). We will discuss these in due course. 
       In any case, given only the remarks just made, it is hard to believe that a creature could grasp one abstractum without grasping a multiplicity of others. Conceptual atomism would thus seem to be as false with respect to our grasp of such entities as it is with respect to our grasp of spatiotemporal entities. 


 Some reasons to accept to atomism 


          Fodor has made it clear that, if one accepts content-externalism, one must advocate an atomistic conception of what it is to be aware of spatiotemporal objects. Fodor accepts content-externalism, and he thus accepts conceptual atomism. Even though many agree with Fodor that content-externalism is correct, few agree with Fodor’s conceptual atomism. But so far as one is a content-externalist, one is guilty of incoherence in rejecting Fodor’s atomism.
      As we will see, Fodor is an atomist across the board: conceptual atomism holds with regard to our grasp of both spatiotemporal and abstract entities. In Fodor’s view, an otherwise conceptless creature could grasp the concept of justice or number or money (1990, 1998). A creature that didn’t have concepts like society or property could, according to Fodor, have the concept of money.
      Of course, this is, on the face of it, an implausible view. But to echo what we said a moment ago, content-externalism demands that just this view be accepted. So supposing that content-externalism is correct, Fodor is guilty only of seeing what others fail to see. 
        Fodor realizes that conceptual atomism is a counterintuitive doctrine. For this reason, he provides a number of brilliant arguments on behalf of it (Fodor 1998). He also successfully shows that a number of independently plausible positions actually demand an acceptance of atomism. (He does not, however, show that those independently plausible positions are correct. We will see reason to thin k that they are not.)


Why content-externalism presupposes conceptual atomism


          In this section, I would like to discuss why content-externalism demands an atomistic conception of conception. In this context, we will suppose for the sake of argument that content-externalism is correct.
       According to that doctrine, the contents of a mental state is a function at least in part of the origins of that mental states. Brainstates b and b* may have different contents even if, leaving aside their causal origins, they are qualitatively identical. For example, b may be a concept of Smith, while b* is a concept of Jones, even though (leaving aside their distal causes) b and b* are qualitatively identical, and are embedded in the same way in qualitatively identical nervous systems. 
         It may help to recall the story that we told in Chapter 1. The information encoded in Max’s perceptions and subsequent thoughts is different from that encoded in Twin-Max’s corresponding perceptions and thoughts; and those differences lie entirely in the fact that the one person’s mental states have different origins from the others. They lie entirely in the fact that, after time t, Max’s perceptions and subsequent thoughts do, whereas Twin-Max’s do not, originate with some state of affairs that have rock R as a constituent. It isn’t as though, for Max and Twin Max to diverge in this way after time t, they must already differ in respect of what concepts they have. The just described differences between Max and Twin-Max don’t presuppose any conceptual differences. 
       In general, if content externalism is right, two creatures can differ with respect to a single concept. X and Y can be absolutely identical except that, where X has a concept of Smith, Y has a concept of Jones. So it is a straightforward consequence of content-externalism that some concepts are atoms. 
          A corollary is that atomism is false only to the extent that the content of a mental state is not a function of its causal origins. On pain of incoherence, one is an atomist to the extent that one is a content-externalist. Content-externalism is a form of atomism. 
         Conceivably, one could be an externalist with regard to certain concepts (e.g. one’s concept of Smith) but a non-externalist with regard to other concepts (e.g. one’s concept of the number five). Indeed, I am sure that this is the position that most self-described content-externalists would take. If Smith and Jones are atom-for-atom duplicates of each other, then surely Smith has a concept of the number five iff the same is true of Jones. Content-externalism is presumably meant  to hold with respect to our concepts of spatiotemporal objects. 
        But even if we confine ourselves to this class of objects, it is pretty clear that content-externalism is not meant to hold across the board. Any theoretical notion is ipso facto one that can be grasped only in the context of a number of other notions (Hempel 1952, 1965, Nagel 1962, Carnap 1966). One couldn’t have a concept of a quark unless one 666 had some understanding the structure of the atom and, therewith, of the strong and weak forces, and so on. (This is not to mention that one would have to have at least some grasp of concepts such as motion, energy, mass, time and the like. A being that had no concept of motion surely wouldn’t have a concept of a quark.) So, at least to an extent, one’s grasping the concept of a quark 666 is to be understood in descriptive terms and thus cannot be understood in strictly causal terms.
       What we said about a concept of a quark is true of a concept of anything spatiotemporal. To the extent that one’s concept of Smith is descriptive, it cannot be understood in atomist, or therefore in strictly externalist, terms. So the content-externalist must hold that one’s concept of Smith is an atom. 
        A moment ago we said that one’s knowledge of theoretical entities is essentially descriptive. This is not to advocate some kind of instrumentalism or anti-realism about theoretical entities. A good case has been made that instrumentalism, operationalism, and other forms of theoretical anti-realism are quite erroneous (Hempel 1952: 29-50, 1965: 123-135, Pap 1963: 39-74[135]). 
        But given only that theoretical entities are to be understood in terms of non-theoretical data, it doesn’t follow that such entities are nothing but constructs of such data. To think otherwise is to fail to make some basic distinctions relating to scope. 
        Remember what we said about the word “Socrates.” When one is told: 


(i)  “Socrates” is the name of the great philosopher who drank hemlock, 


what one is being told is not: 


(ii) “Socrates” names anything x such that x is a unique great philosopher who drank hemlock (and exactly one thing was a unique great philosopher who drank hemlock).


Rather, what one is being told is: 


(ii) Somebody x is a unique great philosopher who drank hemlock, and “Socrates” names x.


         The descriptive information is given wide-scope with respect to the “names”-operator, so that it has a reference-fixing, as opposed to a meaning-giving, role. But the term “Socrates” is still understood in terms of the description to the left of the “names”-operator. 
       Similarly, when one is told: 


(i*) the term “quark” refers to instances of that natural kind whose supposed existence helps account for data D1…Dn, 


one is not being told: 


(ii*) the term “quark” refers to an instance of any natural kind N such that N’s supposed existence helps account for D1…Dn.


Rather, one is being told: 


(iii*) there is some natural kind N such that N’s supposed existence helps account for D1…Dn and such that the term “quark”  refers to instances of N.  


So some description couched in terms of D1…Dn fixes the referent, but doesn’t give the meaning, of the term “quark.” 
        Given this fact, it is obvious why there is no tension between, on the one hand, the obvious truth that theoretical entities are understood in terms of non-theoretical data and, on the other hand, the well-established thesis that statements about theoretical entities are not synonymous, or otherwise reducible to, statements about macroscopic data.[136] Because that data has a reference-fixing role, there are counterfactual scenarios where those same theoretical entities generate very different experimental data. So the counterfactual properties of statements about that experimental data don’t track the counterfactual properties of statements about those theoretical entities; and this thwarts attempts to reduce the one set of statements to the other.  
              
Fodor’s reasons for accepting conceptual atomism 


     Fodor sees very clearly that conceptual atomism is a direct consequence of content-externalism. So given how implausible atomism is, why doesn’t Fodor reject content-externalism? 
       Before content-externalism even existed[137], Fodor (1968, 1975) advocated the so-called Computational Theory of Mind (CTM). As Fodor has always realized, CTM demands an acceptance of conceptual atomism. So Fodor correctly sees CTM as providing independent corroboration for the atomism demanded by content-externalism. 
      Fodor also advocates the Symbolic Theory of Thought (SCT). As Fodor realizes, CTM demands SCT. But Fodor also sees clearly that, apart from its connection with CTM, there is much support for SCT. So Fodor correctly sees SCT as providing independent corroboration for the atomism demanded by content-externalism. 
      It is no surprise that no one has argued more powerfully than Fodor for either CTM or SCT. As previously noted, Fodor’s arguments for CTM are intertwined with his arguments for SCT. Let us now consider those arguments 


The raison d’être for CTM


      CTM is given by the thesis: 


(*)  “To think is to compute; thinking is computing.”[138] 


Before we consider the reasons for accepting CTM, we must ask: what does the word “compute” mean? What is it to perform a computation? Right now I could perform a computation; I could compute a sum (i.e. I cold add two numbers). But given that interpretation of the word “compute”, (*) is patently false, at least as a general statement about cognitive activity. A precondition for my adding two numbers is that I already have many thoughts, and that I have a wealth of concepts. I must know various symbolic conventions (e.g. that “1” denotes the number one); I must grasp various mathematical principles; I must have cognitive wherewithal to have perceptions of enduring physical objects (e.g. the paper and pencil that I will use to compute the sum in question) and also to synthesize those perceptions into a body of mnemic information on which I can draw as circumstances require (I won’t be able to add if I can’t keep track of the various figures I write down, or of what my reason for doing so was).
         So if the word “compute” is taken in its customary sense – in the sense that it bears in statements like “Smith is performing a computation” – then the existence of computations is actually an extremely derivative form of mental activity and, consequently, CTM is viciously circular.  
         Fodor is aware of this problem, as are most advocates of CTM. In an attempt to avoid this vicious circularity, advocates of CTM define the terms “compute” and “computation” as follows: 


(FC) Every case of computing is a case of manipulating symbols, but not vice versa. For a symbol-manipulation to qualify as a computation, it cannot be to any degree semantics-driven, and must therefore be driven entirely by the forms of the symbols in question.[139]


     When a calculator adds a sum, it doesn’t consider what is meant or referred to by the discolorations on its monitor; the calculator’s behavior is driven entirely by the formal properties of those symbols. A computation is a form-driven manipulation of symbols. When the words “compute” and “computation” are taken in this sense, there is no vicious circularity in saying that the mind is a computer, and that cognitive activity consists entirely in the performing of computations. So CTM is given by (*), with the qualification that the words “computation” and “compute” are to be understood in the sense assigned to them by FC. 


Some commitments of CTM


      As we will see in a moment, there are excellent reasons to advocate CTM. But before we consider those reasons, we must make a couple of points explicit. CTM is obviously committed to the idea that we think in symbols – that the basic units of thought are expressions and that, consequently, we think in a language. 
       A consequence is that CTM is committed to conceptual atomism. If, as CTM requires, we think in a language, then its expressions are our concepts. Any language must have ultimate units of significance (also known as “morphemes”). Given any language, some of its expressions are complex, and others (“Socrates”) are simple. It isn’t possible for every expression of a language to be complex. So supposing that we think in a language, some of the expressions of that language are simple and foundational, and all the rest are built out of those simples. This means that some of our concepts are simple and foundational – they are atoms – and the rest are built out of those atoms. CTM is thus committed to conceptual atomism. 
        There is a possible objection to this: 


       You say that, if we think in a language, then some of our concepts are foundational and therefore simple. But this follows only if one rejects a certain plausible view as to the nature of linguistic meaning. According to that view, the meaning of an expression is constituted by its inferential role. Given any sentence of the form “Aristotle was wise” that sentence follows from certain other sentences (e.g. “either there are square circles or Aristotle was wise”) and certain other sentences follow from it (e.g. “somebody was wise”). In general, given any sentence of the form ┌…Aristotle…┐, certain sentences entail that sentence, and that sentence entails certain other sentences; and what “Aristotle” means is a function entirely of what those entailment relations are. Even more generally, for any expression E, any sentence of the from ┌…E…┐ entails, and is entailed by, certain other sentences; and what E means is a function of what those various entailment-relations are. If you accept a “conceptual” role account of meaning – if you accept “Conceptual Role Semantics” (CRS) -- then the meaning of any given symbol is determined by its relations to other symbols; and, from a semantic viewpoint, there are no “simple” or “foundational” symbols. Supposing that “Aristotle” has meaning (or reference) M, it has that meaning in virtue of the fact that “Aristotle” is related in a certain way other symbols. So there is no straightforward inference from “we think in language” to “some kind of conceptual atomism holds” (Sellars 1963, Field 1977, Brandom 1998). 




      There are several points to make here. The first of these points is made by Fodor himself (Fodor 1998: 13[140], Fodor and Lepore 202: 101[141]). If one accepts CTM, one cannot advocate any form of CRS. CTM is trying to account for cognitive behavior in terms of operations on symbols. According to CRS, something can be a symbol only if it is already a part of a pattern of inference-making. So CRS makes the having of vast networks of thoughts be a pre-requisite the use of any symbols. Thus, to avoid vicious circularity, any identification of thought with the manipulation of symbols must not accept a CRS-account of meaning; and any such identification must accept the conventional view that some of the symbols of any given language are foundational and atomic, and are thus not to be defined in terms of other symbols belonging to that language. So whatever merits it has a general statement about language, the objector’s point is irrelevant in this context.
       But not only is the objector’s point irrelevant: it is also demonstrably false. “Socrates” doesn’t have the same semantics as “Aristotle.” But nothing is entailed by “Socrates snored” that isn’t also entailed by “Aristotle snored”; and “Socrates snored” doesn’t entail anything not also entailed by “Aristotle snored.” Of course, what we just said about “snored” is true of any other predicate. So an inferential account of the semantics is incapable of discriminating between “Aristotle” and “Socrates” and, in general, between any two proper names.[142]
       One could side-step this last point by saying that, given what we’ve learned about  Aristotle and Socrates, “Aristotle snored” does have different entailment-relations from “Socrates snored”. Given our historical knowledge, the one does, while the other does not, entail “the author of the Metaphysics snored”; and the one does, while the other does not, entail “somebody who died of hemlock-poisoning snored.” 
       But, as Fodor and Lepore (2002: 101) say, if we take that point of view, then every sentence of the form ┌Aristotle has phi┐ that we know to be true becomes an analytic truth. The sentence “Aristotle died before his 90th birthday” becomes analytic. Since it obviously isn’t analytic, the point of view just described is false. Thus, CRS is both false and irrelevant; and we may therefore conclude that SCT is committed to conceptual atomism. 
          An advocate of SCT could counter-respond by saying that the Mentalese symbol for Aristotle is different from its counterparts in English: the former is, whereas the latter are not, to be understood in terms of its inferential role. But given this position, one’s Mentalese symbol for Aristotle becomes so different from “Aristotle” that it can no longer be regarded as a mere translation of the latter. More generally, this position makes the so-called “symbols” of Mentalese so different from their English counterparts that it becomes unclear whether the former are fruitfully likened to linguistic expressions.  This is an issue that will recur throughout the remainder of this work. 


How CTM solves the tracking-problem 


           Let us now turn to the question: Why advocate CTM? (The argument about to given is found in Fodor 1981: 13-17, 226-227, 1987: 18-20, 1994: 294-298.) Thoughts are identical with, or at least realized by, brain-activity. (In any case, this is a plausible and widely held view.) Brains are physical objects, and are therefore governed by the laws of physics. The laws of physics are not laws of rationality. Whether the billiard ball goes in this as opposed to that direction has nothing to do with canons of good reasoning. The same is true of our brains and of the various structures they comprise. All of these things are entirely physics-driven, and there would thus seem to be no room for canons of good reasoning to play any part.
         At the same time, our cognitive activity is rational, at least to a high-degree. Our thoughts follow one another in ways that are generally consistent with the canons of logical reasoning. But how is this possible, given that those thought-sequences are purely physics-driven and that the laws of physics have nothing to do with the canons of good reasoning? How is it possible for rationality to track physics, given that everything spatiotemporal falls within the scope of physical law and that physical laws are not laws of rationality? We will refer to this as the “tracking-problem.” 
       CTM solves this problem. Symbols (or symbol-tokens, strictly speaking) are purely physical objects. But we can create environments in which they follow one another in ways that are consistent with the strictures of logic. Given a set of symbol-tokens, we can create environments such that, given the laws of physics and the physical properties of those symbol-tokens, the latter are physically compelled to form patterns that constitute rational ideation (Fodor 1981: 226, 1981b, 1987: 18-20, 1990: 22). 
         Consider the symbols “Jerry is not bald”, “either Smith is tall or Jerry is bald”, and “Smith is tall.” We can create a physical environment such that, if the first two symbols are tokened (at more or less the same time) in that environment, then the first symbol is tokened in that same environment immediately thereafter. 
          Here is another example. Consider the symbols “12”, “+”, “14”, “=”, “26”. We can create a physical environment such that, if the first four symbols are tokened (in that order) at a given time in that environment, then the fifth is tokened in that same environment immediately thereafter. 
           In fact, not only can such environments be created: we create them all the time. They are called “computers” or “calculators.” (In this context, the distinction between calculators and computers isn’t important.) So the tracking problems vanishes if we assume that brains are computers. 


CTM incompatible with the causal potency of representational content 


          There is an obvious apparent problem with CTM – but if one accepts content-externalism, that apparent problem turns out to be a virtue. Contrary to what CTM says, our thinking obviously is (or at least seems to be) semantics-driven. I believe that Smith is either in Iceland or in Jamaica. I then learn that he is not in Jamaica. On this basis, I conclude that he is in Iceland. Presumably it is because the first two thoughts have certain contents that they lead to my having the third thought. So supposing, as CTM does, that my having these thoughts consists in my various expressions being tokened in my brain, I obviously arrive at this conclusion on the basis of the meanings of those expressions, and not (merely) on the basis of their non-semantic properties. Thus, if indeed we think in symbols, our thinking is semantics-driven, and CTM is therefore false. 
       Here there are two points to make. First, as we’ve already seen, if content-externalism is right, then content is causally inert. What is causally potent is always what is local; and, according to content-externalism, a brain-states having a certain content does not supervene on what is local: on the contrary, it supervenes specifically what is non-local – what is distal and purely relational and therefore causally hollow. So, as Fodor (1981, 1987b) clearly says, content-externalism is incompatible with the view that semantics is causally operative. 
      Further, for a theory to be adequate, it must it must be consistent with the relevant data, and not with our a priori beliefs (except, of course, in so far as our a priori beliefs are consistent with the data). In this context, the data is that certain kinds of thoughts are likely to follow certain other kinds of thoughts. Just as there are regularities in the non-mental world, so there are regularities in the mental world; and the latter regularities are the data that a correct model of cognition must accommodate. It is not a datum that semantic content is what is responsible for those regularities. 
        Here our comparison with physical theory may once again be useful. As Hume pointed out, it is not a datum that there are “forces” or “powers” in the physical world. Similarly, it is not a datum that, in the cognitive sphere, there are “semantic forces.” This isn’t to say that such thing don’t exist, but only that the question whether such forces exist cannot be answered a priori and must be answered on the basis of future research. If Fodor is right, that research has established that they don’t exist. 
        Thus CTM solves the tracking-problem; and, supposing (as Fodor and many others do) that content-externalism is correct, the fact that CTM strips semantic-content of causal powers actually redounds to its credit. 
       This is not to mention the fact that CTM provides a speedy solution to the mind-body problem: there is obviously no difficulty explaining how computers arise out of non-mental, purely physical entities. So supposing that there our brains are computers, there is no difficulty explaining how mind arises out of such entities. There is thus much to be said for CTM. 
       We’ve seen that an acceptance of CTM demands an acceptance of SCT; and we’ve seen that, at least in this context, an acceptance of SCT demands an acceptance of conceptual atomism. So there is much to be said for conceptual atomism; and there are many reasons to accept that doctrine independently of the fact that content-externalism requires it. 
  
Reasons to question CTM


        I would now like to argue that CTM is erroneous and that the arguments for it involve irreparable non-sequiturs. Let us start by putting forth one of the standard criticisms of CTM – a criticism that is probably coeval with CTM itself. 
    Given any symbol-token S, and given any meaning (or referent) M, there is some possible language L such that S means M in L. In English, the symbol-token “Socrates” refers to Socrates. But there are possible languages in which refers to Plato and possible languages in which it doesn’t refer to anything. For exactly similar reasons, there is a possible language in which the symbol-token “4” refers to Socrates, a possible language in which it refers to the number seven, a possible language in which it refers to Pluto, and so on.
       Thus, if a computer transitions from “2+3=” to “5”, that is a valid transition only if it is assumed those shapes instantiate English symbols. That transition is valid only from the viewpoint of somebody who speaks English, and its validity therefore presupposes the existence of thought: it presupposes the formidable cognitive wherewithal needed for somebody to have mastered the relevant symbolic conventions. So computational processes presuppose cognitive ability, and therefore cannot be constitutive of it. (See Dennett 1978: Chapter 6, Lycan 1984: 237, Kuczynski 2002, Searle 1984, 1992.[143])   
       This line of thought is easily generalized. Given any sequences of physical events, there is some language L such that, in L, that sequence of events tokens a valid argument or a correctly executed mathematical operation. Indeed, given any sequence S of shapes, and given anything that can be encoded in language – be it a poem, a political speech, or a proposal for world peace – there is some language L such that S encodes that poem (or political speech or…) in L. Given that not every single sequence of events is an actual instance of a beautiful poem (or political speech or…) being articulated, it follows that no sequence of events has any meaning at all merely in virtue of its shape. If an event E has a certain meaning M, that is not merely in virtue of E’s morphology. Nothing means anything merely in virtue of its morphology. 
        What is the advocate of CTM to say in this response to this point? One possible response is this: 


     As you say, a token of the expression “2” doesn’t refer to the number two merely in virtue of its shape. It is only because various symbolic conventions are at work that an object with that shape refers to that number. But this has no relevance to CTM. Mentalese symbols are not comparable to the symbols of a public language. It is not because of convention that 2 refers to two, or that snow refers to snow. The connection between “2” and two is mediated by human thought. Hence the problem that you were discussing a moment ago. Since the connection between 2 and two is not thus mediated, the problem you bring up is irrelevant. 






        But then we have to ask: in virtue of what does 2 refer to two? Here is Fodor’s (1990, 1998) answer: 2 refer to two in virtue of the fact that the 2 has a certain causal connection to instances of the number two (i.e. to pairs of apples, pairs of shoes, and so on). Even if Fodor is right about this, it doesn’t help CTM. As we’ve seen, the fact that 2 has certain origins is causally and explanatorily inert. The fact that the beginnings of that symbol-token are to be traced to some state of affairs involving some particular pair of shoes is irrelevant so far as 2’s behavior is concerned. (Jackson and Pettit (2004) disagree. But we saw in Chapter 12 that the grounds for their disagreement are spurious.) So if indeed it is in virtue of its causal origins that 2 refers to two, then from the viewpoint of the description and explanation of brain-processes, 2 might as well be in the same category as some symbol that refers to Pluto or to the number five or to nothing at all. 
       So given a content-externalist conception of mental content, 2 is indistinguishable from any other shape, at least as far as the analysis of psychological and neural activity is concerned. In that case, the very problem that we discussed recrudesces. The sequence 2+3=5 is, from every relevant viewpoint, indistinguishable from a symbol that means 2+3=978 and from one that means snow is green and from one that means nothing at all. Given an acceptance of content-externalism, the objector’s position implodes, and our original criticism of CTM prevails. 
       Thus, if the objector’s point is to prevail, semantics must be causally operative. It must be in virtue of its referring to a certain number that 2 has the causal role it does. But if semantics is operative, then CTM implodes, since the essence of that doctrine is that thinking consists in sequences of symbol-tokenings that are not semantics-driven. 
        This connects with another point. As we’ve discussed, there is no intrinsic connection between “2” and two. (This point was famously made by Saussure 1966.) Whatever semantic connection holds between them is derivative of human thought and social practices; and this point mutatis mutandis holds of every symbol of every natural language. As we’ve seen, the connection between 2 and the number two cannot be conventional. The semantic connection between them must be built into that symbol, and that connection must therefore not be arbitrary. 
       Of course, there is no shortage of cases where, independently of human thought or social practices, one thing means another. Given the presence of smoke, it may reasonably be inferred that there recently was fire. So smoke means fire. In this sense of the word “means”, meaning is a strictly causal relation.[144] In general, any case of “meaning” that doesn’t presuppose thought is a strictly causal relation. But we’ve already seen that CTM fails in so far as the connection between 2 and two is causal. So if this is the kind of meaning that advocates of CTM have in mind – and it is, in fact, the kind of meaning that Fodor has in mind --  CTM collapses. 
        This is not to mention an even more obvious problem. When we say that smoke “means” fire, we don’t mean that it means fire in anything comparable to the sense in which “2” means two. As we said a moment ago, we mean only that, given a knowledge of the relevant regularities, an awareness of smoke licenses an inference to the recent occurrence of fire. Meaning in this sense has to do with the permissibility of inferences; it has nothing to do with anything’s being an awareness or concept of anything else. So if some brain-state refers to Socrates in this sense, that is perfectly compatible with that brain-state’s not being a concept or awareness of Socrates. For anything X, so far as some brain-state means (or refers to) X in this sense, that is compatible that brain-state’s not being a concept of X at all. 
        “For x to represent y is for some causal relation to hold between them” – this is what Fodor and others contend. But that contention embodies a failure to distinguish between these two meanings of the word “meaning.” (In literary theory, this confusion is known as the “pathetic fallacy.”) Fodor holds that a strictly causal theory of conception is de rigueur, given the truth of semantic externalism. But in Part I, we saw why this is not the case.  


Symbols as intermediaries: why CTM eviscerates the concept of a symbol


           As we’ve seen, the connection between a Mentalese symbol and its meaning cannot be conventional or otherwise mediated by thought. For CTM to work, 2 must naturally mean two. In that case, 2 is just a direct awareness of that number. On the one hand, we have a brain-state (consisting of some token of a Mentalese symbol); on the other hand, we have a number; and the former is a direct awareness of the latter. But it seems to be of the essence of symbolhood that a symbol is a kind of intermediary (Kuczynski 2002, Horst 1996). 
       There is no symbolic awareness of Smith where there is a direct awareness of him. A symbolic awareness of Smith consists in my encountering some symbol like “Smith”, and duly interpreting it in the light of the relevant symbolic conventions. A direct awareness of Smith would consist in my seeing him. The two kinds of awareness are antithetical to each other. (Of course, I could read and understand a sentence like “Smith is wise” while also looking at Smith. But in so far as I am doing the one, I am not doing the other.)
     So unless we trivialize the notion of a symbol by saying that any awareness of anything is ipso facto symbolic, it isn’t clear how Mentalese symbols (so-called) have any significant similarity with actual symbols. This, of course,  calls into question the viability of CTM, since that doctrine just is the thesis that thinking consists in symbolic-manipulations of a certain kind (Kuczynski 2002). 
       Of course, an advocate of CTM could defend against this by saying that the word “symbol”, as used by CTM, is meant only in a metaphorical or otherwise extended sense. (This, in fact, seems to be the position taken by Fodor 1975: 65-67, Lycan 1984: 237, and other computationalists.) But in that case, CTM is reduced to the explanatorily innocuous platitude that thinking consist in operations involving things that are like symbols, in as much as both they and symbols represent things, but aren’t really symbols. 


Why CTM is based on an equivocation on the term “form”


        But underlying CTM is a confusion even more insidious than any of those just discussed. CTM identifies thinking with form-driven, or formal, manipulations of symbols. The question is: what reason is there to believe that a purely formal operation on symbols could qualify as a cognitive achievement? 
       On the face of it, a formal operation is the antithesis of one that is thought-driven. It is precisely when people don’t understand the formulas in front of them that they are forced to rely on mechanical procedures. Where a neophyte needs to fall back on a formal procedure to solve a problem (e.g. to derive an integral), a mathematician can generate the right answer on the basis of genuine insight into the concepts involved. The mathematician’s answer would seem to be more thought-driven than the neophyte’s and, in general, it would seem that a symbolic operation is formal precisely to the extent that it is not thought-driven.
       Nonetheless, there is some basis for CTM’s identification of formal manipulations of symbols with genuine cognitive achievements; and the grounds for that identification can be distilled into the following argument. 


      Suppose that you use a truth-table to ascertain the truth-value of some sentence (or sentence-schema). There is no denying that, in so doing, you have figured something out and thus deserve credit for some kind of cognitive achievement. And there is no denying that, in this case, that cognitive achievement was generated through a purely formal (or mechanical or algorithmic) operation on symbols. 
       So even though informal operations typically demand more cognitive wherewithal than formal ones, the latter do clearly constitute cognitive achievements and are therefore cases of thinking. Thus, given the reasonable position that calculators and computers successfully carry out formal symbolic manipulations, it readily follows that they think. And, as we discussed, once it is granted that they can think, both the tracking problem and the mind-body problem immediately vanish. 


   
       But this argument involves a fallacy. The words “form” and “formal” are ambiguous; and the argument just given equivocates between the different meanings of these terms. The words “mechanical” and “automatic” are ambiguous in a comparable manner. The whole of CTM involves a failure to register the different meanings of these various expressions; and once these ambiguities are exposed, there remains little temptation to advocate CTM.
       The argument in question fails to distinguish between form in the morphological sense and form in the syntactic sense. Consider the following two sentences: 


(1) If Fred is wise, then Fred is a sentient being.
(2) If Fred is wise, then either Fred is wise or Fred is a cucumber. 


Each of these is analytically true. But only the second is formally true. If someone transitions from “Fred is wise” to “Fred is sentient being”, he has made an analytically correct inference that is not formally valid. But if someone transitions from “Fred is wise” to “either Fred is wise or Fred is a cucumber” he has made an inference that, in addition to being analytically correct, is also formally valid. 
       But what do these statements mean? What is the difference between “analytic” and “formal”? What, in this context, do the words “formal” and “form” mean? Right now I’m going to give the canonical answer to these questions – the answer that would be given by mathematical logicians and also by advocates of CTM: 


(SYN) (2) holds entirely in virtue of its syntactic structure. To know that (2) is correct, it is necessary to know only its syntactic structure. It isn’t necessary to know its semantics; it isn’t necessary to know, for example, what is meant by “wise” or “cucumber.” By contrast, (1) does not hold merely in virtue of its syntactic structure. There are syntactically identical sentences that express invalid inferences, for example: 


(3) If Fred is wise, then Fred is a rock. 


   To know that (1) is correct, one must know its semantics; one must know what is meant by “wise” and “sentient being.” 
     So even though it is analytic, (1) is not formally correct, the reason being that its syntax doesn’t guarantee its truth. By contrast, in addition to being analytic, (2) is formally correct, the reason being its syntax does guarantee its truth.[145] 


    
        By way of anticipation, we will find that (SYN) is unsatisfactory in many ways. (In particular, we will find that a knowledge of semantics is to some degree constitutive of a knowledge of syntax and that (SYN) is therefore wrong, since it demands that knowledge of syntax be entirely independent of knowledge of semantics.) But it is a good point of departure, since it is approximately correct. Also, because it is the answer given by advocates of CTM, we should grant it, if only for the sake of argument. If we show that CTM fails given (SYN), then we will have shown that CTM fails relative to its own assumptions, and is therefore uncontroversially false. 
        Supposing that (SYN) is correct, it is clear why CTM cannot be accepted. Syntactic form is completely different from geometrical form. (We will use the expressions “morphology” and “morphological” to denote form in the geometrical sense.) First of all, morphology is a property of expression-tokens, not expression-types, since expression-types are abstract objects and thus don’t have morphology. Two morphologically identical expression-tokens can have completely different syntactic forms; and two syntactically identical expression-tokens can have two completely different morphologies. 
        Consider the symbol-token “snow is white.” There is a possible language L in which that token, or at least one morphologically identical with it, means: if Beethoven had been born in 1400, he would have invented the fugue. Considered as an expression of L, that token has one syntactic structure. Considered as an expression of English, it has an entirely different syntactic structure. (Incidentally, this shows that what syntactic structure an expression has is a function of what it means – of its semantics: a point we will find to be of inestimable importance.) In general, a sentence-token’s morphology imposes no constraints on its syntax. 
        Given any sentence-type, there is no limit to how different in respect of morphology two tokens of it can be. Consider the sentence-type: “snow is white.” That sentence could be tokened by sounds, hand-signal, light-rays, noises. And even within a single one of these media, there is little limit to how different in respect of morphology two tokens of that sentence can be. We could imagine a token of that sentence being uttered by someone with a very deep voice over a period of a year; and we could imagine a token of that same sentence being uttered by someone with a high voice (so high, in fact, that it isn’t audible by humans) over a period of one nanosecond. 
       Of course, given two tokens of the sort just described, there will be a respect in which they are isomorphic. But the isomorphism couldn’t be understood in strictly acoustical terms, and would have to be understood, at least in part, in terms of the meanings of the expressions involved. The correspondence could be established only by showing that each of two sounds was an utterance of the word-type “snow”, and that each of two other utterances was an utterance of the word-type “is”, and so on. Doing this would involve much more than just pointing out the purely acoustical properties of the sounds in question; it would involve discussing the psychological and social conditions underlying the production of those sounds. The isomorphism in question would thus not be of a strictly physical or morphological kind. 
        Syntactic form has little or nothing to do with morphological form; and a morphology-driven symbolic operation needn’t to any degree by syntax-driven. A being that is responding to form in the morphological sense is not, in virtue of that fact, responding to form in the syntactic sense. 


The concept of syntactic form


      Here it becomes necessary to develop a point already hinted at. The syntax of an expression lies in its semantics. (2) has the same syntax as: 


(4) If Smith is bald, then either Smith is bald or Smith is a bat.         


(4)’s syntactic structure is a function of the meanings of the expressions of which it is composed. Suppose that one of the occurrences of “Smith” were replaced with an occurrence of an expression belonging to a different semantic category. In that case, the result would be meaninglessness. (Consider the sentence that would result if “Smith” were replaced with “cucumber.”) This shows that it is because “Smith” falls into a certain semantic category that (4) is characterized by a certain syntactic structure. Obviously (4)’s syntactic structure is determined, in part, by the fact that its main connective (“if…then…”) has a certain meaning; and that sentence would have an entirely different syntax, at least in the relevant sense of the word, if the main connective were replaced with a different one (e.g. “and” or “or”), let alone with an expression not belonging to the same semantic category as that connective.
       If you replace the occurrence of “Smith” in (4) with “Jones”, a sentence with the same syntactic structure results. But nonsense results if you replace that occurrence with an expression (e.g. “cucumber”, “elephant”, “not”) belonging to a completely different semantic category. A sentence’s syntax thus seems to lie in its more abstract semantic properties. A syntactic description of a sentence is a low-resolution description of its semantics. (Later we will replace this vague statement with a more precise one.)
       It follows that a manipulation of symbols is syntax-driven only if it is semantics-driven. As we’ve seen, CTM cannot countenance the idea that the symbolic manipulations constituting our cognitive processes are semantics-driven. Therefore those manipulations are not form-driven in the syntactic sense of “form.” We’ve already seen why those manipulations cannot be form-driven in the morphological sense. Aside from syntactic and morphological form, it isn’t clear what kind of form could possibly be relevant to CTM. 
        It thus appears that no disambiguation of the word “form” validates the idea that our thinking consists in form-driven operations on symbols. So far as that idea has credibility, it is, I believe, because logical (or syntactical) form is being conflated with morphological form. This equivocation creates the illusion that purely morphology-driven operations can miraculously have the property of realizing logic-driven, and therefore cognitively pregnant, symbolic operations. 
            
Indexicality and the irreducibility of logical to syntactical form
  
         For the sake of argument, let us set aside everything just said. Let us suppose, solely for the sake of argument, that syntactic form is identical with morphological form or, at least, that the two can be brought into some kind of meaningful alignment. That still wouldn’t save CTM. This is because, given any language L that is rich enough to mediate the thoughts any person is capable of having, the syntactic structures of L’s sentence-tokens will categorically fail to track the logical forms of the propositions meant by those sentence-tokens. 
         Here I should take a moment to make a clarificatory point. Frege (1884) and Russell (1905) argued compellingly that logical form is very different from grammatical form. Grammatically, “some man snores” has the same structure as “no man snores”, and both have the same structure as “Smith snores.” But in terms of logical form, no two of those sentences are comparable with each other. In general, where natural languages are concerned, grammatical and logical form pull apart.[146]  
        My point is that, given any language L, whether artificial or natural, that is rich enough to express even a tiny fraction of the thoughts that any person can have, the logical forms of L’s sentence-tokens will pull apart from their syntactic forms. There is no possibility of the kind of isomorphism between syntactic and logical form needed by CTM.
         Practically any thought that a person has is expressed by a sentence that has a context-sensitive component. Consider the information that is coursing through your psyche at this very moment. So far as it can be expressed by language, it is expressed by sentences like “that is a hideous painting”, “I am feeling tired”, “now it is raining, but yesterday it was not raining.” The italicized expressions are indexicals. If expressed in language, the information that is useful to an organism’s survival is necessarily expressed by sentences that have an indexical component. (“That animal is running towards me”, “I am now in terrible pain because this thorn is in my finger.”) The only thoughts that can be expressed by indexical-free sentences are those that concern immutable relations among concepts (e.g. “1+1=2”, “causes precede their effects”). Our thoughts can be expressed by indexical-free sentences only in so far as they are of a strictly mathematical or philosophical nature. Important as such thoughts are, they are not very important to a creature’s survival or to its internal regulatory processes; and no matter how intelligent a creature is, only a tiny fraction of its thoughts are of this sort.  
       Long ago, Strawson (1950) made it clear that, where there are indexicals, there is necessarily a divergence between logical and syntactical form.  (Kaplan (1977, 1989), and also Barwise and Perry (1999), developed Strawson’s insight.) Let T and T* both be utterances of “that is identical with that.” But suppose that in T  both occurrences in T of “that” refer to Fred, whereas in T* one occurrence refers to Fred while the other refers to Bob. In that case, T encodes the logical truth Fred=Fred whereas T* encodes the absurdity Fred=Bob. But, of course, T and T* have precisely the same syntactical structure. By exactly analogous reasoning, a token of “if it is warm here, then it is warm here” may encode an argument that is valid, invalid, or merely inductive (and thus neither valid nor invalid), depending on whether both tokens of the indexical “here” co-refer. It is easy to generate further illustrations of the principle at work here ad libidum. For the reasons stated in the previous paragraph, if our thoughts are mediated by some kind of language, the expressions of that language are replete with indexicals. As we’ve just seen, where expressions of that kind are concerned, syntax cannot possibly track logical form.[147] So even if we waive all of the problems relating to the fact that morphology and syntax have vanishingly little to do with each other, and even if we concede to CTM that syntax and morphology can be brought into some kind significant alignment, a form-driven manipulation of symbols is more likely than not to fail to constitute a valid piece of reasoning. 
         Thus, even if we grant CTM all of its own assumptions – even if we concede that there is a coincidence of morphology and syntax, and even if we concede that our thoughts consist in form-driven operations on symbols – CTM fails to account for the fact that our cognitive activity embodies a sensitivity to logical form.  
        What we’ve said can easily be condensed into a few points (it is easily seen that some of these are logical consequences of others, and that the following list therefore contains some redundancies): 


(*) There is no morphological characterization of syntax. 
(*) There is no syntactic characterization of logic. 
(*) There is no morphological characterization of logic. 
(*) A morphology-driven manipulation of symbols is not necessarily one that tracks either syntactic or logical form. 


      
Analytic versus formal truth 


         We’ve seen that CTM involves a misunderstanding of the concept of “formal” truth and that it fails to realize that the relevant kind of form is semantic in nature. Let us now further examine the concept of formal truth. This will shed further light on the nature of the misunderstandings that underlie CTM. 
         First of all, we must distinguish between analytic truth and formal truth. “Either it is raining or it is not raining” is formally true (as well as analytically true). By contrast, “anything wise is sentient” is not formally true, even though it is analytic. But what exactly is the difference between formal (logical) and analytic truth? 
        Let us start by giving the conventional answers to this question. Sometimes a sentence is said to be “logically true” if it is true “under all reinterpretations of its non-logical constants”, where a “logical constant” is any of the following expressions:  “if…then…”, “and”, “or”, “not”, “=”, “some”, “all.” Sometimes modal connectives, e.g. “possibly”, are put on this list (Quine 1970: 50). (Superficially, this definition seems to be circular, since the term “logically true” is defined in terms of the expression “logical constant” and thus in terms of the expression “logical.” But the circularity vanishes if the expression “logical constant” is taken as an abbreviated way of referring to the list containing all and only “not”, “all”, “=”, and so on.) Consider the following four sentences:


(1) If Fred is wise, then Fred is a sentient being.
(2) If Fred is wise, then either Fred is wise or Fred is a cucumber. 
(3) If Fred is wise, then Fred is a rock. 
(4) If Smith is bald, then either Smith is bald or Smith is a bat.         


(2) and (4) are both true, and (4) is what results when the non-logical expressions (“Fred”, “wise”, “cucumber”) are uniformly replaced with other non-logical expressions.  (1) is true, and (3) is false. But (3) is what results when a non-logical expression in the former is replaced with a different expression. For this reason, (1) is not a logical truth, even though it would traditionally be regarded as an analytic or necessary truth (Quine 1970: 47-50). 
       There are two reasons why this analysis of logical truth is unsatisfactory. Suppose that we defined the term “whole number” as “any number that is not a fraction or a real number or a quaternion or an imaginary number…” Our definition would be extensionally correct, but it would fail to put its finger on the property that all and only whole numbers have in common (apart, of course, from the negative and disjunctive property of not being either a negative number or a fraction or a real number…). Quine’s analysis of logical truth is guilty of a similar defect, since it defines a logical truth as one that is true under all substitutions of its component-expressions other than  “and” and “or” and “=” and… Even if that analysis is extensionally correct, it doesn’t say what it is for a sentence to be logically true. 
     This brings us to the second problem with Quine’s analysis: it isn’t extensionally correct. As Kaplan (1977, 1989) observed, sentence-tokens like “I am here now” are naturally described as logically true. But the analysis of logical truth under examination cannot accommodate that fact. By the same token, that analysis cannot accommodate the fact that “I am not here now” is logically false. 
       Can we say that a sentence is logically true iff it encodes an analytic proposition? No. Given such a position, we couldn’t mark the obvious difference between


(KB) “any case of knowledge is a case of belief”


and (SW) by saying that the latter is, whereas the former is not, logically true. Nor would that position accommodate the fact, mentioned a moment ago, that a token of “I am here now” is logically true, at least on one reasonable delineation of the term “logically true.” This is because, when I say “I am here now”, the proposition meant by my words is identical, or at least equivalent, with the proposition: JM is in Santa Barbara on Oct. 6  2006, and that proposition is contingent. 


Formal truth as semantic truth


         Given these points, I would propose a very different analysis of the concept of logical (or formal) truth. Let T be some token of “I am here now.” Why is that token logically true, even though it encodes an a posteriori, contingent proposition? Because it is a theorem of the semantic rules of the language to which it belongs that it is true. (2) is logically true for the same reason. In general, a sentence-token S, belonging to language L is logically (or formally) true exactly if S’s truth is a theorem of the semantic rules of L. 
           Consider the sentence: 


(KB) “any case of knowledge is a case of belief”


    Given that (KB) means any case of knowledge is a case of belief, it logically follows that (KB) is true. But the semantic rules of English do not themselves assign truth to that sentence. Those rules merely assign a certain meaning to it. At that point, non-semantic (albeit purely conceptual and a priori) facts assign the truth-value true to it. English semantics rules do not themselves assign the truth-value true to (KB) (or any token thereof).
         But a token T of “I am here now” is in a different category from (KB).  The rules of the language to which T belongs themselves assign truth to T. To see this, let us consider those rules, leaving out irrelevant technicalities. One of those rules is “if somebody x utters a token of ┌I have phi┐, that token is true, i.e. it is assigned the truth-value true, exactly if x has phi. Another is: “if in place x, there occurs token of ┌this place has phi┐ [or, equivalently, ┌here it is phi┐], that token is assigned the truth-value true exactly if x has phi. Yet another is of those semantic rules is: “if at time x, there occurs token of ┌this time has phi┐ [or, equivalently, ┌now it is phi┐], that token is assigned the truth-value true exactly if x has phi.” Given these, and a few other, strictly semantic facts, it follows that it is a theorem of English semantics that any token of “I am here now” is assigned truth. That is why any such utterance is logically true, even though what such an utterance semantically encodes is contingent and a posteriori. 
         Another example may be appropriate. Any token T * of: 


(RNR) “either it is raining or it is not the case that it is raining” 


          is syntactically (or formally) true. To see why this is so, let us consider the semantic rules that assign meaning to such a token. (As before, we will set aside irrelevant technicalities.) One of those rules is: “a token of ┌it is not the case that S┐ is true, i.e. is assigned the truth-value true, iff S is false.” Another is: “A token of ┌either S or Q┐ is assigned the truth-value true iff either S is assigned is the truth-value true or Q is assigned that truth-value. Given these facts, and a few others of a strictly semantic nature, it follows that it is a theorem of English-semantics that T* is assigned the truth-value true. So T and T* are logically true because of how they are assigned the meanings that they in fact have. 
      This suggests that syntax is an aspect of meaning, the same therefore being true of syntactic (“formal”) truth. Given what we’ve seen, a sentence-token’s syntax would seem to lie in how it means what it means (as opposed to in what it means). In a moment, we will substantiate this thesis as to the nature of syntax. We should point out that, if that thesis is correct, then T and T* are logically true because of how they mean what they mean, and their being formally true can be understood in terms of their morphology or, indeed, in terms of any other than semantics.
         
The relevance of these points to CTM


           Formal truth is semantic truth. Indeed, there is no notion that is more semantic than that of formal truth, since E is a formally true expression just in case E’s truth is a theorem of the semantic rules that assign it meaning. It is therefore clear that unless a creature is responding to the semantic properties of the symbols that it houses, it is not responding to the forms of those symbols, at least not in any relevant sense of the word. 
        Our analysis is also consistent with the close connection between the concepts of formal truth and computation. A statement is formally true or formally false exactly if its truth-value can be computed on the basis of the rules that assign it meaning. 
         One might make the following objection to this analysis: 


You may be right to say that all cases of formal truth are cases of semantic truth. But the converse doesn’t hold. Given the semantic rules assigning meaning to “1”, “2”, “+”, and so on, it is a semantic theorem that “12+13=25.” But surely that is not a truth of logic. Its truth is a theorem of the relevant semantic convention, and the proposition meant by it is true on purely conceptual grounds. But that proposition is not sufficiently generic. Its subject-matter is far too specialized to grant it membership in the class of logical truths.[148] A sentence expresses a logical truth only if the truth of that sentences turns on facts about highly general concepts – concepts like disjunction, negation, and the like. Concepts like 12, 25, and addition are much too specialized. 


    
            Even if this objection is correct, it concedes that semantic truth is a necessary condition for formal truth, and that objection thus doesn’t help CTM at all.[149] 
          We’ve seen that the word “form” is ambiguous, and that CTM involves a failure to register this ambiguity. Points similar to those just made in connection with the word “form”, and in connection with CTM’s use of it, are true of a number of other expressions that occur in arguments on behalf of CTM and, more generally, in discussions on the foundations of mind. Among these other expressions are “automatic procedure”, “mechanical procedure”, and “algorithm.” 
        Sometimes we say that there is a “mechanical” procedure for deciding whether a given sentence is true or not. Consider the following four sentences: 


(1) Either Smith is tall or Smith is not tall.
(2) Smith is tall and it is not the case that Smith is not tall.
(3) There are continuous functions that cannot be differentiated at any point.
(4)  It is false to say that laws are simply commands and do not necessarily differ in any significant respect from a gunman’s threats.


       No one would say that there was any mechanical way of determining whether (3) was true. In fact, (3) is true. But that was established on the basis of creative insight, not on the basis of an application of a mechanical test. The same point holds of (4), supposing that (as H.L.A. Hart argues[150]) it is in fact true. But there is a strictly mechanical procedure determining whether (1) and (2) are true or not. We need only apply the method of truth-tables. 
      In this context, what does the term “mechanical procedure” mean? The naïve answer is to say that a mechanical procedure is one that a machine could implement. But a machine couldn’t determine whether (1) and (2) were true or not.  Obviously there is no reason why we couldn’t construct a machine that scanned (1) and (2),  and then wrote “true” next to (1) and “false” next to (2), and did the same for any other sentence whose main connective was a truth-functional operator like “and” or “either…or…”. But, as we saw earlier, unless the machine’s behavior is semantics-driven, it isn’t figuring out whether those sentences were true or false. 
          If we allow that the behavior of a “machine” can be semantics-driven, then a machine is no less capable than we are of figuring out whether (3) and (4) are true. In that case, if we say that a mechanical procedure is one that a “machine” can apply, we are falsely saying that there is a mechanical procedure for determining whether (3) and (4) are true and, by the same token, for writing effective literary criticism and composing great symphonies. So it is false to say that a mechanical procedure is one that a machine can implement. 
       Given the points made a moment ago concerning syntax, I would propose a different answer to the question: what is a mechanical procedure? It is a semantic theorem that (1) and (2) are true. It is not such a theorem that (3) and (4) are true (even though they are both conceptually true). As we noted, it is generally held that there is a “mechanical procedure” for ascertaining the truth-values of (1) and (2), but not of (3) and (4). This suggests that there is a “mechanical procedure” for determining the truth-value of a sentence (or sentence-token) S, belonging to language L, exactly if it is a theorem of the semantic rules of L that S is true. If this is right, then the execution of a “mechanical” procedure presupposes a heavy backlog of semantic and extra-semantic knowledge. 
      
 Syntax as meaning-how


         We’ve already seen some reason to believe that CTM may be abetted by a misunderstanding of the term syntax. We’ve seen that the syntactic properties of a sentence are among its semantic properties, even though the principle arguments for CTM presuppose that the exact opposite is the case. But what exactly is syntax, and what is it for two sentences to have the same syntax?  Given plausible answers to these questions, it becomes even more apparent than before that CTM involves a misuse of the concept of syntax. 
       Let us start with some truisms. Two sentence-tokens have the same semantics if they mean the same thing; semantics is meaning. But there are different ways that a given semantics can be assigned to a noise or ink-mark. It would seem that


(BKC) “Brutus killed Caesar” 


encodes the same proposition as


(CKB) “Caesar was killed by Brutus.”


      Some would deny this, saying that (BKC) and (CKB) encode distinct but equivalent propositions. But it seems more reasonable to suppose that those inscriptions differ not in respect of the proposition that they encode, but in respect of the grammatical mechanisms that link them to some one proposition.
       The proposition meant by “triangles have three sides” is logically equivalent with that meant by “1+1=2.” But the relationship between these two propositions obviously isn’t comparable to relationship between the proposition meant by (CKB) and that meant by (BKC). In the one case, it can plausibly be said that we are dealing only with “purely verbal” differences. In the other case, this cannot be said. A reasonable synthesis of these facts seems to lie in the supposition  that (CKB) and (BKC) differ not in respect of what they mean, but in respect of how they mean what they mean. 
      It is uncontroversial that, from a linguist’s standpoint, (CKB) and (BKC) are syntactically different.[151] Given that those tokens encode the same proposition, this suggests that those tokens are syntactically different because of how they mean what they mean. In general, syntax is meaning-how, whereas semantics is meaning-what.     
         (BKC) is syntactically identical with: 


(JKS) “Jones killed Smith.”


Why is this? (JKS) and (BKC) have structurally identical “derivation-trees.” Though they have different meanings, they are “hooked up” to those meanings in similar ways.  
        Since the syntax of an expression lies in the relationship that it bears to its meaning, it is absurd to say that syntax-driven operations are semantically innocent. 
       Independently of CTM and of our criticisms of it, it is pretty clear that, even though they have different propositions for their meanings, it is in virtue of some kind of meaning-involving similarity that (BKC) and 


(SSJ) “Smith saw Jones”


are syntactically identical. Each of “Smith” and “Caesar” is a singular term; each of “saw” and “killed” are past-tense transitive verbs; and so on. These are semantic facts. (A singular term is one that refers to a certain kind of object; a verb is a term that expresses a certain kind of relation; and so on. The concepts of reference and expression are obviously semantic in nature.) It is obviously in virtue of these semantic facts that (SSJ) and (BKC) have the same syntax. Facts about syntax are facts about meaning, even though two expressions can have the same meaning and different syntaxes and vice versa. The tension between these two facts vanishes when it is seen that an expression’s syntax lies not in what it means, but in how it means what it means. 
         Let 


(*) XYZ 


be some (presumably quite long) sentence of Finnish that means: 


(**) if aardvarks were composers, then given their psychologies, they would probably be inclined to express their musicality in the form of highly contrapuntal but melodically impoverished compositions. 


       For the sake of argument, let us suppose that you don’t speak Finnish. If a Finn tells you that (*) has (**) for its meaning, there is a sense in which you know the meaning of (*), but there is also a sense in which you don’t. A Finn does, whereas you do not, have any understanding of the semantic decomposition, to use Jerrold Katz’s (1972) expression, of XYZ. You don’t know which part of XYZ means aardvarks, or which part means musicality, and so on. But even if you have a dictionary, and thus know which words in (*) are the translations of “melodically”, “aardvarks”, and so on, you still won’t know why those words are ordered or inflected in the way that they are, so far as you are even able to distinguish inflections from word-roots.
          So there is at least one reasonable delineation of the term “meaning” relative to which a Finn does, whereas you do not, know the meaning of XYZ, notwithstanding that you know which proposition XYZ encodes. What a Finn knows that you do not is the derivation-tree of XYZ. This follows directly from our description of the situation. It is entirely consistent with existing usage of the term “syntax” to say that a Finn does, whereas you do not, know XYZ’s syntax.  
      It immediately follows that the concept of syntax is not a meaning-innocent notion and that CTM is false so far as it assumes otherwise.  A corollary is that, so far as the term “mechanical procedure” has syntactic content, a sensitivity to meaning is a pre-requisite to executing such a procedure. For reasons already considered, this is problematic for CTM.   
       Let us consider some possible responses to our analysis: 


      In natural language, grammatical and logical form diverge, as you’ve discussed. “Socrates is wise” and “no one is wise” have the same grammatical form, even though they have very different logical forms.  But we can construct languages in which the logical differences between “Socrates is bald” and “no one is bald” are not obscured by grammatical similarities and in which, in general, grammatical and logical form coincide. 
       The word “syntax” can refer either to the syntax of one of these idealized  languages or it can refer to the syntax of natural languages. Linguists typically use that word in the second sense, and logicians typically use it in the first. 
       So far as you have shown anything, it is only that, in the linguist’s sense of the word “syntax”, sensitivity to meaning is a precondition for engaging in syntax-driven operations. You have not shown that anything comparable holds in connection with the other disambiguation of that word. Since it is the latter disambiguation that matters in this context, you have not shown anything of significance.


  
         For the sake of argument, let us grant the objector’s supposition that syntactic and logical form coincide where Mentalese expressions are concerned. That reinforces more than it undermines our analysis of syntax and our related criticism of CTM. 
      Let P and P*  be the propositions meant by “nothing is wise” and “Socrates is wise”, respectively. The grammatical mechanisms that hook up the former with P are similar to those that hook up the latter with P*. More precisely, the derivation-tree for the one sentence is structurally the same as the derivation-tree for the other. That is what creates the illusion of a semantic parallelism, i.e. of a parallelism in respect of the propositions that those sentences express. 
      Now let us suppose that English* is just like English except that, in English*, logical differences are always marked by syntactic differences. So in English* one doesn’t say “nothing is wise”; rather, one produces a sentence whose grammatical form matches its logical form, e.g. “the property of being wise is uninstantiated.”  
        In English*, syntax and logical form coalesce because dissimilarities between what sentences mean are not covered up by similarities in respect of how they have these meanings, and xxx dissimilarities between what sentences mean are not covered up by similarities in respect of how xxx they have those meanings.
          For exactly similar reasons, if Mentalese is logically perspicuous, that is because (dis)similarities between what two expressions mean correspond to (dis)similarities in respect of how they have those meanings. So contrary to what the objector says,  syntax is no less a meaning-involving affair than where English is concerned than where Mentalese is concerned.[152]  
          One of the objectives of the present work has been to show that facts about pre-semantics are often mistaken for semantics itself. The how of meaning is displaced onto its what. Given a failure to distinguish meaning-what from meaning-how, it is no wonder that what should in fact be described as “syntax” ends up being described as “semantics.” It is because of this muddle that there is nowhere for “syntax” to go other than the domain of pure morphology. 
          It is therefore not unreasonable to conjecture that a failure to distinguish semantics from pre-semantics is responsible for CTM’s presupposition that syntax is identical, or at least capable of being meaningfully aligned, with pure morphology. In its turn, the idea that morphology by itself has some kind of significant connection with syntax validates the idea that, from at least one point of view, a symbol-token just is a bit of morphology.
 
Another disambiguation of the term “syntax”


         A linguist would say that 


(i) “snow is white or snow is not white” 


has the same syntactic structure as 


(ii) “snow is white and snow is not white.” 


But a mathematical logician would not say this. This isn’t because the mathematical logician disagrees with the linguists; it is only because the two use the word “syntax” in different ways. 
         In any case, it is easily seen that the mathematical logician’s disambiguation of that term is no more capable than the linguist’s of validating CTM. For the mathematical logician, two sentences have the same syntax iff there are no significant proof-theoretic differences between them.[153] (i) and (ii) are significantly different from that viewpoint. So are (ii) and 


(iii) “if Smith is green, then either Smith is green or he is not green”, 


even though both (i) and (iii) are both “syntactically true” and are therefore both provable. Two syntactically true sentences are syntactically identical if they are identical in respect of their proof-theoretic properties. 
      Of course, not all sentences are syntactically true (or syntactically false). But because we know what it is for two syntactically true sentences to be syntactically identical, it is easy to produce a general criterion of syntactic identity – one that applies to any pair of sentences, regardless of whether its members are syntactically true or not. Any sentence, whether syntactically true or not, can be embedded in a complex sentence that is syntactically true. The sentence “if Smith is tall, then something is tall” is syntactically true, even though “Smith is tall” is not. In light of this, let S and S* be any two sentences, whether syntactically true or not; and let C(S) be any syntactically-true sentence of the form…S…If C(S) is syntactically identical with C(S*), then S and S* are syntactically identical; and if not, not. 
        When the mathematical logician talks about “syntax”, he is talking about an aspect of semantics. If he says that a sentence is syntactically true, he is saying that it is a theorem of the rules that assign it meaning that it is true; and if he says that two sentences S and S* are syntactically identical, he is saying that the proof of the theorem that C(S) is true is relevantly similar to the proof the corresponding theorem for C(S*), where C(S) and C(S*) are defined as before. Like the linguist, the mathematical logician uses the term “syntax” to refer to meaning-how. The logician and the linguist operate with different contextualizations of the notion of meaning-how. But that doesn’t matter in this context. What matters is that, when the mathematical logician uses it, the term “syntax” refers to an aspect of meaning and that, consequently, a syntax-driven operation is meaning-driven. We may conclude that neither the linguist’s nor the mathematical logician’s disambiguation of the term “syntax” favors CTM.[154]


More on the concept of a mechanical procedure 


        There is another delineation of the “mechanical procedure.” Let us see if it does a better job of validating CTM than the delineation just considered. 
       Let LM be the system of semantic rules that assigns the number one to “1”, the number two to “two”, the operation of addition to “+”, and so on. As almost everyone past the age of six knows, there are special techniques involving those rules that enable one to add (or multiply or divide…) large numbers. If one wants to add 1,297,967 and 7,645, one writes down the corresponding numerals, making sure to line up with the “5” with the “7”, the “4” with the “6”, and so on. Once that is done, adding those two numbers is reduced to adding a series of single digit numbers. So what would otherwise be a task requiring Herculean mathematical prowess becomes a task that is entirely “mechanical”, meaning that no intelligence (over and above such as is possessed by anyone of normal cognitive ability past infancy) is required to execute it. 
        Obviously this delineation of the term “mechanical” doesn’t validate CTM. In order to implement the procedure just described, one must have a formidable repertoire of perceptual and cognitive capabilities. One must be able to see, hear, and write down symbols; one must have mastered a system of symbolic conventions. Only a creature that already has considerable cognitive powers can engage in operations that are “mechanical” in the sense just described. It would therefore be absurd to suppose that the foundations of cognitive life consisted in the implementation of such operations.[155] 
        There is a third delineation of the term “mechanical procedure.” Given the existence of certain symbolic conventions (e.g. the convention that “1” denotes the number one), there is a function that assigns truth-values to arithmetical statements on the basis of their shapes. There is a function that assigns truth to “1+1=2” on the basis of its shape and that assigns falsity to “1+1=3” on the basis of its shape. And there is no difficulty constructing a machine M such that, given the left-side (so to speak) of an arithmetical equation, M produces a shape that is assigned truth by the function in question. (So given “12+12=”, M writes down, or otherwise generates, a “24”, thus producing a shape – “12+12=24” – that is assigned truth by the function in question.) The activity of a machine like M is obviously mechanical in a quite strict sense of the word: it is purely physics-driven; consideration of meaning plays no part. 
     One is tempted to say of machines like M that they add, subtract, and so on. Of course, we add and subtract; and in so doing, we are thinking. Given this, it seems to follow straightforwardly that, in virtue of engaging in purely mechanical procedures, machines like M are thinking. In general, purely mechanical activity can yield thought. 
        But such a position involves a blunder that we’ve already discussed. Given any inscription, no matter what its morphology, there are infinitely many languages L such that in L that inscription means nothing or means something false. Since M’s behavior isn’t driven by a sensitivity to the relevant semantic conventions, that behavior does not, by itself, constitute a case of adding twelve to itself. 
      This must be understood aright. Given that M has written “12+12=24”, there has been a genuine cognitive achievement: there has been a case of twelve being correctly added to itself. But the structure of that achievement is very different from that ascribed to it by the position described in the last paragraphs. 
      This can be made clear through a story. Smith is somebody who knows about the conventions constitutive of L. Also, Smith knows that M has been so constructed that it produces inscriptions that, relative to those conventions, constitute true arithmetical statements. Finally, Smith punches in “12+12=”, and watches as M generates a “24.” (To simplify discussion, let us suppose that Smith is so mathematically incompetent that he can’t add twelve to itself without the assistance of a calculator.) 
        Twelve has been correctly added to itself. But that achievement consists not in anything that the calculator does, but in Smith’s being able to put the calculator’s activity into the appropriate psycho-social context. Smith realizes that, given the conventions of L and given the sort of thing that M is, the fact that M produces a token of “24” under the circumstances described warrants the conclusion that 12+12=24. A purely mechanical procedure (M’s engaging in certain strictly physics-driven manipulation of shapes) is constitutively, and not merely causally, involved in Smith’s having this recognition. This is shown by the fact that, if M malfunctioned, but by some coincidence produced a “24”, Smith wouldn’t have had acquired any mathematical knowledge. (Supposing that Smith had every reason to believe that the machine wouldn’t malfunction, we’d have a case of justified true belief that isn’t knowledge.) But that physics driven process by itself doesn’t constitute such an achievement. It is Smith’s having a certain recognition that does so.[156] 
        A procedure that is “mechanical”, in the sense just described, doesn’t presuppose any mental faculties of any kind. But, as we just saw, such a procedure also fails to generate anything mental. So even though it wouldn’t be viciously circular to suppose that our thinking is realized by mechanical processes of the kind just described, such a supposition would still be quite erroneous. This third delineation of the term “mechanical procedure” therefore fails to validate CTM. 
         An “algorithm” is a “mechanical procedure” for deciding the truth-values of statements. Given what we’ve just said, it follows there is no delineation of the expression “algorithm” that validates CTM.


Linguistic communication as involving isomorphism, not identity, of thought (revisited) 


         Earlier we discussed why linguistic communication demands that speaker and auditor have isomorphic, not coincident, thoughts. Before that, we discussed why what a sentence communicates consists less in what is literally meant by it than it does in what the auditor learns in the process of figuring out what is literally meant by it. In this section, we’ve seen why “formal” truth is syntactical truth and that, consequently, a sentence-token is “formally true” in virtue of how it means what it means. A short story will help show how these points relate to one another, and also why they have so often been overlooked. 
      Aaronson is  a scientist who has generated a great deal of experimental data. He sends a report of that data to me. His report contains no analysis – just raw data. My job is to distil that data into a theoretically significant statement. In the process of doing so, I must add two 87-digit numbers. Even though I don’t have a calculator, I am able to compute the relevant sum, thanks to the algorithms that I learned as a third-grader.  It is beyond my powers to figure out to what exact number an 87-digit number-expressions refers. So identities of the two numbers that I am adding are unknown to me, as is the identity of their sum.
      I include my computations in my lab-report, which I then send to Brown. Brown is no more able than I am to excogitate the reference of an 87-digit number-expression. But, for reasons similar to those just discussed, he can still use my written record of my computation to analyze what I have sent him. (Brown’s job is to mediate between scientists and non-scientifically inclined policy-makers. So his job is to analyze my analysis into a form that is meaningful in the context of a political discussion.) Brown’s analysis is condensed into a statement that contains only short, easily understood number expressions, if it contains any such expressions at all.  He then relays that analysis to policy-maker Green. 
         Here information was transmitted from Aaronson to Green. Many of the symbols that were instrumental to that accomplishment were not understood. But those symbol-tokens were not therefore frozen or otherwise useless. Even though nobody fully understood the 87-digit number-expressions just described, those expressions facilitated the flow of information from person to person. We thus see corroboration for our earlier point that part of what makes language so useful is precisely that it isn’t in lock-step with thought. 
        One might argue that this digression ultimately undermines our position. Those number-expressions were useful in this context, despite their not being fully understood, only because there are formal rules for operating with them. So even though it may support our views concerning the distinction between literal and cognitive meaning, this little digression undermines our critique of CTM and is therefore, on balance, to the discredit of our position. 
        But this is not so. What does it mean to say that, in the story just told, my operations with those number-expressions were “formal”? I knew the rules assigning meanings (referents) to those digits; I knew that “1” denotes one; that juxtaposing single-digit numerals m and n denotes the result of adding the number denoted by n to the number that results when the number denoted by m is multiplied by ten; that “+” denotes the operation of addition; and so on. My having purely formal knowledge consisted in my knowing how those 87-digit expressions meant what they mean without knowing what they mean. So we find corroboration for our position that the syntax of an expression – its formal properties – lies in how it means what it means Syntax is meaning-how, as opposed to meaning-what. We’ve already seen why this is a problem for CTM.
        In Part I, we argued at length that the information that person A takes away from a verbal exchange with person B is absorbed in the process of the A’s figuring out what is meant by B’s words. What is actually meant by those words is, of course, important. But its importance lies not in its coinciding with what is transmitted, but in its directing the auditor’s information-gathering efforts in a certain direction. 
      We found corroboration for this line of thought in our discussion of the 87-digit number-expressions. Nobody in our story knew what those expressions referred to. But those expressions facilitated the transmission of information from Aaronson to Green. And they did so not because anybody knew what they referred to, but because of the efforts that people made in the way of operating with the rules that assigned them meaning.


The viability of CTM re-visited 


           It is natural to suppose that a language is a set of rules that assign meanings to objects on the basis of their morphologies. This is exactly what CTM assumes; for it is built into the CTM-view that there are strictly morphological characterizations of syntactic structures and also of semantic notions such as proof, entailment, and confirmation.[157]
          We will see in the next chapter that such a view is quite false. Given any language, actual or possible, an object’s having this or that shape is neither necessary nor sufficient for its being assigned any meaning by that language. But right now, if only for the sake of argument, let us suppose that this assumption of CTM’s is correct. 
       What follows from this supposition is not that thought consists in shape-manipulation per se. As we saw a moment ago, sensitivity to semantic (and extra-semantic) facts is a pre-requisite for cognitive achievement, even in domains where all issues can be decided through decision-procedures. Even such where domains are concerned, what counts as a genuine cognitive achievement is one’s recognition of a rather complex proposition, one having the form: given that such and such conventions are operative; given that, because those conventions are operative, there is a morphological characterization of truth; and, finally, given that this particular shape has the relevant morphology; it follows that this particular shape expresses a truth. 
       There is nothing mechanical about one’s coming to see the truth of such a proposition, and one’s doing so has no intrinsic connection with one’s manipulating shapes. Of course, the manipulating of shapes is often a psychological aid to one’s arriving at the correct judgment; and one often writes down the judgments that one generates. But in both cases, the connection is entirely causal, as opposed to constitutive, and is therefore entirely contingent. 
       Suppose that Smith proves some theorem. Here we must distinguish three things: first, the proof itself; second, Smith’s knowledge of that proof; and third, his communicating that proof to someone else. The first is an abstract object. In fact, it is a network of logical, and therefore abstract, relations holding among objects (numbers, propositions) that are themselves abstract. The second is a psychological condition. The third is a complex state of affairs having both psychological and non-psychological components. To communicate his knowledge, Smith must produce various noises or ink-marks; and producing such ink-marks and noises may also help Smith generate that knowledge. (It is easier to solve a problem with a pen and paper than it is to do it entirely in one’s head.) Symbolic manipulations may thus be causes or effects of that knowledge. But under no circumstances are they constitutive of it. 
        CTM seems to involve the view that the behavioral expressions of proof-derivation are identical with proof-derivation. This view is false, given that it is a form of behaviorism and that behaviorism is false.[158] (Ironically, no one better articulates the reasons for rejecting behaviorism than Fodor (1968) himself.)[159]
        Some fiction may help both illustrate and corroborate this of thought. On some other planet, there is a society S where completely different symbolic conventions are used. “1” doesn’t mean one, “+” addition doesn’t refer to addition; in fact, none of these symbols means anything.  In S, a freak accident creates an object X that is qualitatively just like one of our calculators. Obviously the members of S won’t regard X has doing anything meaningful. And given how it came into existence, there is little intuitive support for the idea that X is actually computing anything when it transitions from “1+4=” to “5.” On the contrary, our intuition suggests that X hasn’t performed a computation or otherwise done anything cognitive. We would have the same intuition with regard to X’s behavior if it were to have been created (through some random accident) on an unpopulated planet. So there is no intuitive evidence that by itself X is computing or otherwise thinking. 
       Of course, in our world, when objects like X transition from 1+4=” to “5”, and make other comparable transitions, many of us have the intuition that those objects really are computing. But that intuition vanishes when we place X in an environment where our symbolic conventions don’t hold. This suggests that, so far as people see objects like X as actually thinking, it is because they are telescoping into their judgments about X’s behavior their background knowledge of the socio-psychological conditions that generated X. In general, so far as people have the intuition that calculators and other automata think, their intuitions make heavy allowances for  the intentions and social functions of the people and institutions that produce those machines, and are therefore not hewed strictly to the activity of those machines. It is obvious why these facts strip those intuitions of any credibility that they might otherwise have. 
        The content-externalist has a counter-response to this last argument 


    The essence of content-externalism is that what an object is thinking, and therefore whether it is thinking, is a function of its causal liaisons to the environment. You are right to say that an object qualitatively just like one of our calculators wouldn’t really be calculating or otherwise cogitating if it were created by a freak accident on some planet where our symbolic conventions weren’t operative. But content-externalism shows that an object qualitatively just like you wouldn’t be thinking about water on a planet where XYZ, as opposed to H2O, came out of water-faucets and filled our oceans, and so on. 
      
       But we saw in Part I why this point of view cannot be accepted.  
 
Analytic functionalism and the Ramsey-Lewis sentence  


     There is a way that an advocate of CTM might respond to the general line of thought just put forth. It involves – indeed, it practically coincides with -- a conception of mental content that is widely accepted and that is discrepant with the analysis put forth in this book. So even though, as we will see, it is not a line of thought that Fodor countenances, it is one that we must examine carefully:


(AF)      Given only that machine M outputs a “12” in response to an input of “7+5=”, it doesn’t follow that M has done a sum; and you are right to say that one is guilty of the crudest form of behaviorism in so far as one thinks otherwise. But this is neither here nor there as far as CTM is concerned. David Lewis (1972) used the concept of a Ramsey-sentence to show how a creature’s mental states – while not identical with dispositions towards certain behaviors, given certain inputs – can nonetheless be understood entirely in terms of that creature’s inputs and outputs. 
        Let C be a creature and let S be a giant, conjunctive sentence giving a complete description of C’s psychology. Obviously, S will not contain only psychological terms; it will contain at least some terms linking psychological states to publicly verifiable inputs and behavioral outputs. must be made for will make at least some mention of inputs and behavioral outputs. So S will contain sentences like “ceteris paribus, given a perception of cold-water, C will grab said class and drink its content.” (Given any psychological theory – whether Freudian, Chomskyan, or Skinnerian – it will surely make at least some allowance for the behaviors characteristic of mental states, even though those theories may differ among one another as to the relationship between mental and behavioral facts. Also, if S doesn’t contain sentences concerning overt behavior, then it is hard to see how it could constitute a testable, or therefore empirically significant, theory. So there is nothing question-begging in Lewis’ supposition that S will refer to publicly ascertainable inputs and outputs on C’s part.) We now “Ramsify out” all the expressions in S that refer to mental states. Given any mental term mi occurring in S, we replace it with a variable xi, and then prefix the resulting open-sentence with a quantifier that binds all of the occurrences of xi. (The identity of this quantifier may depend on the value of i. So it might sometimes be ┌for some xi┐, and it might other times be ┌given any xi. ┐) Let S* be the sentence that results from this process. 
     Given any conception of scientific rigor, S* will be no less an adequate description of C’s psyche than S. Really, the differences between them will confined to phraseology. (Where S says “given a perception of ice-water, thirst is what causes C to reach for the glass”, S* says “there is some state x such that, given a perception of ice-water, x is what leads C to reach for the glass.) Obviously S* contains no mental terms, and the only constants in it refer to non-psychological inputs and outputs. But unlike behaviorism, S* does justice to the fact that, to some extent at least, we must understand C’s psychology  in terms of interactions among C’s mental states. But, like behaviorism, S* describes psychology entirely in terms of stimulus and behavioral response. And because, as previously noted, any reasonable description of C’s psychology will contain at least some sentences linking C’s mental states to its inputs and outputs, there seems to be no reason why the process just described wouldn’t hold equally for all admissible values of S.
      A moment ago you suggested that CTM involves a simple failure to distinguish between a mental state and its behavioral expression. Given the concept of a Ramsey-sentence, it seems that this criticism is unjustified. M’s computing a sum isn’t to be identified with its engaging in certain behaviors in response to a certain input. But its doing that sum is still constitutively linked with having that behavioral response to that stimulus.
     Further, the idea that computing has at least some constitutive connection with overt behavior seems to me more reasonable, and more scientific, than your idea that, so far as computing is concerned, behavior is a “mere epiphenomenon.” Your view seems to be that a disembodied brain could compute. But such a position is inherently untestable, and provides no empirical (observable) interpretations, no matter how partial, of its theoretical (mental) terms. Given points that were well established long ago, it follows that your position is incompatible with the most basic tenets of scientific methodology. 


    
           The position just described is a form of functionalism, and we’ve already (Chapter 13) seen one reason why that doctrine cannot be accepted. 
        There are other problems with (AF) and with functionalism generally. One of these problems is identified by Fodor himself (Fodor 1998: 45, Fodor and Lepore 2002). If content is causal role, then the same content cannot possibly have different causal roles. But supposing that b is your belief that snow is white, there are obviously counterfactual scenarios where b has a causal role different from the one it has here. (If you had written your dissertation on crystallography, instead of on Bentham’s political theory, your belief that snow is white would have led you to make many inferences that have not in fact made.) (AF) makes b’s association with its representational content much more brittle than it actually is. For similar reasons, (AF) makes it virtually impossible for two different people to believe that snow is white, since the causal role of one person’s belief in that proposition will inevitably differ from that of another person’s corresponding belief. Of course, what we just said about beliefs that snow is white is true of all beliefs and, indeed, of all propositional attitudes.
       The counter-response would be to say that if two causal roles are sufficiently similar, then they both realize the same content. So causal role fixes content, but content doesn’t determine a unique causal role. 
     There is an obvious problem with this counter-response. The causal role of one person’s belief that snow is white can be extraordinarily different from the causal role of another person’s belief that snow is white. Smith is a physicist who has spent his life studying the reflective properties of crystals and who believes (correctly, let us suppose) that a solution to the major problems of contemporary physics are to be found through careful consideration of snow’s chromatic properties.  Brown is a ski-instructor who wishes that snow were green, because the glare caused by snow’s whiteness gives him headaches and makes it hard for him to see. Let bs the brain-state realizing Brown’s belief that snow is white, and let bb be Smith’s corresponding brain-state. 
       Obviously the causal roles of these two states differ dramatically. So far as they have anything in common, it seems to be that each realizes a belief that snow is white: so far as bb‘s functional role is similar to bs‘s, this similarity lies in the fact that, in each case, this functional role is generated by some object’s being a belief that snow is white. But if we say that the contents of these states supervene on their functional roles, we cannot without vicious circularity say that their functional roles are determined by their contents.[160] In general, we cannot without vicious circularity understand causal role in terms of content if we understand content in terms of causal role. (AF) thus turns out to be viciously circular.[161] 
 Chapter 14 The concept of a symbol 


         If a coffee-machine accidentally produced the sounds “snow is white”, nothing would have been said; no symbols would have been tokened. Of course, one might think that the coffee-machine was actually producing symbols. But one would believe this only in so far as one believed that the coffee-machine’s production of those sounds was actually animated by certain intentions (or that the coffee-machine had been created by somebody with certain intentions and that, consequently, somebody was speaking through the machine, much as one can speak through a letter or an email). The moment one accepts that the coffee-machine is inanimate, and that its production of those sounds is simply an accident, and not the result of its creator’s intentions, one immediately accepts that nothing has been said and that nothing linguistic has occurred.[162] 
      This suggests that the psychological underpinnings of a symbol-token are not just causally, but also constitutively, involved in that tokening. Even though it is imperceptible to others, one’s mental state is constitutive of the symbol-token one is producing. This shows that when the symbol-type “snow is white” really is instantiated, a constituent of that instance is some kind of mental state: when somebody says “snow is white”, the symbol-token that has been produced actually comprises at least some aspects of the mind of the person who produced that token. 
     Of course, it would be false to say that every aspect of that person’s psyche is a constituent of that token. Suppose that, while experiencing a tickle in my left foot, I say “snow is white”, but that my reasons for saying this have nothing to do with that tickle. In that case, even though it is an aspect of my mental condition, that tickle is not constitutive of the symbol-token I have produced. But this obviously doesn’t mean that other mental states of mine are not thus constitutive; and we just saw that they are. 
      Sometimes the psychological aspects of a symbol-tokening are spatio-temporally remote from its morphological aspects. Suppose that I am typing on a keyboard that forms letters out of giant rays of light in some remote galaxy. In that case, the morphological aspects of the token of “snow is white” that I produce is estranged by millions of years and miles from the psychological aspects that same token. 
 
Symbols not strictly psychological entities


      At the same time, psychology cannot single-handedly turn an otherwise dead sound into a living symbol-token.  Suppose that, while in the grips of a psychotic delusion, Smith utters complete gibberish, thinking that it means snow is white. 666 One might be able to figure out that Smith meant snow is white. But this would be a case of one person’s having psychoanalytic or criminological insight into another. It would not be a case of two people speaking a common language. 
       Indeed, it would not be a case of anybody using any language. Given only that Smith thinks that his words mean snow is white, it doesn’t follow that they really do mean that, albeit in some private language. (My reasons for this do not have anything to do with Wittgenstein’s celebrated “Private Language Argument”, which we will discuss in Chapter 18. In any case, any similarity between my argument and Wittgenstein’s is unintended.) Suppose that Smith snaps out of his delusional state, but remembers the exact noises that he produced. He will say: “I thought I was saying that snow is white; but I now realize that I was uttering gibberish.” He won’t say: “I was saying that snow is white, but I was saying it in my private idiolect.” 
        Here we must remember that Smith’s intention is to speak some language that others speak: Smith thought that he was speaking English or some other public language. So even if Smith does have some kind of private code whereby he communicates with himself; and even if, relative to that code, the sounds he produced mean snow is white; his intention was to use some public language, and not that private code. So it was an accident that the gibberish he produced was homonymous with the sentence that means “snow is white” in his code. 
       Suppose that I try to produce the English words “snow is white” but that, solely because of some vocal chord malfunction and not because of some repressed urge to speak French, I end up producing the sounds “la neige est blanche.” In that case, I haven’t spoken French 666 any more than the previously discussed coffee-machine is speaking English. Of course, witnesses would probably assume that a French sentence had been uttered 666. But they would be wrong, as we just saw. It may be that I do speak French. But given that my French knowledge was not implicated in my producing the sounds “la neige est blanche”, my producing those sounds was not meaningfully related to anyone’s knowing French, and thus wasn’t a case of French-speaking. Similar considerations apply to Smith’s case. 


Why any symbol-token necessarily has non-morphological components 


           In order for a symbol to be tokened, it is necessary that it arise in a certain way from a certain kind of social knowledge. (Later on, we will try to state more precisely the nature of this knowledge.) In this context, the word “necessary” denotes constitutive, not causal, necessity. So the just described psychological and social conditions are veritable constituents of the symbol-token. 
      This doesn’t conflict with our presumption that symbol-tokens, unlike social practices, are discrete entities. If our analysis is right, a symbol-token is a convergence  of a number of different factors, and that convergence-point is discrete, even though the forces that are converging are not. 
        A symbol-token has morphological, psychological, and sociological components. The morphological components indicate an awareness of the relevant semantic rules; and the relevant semantic rules constitutively involve the existence of social practices. (Initially, this might seem to be viciously circular, since the social-practices in question presumably involve the use of symbols. In Chapter 25, when we are proposing a Searle-based alternative to Grice’s theory of meaning, we will see why there is no vicious circularity.) To some degree, the function of the morphological aspects of the symbol is to indicate the operativeness of psychological and sociological factors. But there can be no more be a symbol in the absence either of the latter two factors than there could be in the absence of the first. So far as we tend to think otherwise, it is a reflection of our tendency to telescope meta-perceptual into perceptual information. 
       Here it is crucial to keep in mind the distinction between saying and expressing. When I produce the sounds “snow is white”, that symbol-token doesn’t mean that such and such socio-psychological factors are now operative. Semantically, that symbol-token ascribes a certain color to snow, and that is all it does. But given that a symbol-token meaning snow is white has been produced, it can be inferred that certain psycho-social factors are  operative. So that symbol expresses, but does not state, the existence of those factors. 
      A symbol is what results when a bit of morphology is produced in consequence of the convergence of social and psychological factors. A symbol-token is thus best thought of as a convergences of psychological and sociological forces. 
         Of course, we instinctively gravitate towards the position that symbol-tokens are discrete physical objects – bits of ink and noise. In fact, that position may even seem a truism or a definition. But it is only because we labor under a number of misconceptions that we gravitate towards such views, and I think that the following comparison may help loosen the hold that those misconceptions have on us. (The comparison is one that is found in Wittgenstein (1958). Much of what we will say in connection with money resembles what is said there.)
       What is money? Here is a line of thought to which we are instinctively drawn: 


($) Dollar bills and nickels and quarters are money. They are also physical objects. They are bits of paper or metal. Money is created (in mints), and it can be destroyed. In the U.S. it is actually illegal to destroy money. If you burn a dollar bill, you are breaking that law. So a dollar bill is just a piece of paper. For exactly similar reasons, a nickel is just a piece of metal. 


       Though there are elements of truth in it, ($) is false on the whole; and it is worthwhile to say precisely why it is false, since there is such a strict parallelism between ($) and the conception of symbol-hood that I am attempting to refute.
      Let B be some particular dollar bill – e.g. the dollar bill that is in your pocket. Now imagine the following scenario. Tomorrow, the U.S. is taken over by a foreign power. A new system of government is imposed, and this involves changing the currency that is used. The bits of paper that Americans used to use to make purchases are now as useless as Monopoly money.[163] 
       Under these circumstances, what has become of B? (We are supposing that B hasn’t been damaged or destroyed.) Obviously B isn’t money anymore. Given this, the problem with ($) is clear. B is a piece of paper. That piece of paper hasn’t been destroyed. But B isn’t money any more: as far as its being money is concerned, B might as well have been incinerated. Leibniz’s Law thus prevents us from saying that B itself is money. 
      Given these points, what we must say is at least approximately as follows. B per se was never money. B was a certificate of some kind. It certified that its possessor has certain rights within a certain legal-political structure. Since that structure is now gone, what B certifies doesn’t exist: B is a bogus certificate, and thus not a certificate at all. By itself, B never had purchasing power. Something that has no purchasing power isn’t money. So B was never money. What did have purchasing power, and what was therefore money, was B’s being embedded in a certain legal-political structure. By itself, a piece of paper isn’t money. What is money is that piece of paper’s being embedded in certain social practices. 
      Up to a point, the function of the piece of paper is to indicate the presence of those social factors. That is why there are so few limits as to the physical form that money can take. So long as the relevant social factors are indicated, the physical composition of the indicator is irrelevant. That is why there can be billionaires who are not in a possession of a quarter or dollar bill. So far as it has any physical incarnation, a person’s vast fortune may be realized by patterns of electrical impulses transmitted from computer to computer. 
       This is not to deny that physical tokens – e.g. dollar bills, nickels – are constitutive of money. It would be an overstatement to say that B was merely an indicator the presence of the just described social factors. (Let us now assume that B is valid currency – that the political take-over earlier described never occurred, and that the bits of green paper in your wallet remain valid currency.) Suppose that a copy of a legal contract is destroyed. If a duplicate is found, then the legal situation hasn’t changed: ceteris paribus the judges, lawyers, and so on, are still going to do whatever they were going to do prior to the destruction of the first copy.[164] The physical copy of the contract is there merely to indicate that some kind of agreement has been entered into; its legal purpose is merely evidential. But this is not the case with B. If B is destroyed, its possessor has lost certain entitlements: he cannot get on the bus; he cannot go to the baseball game. It is irrelevant whether B was destroyed in plain view of a judge or public notary. When B is destroyed, money is destroyed.  
       But in this context what is relevant is that money is destroyed when the social structure of which B is a part is destroyed. B’s being money is destroyed 666  under that circumstance 666; and this shows that what is money – what has purchasing power - is not B itself, but is rather a constellation of forces that converge in B. If we insist on saying that B itself is money, then we are stuck with the consequence that money has no purchasing power and, indeed, that it has no powers that distinguish it from scrap paper. Since money has causal powers that a mere piece of paper does not, a piece of paper is, at most, a constituent of a piece of money, the other constituent being some political-legal apparatus. And up to a point, though not entirely, the function of the piece of paper is merely to indicate the operativeness of that apparatus. 
       Everything that we just said about money is true of symbol-tokens. Admittedly, it is unclear whether this discussion of money provides any independent corroboration for our discussion of symbols, since a piece of money is itself a symbol or, in any case, seems to presuppose the existence of symbolism. Nonetheless, our discussion of money does at least clarify the structure of our analysis of symbolism, and hopefully makes it clear what that analysis is not as revisionist as it might initially seem. 
       Also, our discussion of money brings to light some principles that will enable us to neutralize an obvious criticism that might reasonably be made of our analysis of symbolism: 


      You may be right to say that, as a matter of analytic necessity, there are genuine symbol-tokens only where there are socio-psychological factors of the sort you describe. But you are guilty of a blatant non sequitur in inferring from this that those factors are veritable constituents of symbol-tokens. As a matter of necessity, I couldn’t have had different parents from the ones I actually had. But my parents are not in any sense constituents of me. The idea that a symbol is just a bit of morphology is thus perfectly compatible with the view (held by you and others) that symbol-tokens necessarily originate in socio-psychological conditions of a certain kind. Those views are no more incompatible with each other than the obvious fact that people are distinct from their parents is incompatible with the thesis that no one other than Y and Z could have been X’s parents if those two are in fact his parents. Your thesis that psychological and social conditions are actual constituents of symbols thus seems to be, at best, a proposal that redefine the term “symbol” (or “symbol-token”). Currently, that term to denote ink-marks and noises; and you are proposing that we have it refer to ink-marks (or noises) plus their social and psychological concomitants. What you’ve said in connection with symbols is false if taken as an analysis, and sterile if taken as a proposal to change our nomenclature. 


    
      
       Remember what we said a moment ago about money: we strip money of many of its causal powers if we identify it with mere bits of paper. Of course, we do not thereby strip it of all of its causal powers; but we strip it of those causal powers that distinguish it from mere scraps of paper. Like money, symbol-tokens have causal powers. If we identify symbol-tokens with bits of ink or noise, then we strip them of many of their causal powers. Of course, we do not thereby strip symbol-tokens of all of their causal powers; but we strip them of those causal powers that distinguish them from mere ink-marks and noises. If we say that a token of “snow is white” is merely a sound or ink-mark, then we strip that token of the causal powers that distinguish it from the barking of a dog or the grumbling of someone’s stomach: we strip it of its distinctively symbolic causal powers. Because so many aspects of human thought and behavior are to be understood in terms of the manipulation of symbol-tokens, it isn’t reasonable to take the position that symbol-tokens don’t have any causal powers not also had by mere noises and ink-marks. Such a position would either nullify obviously correct analyses of human conduct or it would demand a tedious and unproductive rewording of those analyses. If we are to accommodate the fact that symbol-tokens have causal powers not had by mere ink-marks and noises, then we must take the position advocated earlier, and denied by the objector: any symbol-token has a morphological component; but up to a point, though not entirely, the function of that component is merely to indicate the presence of socio-psychological factors that are themselves components of that token. There is no way to account for the causal efficacy of symbol-tokens qua symbol-tokens without seeing the morphological, psychological, and sociological factors necessary for the existence of symbol tokens as veritable constituents of those tokens. 


Symbol-caused versus symbol-driven 


        A short story can help us substantiate this line of thought. One day, while rummaging through your attic, you come across a bottle of colorless liquid. On the bottle there is a strange ink-mark. We will refer to that ink mark as “X.” But the ink-mark itself does not itself have an X-shape. 
      We must keep in mind that “X” is our word for an ink-mark. If it should turn out that X betokens an expression of some language, “X” is not our word for that symbol-token, but only for the corresponding ink-mark. In this context, we need to be especially fastidious about this distinction if we are to avoid prejudging the issue being discussed. 
       It turns out that X does betoken a symbol belonging to a language L, and the English-translation of that symbol-token is: “If consumed, the contents of this bottle cure arthritis.” But you don’t know now what X means and you don’t even think that it is a symbol. Your inclination is to believe that it is meant only to be a logo or some kind of decoration. 
      Nonetheless, you find X’s design to be intriguing, and you put the bottle on your windowsill in an effort to enhance the appearance of your under-decorated room. Your friend Brown, who suffers from acute arthritis and has had no luck with conventional medicine, is a native speaker of L. One day, he sees the bottle. He immediately uncaps it, and drinks it down. He is immediately cured of his arthritis. The statement on the bottle was correct. 
       It is a datum that Brown’s activity was symbol-driven, whereas yours was not. But what exactly does it mean to say this? Here we must remember a point made earlier, and to be discussed at length in a later section. It is not objects, but states of affairs, that have causal properties. It is not the rock that breaks the window, but is rather some state of affairs consisting of the rock’s having a certain mass and moving with a certain velocity at a time vanishingly close to the moment of impact. From the standpoint of causal explanation, the rock is inert; what does all the work is the rock’s having a certain mass, its moving with a certain velocity, its having a certain structure, and so on. For exactly similar reasons, the ink-mark is a non-entity from the viewpoint of causal explanation. What does the work is the ink-mark’s having this or that property. 
       Here we might be tempted to say that Brown’s behavior is symbol-driven because it is caused by the ink-mark’s being a symbol. But this wouldn’t be right, as we can see by slightly extending our story. After watching Brown guzzle the contents of the bottle, you suddenly fear that the bottle might have contained poison. So you call for an ambulance before Brown has a chance to explain his behavior to you. If indeed, Brown’s behavior is a consequence of the ink-mark’s being a symbol of a certain kind, then the same must be true of your behavior: after all, since Brown’s behavior is causally responsible for your behavior, anything that is responsible for his is also responsible for yours. (Here the term “responsible” doesn’t have any moral connotations.) But your behavior obviously isn’t symbol-driven. From your viewpoint, the ink-mark remains just that – an ink mark. 
           Brown’s behavior is symbol-driven because it is caused by his recognition that the ink-mark in question was the effect of certain socio-psychological conditions. X’s  functioning symbolically involves Brown’s recognizing that X had certain origins. X’s functioning as a symbol does not consist in its having a certain morphology or even in anyone’s recognizing that it has such a morphology. (You recognize that it has that morphology, but your relationship to X is not significantly different from your relationship to some non-symbol, such as a wallpaper-design.) In general, an object’s  functioning as a symbol involves someone’s recognizing  that it has certain origins. 
       If that recognition is absent, we have non-symbolic activity. In the story just told, you don’t have such a recognition, and your subsequent activity is not symbolic. If that “recognition” is false – in other words, if the object in question doesn’t have the right origins, but someone thinks otherwise -- then what results is faux-symbolic activity.  More exactly, what results is activity that isn’t symbolic but that is, from a strictly psychological viewpoint, indistinguishable from such activity. We may illustrate this last point through a slight change in our story. 
      You think that X is an attempt on the part of aliens to communicate with you. By sheer coincidence, you think that X means: if consumed, the contents of this bottle cure arthritis. So you happen to be right about what X means, but this is entirely a matter of good luck. Because you have arthritis, you guzzle down the contents of the bottle. Are we to say that X has functioned as a symbol here? No. Even though X is in fact a symbol that means if consumed, the contents of this bottle cure arthritis, and even though your belief that it has that meaning is what governed your conduct, X has not functioned as a symbol that has that meaning. A genuinely symbolic response to an ink-mark (or sound or pattern of light on a computer-monitor…) involves a knowledge that it has certain origins. Coincidentally correct belief won’t suffice. 
        Brown has assimilated certain linguistic rules that you have not. This is obviously part of what explains the differences between your behavior and Brown’s. The differences between people are frequently to be understood in similar terms. Much human thought and conduct is symbol-driven. It is therefore not an option to say that symbol-tokens qua symbol-tokens are causally inert. But this is precisely what we are forced to say if we insist on saying that symbol-tokens are ink-marks and noises. To accommodate the causal powers had by symbol-tokens qua symbol-tokens, we must insist that an ink-mark (or noise or pattern of light…) is but one aspect of the instantiating of some symbol-type.   


The relevance of these points to CTM’s viability 


       These points about symbolism have manifold relevance to the question of whether CTM is viable. Given only that the presence of what is in fact a symbol has caused you to act in a certain way, it doesn’t follow that your subsequent thought or behavior has any symbolic dimension. The presence of X on the bottle caused you to do things that you wouldn’t otherwise have done, and to think things you wouldn’t otherwise have thought. But those thoughts and deeds were not relevantly different from the thoughts and deeds that would have been precipitated by your seeing a beautiful flower or a graceful foal. If we insisted on describing your activity as symbol-driven, we thus would strip that term of any meaning. 
      We will henceforth reserve the term “symbol-driven” for activity that is similar to Brown’s – activity constitutively connected with one’s acquiring information through a symbolic intermediary. (In this context, the word “information” is meant to denote any content, not just true content.) 
        CTM doesn’t register the distinction between a behavior’s being symbol-caused xxx and its being symbol-driven xxx. There is no denying that the calculator’s behaviors are caused by the presence of what are in fact symbols. But it doesn’t follow that the calculator’s behavior is symbol-driven, i.e. it doesn’t follow that anything’s being a symbol is responsible for the calculator’s behavior. And, as we saw, in so far as the calculator’s behavior is strictly morphology-driven, its behavior is demonstrably not symbol-driven. 
      In our story, Brown’s response to X was symbol-driven because it embodied an understanding of the socio-psychological conditions that gave rise to X. Brown’s relationship to X is not significantly paralleled by calculator relationship to the ciphers that appear on its screen.  
      Brown’s relationship to X presupposes socio-psychological knowledge on his part. This provides indirect, but powerful, confirmation for a point that we defended earlier. For a symbolic-operation to be form-driven, in any relevant sense of the word “form”, is for it to be driven by a knowledge of at least some of the semantic properties of the symbols in question. More exactly, a formal symbolic-operation is an attempt to show that the truth of a certain symbol (or symbol-token) is a theorem of the semantic rules that assign meaning to that token. Obviously semantic facts are, at least in part, a consequence of psychological facts. If the cognitive activity associated with the sound “Mars” traded places, to so speak, the cognitive activity associated with the sound “Jupiter”, then “Mars” would refer to Jupiter and “Jupiter” would refer to Mars. Given that semantics is fixed, at least in part, by psychology, it is to be expected that a sensitivity to semantics would be confluent with a sensitivity to psychology. According to our analysis, Brown’s behavior is symbol-driven in virtue of (inter alia) its embodying a certain kind of socio-psychological knowledge. Our analysis thus accommodates, and to some degree accounts for, the obvious interconnectedness of psychology and semantics. 
       This is not to say that semantics is completely determined by psychology. It is not. There is no denying that semantic facts are fixed not only by human psychology, but also by facts about the environment. (Kripke 1972, Putnam  1975, Burge 1979, and Kaplan 1989 provide cogent arguments for this.) Throughout this book, we have defended semantic-externalism. (It is content-externalism that we reject.) Remember the scenario described at the beginning of this book. In W, “Rocko” refers  to one rock, and in W* “Rocko” refers to some other object, even though the inhabitants of W are psychologically identical with the inhabitants of W*. But this very example brings out fact that human cognitive activity is always partially constitutive of what words mean. In W, “Rocko” refers to R because Max sees a rock, point to it, dub it “Rocko”, and sees to it that his use of is generally accepted. 
        In any case, even the content-externalist accepts that facts about human psychology are partially constitutive semantic-meaning. In fact, the content-externalist takes a much stronger line on this than we do. On our view, Max and Twin-Max are psychologically identical. At the same time, what an utterance of “Rocko” means coming out of Max’s mouth is different from what such an utterance means coming out of Twin-Max’s mouth. It is thus a consequence of our view that psychological facts fail to fix semantic-meaning. But on the content-externalist’s view, Max and Twin-Max are psychologically different: Max has a concept of R in the cognitive place, to so speak, where Twin-Max has a concept of some other rock. So on the content-externalist’s account, the semantic differences between W and W* are matched by psychological differences; and (given only the points just made) there is therefore no reason for the content-externalist to deny that semantics supervenes on psychology. 
        
 The concept of morphological elasticity 


      Let us continue our discussion of the concept of a symbol. We’ve seen reason to accept each of the following points (in this context, the term “ink mark” is short for “ink mark or noise or pattern of light…”): 


(i) An ink-mark is, at most, one component of a symbol-token. 


(ii) Whenever an ink-mark is a component of a symbol-token, its function is in large part to indicate the operativeness of certain socio-psychological conditions. 


(iii) Two tokens of a single symbol-type may be morphologically very different from each other. More precisely, there is no limit to the extent to which two symbol-tokens may differ from each other in respect of morphology.


       It is clear that (iii) is a consequence of (i) and (ii). It is also clear why (i)-(iii) pose a problem for CTM additional to those already discussed. CTM needs there to be a morphological characterization of certain semantic notions; it needs to bring 666 semantic facts (e.g. the fact that one sentence entails another) into alignment with facts about morphology. Supposing that our semantic rules permitted little or no morphological divergences between two tokens of a given symbol-type, such an alignment might be possible within “certain famous limits.” But given what symbol-tokens are, the a priori possibility of such an alignment occurring is vanishingly close to zero. In any case, the conditions under which such alignments would occur would constitutive obfuscations, not expressions, of the basic facts about what symbols are. Any symbol-token has psychological and sociological components --  I am referring to the symbol-token itself, not to what it refers to or otherwise signifies. The function of its morphological component is in large part merely to indicate those other components. Therefore, we cannot reasonably demand of a language that its morphological aspect remain stable. That is like expect the pressure of the gas in a sealed vessel to remain constant, while we raise its temperature. We cannot expect dependent variables to behave like constants (or like independent variables). 
     CTM need the morphological and semantic aspects of language to be in lockstep. For the reasons just given, the circumstances that permit such alignments are in the nature of singularities. There are situations where, within limits, a morphological characterization of certain semantic notions are possible. These are cases where what is in fact the dependent variable (morphology) appears as though it is one of  independent variables (psychology and sociology); and, in its turn, this misleading appearance creates the misleading appearance that the socio-psychological components of symbol-tokens are parasitic on their morphologies. Such situations thus doubly obscure the nature of symbolism, as they invert the structure characteristic of symbol-tokens, and  then proceed to condense the ordinarily distinct entities constitutive of that structure. In taking morphology as primary, CTM erroneously takes such singularities as its paradigms, and erroneously regards non-singularities as deviations or irregularities. 
      Some fiction may help elucidate and also substantiate these remarks. In the year, 2025, human beings lose the ability to speak and to write. They cannot generate new sounds or new ink-marks. If a person wishes to speak, he has to go to a special letter-depository. 666 Such a place is like a library, but instead of containing books, it contains marble representations of the letter R, the letter Q, and so on. So if I wish to propose to my fiancé, I must go with her to a letter-depository, and must physically assemble a set of marble letter-tokens in such a way that there is a token of the sentence WILL YOU MARRY ME? Finally, there is only one such letter-depository in the whole world, and there is only one instance of each letter. So there is only token of the letter A in all of existence, the same being true of every other letter. (In this context, let us abstract from the fact that, for psychological and logistical reasons, such an arrangement would be totally unsustainable.) The letter-depository contains tokens of each of the symbols associated with mathematical and logical extensions of English. So it contains a token of “→” (the sign for material implication), a token of “+”, and so on. But, of course, it contains only one token of each of those symbol-types. 
      Under these circumstances, the morphological elasticity associated with symbols of actual languages would be entirely absent. There would be only one way to say KARL PEARSON DESERVES CREDIT FOR MANY OF THE INSIGHTS ATTRIBUTED TO THE LOGICAL POSITIVISTS or MARTIN SCORSESE’S MOVIE “CASINO” IS GROSSLY UNDERRATED. 
         Under these circumstances, thanks to the complete petrifaction (literally) of symbol-morphology, it would be possible to give a strictly morphological characterization of at least some semantic notions. (For reasons given earlier, the “automatization” or “mechanization” of thought would be no more possible under these circumstances than under our own. But here we are setting this issue aside, so as to develop a new and independent criticism of CTM.) But notice the lengths 666 to which we must go to create the needed alignment of morphology and semantics; 666 notice also how unstable that alignment would be (it would vanish the moment new letter-tokens were  created). This suggests that it is not in the nature of symbol-tokens to be amenable to such an alignment, and this in turn confirms our thesis that symbol-tokens are not mere bits of morphology. We’ve already discussed why this last fact is problematic for CTM. 
        Suppose that I ask you, in writing, to solve some problem of arithmetic. Of course, if my request is to be intelligible to you, it must satisfy certain basic requirements. Those letters cannot be microscopic; nor can they be the size of planets. They cannot be written in lemon juice or in white glue. But within the extremely broad limits set by these requirements, you will have no trouble understanding my inscription of: “what is the sum of 12 and 17?” There is no one font that I must use, no one size that the letters must have, no one material that they must be composed of. 
       But now suppose we are dealing with a creature – as before, let us refer to that creature as “Smith” ---  that he has a strictly morphological understanding of what those symbols are. Smith won’t realize that the inscription 12+17=29 is not relevantly different from the inscription 12+17=29 or the inscription 12+17=29. From a strictly morphological standpoint, any two of those inscriptions are quite different from each other. Similarly, Smith won’t realize that the inscription 11+11=22 is relevantly different from the inscription 111+11=22.  (To simplify discussion, we will suppose that Smith speaks and understands English, but is completely illiterate.)  Given this, suppose you say to Smith: 


(*) To the right of any symbol that is like this [you point to an inscription of “11+11=”] you must write a symbol that is like this  [you point to an inscription of “22”].  


Of course, you and I know what is meant in this context by the occurrences of “like this.” We know that the inscription “11+11” does, whereas the inscription “11-11” does not, satisfy the relevant condition. But because Smith has a strictly morphological conception of what is meant by “like this”, he cannot comply with your instructions except within vanishingly narrow horizons. Smith cannot execute your orders unless in cases where the inscription before him is a perfect duplicate of the paradigm that you gave him.
       In any case, given only what you’ve told him, Smith has no reason to believe that “11×11” is relevantly different from “11+11”, or that the latter is relevantly similar to “11+11.”  From a purely morphological standpoint, the second two symbols are much less alike than the first two. (Of course, what it is for two symbols to be “morphologically alike” depends on the context. Given his investigative concerns, physicist may regard “11×11” as being morphologically closet to “11+11” than to “11+11”, whereas given his concerns, physicist B may take the opposite view. Like all forms of resemblance, morphological similarity is to be understood in contextual terms. But for analogues of the reasons just given, that fact itself redounds to the discredit of CTM.) 
      In fact, even if the inscription before Smith is an atom-for-atom duplicate of his paradigm – even if it is just like the inscription of “11+11” from a few lines back -- he still cannot carry out your instructions. Even under those circumstances, it would be no less rational of him to write a “78” next to that inscription of “11+11” than it would be to write a “22.” This is because, given only what you’ve told him, what you meant by “like this” might have had little or nothing to do with strictly physical properties of the inscriptions that you were indicating. 
         Imagine the following. In plain view of both you and Smith, your beloved daughter etches a token of “11+11=” in the ground. And, again in plain view of both of you, your much reviled son then inscribes a “22” to the right of the equals-sign. It could be that, given your obviously irritated response to your son’s behavior, along with the familial saga in which it is embedded, Smith is not being irrational in taking your first utterance of “like this” to mean something that reminds me of my beloved daughter, and in taking your second utterance to mean something that reminds me of my despicable son. So given only what Smith has been told, it would be no less rational of him to draw a picture of your son next to the instruction or “11+11” than it would be to write a “22.”[165]
       There is another way to establish this same point. Two distinct expressions can be betokened by physically indistinguishable objects: context determines whether it is the one, as opposed to the other, that is being tokened. But context selects the appropriate disambiguation on the basis of the meanings of the symbols in question. Smith says “I’m going to the bank.” Given that he is carrying a fishing pole as opposed to a briefcase, his words probably mean that he is going to a river’s edge.  
        Until Smith knows what you mean by “like this”, he isn’t in a position to carry out your instructions. But the concepts meant by your utterances of “like this” are semantic in nature. Given what you mean by your first utterance, an object (e.g. an inscription) is relevantly like the inscription you are indicating if, and only if, that object is an instance of the same symbol-type. An object satisfies the condition in question if, and only if, that object has right semantic properties. 
         Let us now develop a point made earlier. It is obvious that, given any physical object O, and given any meaning (or referent) M, there is some possible language L, such that O means M in L. But there is a stronger point to make. Given a language L, and given an object O, O’s morphology by itself does little to determine whether O tokens some expression-type of L and, even if O does betoken such a type, O’s morphology does little in the way of fixing the identity of that type. (Later we will see that, by itself, O’s morphology does nothing in the way of fixing the identity of the expression that it tokens. But right now we will defend the weaker claim that, at most, it does little in that respect.)
       Suppose that Jones, Brown, and Aaron are all competent speakers of English. From a strictly acoustical standpoint, Smith’s utterance of “we’re having excellent weather today” may bear much less resemblance to Brown’s utterance of that same sentence than it does to Aaron’s utterance of “weird squirrels abound in that stack of hay.” 
      Of course, it would be an overstatement to say that morphology imposes no constraints on semantics. Obviously it imposes crucial constraints: if you fail to enunciate, or if your calligraphy is poor, I won’t know what you are saying. In fact, if your utterances result from an intention to produce the wrong kind of morphology, then your utterance isn’t a case of speech at all. 
       Here is an illustration of this last point. Smith produces the sounds “snow is white.” His intention is to say that grass is green. He says “snow is white” because, not having a good command of English, he thinks that it means grass is green.
       If Smith has affirmed anything, it is either that grass is green or that snow is white. He hasn’t affirmed that snow is white: he had the wrong intention. And he hasn’t affirmed that grass is green: he made the wrong noise. Therefore, Smith hasn’t affirmed anything. So it is at least partially in virtue of its strictly morphological properties that a physical event or structure qualifies as a symbol-token. 
      Nonetheless, as we’ve seen, morphology only has an extremely partial role in the way of determining whether a physical object betokens this as opposed to that expression-type. 


Why there cannot be too tight a connection between morphology and symbolhood 


        Too much of a connection between semantics and morphology is as threatening to the existence of a usable language as the absence of such a connection. I have probably never heard two utterances of “he’s over there” that sound quite the same. The class of circumstances that permit a perfect instantiation of a given morphology is only a tiny subset of the class of circumstances where we wish to communicate, and language would therefore be useless if there were too close a connection between morphology and meaning. 
          A corollary is that a certain plasticity is built into any aspect of a creature’s functioning that has a genuinely symbolic dimension. To the extent that a creature’s behavior is strictly morphology-based, it doesn’t bear any significant resemblance to anything that is uncontroversially an instance of symbolic activity. Genuinely symbolic activity does, whereas strictly morphology-driven activity does not, allow for an unlimited degree of deviation between a creature’s linguistic paradigms and its reproduction of those paradigms. Genuinely symbolic behavior has a plasticity not had by its mechanical analogues. 
         At first it might appear that, if indeed this last point is true, that is merely a reflection of an evanescent, if not already extinct, fact about our technology. These days one can buy scanners that have “character recognition.” So if you a scan a typed document, what is uploaded is confined to semantically relevant material, and excludes the semantically irrelevant material (e.g. coffee-stains, crushed insects, smudges) that tends to gather on documents. A scanner with character recognition can recognize the word “snow” in physical objects having very different morphologies. So such a scanner seems to have the plasticity that, according to what was just said, they lack. 
        Also, there are technologies that transcribe the spoken word. These technologies are currently imperfect. But the imperfections are rapidly being eradicated; and it is not unreasonable to  expect that, in a few years, there will no longer be a need to type (at least as far as those can afford such machines are concerned). Again, it seems that a technological fact counterexamples my analysis. 
        But this line of thought presupposes the very conception of symbol-hood that it is meant to support and that we have seen reason to reject. Let S be some transcribing-device that has maximally good character recognition: M has no trouble “recognizing” the words that Brown has uttered, even if Brown has a medical condition that makes it impossible to enunciate properly.  Even though it satisfies these conditions, M will still fail to “recognize” symbol-tokens that any English-speaker would, in virtue of being an English-speaker, easily recognize. The following scenario illustrates this. 
        X and Y are conversing with each other. They are both reasonable people of average or above average intellect. At some point in the conversation, Y asks X a question. There are only a few answers that X can reasonably give. Y has asked X “what did Smith do today?” As X and Y both know, and as each knows the other to know, there are only two answers that, given Smith’s personality and general situation in life, have anything more than a remote chance of being correct, namely: “he went to O’Reilly’s [the local bar]” and “he spent the whole day in bed.” Under the circumstances, it isn’t necessary for X to produce a crisp, lucid utterance of: “he went to O’Reilly’s.” It is necessary only that X produce a sound that is obviously not a token of  “he spent the whole day in bed.” Such a sound could, and probably would, be little more than a grunt that has a certain intonation and arc. It could be that X is able to answer Y’s question with a sound that, in purely acoustical terms, is much closer to a typical utterance of “we are now having high-tea” than it is of a typical utterance of “he went to O’Reilly’s today.”  
        But S (the previously described scanner) would wrongly transcribe X’s utterance. By hypothesis, S’s character-recognition capabilities allow it to respond correctly to symbol-tokens that are morphologically extremely degenerate. But from a purely morphological standpoint, X’s utterance is so degenerate that even S cannot recognize it.  Even if S can recognize that particular utterance, there will be others that, for analogues of the reasons just given, it will not be able to recognize. 
        Also, supposing that in that particular case S is sufficiently sensitive to generate the right symbol-token, that same sensitivity will dispose it to assign the wrong symbol-token in other cases. There will be cases where S is given precisely the same acoustical data that it was given here, but where it should generate a token of “we’re having high-tea today” or “Pete likes Green Sleeves.” Because S has the sensitivity needed to generate the right symbol-token in this case, it will ipso facto be locked into producing the wrong symbol (“he went to O’Reilly’s today”) in these other cases.
       To the extent that context-makes it clear what one is saying, it isn’t necessary that morphology do so. Obviously morphology always has a role; context can never completely do the job of morphology. But there is little or no limit to how much context may marginalize the role of morphology. 
        A corollary is that, even if we focus on a single language and even if we leave aside cases of homonymy, a single morphology can instantiate any number of different expression-types.
         A related corollary is that any given expression-type can be instantiated by any number of different morphologies. Anything whose operations are strictly morphology-driven is ipso facto incapable of keeping pace with such context-generated variations. For these reasons, no significant parallel can be established between symbol-driven and morphology-driven activity.  
      Of course, there are several objections to be made to this line of thought: 


     You may be right to say that whole sentences can be tokened with noises that bear little acoustical resemblance to the paradigms through which English is taught, and that symbol-morphology deteriorates as context assumes a greater role in communication. But even after we allow for the morphological deterioration characteristic of everyday speech, you chose a case of symbol-tokening that is too degenerate to be regarded as representative and that, consequently, must be regarded as a kind of singularity. So far as a hypothesis is counterexampled only by degenerate or singular cases, it isn’t counterexampled at all. Basically, given that you can make your case only in terms of such a tendentious and artificial example, it follows that you have no case. 




      A symbol-token has both morphological and socio-psychological components, and the morphological component has done its job provided that it directs the auditor (or reader) towards the right social-psychological component. So there is nothing linguistically degenerate about X’s utterance, even though it may fail to satisfy the aesthetic strictures of a diction-coach. 
      Of course, X’s utterance is morphologically degenerate, as I myself said. But that is just an elliptical way of saying that in most contexts an utterance acoustically like X’s wouldn’t provide the information needed to direct the auditor towards the socio-psychological component of the relevant symbol-token. 
      There is no sense in which the story just told concerns a singularity or degenerate case. In the exchange between X and Y, context is probably doing more than it ordinarily would, and morphology is probably doing less than it ordinarily would. But these quantitative differences don’t constitute structural or categorical differences. We are dealing with a garden-variety expression of the forces involved in the composition of any symbol-tokening and, therefore, in any linguistic exchange. The dialogue between X and Y could be described as a “degenerate” or “singular” case only if it were assumed that any utterance that isn’t in lock-step with the aesthetic strictures of a diction-coach is ipso facto degenerate. But in addition to being question-begging in this context, such an assumption would demand that we categorize virtually every utterance every produced as degenerate. 
        Let us consider another objection:


     You are confusing statistical with dynamic facts. Technically speaking, there are no straight lines, rigid bodies, or smooth surfaces. But the physical world must be understood in terms of such idealizations. So even though are statistically absent, they are dynamically or explanatorily present. Statistically there are very few utterances of “Smith went to O’Reilly’s” that satisfy the stricture of a diction-coach. But, in this context, that is irrelevant. What is relevant is that, so far as they discharge successful speech-acts, the bits of morphology that we produce approximate to such paradigms. X’s utterance of “Smith went to O’Reilly’s” is to be understood in terms of  a diction-coach’s crisp utterance of that same sentence. Of course, what we just said about X’s utterance is true in general. Utterances are understood only in so far as they are associated with the right paradigms. Such paradigms are therefore dynamically ubiquitous, even though they are statistically few and far between. You  may be right to say that CTM insists on a much tighter connection between morphology and semantics than is found in everyday speech. But contrary to what you say, that doesn’t show that CTM is wedded to an artificial, or otherwise erroneous, understanding of what it is for a physical object to be a symbol. On the contrary, it shows that CTM embodies a sensitivity to the relevant dynamic facts and, unlike you, doesn’t naively derive semantics from statistics. 
         


          I agree with the objector on many points. Linguistics is not statistics, as Kent Bach (1984) said. What sentences mean cannot be identified with what they are taken to mean. Of course, there is typically an extremely tight connection between what people take sentences to mean and what they actually mean. But this connection is to be understood in dynamic, as opposed to statistical or enumerative, terms. That is why, as semanticists often point out, there are well-formed sentences that are systematically misunderstood, for example: “The man the boy the girl hit kissed moved.”[166] 
         But the objector is misapplying this point, as we may see by contrasting the dialogue between X and Y with a situation that actually exemplifies the principle that the objector is discussing. Consider the sentence: 


(a) “some number is bigger than every number.” 


(a) is false. But it is conceivable that English speakers might  take those words to mean


(b)  given any number x, there is some number y such that y is greater than x, 


which is true, instead of 


(c) there is some number x, such that given any number y, x is bigger than y, 


which is false. 
    What somebody who wishes to affirm (b) should utter is: 


(d) “there is no greatest number.” 


         There is indeed a sense in which utterances of “Smith went to O’Reilly’s” should bear a greater resemblance to a diction-coach’s pronunciation of that sentence than  Smith’s does. But it is not comparable to the sense in which somebody who wishes to affirm (b) should utter (d) as opposed to (a). If you utter the sentence “Smith went to O’Reilly’s” with the intention of affirming the proposition Smith went to O’Reilly’s, people are generally more likely to know that your speech-act is in keeping with the relevant linguistic rules if your utterance is more like a diction-coach’s than it is like Smith’s.  It is easier to know what a diction-coach is saying than it is to know what is being said by somebody who is mumbling or has laryngitis. But this doesn’t mean that the expressions produced by a diction-coach are more correct, relative to the rules constitutive of the language in question, than what is said by somebody who has laryngitis. It doesn’t mean that the diction-coach’s speech is more in keeping with those rules than that of somebody with laryngitis. It only means that ceteris paribus it is easier in the one case than the other to identify the speech-acts that have in fact been performed. So the sense in which one should speak like a diction-coach is comparable to the sense which one should speak directly into a microphone. The “should” here is of a generally instrumental nature, and has no specifically linguistic significance. 
      But supposing that I wish to affirm (b), the sense in which I should utter (d), as opposed to (a), is of a distinctively linguistic nature. In uttering (a), I am guilty of linguistic incompetence. But I am guilty only of garden-variety instrumental incompetence if I mumble (d) with the intention of affirming (b). 
     There is another objection to our analysis that we should consider: 


       You start with a correct point and end with a false one. There are indeed many ways that a given symbol-type of a public language can be instantiated, and natural languages are thus characterized by a certain “morphological elasticity.” As you point out, this makes it harder than it would otherwise be to bring morphology into alignment with semantics. But this is completely irrelevant to CTM.  According to that doctrine, thinking consists in manipulating symbols of some internal language, not of some public and external language like English or Spanish. To immunize CTM from the criticisms that you’ve just put forth, we need only assume that this internal language (“Mentalese”) is petrified, i.e. that where that language is concerned, there are strict limits as to how much two instances of given symbol-type can differ from each other in respect of morphology. 
         


         This line of thought is a non-starter, the reason being that it is inherent in the nature of symbolism that morphologically different entities be capable of betokening the same symbol, and that morphologically identical entities be capable of betokening different symbols. 
        Whether a given sound (or ink-mark or pattern of light….) betokens this as opposed to that symbol is a function, not of that sound’s morphology, but of the relation of its morphology to the socio-psychological context of tokening. That is why two morphologically identical sounds (or ink-marks or patterns of light...) can betoken different words, and that is why two morphologically very different sounds (or ink-marks…) can betoken the same word. 
      Let T1 an occurrence of word “bank” (financial institution), and let T2 be a morphologically identical occurrence of the word “bank” (river’s edge). Why do T1 and T2 betoken different words? In the one case, the context of utterance involved a perception of Smith putting a fishing pole into the back of his pick-up truck. In the other case, the context of utterance involved a perception of Jones angrily snapping his briefcase shut after unsuccessfully attempting to borrow money from his brother. Even though the morphology is the same, the relationship between morphology and context of utterance has changed; and that is why two words have been tokened, instead of one. Obvious extensions of this reasoning show why two different tokens of a single expression-type may be very different in respect of morphology. 
        This line of thought accommodates the fact that morphology has some constitutive involvement in the tokening of a symbol. For a given symbol to be tokened, it is necessary that there exist a physical object (e.g. a noise or ink-mark) whose morphology stands in a certain relation to the context. This means that there is no symbol (or symbol-token) where there isn’t a bit of morphology. It also means that, all other things being equal, two tokens of a given expression-type will be morphologically similar. 
       But this same line of thought accommodates the fact two tokens of a given expression-type can be morphologically very different. Given a sufficiently large change in the context of utterance, a commensurately large change in morphology will be needed to ensure that the relation between morphology and context is preserved. (If you gain two hundred pounds, the clothes that you wear must also change if they are to fit, i.e. if their relationship to your new physique is to coincide with the relationship had by your old clothes to your old physique.) 
         A symbol-type is instantiated in a given context iff there occurs an event whose morphology has a certain relation to that context. A symbol-token is thus an instance of a certain kind of relation: a relation between morphology and context. A symbol-type is such a relation. For reasons already discussed, the word “context”, as it occurs here, is to be understood, at least up to a point, in social and psychological terms. 
          Because symbols are relations between morphology and context, it is not an option to suppose that there are, or even could be, morphologically petrified languages. Here is a stark illustration of the principle at work here. A ratio is, by definition, a relation between two integers. So the ratio 1:2 is identical with the ratio 3:6, since the relation between one and two is the same as the relation between three and six. Given a ratio, let us speak of the numbers to the left and right of the colon as the  “numerator” and the “denominator.”  Suppose that somebody decided to speak of  “numerator-frozen” ratios. Given two integers m and n, m:n would be a numerator frozen ratio if there no integers m* and n*, distinct from m* and n*, such that m:n was identical with m*:n*. That would be absurd. Given that symbols are relations between morphology and context, one is guilty of an exactly similar absurdity if one speaks of morphologically-frozen languages. 
      We’ve seen some reason to think that the concept of a symbol-token is psychologically pregnant. Much of the debate between advocates and opponents of CTM concerns whether this is actually true and, if so, whether it has any bearing on the thesis that thinking consists in symbolic-manipulations. But the criticism that we just put forth is independent of this debate, and doesn’t presuppose the truth of any particular resolution of it. Given that a symbol-token is an instance of a relation between morphology and context, it immediately follows that there is no purely morphological characterization of any symbol-type. It immediately follows that there is no strictly morphological characterization of any of the symbol-types constituting any language, whether actual or possible. Of course, we’ve seen reason to believe that the contexts in question have a psychological (and also a sociological) dimension, and advocates of CTM are likely to deny this. But the argument just presented has nothing to do with the specific nature of the contexts in question, and it goes through regardless of whether we were right to see such contexts as being psychologically pregnant. Once it is granted that a symbol-token is an instance of a relation between morphology and context, then regardless of whether that context is understood in psychological terms it immediately follows that there is one morphology that two tokens of any symbol-type of that language must have in common. More exactly, given any symbol-type S of any language L, if two physical events are morphologically similar, it cannot be solely in virtue of their both being instances of S. So supposing that DOG is a symbol-type of Mentalese, if two brain-events are morphologically similar, that is not solely in virtue of their both being instances of that symbol-type; and given only that two brain-events are both tokens of that symbol-type, there is no limit to much they can differ in respect of morphology. 
     Thus, symbolic manipulations can never track semantics in virtue of being morphology-driven. This must be understood aright. Obviously morphology-driven operations sometimes track semantics. A monkey can manipulate letter-blocks in such a way that they form a meaningful sentence-token. But given any language, and given any series of inscriptions (or noises...), the morphologies of those inscriptions leave it entirely open what, if any, expressions of that language have been tokened. Because symbols are relations between morphology and context, we cannot even coherently conceive of a language of which what that isn’t true. 
         It could well be that, circumstances being what they are, there is in fact only way to token the symbol-types of a particular language. We described such a scenario earlier. (There is only one instance of each letter in the alphabet, and these are stored in a public letter-depository...) But it can never be an inherent fact about any language that its symbols are thus frozen. 
        Conceivably, an advocate of CTM might respond by saying that, even though Mentalese expression-types can in principle be tokened by different morphologies, the structure of the brain prohibits different morphologies from instantiating a given symbol-type – much as, in our story about the letter-depository, contingent circumstances prohibited different morphologies from instantiating English words. 
           But given what we’ve said, it is clear why this move won’t work.  Because it is never strictly in virtue of its morphology that a physical object is a token of some expression-type, it is no longer an option to say that a creature is computing in virtue of manipulating shapes. So even if we concede to CTM that mere symbol-manipulation can constitute computation, it still doesn’t follow that a creature is computing in virtue of manipulating shapes. Since a symbol-token is an instances of a relation between morphology and context, mere morphology-manipulation isn’t symbol-manipulation. 
  
Why CTM strips the mental of any causally significant properties


           Another consequence of our analysis is that, in direct opposition to what Fodor believes, CTM is no more consistent with the causal efficacy of the mental than is content-externalism. In fact, CTM makes it harder than it would otherwise be to accommodate the obvious fact that it is often in virtue of their representational properties that mental states have causal efficacy. 
        Here is Fodor’s view: 


        To think is to compute. To compute is to manipulate symbol-tokens. Symbol-tokens are shapes. Shape is causally efficacious. (In virtue of being round, as opposed to square, an object has causal properties that it wouldn’t otherwise have. That is why square wheels would be so useless.) So if we identify thinking with computing, we have no trouble accommodating the fact that our thoughts have causal powers – that thoughts generate other thoughts and also generate actions. 


        An expression-type is not a shape, and an expression-token is not an instance of a shape. A expression-type is a relation between morphology and context, and an expression-token is an instance of such a relation. So to identify thinking with computing is to identify thinking with the manipulation of instances of relations between morphology and contexts. (More exactly, it is to identify thinking with the manipulation of instances of relations of instances of morphology to instances of certain kinds of context.) It is not to identify thinking with the manipulation of bits of morphology.  
         Given these points, if we are to evaluate Fodor’s view, we must ask: where a Mentalese expression is concerned, what is the relevant context? Suppose that S is a token of the Mentalese word SOCRATES. Supposing that our analysis is correct, S is an instance of a relation between morphology and context. Given CTM, the morphology in question must be had by some brain-state (some neural structure or pattern of neural stimulation). Let B be that brain-state. But what is the relevant context? 
         There are different possible answers to the question, and none of them validates CTM. Let us start with the answer that Fodor himself gives. According to Fodor, so far as B represents Socrates, it is because some state of affairs is causally responsible for B’s existence. (Of course, Fodor doesn’t think that just any mode of causation will do. He thinks that there is some specific causal relation R such that, in so far as B represents Socrates, it is because some state of affairs involving Socrates stands in causal relation R with respect to B.) So far as B represents Socrates, it is, according to Fodor, because B is at one end of a long sequence of events beginning with Socrates himself. Thus, if Fodor is right, the relevant context includes a state of affairs that existed over two-thousand years ago. Supposing that we are right to analyze symbol-tokens, as instances of relations between morphology and context, it follows that S is a symbol-token representing Socrates in virtue of the fact that it is an instance of a relation between an instance of morphology and context. The instance of morphology would be B and the context would be some protracted state of affairs involving Socrates himself. So any manipulation of the Mentalese symbol for Socrates would involve a manipulation of some vast stretch of human history. But, of course, it makes no sense to say that vast stretches of history are manipulated. Leaving that aside, it is clear that thinking doesn’t consist in such manipulations and also that Fodor doesn’t wish to identify thinking with such manipulations. At any rate, in holding that thinking consists in manipulations of symbol-tokens, CTM is committed to the most aggressive form of content-externalism imaginable. This is because the symbol-tokens in question would involve remote stretches of space-time, and CTM becomes no more capable than content-externalism in explaining how our thoughts can have any causal properties at all. 
      Fodor’s view is that B – the intra-cranial bit of neuro-morphology -- is the relevant symbol-token and that, consequently, there is no trouble explaining how it is that B can be manipulated. But, as we’ve seen, CTM cannot coherently say that B itself is the relevant symbol-token.  
       We’ve seen that Fodor’s answer to the question “what is the relevant context?” doesn’t enable CTM to accommodate the fact that thoughts are not causally inert. (More precisely, we’ve seen that Fodor’s answer doesn’t enable CTM to accommodate the fact that it is at least sometimes in virtue of being a thought that a brain-event has causal properties.) But is there some other possible answer that would accommodate this fact? 
        Obviously such a symbol-token would have to be entirely intra-cranial. Otherwise we are forced to say, absurdly, that thinking consists in manipulating vast stretches of extra-cranial space-time. So if a brain-event tokens a symbol of Socrates, that is entirely in virtue of what is intra-cranial. Of course, what we said goes for any other brain-event that tokens a symbol. It immediately follows that any version of CTM that accommodate the fact that thoughts have any causal powers is completely incompatible with content-externalism. This is a problem for Fodor, since one of his principle reasons for advocating CTM is that he accepts content-externalism and believes that an acceptance of CTM is needed to reconcile content-externalism with the fact that thoughts are causally efficacious. 
       So given that Mentalese symbol-tokens would have to be intra-cranial, it is clear that Fodor’s argument on behalf of CTM are in jeopardy. But, setting aside the already discussed problems with CTM, does it follow that CTM itself is in jeopardy? 
      Yes. As we’ve just seen, one must accept content-internalism if those symbols (or symbol-tokens) are intra-cranial. One must take the view that content is entirely “in the head.” More precisely, one must take the view that, if a brain realizes mental states with certain contents, that is to no degree a function of the causal origins of that brain’s current condition, and is thus entirely a function of those properties of that brain that can be understood in abstraction of those origins. But if one takes the view that representational content is in the head, then there is no need to deny that it is in virtue of their representational properties that brain-states have causal powers. If you think of brain-states as symbol-tokens, there is thus no need to deny that it is in virtue of their semantic  properties that brain-states have causal powers. We can continue to say what we have a strong pre-theoretically wish to say, namely: beliefs and desires have causal powers. (More exactly if x is a belief or desire, then in virtue of that fact x has causal powers that it wouldn’t otherwise have.) 
       In identifying cognitive operations with non-semantic operations, CTM demands an abandonment of the our presumption that my desire to drink water is at least part of what causes me to walk over to the water fountain and drink from it. In fact, an abandonment of that presumption is really the essence of CTM, since that doctrine is given by the thesis that semantics does nothing and morphology does everything. We’ve just seen that if symbol-tokens are intra-cranial, there is no need to deny this presumption, and thus no need to accept CTM. So CTM fails on any answer to the question, posed a moment ago, “what is the relevant context? “, and there doesn’t seem to be any delineation of the term “symbol” that validates CTM. 
        Let us consider a point that might be made on behalf of CTM: 


      Expressions of English are betokened by bits of noise or ink, whereas expressions of Mentalese are betokened by patterns of neural stimulation. Tokens of English expressions are typically audible (or visible), whereas tokens of Mentalese expressions are not. One has to learn English, but one doesn’t have to learn Mentalese. These are but a few of the many differences that we may expect to find between Mentalese and any public language. No advocate of CTM has ever denied that such differences abound, and none of these differences warrants the rejection of CTM. Consider the fact that, if they exist, tokens of Mentalese expressions aren’t made of ink or noise. It would be absurd to conclude on this basis alone that thinking does not consist in operations on symbol-tokens belonging to an internal language. It seems to me that all of your criticisms of CTM are comparably absurd. All you’ve done is to uncover more evidence in favor of the trivial point that Mentalese differs from English (and other public languages) in many ways. Leaving aside your view that CTM is wrong, you haven’t said anything that any advocate of that doctrine would necessarily disagree with. At most, you’ve helped CTM hone its conception of the nature of the internal symbols that mediate thought. 


   
         Consider the English word “dog.”  Here is what we have said about it. If a noise betokens that word, it is not solely in virtue of its morphology. Rather, it is in virtue of its morphology plus facts about the context of utterance. More exactly, it is in virtue of the relationship between the morphology of that noise and the context in which it occurred. There are instances of expression-types when, and only when, there are instances of relations of the sort just described. This suggests that, where public languages are concerned, expression-types just are such relations and expression-tokens are instances of such relations. 
         Supposing that this analysis is correct, anything that isn’t an instance of such a relation doesn’t have any significant similarity to the things are ordinarily referred to as “expressions.” We’ve discussed why CTM cannot coherently regard tokens of Mentalese expressions as instances of relations of this kind. CTM thus cannot coherently regard cognition as an operation on anything that can appropriately be referred to as an “expression” or  “symbol.”  
       We must make a distinction. It is one thing to say that there is no interpretation of terms like “symbol” and “linguistic expression” that validates CTM, and it is quite another to say that we don’t think in symbols or linguistic expressions. What we’ve seen so far is not that we don’t think in symbols. What we’ve seen is that there is no interpretation of expressions like “symbol” and “sentence-token” that validates CTM’s thesis that thinking consists in formal symbolic (or linguistic) operations. We have not yet seen that thinking doesn’t consist in the tokening of expressions of some kind. 
       CTM and SCT are distinct doctrines. CTM  presupposes the truth of SCT, but SCT doesn’t presuppose the truth of CTM. I will argue that SCT is indeed false. But it is not false because CTM is false; it is false for its own distinctive reasons. 


Mental causality revisited: Fodor’s syntactical approach


          For reasons that we discussed in Part I, content-externalism seems to be incompatible with the causal potency of the mental. We discussed a number of attempts to refute this, but found them to be fallacious. But there is one important approach to this problem that we did not discuss – that of Jerry Fodor. 
          Fodor’s analysis makes heavy use of the concept of syntax. We were not in a position to evaluate Fodor’s analysis in Part I, since we hadn’t yet analyzed that concept. Now that we have done so, we can assess the merits of Fodor’s view.
          As we’ve discussed, Fodor is a hard-line content-externalist. In his view, given only that, leaving aside facts about the causal origins of their conditions, Max and Twin-Max  are qualitatively identical, it doesn’t follow that they have anything in common in terms of the representational contents of their mental states. At the same time, Fodor takes it for granted that psychologically they are indistinguishable, i.e. that what an omniscient psychoanalyst would have to say about the any given one of them (in his capacity as psychoanalyst) would be identical with what he had to say about either of the other two. Fodor’s position is thus consistent with the causal efficacy of the mental and with the presumption that psychology has at least some integrity as a discipline. 
       Fodor reconciles these two views by saying that, whatever causal properties a thought has, it has them in virtue of its syntax, not its semantics (representational content). The syntactic structures of Max’s thoughts are identical with those of Twin-Max’s thoughts. What those thoughts represent is a function of spatiotemporally remote, and therefore causally inert, facts about the environments in which those individuals are embedded. But syntax is an entirely internal affair. More exactly, given two subjects that are atom-for-atom duplicates, their thoughts cannot differ in respect of syntax, it being irrelevant what environmental facts led to those thoughts. 
       Is this position tenable? No. First of all, thoughts have syntactic structure only if they are sentences. Obviously this is not an innocuous view. But for argument’s sake, let us suppose that it is correct and that, indeed, mental states have syntactic structure and, therefore, that they are sentence-tokens. Given this, let P be the meaning of


(a) “Mary loves Tom”,


and let P* be the meaning of


(b) “Larry punched Bob.” 


Further, let 


(A) Mary loves Tom,


and 


(B) Larry punched Bob 


be tokens of the Mentalese translations of (a) and (b). 
     There is no denying that (A) and (B), being brain-states, have causal properties. They have mass, shape, temperature, and various other causally efficacious properties. The question is not whether brain-states have causal powers or whether Fodor’s view strips them of such powers. The question is whether, supposing that Fodor is right to strip semantics of causal power, he can coherently say that syntax has causal power. In other words, can syntax be causally efficacious if semantics is not?
        No. As we saw earlier, a sentence-token’s syntax lies in how it means what it means. How a sentence-tokens means what it no more supervenes on its morphological properties than what it means. Given only its morphology, a token of (a) doesn’t have to mean: Mary loves Tom.  
      An advocate of CTM could respond by saying that, where Mentalese symbol-tokens are concerned, syntax does supervene on morphology. But given what we said in the last chapter, this would mean that Mentalese symbol-tokens (so-called) were fundamentally different from their English and Spanish counterparts – so different that we couldn’t refer to the former as “symbols” without rendering that term ambiguous. 
      
The Regress-argument revived 


    We saw in Chapter 13 that syntax is semantic decomposition. A sentence’s syntactic structure lies not in what it means, but in how it is assigned that meaning by the semantic rules of the language to which it belongs. 
       Supposing that our thoughts have syntactic structure, the relevant semantic rules are either mentally represented or they are not. If they are mentally represented, those representations cannot themselves coincide with Mentalese sentences (or sentence-tokens), since (for well known reasons[167]) no language can “contain its own truth-predicate”, as Tarski put it. Those rules must therefore be represented either in some non-linguistic form or in Meta-Mentalese (a language distinct from Mentalese that expresses the rules that assign meaning to Mentalese expressions). If we say that those rules are represented in a non-linguistic form, then we are giving up on the thesis that we think in sentences. If we say that they are represented in sentences (or sentence-tokens) of Meta-Mentalese, then we embark in a vicious regress, since everything that we have said about Mentalese is true of Meta-Mentalese.  
      So let us suppose that the semantic rules of Mentalese are not mentally (or neurally) represented.[168] In that case, the operativeness of those rules does not supervene on any fact about one’s brain or, indeed, on any other causally effective fact about one’s person. But then, for the reasons covered in Part I, the syntactic structures of Mentalese sentence-tokens are stripped of any causal powers. It straightforwardly follows that Fodor is wrong to hold that it is every in virtue of their syntactic properties that brain-states do any causal work. 
        In light of these points, we can see why one of the classic arguments against SCT is in fact cogent. If we think in a language, then presumably we understand that language – we know how to interpret its sentences. But interpreting such a sentence either involves translating them into another language that is already understood or it involves generating a non-linguistic representation of its meaning. In the first case, there is a vicious regress. In the second case, there is an acknowledgement that thinking ultimately does not consist in the tokening of sentences. Either way, SCT fails. 
       This argument is well-known to advocates of SCT, and here is how they deal with it: 


(NSK) To know a public language, like English, you must mentally represent its rules. It would indeed be viciously regressive to suppose that one must mentally represent the rules of Mentalese. Given this, we say that you don’t have to know the semantic rules of Mentalese to know Mentalese. All that is necessary is that you be “built to conform” to those rules. You use English-expressions in the right way because you know how to use them. But even though (presumably) you use Mentalese expressions the right way, it is not because you know (or otherwise mentally represent) the corresponding semantic rules. It is because you nervous-system is so structured that you are physically compelled to token those expressions in the appropriate ways. The compulsion here doesn’t involve the mediation of semantic, and therefore regress-generating, activity.[169] 


       To quote Fodor himself: 


        [Y]ou don’t have to represent the rules of a language that you are able to use: all that’s required is that you are so constructed as to conform to the rules. (Cf. the way computers are ‘built to use’ the machine language.) Of course, it’s plausibly that you DO internally represent the rules of (say) English; but that’s not because English is a language; it’s because it’s a language that you LEARN; and its’ quite plausible that to learn a language is to come to internally represent its syntax and semantics (presumably in ‘Mentalese’).[170]


  
         If (NSK) is right, Mentalese is so different from any paradigm-case of a language that we must (once again) question whether the it is appropriately described as a language. The answer to that question is “no”, as we will now see.
        Given any one English-speaker, the English-language could exist if that person didn’t exist or did exist but didn’t speak English. But suppose that nobody spoke English. In that case, it wouldn’t exist. One might respond by saying that languages are purely function-theoretic pairings of physical objects with meanings. In a moment, we will consider this position, finding it to be entirely false. But even if it is true,  it remains an uncontroversial fact that, if nobody spoke English, English would, at the very least, be defunct.  
       Knowing English consists in knowing the relevant semantic rules. English is dead if nobody knows those rules. It is obvious that whether a public language is alive or dead is constitutively dependent on whether people know the relevant semantic rules. This doesn’t mean that any one person has to knows all of those rules. But it does mean that the language in question is dead if nobody knows any of them. It is an essential fact about any public language that its very existence (or, in any case, its not being dead) is constitutively dependent on its rules being known to somebody. 
       But for a language to be alive, it is not sufficient (though it is necessary) that somebody know its semantic rules. A knowledge of those rules must be causally responsible for the judgments that people make as to what noises and ink-marks mean, and as to what noises or ink-marks to produce in a given context. You privately learn how to read and write some long-dead language L, and a number of other people simultaneously do the same. But nobody knows that anyone else knows L; and nobody uses their knowledge of L to communicate anything to anyone else, or even to themselves. Under these circumstances, L is quite obviously a dead language (though it could be readily revived). So supposing that E1…En is a complete list of the expression-tokens that people produce, a language L is alive only if, for some i, a knowledge of L it is causally responsible for somebody’s producing Ei. (Obviously this is not a sufficient, but only a necessary, condition for L’s being alive.) 
     If (NSK) is right, then nobody knows the semantic rules for Mentalese. A fortiori a knowledge of those rules is inert. (Even if Mentalese does exist, and a few cognitive scientists manage to figure out what those rules are, that knowledge obviously isn’t to any degree what sustains the continued existence of Mentalese. The fact that a few people know Sanskrit isn’t enough to make Sanskrit be a living language.) Mentalese is thus crucially different from anything that is uncontroversially a language. 
       A related point is that, as a matter of analytic necessity, where a knowledge of semantic rules is inert, there are no semantic rules, at least no living ones. If (NSK) is right, the semantic rules of Mentalese exist, and remain active, even though nobody knows any of them. The so-called semantic rules associated with Mentalese are so different from those associated with English that it is misleading to use the term “semantic rule”, without qualification, in both cases. 
      How are the (so-called) semantic rules for Mentalese relevantly similar to those for English? Like their English counterparts, the (so-called) semantic rules of Mentalese  assign representational content to bits of matter (or to events). But if anything that assigns content to a bit of matter is ipso facto a semantic rule, it becomes trivial to say that our thoughts are linguistic; and the thesis that we think in symbols is reduced to the platitude that we have thoughts that have content or, more simply, that we have thoughts. 
       (NSK) thus amounts to nothing less than a rejection of the SCT. Supposing that (NSK) is right, the only significant property that Mentalese expressions have in common with their English (or Korean or French…) counterparts is that, in both cases, the expressions (so-called) in question have content. Any other putative similarity ends up being skewered on an analogue of the line of thought just put forth. 
      For example, suppose that one were to suggest (as Fodor does) that Mentalese expressions, like their English counterparts, have syntactical structure. So far as English expressions have syntactic structure, that is constitutively dependent on somebody’s knowing at least some of the rules of English semantics. We’ve already seen that a knowledge of syntax is indistinguishable from a knowledge of the kind of semantic information that is given by contextual definitions. One knows English syntax because one knows (inter alia) how “loves” combines with other expressions into meaningful units – because, in other words, one knows the relevant recursive semantic rules. Syntactic knowledge is combinatorial semantic knowledge. Thus, English syntactic rules are English semantic rules, and everything we just said about the latter is true of the former.
      There is another problem with Fodor’s syntactical approach. Let look at our paradigms again: 


(a) “Mary loves Tom”,
(b) “Larry punched Bob.” 
(A) Mary loves Tom,
(B) Larry punched Bob 


       (a) and (b) are syntactically identical, and the same is presumably true of (A) and (B). Supposing that Fodor is right to say that there are mental-causal differences only where there are syntactic differences, it follows that (ceteris paribus) one’s belief that Mary loves Tom has the same causal properties as one’s belief that Larry punched Bob. Since this consequence is false, so is Fodor’s analysis. 
        Because he identifies syntax with morphology, and not with semantic decomposition, Fodor would not be moved by these arguments.[171] But syntax is not morphology, as we have seen, and the argument just given therefore stands.  
        One might object that, for special reasons, the Mentalese translations of (a) and (b) don’t have the same syntactic structures. But what we just said about (A) and (B) will hold of any two Mentalese sentence-tokens that are semantically different but syntactically identical.
          In response, an advocate of SCT might say that, where Mentalese is concerned, it is impossible for two sentences to have the same syntax but different semantics. (This is not far from the position that Fodor himself sometimes appears to take.) But this suggestion is a non-starter. Syntax is recursive semantics. If Mentalese satisfied the condition just described, the same recursions could never be used twice. Since a language just is a set of recursions defined over a certain lexicon, that is tantamount to saying that there is no such thing as Mentalese. 
        
Chapter 15 Event-causation and the root-problem with CTM


          There is an objection to our criticisms of CTM that is more important than any thus far considered:


(FRM)      Suppose that Smith (a human being) performs some computation. Here we have a paradigm case of computation. It is obvious that Smith’s behavior is not strictly morphology-driven. In general, it is obvious that paradigm-cases of computation differ in significant ways from the so-called computational processes which, according to CTM, realize our cognitive activity. As far as I can tell, you’ve only confirmed the triviality that the processes posited by CTM are different in some ways from the operations that we ordinarily refer to as computations. 
      Let’s suppose that there is some operation – let us refer to it “computation*” – to be defined thus. A computation* is a purely morphology-driven operation on bits matter. It is left open what, if any, semantic or otherwise representational properties those bits of matter have. We now define CTM as the doctrine that thinking consists in computations*. All of your criticisms of CTM now crumble. Those criticisms all presuppose that the “computations” posited by CTM are more or less comparable to the computations performed by engineers and mathematicians. Given our new definition of CTM, that presumption is false. 


       
       There are two points to make here. The advocate of (FRM) might be right to say that my criticisms of CTM are null and void if one takes the computations posited by CTM to be nothing more than bits of morphology impacting other bits of morphology. But given the points we’ve made in connection with terms “symbol”, “algorithm”, “syntax”, “form”, and the like, it isn’t clear what intuitive motivation there would be for (FRM). The idea behind CTM is that, in at least some cases, a cognitive achievement is attained in consequence of strictly morphology-driven interactions among bits of matter. The question is: why believe that semantically antiseptic interactions among dead bits of morphology can generate cognitive achievements? As it is traditionally defined, CTM answers by saying: such interactions are relevantly similar to the cognitively pregnant symbolic-operations performed by logicians and mathematicians. But (FRM) rejects this answer; and (FRM) doesn’t have an answer to the question “why should we believe that semantically antiseptic interactions among dead bits of matter constitute cognitive achievements?” 
        It could well be that, when somebody has a thought, that is in virtue of the fact that some neural state of affairs has certain morphological properties. In fact, there is almost certainly at least an element of truth in that view, given that our cognitive activity is almost certainly not entirely independent of the morphological properties of our brain-states. So (FRM) may be right. But (FRM) doesn’t have any meaningful similarity to (CTM), as it is traditionally understood. 
        There is another difference between (CTM), as traditionally understood, and (FRM). Supposing for the sake of argument that there is a one-one correspondence between neural morphology and mental content, (CTM) aspires to explain that correspondence. (CTM) aspires to explain how thought arises out of unthinking matter. If we grant (CTM)’s supposition that strictly morphology-driven operations among bits of matter are the essence of cognitive achievements like proof- and theorem-generation, it does indeed become clear how it is that bits of dead matter can realize thought; and that is obviously at least part of the reason that (CTM) is so widely accepted. But (FRM) explicitly refuses to endorse that very supposition, and it thus strips (CTM) of much of its raison d’être. So even if it turns out that (FRM) is correct, that wouldn’t redound to the credit of (CTM), at least not on any natural understanding of that doctrine. 
  
The root-problem with CTM


      But there is a much more important point to make in response to (FRM). It can be shown that, in so far as interactions among brain-states (or physical objects any kind), constitute instances of thought, those interactions must be driven by the representational (semantic) properties of those states. This doesn’t mean that strictly morphology-driven interactions don’t generate thought. But it means that, in so far as such interactions do generate thought, it is because representational properties are identical with, or realized by, morphological properties and that, consequently, morphology-driven interactions are ipso facto semantics-driven. 
       Let us start by recalling a point made earlier. It is not objects, but states of affairs, that have causal properties and that figure into adequate causal explanations. It is not the rock that breaks the window. What does so is the rock’s colliding with the window with a certain amount of force at a certain instant. Language often obscures this fundamental fact about causality. We say things like “Hitler was the cause of World War II.” But this is obviously elliptical for some statement to the effect that such and such actions on Hitler’s caused (or were partial causes of) World War II. We should also point out that it is states of affairs, not objects, that are caused. What is caused is not the statue, but rather the existence in a certain place and time of a piece of marble with certain properties. 
       I should point out that, in this context, the term “state of affairs” is meant to cover both events as well as static conditions. Some artist is causally responsible for the fact that there is a certain statue in a certain place and time. Here what was caused was a (relatively) static condition. Of course, that condition was caused by way of events: the artist had to chip away at a hunk of marble and then arrange for it to be moved to a certain place. So static conditions are created by way of changes. What is relevant here is that both will be referred to as “states of affairs.” (Incidentally, our usage of that expression is not stipulative or neologistic, and is perfectly consistent with its existing meaning. As we will see later, what we refer to as “static” states of affairs – e.g. a statue’s remaining in a certain place --  are uniform changes, and what we refer to as “events” – e.g. the statue’s being moved from one place to another -- are changes in the manner of change. So both events and so-called static conditions are both changes, and our usage of the term “state of affairs” in no way renders it ambiguous and thus doesn’t involve any equivocation.)[172] 
         A given object has many different causally effective properties. Let R be a given rock. R has a certain mass, a certain weight, a certain shape, a certain structure, a certain temperature, a certain color, and so on. In virtue of having any given one of these properties, the rock has certain causal powers that it wouldn’t otherwise have. Thus, these properties are not causally inert. Of course, the rock does have some causally inert properties. For example, it has the property of a thing x such that x is either a square or is not a square. But the properties listed a moment ago are not in this category, and in this context we will focus exclusively on the rock’s causally effective properties. 
        Not every property of the rock is involved in every causal transaction in which the rock is involved. The fact that the rock has a temperature of 72° as opposed to 82° is irrelevant to the fact that the window broke. This must be understood aright. Any two non-simultaneous states have a causal connection with each other. So the rock’s having a temperature of exactly 72° has a causal connection with the shattering of the window. But it doesn’t have any special or relevant connection: the window would have shattered even if the rock had had a temperature of 82°. So even though it is causally effective in general, the rock’s having that temperature is inert in this particular context. 
      Of course, everything that we just said is true of brain-states. Let B be a particular state (or structure or pattern of neural stimulation…) characteristic of Smith’s brain, and let us suppose that B realizes Smith’s belief that two is a prime number. B has a number of causally effective properties. It has thermal, electrical, and structural properties, and each of these is causally potent. In virtue of having any given one of these properties, B has causal powers that it wouldn’t otherwise have. My own view is that B’s representational properties belong on this list: in virtue of being a belief that 1+1=2, B has causal properties that it wouldn’t otherwise have. But that is just what CTM denies, and it is just what I am trying to establish; so it cannot be assumed in this context. 
       Not every case where B is involved in a certain causal transaction is a case where B’s having a specific temperature is causally potent. In some contexts, B’s having that property is potent, and in others it is not. For exactly similar reasons, supposing that B’s being a belief that two is prime is causally potent, not every case where B is involved in causal transaction is a case where B’s having that particular property has any special causal role. 
       Some fiction will help us move onto the next phase of our argument. At time t Smith suddenly thinks Socrates was wise. B is the brain-event realizing this mental event. Later, at time t*, Smith suddenly thinks somebody was wise. B* is the brain-event realizing this mental event. Further, B is what causes B* to come into existence. Of course, given what we just said about causality, what this really means is: some state of affairs involving B is causally responsible (at least in part) for some state of affairs involving B*. 
       Given only what we’ve said, does it follow that Smith’s thinking  Socrates was wise had anything to do with his later thinking somebody was wise? No. Given only that B is what caused B* -- more exactly, given only that some state of affairs involving B is what led to there being some state of affairs involving B* --  it doesn’t follow that Smith’s thinking Socrates was wise had any special connection with this subsequently thinking somebody was wise. That would follow only if B’s being a belief that Socrates was wise is what led to the state of affairs consisting in B*’s being a belief that somebody was wise. If it was B’s having a certain temperature  that was responsible, and not its being a belief that Socrates was wise, then Smith’s thinking Socrates was wise at t didn’t have anything to do with Smith’s thinking somebody was wise at t*. We thus cannot conclude that Smith inferred that somebody was wise  on the basis of his belief that Socrates was wise. So we cannot conclude that Smith thought: Socrates was wise, therefore somebody was wise. 
     Obviously Smith’s thinking Socrates was wise constitutes a cognitive achievement, and his thinking somebody was wise constitutes another cognitive achievement. But it doesn’t follow that this thinking both of those thoughts constitutes some third cognitive achievement. For this to follow, it would be necessary (though not sufficient, as we will see) that his thinking Socrates was wise was responsible for his later thinking somebody was wise. If two thoughts are causally unrelated to each other, then surely they don’t jointly constitute some third thought. We’ve seen that Smith’s thinking Socrates was wise doesn’t necessarily have any (relevant) causal to his later thinking somebody was wise. So we cannot conclude that his thinking both of those constitutes some third cognitive achievement. For example, we cannot conclude that it embodies his making  an inference. It is irrelevant that (so to speak) B is what caused B*, and it is irrelevant that the proposition encoded in B logically entails the proposition encoded in B*. 
      We can reinforce this point by extending our story. Later that day, after reading an article about some historical figure (other than Socrates) who committed an unwise act, Smith suddenly thinks somebody is not wise. This happens at time t**. It would be absurd to say that, in virtue of thinking Socrates was wise at t, and then thinking somebody was not wise at t**, Smith was guilty of some kind of logical non-sequitur. In fact, it would be absurd to say that, in virtue of having those two thoughts, Smith deserved credit for having any thought-process that embodied any view at all as to how, if at all, those two propositions are related. The reason that this would be absurd is obviously that his thinking Socrates was wise didn’t have anything to do with his thinking somebody was not wise. (In any case, those two events didn’t have any special or relevant causal connection, even though, like all non-simultaneous events, they have a causal connection.) For exactly similar reasons, it would be absurd to say that, in virtue of thinking Socrates was wise at t and somebody was wise at t*, Smith has had a thought that embodies any view at all as to how, if at all, those propositions are related to each other. It is therefore out of the question to say that Smith deserves credit for having made a logical inference. 
         The points just made can be generalized in a few different directions. Let us start with the most obvious direction of generalization. Let P be and P* be any two propositions such that P logically entails P*. Further, let bp and bp* be two brain-states, both had by a single person X, such that bp realizes a belief that P and such that bp* realizes a belief that P*. Supposing that bp causes bp*, it doesn’t follow that bp’s being a belief that P has anything to do with bp*’s coming into existence. It could be that it was bp’s having some non-semantic property that was thus responsible. It therefore doesn’t follow that X’s thinking P has anything to do with his later thinking P*. There is no reason to believe that Smith inferred P* from P or, indeed, that he has any thought-process that embodies any views, whether meritorious or not, as to how those two propositions might be related. 
        Let us further generalize our analysis. Let T and T* be any two non-simultaneous events or objects that are representational. For the sequence consisting of those events to form a single representation, it is not enough that T be what causes T* to come into existence: it is necessary that T’s being a representation do so. A bit of fiction may illustrate my meaning. At 3:00 p.m. I am feeling very sad. I attempt to write “I am suffering from great sadness” I manage to write “I am suffering from great.” But right after I write the “t” in “great”, I am struck the beauty of my own penmanship, and this causes me to feel great joy. Because of this, I forget about my earlier intention to write “I suffering from great sadness”, and I form the intention to write “sadness never lasts and, ultimately, life is a great joy.” But right after I right the second “s” in “sadness”, I am interrupted by the doorbell. I never write in my diary after that. 
       Under these circumstances, have I produced a token of “I am suffering from great sadness”? No. I have only produced an ink-mark that looks just like a token of the sentence “I am suffering from great sadness.” Further, the token of “I am” is causally responsible, at least in part, for the adjacent token of “sadness.” Nonetheless, I never managed to carry out my original intention of tokening the sentence “I am suffering from great sadness.” Therefore, that sentence was not tokened in this context, even though the ink-mark I have produced is morphologically just like a token of that sentence. 
          Let T be my inscription of “I am suffering from great”, and let T* be my inscription of “sadness.” It was T’s having certain aesthetic properties, and not its being a symbol of a certain kind, that led to my writing T*.  So T’s being a symbol has nothing to do with T*’s coming into existence. So far as they have semantic properties, the inscriptions “I am suffering from great” and “sadness” are causally unrelated (except in the trivial sense in which any two non-simultaneous entities are causally related), and thus have nothing to do with each other. That is why they don’t jointly form a sentence-token. 
       Supposing that X and Y are symbol-tokens, the juxtaposition of X and Y doesn’t constitute a single symbol-token, unless X’s being a symbol (or representation) is what generates Y (or vice versa). If this condition isn’t met, then X has no semantically significant relation to Y, in which case it immediately follows that they don’t jointly form any semantic unit. The juxtaposition of these symbols may look (or sound) like a meaningful unit, and the causal mechanism that mediates between X and Y may be completely reliable. But if it isn’t X’s being a representation that generates Y (or vice versa), then X and Y aren’t parts of a single representation. Where semantics is causally inert, representations cannot combine to form more complex representations and nothing has any representationally significant relation to anything else. 
       Obviously there are thoughts that consist of other thoughts. If I think grass is green and snow is white, that thought involves the thought grass is green and also the thought snow is white. CTM says that semantics is causally inert. Given what we just saw, CTM thus cannot accommodate the fact that there are thoughts that consist of other thoughts. CTM is inconsistent with the fact that there are complex thoughts. 


Necessary versus sufficient conditions for the formation of complex thoughts 


           Suppose that I think Socrates at wise and then later think somebody was wise. Let b and b* be the brain-states mediating those thoughts. As we just saw, if b and b* are to constitute a single thought, or are to be part of the same thought-process, it is necessary that b’s being a thought that Socrates was wise be at least part of what generates b*. But it is not sufficient, as the following story shows.
          A hypnotist programs me to think something was wise whenever my heart rate goes above 90 beats per minute. One day it suddenly occurs to me that Socrates was wise. (I finally understand some obscure passage of the Republic, and I see that, contrary to what I used to think, Socrates really was wise.) The resulting euphoria causes my heart-rate to sky-rocket. Because of my hypnotic programming, this causes me to think something was wise. Here we have a case where my thinking Socrates was wise causes me to think something was wise. So if b and b* are the brain-states associated with those two thoughts, we have a case where b’s being a thought that Socrates was wise is responsible for b*’s being a thought that something was wise. But obviously we don’t have a case where I have thought Socrates was wise, therefore something was wise and, more generally, we don’t have a case where a single thought or thought-process comprises both of those thoughts. An exact analogue of what we just said about b and b* could be constructed in connection with ink-marks or noises or any other symbol-tokens. 
         In general, for the juxtaposition of two representational entities (be they thoughts or symbol-tokens) to constitute a single, complex representation, it is necessary but not sufficient that the one’s being a representation of a certain kind be causally responsible for the generation of the other. 
          Of course, it is an interesting question what other conditions must be fulfilled. But in this context we don’t need to know the answer to that question. CTM demands that semantics be totally inert, and it thus renders impossible the fulfillment of one of the conditions necessary for the combining of representations into other representations. This by itself is a major against CTM, given how frequently such combinations occur. 


Semantic versus conceptual complexity 


          To develop this line of thought, and to see more fully why CTM must be rejected in light of it, we must first distinguish between two different kinds of complexity. Consider an inscription of the word “Socrates.” That inscription is physically complex, since it consists of a multiplicity of marks. But it is not semantically complex.[173] 
      Any brain-state that realizes a concept of Socrates will inevitably have a great deal of physical complexity. But it doesn’t follow that any such state has representational complexity. I myself believe that anything that realizes a concept of Socrates will have representational complexity. But I cannot take that for granted here, since this is exactly what I am trying to show. In any case, even if anything that realizes a concept does have representational complexity, we must distinguish between the kind of complexity that such a thing has in virtue of being such a concept and the kind of complexity that it has for some other reason. 
        With this distinction in place, let us tell another story. At time t, Smith thinks Socrates. b is the brain state realizing this thought. At some later time t*, Smith thinks snored. b* is the brain-state realizing this thought. For exact analogues of the reasons just given, unless b’s being a representation of Socrates is responsible for b*’s subsequent occurrence, Smith has not thought Socrates snored, at least not in virtue of the fact that b and b* occurred. Semantics cannot be inert if any one is to think anything true or false. No true or false thought is representationally simple. So nobody can think anything true or false except in so far as it is one’s brain-states’ having representational properties that are governing one’s cognitive activity. It readily follows that CTM strips anyone of the ability to think anything true or false, given that, according to CTM, it is never in virtue of its semantic properties that a brain-state has causal powers. 
       I myself believe that, contrary to what the argument just given seems to presuppose, one cannot just think Socrates or snored. Supposing that this right, it might seem that my argument crumbles. But it does not crumble, and this is because, as we discussed earlier, CTM needs it to be possible to think just Socrates or snored or blue. CTM demands that we have atomic concepts, and that our thoughts consist of concatenations of these concepts. So our argument shows that CTM fails relative to its own assumptions. 
         CTM requires the truth of some kind of conceptual atomism. So conceptual atomism would indeed be de rigueur if CTM were correct. But we’ve seen reason to think that CTM is not correct. It involves misunderstandings of the nature of symbolism, formal truth, and causation; and it doesn’t appear that any doctrine significantly similar to CTM would not involve these misunderstandings. So there is no reason to accept conceptual atomism, given only that CTM demands its acceptance. 


Chapter 16 Fodor’s first argument for conceptual atomism 


       Fodor accepts CTM. He also sees that CTM demands the truth of conceptual atomism (henceforth “atomism”), and this is at least part of the reason that he accepts atomism. But Fodor realizes that few are willing to accept atomism, and he thus provides three independent arguments for it (Fodor 1998). In this chapter, we will examine the first of these three arguments. We will examine the other two in Chapters 17 and 18. 


Fodor’s argument
  
         There is no doubt that some expressions are definable. “Triangle” can be defined as “closed planar figure such that any two, but not all three, of its sides intersect.” “Two” can be defined as “the successor of one.” In general, expressions belonging to “bona fide axiomatic systems” can be defined. Further, “patently phrasal” expressions can be defined, at least in a relative sense: “smart brown cow” can be defined as “anything x such that x is smart, x is brown, and x is a cow.” 
       But leaving aside these two classes of expressions, virtually no expression can be defined. No one has produced an adequate definition of “knowledge.” (It used to be thought that “knowledge” could be defined as “justified true belief.” But Gettier (1963) famously proved this false, and attempts to produce an adequate definition have failed. See Shope 1983.)  What we just said about “knowledge” is true of practically any expression denoting a philosophically, or otherwise theoretically, important concept. In fact – what is probably more important – even expressions denoting pedestrian concepts turn out to be incapable of definition. Consider the verb (not the noun) “paint.” Contrary to what might initially be thought, this cannot be defined as “to cover in paint” or even “to intentionally cover in paint.” When you dip your paintbrush into a bucket of paint, you are not painting it, even though you are intentionally covering it in paint. There are other prima facie reasonable definitions of this verb; but they all fail. Given that the word “paint” is indefinable, it follows that the corresponding concept is simple. (In this context, the word “concept” denotes a property or, in any case, some kind of abstract entity. It does not denote a psychological entity; it does not denote one’s grasping of something.) After all, if that concept were complex – if it consisted of other concepts (e.g. cover, intentional, and so on) – then there would be some true statement saying how that concept were composed of those other concepts (just as there is a true statement saying how  water molecules are composed of hydrogen and oxygen molecules). There isn’t; so it doesn’t. “Paint” (taken as a verb) is indefinable and the concept that it expresses is therefore simple. Given virtually any other expression, what we just about “paint” is true of that other expression, showing that all (or nearly all) concepts are simple. (In any case, it shows that all, or nearly all, the concepts denoted semantically non-complex expressions of natural language, leaving aside those concepts that are expressed by artifacts like “integral”, are simple.)[174] 
     
Our response


      In this context, the word “concept” obviously doesn’t denote a psychological entity. So if cogent, the argument just shows that concepts in the non-psychological sense of the word are simples. That argument does not, at least not directly, say anything about concepts in the psychological sense.  To simplify further discussion, let us refer to concepts in the non-psychological sense as “conceptso”, and let us refer to concepts in the psychological sense as “concepts.” So a concept is one’s grasp of something, and a concepto is a platonic entity. 
           Fodor is trying to show that concepts are atoms (simples). He is trying to make a case for conceptual atomism. So Fodor must be assuming that if conceptso are simples, the same is of our psychological representations of those concepts. In any case, if this assumption is not granted, then Fodor’s argument doesn’t show that concepts are atoms.  So for the sake of argument, let us grant Fodor’s tacit assumption that conceptual atomism follows from conceptualo atomism. (Later we will examine this assumption.) 
        Granting this assumption, there are two major problems with Fodor’s argument. Nobody denies that x’s being a belief is necessary for x’s being knowledge, and nobody denies that the necessity in question is analytic, and not empirical, in nature. Nobody denies that putting paint on something is necessary for painting it, and nobody denies that the necessity in question is analytic. Given any concepto C, nothing is easier than to identify conditions that are analytically necessary for something’s falling under it. 
       But surely analytic necessities correspond to conceptualo structure. x is an instance of knowledge does not entail x is an instance of putting paint on something. But the latter is entailed by x is a case of painting. Surely this tells us that the architecture of the one concepto is different from the architecture of the other. 
        In fact, this last point would seem to be a truism: given that to fall under the one concepto but not the other, x must be an instance of belief, those two conceptso are ipso facto structurally different. When we talk about the “structures” (or “compositions” or “architectures”) of conceptso, we obviously aren’t referring to their physical structures.  We are referring to relations of logical dependency, not of spatiotemporal juxtaposition. With a minor qualification to be stated shortly, for conceptso C and C* to differ in respect of their structures just is for x is a C to entail something not entailed by x is a C*. A corollary is that, as long as we can give necessary conditions for x’s falling under C, it follows that C has conceptualo structure.
         Taken in conjunction with this line of thought, Fodor’s own argument would seem to show that any given concepto has an infinite amount of structure. Getteriologists may not have provided necessary and sufficient conditions for something’s being knowledge. But they have succeeded in providing a number of necessary conditions (Shope 1983). Given what we said a moment ago, each of these new necessary conditions corresponds to a newly discovered fact about the architecture of the concepto of knowledge. If there are infinitely many such conditions, then that concepto has an infinite amount of structure. Supposing that there are only finitely many such conditions, then that concepto has a finite, but non-null, amount of structure and, more importantly, that concepto is definable. Either way, Fodor’s argument collapses.[175] 
         Here is a useful analogy. It is a point often made by philosophers of science that the term “explanation” is contextual.[176] To give you a complete explanation of anything, I would have to describe every event that led up to that event, starting with the Big Bang. In this sense of the word “explanation”, it is impossible in practice, and probably in principle, to explain anything. But it is a datum that perfectly good explanations are given by statements like “Smith crashed the car because he was drunk”, “Jones is limping because he twisted his ankle while playing squash”, and so on. So given only that “complete” explanations cannot be given, it would be absurd to conclude that explanation tout court is impossible. It would be absurd to say: “the world is explanatorily amorphous, since nothing can be completely explained.” 
     Similarly, it would be absurd to say: “the concepto of knowledge explanatorily amorphous, since there is no complete account of its analytic structure.” Given that there are partial characterizations of its structure, it follows that it is not analytically amorphous.


An objection to our assessment of Fodor’s argument


      There is objection to this line of thought that we must consider.[177] And it is not just an objection: it is one that embodies a position that Fodor himself holds and that underlies his various arguments for conceptual atomism: 


    According to the argument you just gave, C and C* have different structures exactly if they differ in their entailment-relations. The statement: 


(S) “x is identical with Socrates” 


doesn’t entail anything not also entailed by: 


(A) “x is identical with Aristotle.” 


      So if your argument is correct, then the concepto Aristotle (or identical with Aristotle) is structurally just like the concepto Plato. By itself, this doesn’t mean that those conceptso have no structure. (It could be that x is identical with Aristotle entails x is a spatiotemporal object.) But it does show that, so far as those conceptso differ, that has nothing to do with structural differences between them. That, in its turn, shows that grasping the one concepto as opposed to the other cannot be understood in terms of grasping structural differences between them, and thus cannot be understood in terms of one’s grasping some set of concepto C1…Cn such that the one concept, but not the other, is constructed of those conceptso. So one’s grasping the concepto  Plato as opposed to the concepto  Aristotle is not to be understood in terms of what other conceptso one grasps. That difference is conceptually primitive. What we just said about the conceptso Plato and Aristotle is true of countless other pairs of conceptso. Indeed, what we just said holds of practically any two conceptso. The pairs of conceptso that you chose seem to be more the exception than the rule. What you said about the pair of conceptso knowledge and paint seems not to apply universally or even usually. So, given only what you’ve said, Fodor’s argument may go through, at least for the great majority of conceptso. Further, it seems clear that differences between conceptso are often primitive, i.e. if C and C* are different conceptso, that cannot typically be understood in terms of how those conceptso are composed out of other conceptso. So it would seem that, in the end, Fodor’s argument does go through, notwithstanding some of the technical problems that you have pointed out with it. 




     We have spoken a great deal about the difference between, on the one hand, what is literally meant by expressions and, on the other  hand,  what we learn in the process of ascertaining what is literally meant by them. The objection just stated involves a failure to appreciate this difference. As we’ve seen, there is some x such that what is literally meant by any token T of: 


(HL) “Hesperus is lovely”, 


and also any token T* of 


(PL) “Phosphorous is lovely”,


is simply:


(XL) x is lovely. 


But one must compute the meanings of T and T* on the basis of background semantic and pre-semantic knowledge; and for this reason, those two tokens may diverge dramatically in respect of what they impart to one. For a moment, let us discuss the conceptso Hesperus and Phosphorous (or identical with Hesperus and identical with Phosphorous). Given the points that we will make in connection with these conceptso, it will be clear what we must say about the conceptso Socrates and Aristotle. 
      First of all, which entity are we talking about when we talk about “the concepto Hesperus” or “the concepto identical with Hesperus”? If we are talking about the information through which one computes the meanings of sentence-tokens like T, then that concepto is replete with conceptualo structure. As we saw in Chapter 4, the information that one associates with T (in our technical sense of “associates with”) is some existence-claim having the form: 


(EHL) There is some luminescent beautiful x in such and such part of the morning sky…and what is meant by “Hesperus is lovely” is: x is lovely. 


So on one possible disambiguation, the term “the concepto identical with Hesperus” refers to this wide-scope descriptive information.[178] 
        What else might the expression “the concepto of Hesperus” refer to? Hesperus’ existence is not a simple, ultimate metaphysical fact. Given any possible world W where Hesperus exists, its existence supervenes on various other facts. Certain displacements, having certain origins, resulted in a large solid body having a certain trajectory. Of course, Hesperus is not modally frozen: there are possible worlds where, because of some cataclysm, it breaks free of its orbit around the sun. More generally, there are worlds where it has properties very different from those that it actually has. But there are no worlds where Hesperus has totally different origins from those that it actually has. 
         Given this last point, it would seem that any world W where Hesperus exists is one that has much in common with our world apart from including Hesperus: some space-time region R of W must comprise innumerable sub-atomic events that are qualitatively much like the events comprised by some corresponding region in our world. Further, because Hesperus is presumably individuated by its origins, it exists in a world only if that world comprises at least some objects that are numerically identical with objects in our worlds. (And, of course, the same thing mutatis mutandis holds of those parents objects.) So there is some list of properties P1…Pn such that,  for a world W to comprise Hesperus, it is necessary, and perhaps sufficient, that each of these properties be instantiated in W. (For reasons already given, none of these properties will be identical with Hesperus or identical with Hesperus or a square circle or anything of the sort. For each i, Pi will be some property that is metaphysically and analytically more fundamental than identical with Hesperus or any other such property.) 
     It seems to me that, on one possible (and reasonable) disambiguation, the term “the concepto of Hesperus” refers to this set of properties: the set of properties such that their joint instantiation is necessary (and sufficient) for Hesperus’ existence in any world W. Relative to this disambiguation,   the concepto of Hesperus is replete with conceptualo structure. For exactly similar reasons, “the concepto of Socrates” would refer to a conceptuallyo complex entity. And this, of course, would scuttle the objector’s point that  “the concepto of Hesperus” and  “the concepto of Socrates” refer  to  conceptuallyo simple entities. 
             Inevitably, some will respond by saying things like:


I have a perfectly good grasp of the conceptso Socrates, Hesperus, and Aristotle. But I haven’t the foggiest knowledge as to the nature or identity of the sub-atomic events in virtue of whose occurrences these conceptso are instantiated. So it is not really an option to say that the concepto of being identical with Hesperus (or Socrates or Aristotle…) is to be understood in the way you just proposed. 




       Supposing that this is right, what does it mean to say that one “grasps the concepto of being identical with Hesperus (or Socrates or Aristotle…)”? It means that one is able to think about these objects. Of course, to think about Socrates, it is not necessary to know much at all about his origins, let alone about their molecular basis. But as we’ve seen, to think about Socrates, one does have to know some rather complex description that Socrates alone uniquely satisfies. The objector is quite right that in this sense of the term “concepto of Socrates”, one doesn’t have to know anything about the molecular basis of Socrates’ conditions of origination to grasp a concepto of Socrates. But this is consistent with our point that anything fit to be denoted by the term “the concepto of Socrates” is replete with conceptualo structure.  Of course, what we just said about  “Socrates” is true of “Aristotle”, “Hesperus”, or any other singular term.
        Of course, the objector is entirely right to say that a token of the sentence 


(S) “x is identical with Socrates” 


doesn’t entail anything not also entailed by a token of: 


(A) “x is identical with Aristotle.” 


     But as we’ve seen (Chapters 1-4), nothing at all can be inferred from this fact as to structure of the concepto of Aristotle or of the concepto of Socrates. An exact analogue of the argument just given shows that we have said about singular terms is also true of terms denoting natural kinds (“water”, “wood”). 
  
 Does conceptual atomism follows from conceptualo atomism? 


     As we noted earlier, Fodor’s argument tacitly assumes that the truth of conceptualo atomism is sufficient for the truth of conceptual atomism. Is this assumption correct? No. While a case can be made that conceptualo atomism is necessary for conceptual atomism, no case can be made that the former is sufficient for the latter. 
       For the sake of argument, let us suppose that (with the obvious exceptions that Fodor discusses) conceptualo atomism is correct, and let C and C* be two conceptso. Given only that these conceptso are simple, i.e. that no concepts (other than themselves) are constitutive of them, it doesn’t follow that my mental representations of them are conceptually simple. Let X and Y be two qualitatively identical, perfectly homogeneous spheres that are located in different places. I think of X as the sphere in Aunt Jenny’s basement and I think of Y as the sphere in Uncle Fred’s attic. So even though X and Y are qualitatively identical, and even though they are both lacking in internal structure, it doesn’t follow that my concepts of them are qualitatively identical or that my concepts of them are without internal articulations. 
     Given only that two different conceptso have no structure, and thus vacuously have the same structure, it doesn’t follow that my concept of the one is qualitatively identical with my concept of the other. What follows is that I cannot distinguish those conceptso on the basis of their internal structures, not that my concepts of them are themselves without structure. 
     Of course, X and Y are spatiotemporal individuals, whereas conceptso are not; and, conceivably, one might argue that where non-spatiotemporal entities are concerned, the structures of our concepts do mirror those of their objects. But Fodor provides no argument for such a view; and, more importantly, it is extremely implausible. Structurally identical spatiotemporal individuals can be distinguished by their differences in spatiotemporal location. But structurally identical conceptso could not be distinguished in this way. So far as conceptso can be distinguished from one another, it seems to be on the basis of their structures. In any case, Fodor’s tacit assumption (conceptualo atomism is necessary for conceptual atomism) is false. 
    
Quine on analyticity 


       Let us end this section by discussing Quine’s (1951) analysis of the analytic-synthetic distinction. Quine holds that, with a few trivial exceptions, all sentences are synthetic. (The exceptions involve cases where one term has been stipulated to have the same meaning as another.) Our argument against Fodor assumes that there are analytic truths. Indeed, we have made liberal use of this assumption in this work, and we must therefore consider Quine’s views on analyticity. It should be pointed out that Fodor (1998: 25, 45-46) agrees with Quine. Indeed, Fodor takes it as a foregone conclusion that Quine’s arguments are cogent, give or take some nuances. 
        Here is the basic structure of Quine’s argument. Analyticity is to be understood in terms of synonymy. But synonymy must be understood in terms of analyticity. Therefore the concept of analytic truth is incoherent one. Let us now state Quine’s argument in full. 
       If indeed “bachelors are unmarried males” is analytic, that is because “bachelor” is synonymous with “unmarried male.” Similarly, if “triangles are three-sided, closed, planar, straight-edged figures”, that is because “triangle” is synonymous with  “three-sided, closed, planar, straight-edged figures.” 
      What is it for two expressions to be synonymous? It is not merely for them to be insubstitutible salva veritate.  “Rhenates” and “chordates” can be intersubstituted salva veritate but they are obviously not synonymous. For two expressions to be synonymous, intersubstitutions of them must preserve not only truth, but also meaning. But the concept of meaning is itself to be understood in terms of the concept of analyticity: ┌x has phi┐ has the same meaning as ┌x has psi┐ iff ┌x has phi iff has psi┐ is analytic. So analyticity is to be defined in terms of synonymy, and synonymy is to be defined in terms analyticity. Attempts to define analyticity are doomed to failure, since they are necessarily characterized by the same vicious circularity as attempts to inductively justify induction; and the concept of analyticity is therefore incoherent. 
      In objection to what we’ve just said, it might be said that “rhenates” and “chordates” cannot be intersubstituted substituted salva veritate. “Smith believes that rhenates are rhenates” is true, but not “Smith believes that rhenates are chordates.” In intensional contexts, intersubstitutions of co-extensive expressions don’t generally preserve truth-value. So we can define “synonymous” is “intersubstitutable salva veritate”, breaking the vicious definitional circle. 
        Quine considers this very point, and successfully rebuts it. The concepto of an “intensional” context is itself to be understood in terms of the concepto of analyticity. C is an intensional context iff intersubstitutions of its component expressions preserve the truth-value of the host-sentence only if those intersubstitutions involve expressions having the same meaning. As we saw a moment ago, the concepto of meaning is to be understood in terms of the concept of analyticity. So “synonymous” cannot be non-circularly defined 666 as “intersubstitutable salva veritate.”


Evaluating Quine’s argument 


       If there are any analytic sentences at all, one of them is: 


(*) “n is a unique even prime iff n is one less than three.” 


Quine explicitly assumes that the expressions flanking the biconditional must be synonymous if that sentence is to be analytic. But the expression “n is a unique even prime” obviously isn’t synonymous with the expression “n is one less than three.” So Quine is therefore wrong to assume that there is analyticity only where there is synonymy, and his argument therefore implodes. 
      Conceivably, Quine might deny that (*) is analytic on the grounds that the expressions flanking the biconditional are not synonymous. But in that case, he would simply be redefining the term “analytic”, and his argument would have force only against an artifact of his own definitions. 
        Let us develop this criticism of Quine’s argument. Sometimes when a sentence is described as “analytic”, what is meant is that it encodes an analytic proposition, where an analytic proposition is one that holds entirely in virtue of the structures of the conceptso composing it. An example of such a sentence would be: “there is no law where there is no government.” Surely it is not an empirical fact that there is law only where there is government; it is part of the concepto of law that instances of it presuppose the presence of government.
        But sometimes when a sentence is described as “analytic”, what is meant is that it is formally true. Even though no empirical knowledge (over and 666 above such as is needed to grasp its meaning) is needed to determine the truth-value of “there is no law where there is no government”, that sentence is not formally true. By contrast, a token of “I am here now” is formally true, as is a token of “if snow is white, then snow is either white or green.” As we discussed earlier, a sentence-token T belonging to language L is formally true iff it is a theorem of the semantic rules of L that T is true. 
        Quine’s statement that analyticity is to be understood in terms of synonymy is therefore ambiguous. Let us consider each disambiguation of Quine’s statement. 
         The concepto of formal truth is not to be defined in terms of that of synonymy. (A sentence or sentence-token T is formally true if its truth is a theorem of the relevant semantic rules. There is no mention of synonymy here.) So Quine’s argument implodes if by an “analytic” sentence, Quine means one that is formally true. 
        Let us now consider the other disambiguation of Quine’s statement. The sentence “there is no law where there is no government” is analytic because it expresses a logically true proposition. (In this context, the term “logically true” is meant broadly, a “logically true” proposition being one whose negation is incoherent.) The same is true of “there is no pain where there is no sentience”, “causes precede their effects”, and “there are continuous functions that cannot be differentiated at any point.” These sentences are not formally true; but their negations are incoherent, because the propositions that they express hold entirely in virtue of the structures of the conceptso composing them. 
       In general, a sentence is “analytic”, on this disambiguation of the term, iff it expresses a proposition whose truth is guaranteed by the structures of the conceptso composing it. There is no mention of synonymy here, and thus no vicious circularity.[179] So Quine’s argument once again collapses.
        A brief look at philosophical history may shed some light on this topic. Leibniz held that all the laws of logic can be reduced to the law of identity (now called “Leibniz’s Law”): if x and y are identical, then x has a given property iff y has that same property. So, in Leibniz’s view, all logical truths – e.g. if p, and if p then q, then q – are really instances of Leibniz’s Law. 
        But Arthur Pap (1958) showed that in order to reduce truths of logic to instances of Leibniz’s Law, one must presuppose the truth of logical principles other than Leibniz’s Law and that, consequently, principles other than that law are ineliminable components of logic. Leibniz’s thesis is therefore wrong. 
       In holding that all logical truths can be modeled on “all bachelor’s are married”, Quine is guilty of a version of Leibniz’s thesis. (Chomsky (1988) makes a similar point.) Not all logical (or analytic) truths express identities (“the class of bachelors is identical with the class of unmarried adult males”) or partial identities (“the class of bachelors is a subset of the class of unmarried entities”). There is no obvious sense in which “legal obligation presupposes governmental protection” holds in virtue of some synonymy-relation between two expressions; and any equivalence between that sentence and an identity (or partial identity) could be shown only on the basis of analytic truths that are not identities. So, contrary to what Quine assumes, it is not the case that, if there are analytic truths, they can all be modeled on “all bachelors are unmarried” or on any other sentence whose analyticity derives from a relation of synonymy. 
        It is not hard to find independent corroboration for this criticism of Quine’s argument. “All bachelors are unmarried” is trivial. The same is true of any sentence whose analytic status depends entirely on some instance of synonymy: “there are three feet in a yard”, “women are adult female humans”, “banks are financial institutions.” 
      But many analytic sentences are not trivial; and all non-trivial analyticities do not hold in virtue of synonymy relations. Consider the following sentences: “there are continuous functions that cannot be differentiated at any point”, “laws are narrow-scope governmental assurances of protections of moral rights”[180], “a symbol-token is an instance of a relation between morphology and socio-psychological context”, “the minimum number of sides that a three-dimensional closed figure can have is five”, “there is no complete and consistent formalization of arithmetic.” (If you think that any one of these sentences is false, then prefix it with an “it is not the case that”, and the resulting sentence will be analytically true iff the original sentence was false.) The analytic status of any given one of these sentences cannot be understood in terms of the fact that one term is synonymous with another. Unlike “all bachelors are unmarried”, these sentences do not merely register synonymies; and that is why they are all non-trivial. 
      There are trivial analyticities that do not merely register synonymies, e.g. “green is a color.” (Attempts were made to show that “green” could be defined in terms of “color”; but these attempts failed, and it is clear that they must fail.[181]) But all non-trivial analyticities do more than register synonymies. 
      Quine’s mistaken thesis that analyticity is to be understood in terms of synonymy can be understood as a distortion of the correct point that a sentence is analytic, on one disambiguation of that term, iff it is semantically true. Synonymy-based analyticities are among the more obvious cases semantic truths: “there are three feet in a yard” is analytically true because a “yard” is defined as a distance of three feet. But they are not  the only examples of analytic truth. 


Additional problems with Quine’s argument 


           We said that, on one disambiguation of the term “analytic”, a sentence is analytic iff it expresses a logically true proposition. (Given how we are using the term “logically true” in this context, it is clear why this analysis is not guilty of any circularity.) Quine did not believe in propositions or in meanings generally, and would thus reject this characterization of analyticity. 
         At least part of the reason that Quine rejects the notion of meaning (and, thus, of propositionality) is that he is a nominalist: he believes in spatiotemporal individuals, but not in platonic abstracta – there are instances of properties, but no properties (except in so far as properties can be identified with, or otherwise reduced to, instances of properties). In Quine’s view, there are noises and ink-marks, but no propositions (except in so far as propositions can be constructed out of noises, ink-marks, and the like). 
        My own view is that nominalism is wrong. But we don’t have to refute nominalism to show that Quine’s position is indefensible. Consider the sentence (or, if you prefer, a token of the sentence): “there is no law where there is no government.” That sentence is not formally true, i.e. it is not a theorem of the relevant semantic rules that it is true. But given those semantic rules, and given no additional empirical information, it follows that it is true.
        In general, a sentence (or sentence-token) S, belonging to language L, is analytic exactly if, given the semantic rules of L, and given no other empirical information, S’s truth follows. This definition of “analytic truth” satisfies two relevant conditions. First, it doesn’t involve the notion of synonymy. (So supposing that it is correct, Quine’s argument is blocked.) Second, that definition doesn’t involve the notion of a proposition,  except in so far as the conceptso semantic rule and following from involve that notion. These are conceptso that Quine himself accepts and that surely must be accepted. It would be absurd to deny that there are semantic rules, even though there are obviously different reasonable views as to what semantic rules are. It would also be absurd to deny that certain statements follow from other statements. (Somebody who denies that statement is affirming the statement: the statement that nothing follows from S follows from the statement that S is a statement. So somebody who denies that statements ever follow from statements is affirming the negation of xxx his own view.) So, contrary to what Quine says, it is possible to give a non-circular analysis of the concepto of analyticity. 
        Most importantly, it is clear at an intuitive level that some truths are analytic. To know that there is pain only where there is sentience, one doesn’t need empirical knowledge, over and above such as is required to grasp that proposition (or, if you prefer, to understand the corresponding sentence).[182] Quine’s argument is too wobbly to demand that we repudiate this intuition.    
        Quine would say this intuition is deceiving us, just as Kant’s intuitions were deceiving him when they led him to repudiate the very idea of a non-Euclidean space, or a non-Newtonian mechanics, or a non-Aristotelian logic. But as Laurence Bonjour (1998: 5-7) and Michael Dummett (1973: 592-595) show, it is not hard to find demonstrable support for our intuitions. Bonjour and Dummett provide essentially the same argument, which I will now outline.
       For the sake of argument, suppose that no statements are analytic. (The term “statement” may be taken to mean either sentence or sentence-token or proposition.) In that case, no statement of the form S1 confirms statement S2 to degree n is analytic: every such statement is synthetic and, therefore, whether it is true or false is a matter that sense-experience alone can determine.666 By the same token, for any statement S3 that is learned through experience, it is up to future empirical findings to determine what degree of probability S3 gives to S1 confirms statement S2 to degree n. By itself, S3 will thus be incapable of giving any degree of confirmation to that statement. By an exactly similar argument, any future empirical finding will be incapable of confirming any statement of the form xxx the statement that S1 confirms statement S2 to degree n is confirmed to degree m by statement S3. And so on ad infinitum.  
      Nothing can confirm anything unless at least some confirmation-relations are analytic. This doesn’t mean that this or that specific statement (e.g. “there is no government where there is no law”, “there is no pain where there is no sentience”) is analytic. (Actually, it does show that the statement “given that some statements confirm other statements, it is analytic that there are analytic truths” is analytic. But with a few exceptions of this sort, this argument provides no special support for the view that this or that specific statement is analytic.)  But it does show that the class of analytic truths is non-empty. 
      This brings us to another argument against Quine’s position. If the statement: 


(NAT) there are no analytic truths


is analytic, then Quine’s position is false. If (NAT) is synthetic, then empirical research could show that it is true. So there can be no demonstration or non-empirical proof of (NAT) if that statement is true. Therefore that statement is non-demonstrable if true. So if Quine is right to deny that there is analytic truth, then we must regard his argument for that position as fallacious. 


Hempel on analyticity 


         Carl Hempel (1952: 26-28, 1965: 113-116) has provided an argument against the analytic-synthetic distinction that, although ultimately fallacious, is considerably more compelling than Quine’s. 
        Scientific conceptso are capable of partial (though almost never complete[183]) operational definitions. “x has length L” can be partially operationally defined as 


(1) “x can be made to coincide with object y”, 


(where y is some other object, e.g. the standard meter in Paris) or as 


(2) “it takes light n nanoseconds to travel from one end of x to the other.” 


Of course, stipulative definitions are analytic. So supposing that O has length L, it is analytic, given (1) and (2), that:


(3) it takes light n nanosecond to travel from one end of O to the other, 


and it is also analytic that 


(4) O can be made to coincide with y. 


But (3) and (4) are not logically equivalent. Given that the one is true, it does not analytically follow that the other is true. If (3) and (4) have the same truth-value, that is entirely a matter of a posteriori fact. 
       Any one operational definition is purely analytic. But when one attempts to give multiple (partial) operational definitions of a concept, one has to make sure that those definitions are empirically consistent with one another – otherwise the concept defined is incoherent. For example, there is nothing incoherent in supposing that light takes m (≠n) time to travel from one end of O to the other, but that O can be brought into coincidence with y. For the sake of argument, suppose that to be true. In that case, given both (1) and (2), the statement “O has length L” entails both that L can, and also cannot, be brought into coincidence with y. To avoid saddling the term “length” with a broken and incoherent concept, we must make sure that our various operational definitions of that term are mutually consistent; and that can be done only through empirical work. 
       Supposing that we (partially) define “length” in terms of (1) and (2), but we haven’t yet established the empirical equivalence of those definitions, we are left with a situation where a true statement (“O has length L”) analytically entails two other statements, namely (3) and (4), but where it remains an empirical question whether both of those statements are compatible. But, granting that there is a sharp distinction between analytic and synthetic statements, this is not a tenable situation. If S1 is true, and analytically entails S2 and S3, then it is ipso facto settled whether both of S2 and S3. The distinction between the analytic and the synthetic appears to have broken down; and the statement “if O has length L, then it takes light n nanoseconds to travel from one of O to the other” isn’t non-arbitrarily categorized as either analytic or synthetic. 
       What was just said about “length” is true of each member of an extensive and important class of expressions. Many terms begin as expressions of lay-discourse and are later appropriated by science. Having been thus appropriated, they are redefined, and usually thereby rendered both more precise and more comprehensive in extension, in light of scientific theories. Terms like “heat” and “temperature” have been existed as long as language itself. But, as they are used by the lay-person, those expressions seem to have no determinate meanings outside the extraordinarily narrow corridors of day-to-day human experience. 
         Physics 666 has established that, for any number n that corresponds to a temperature that can be directly experienced by human beings, a substance’s having certain molecular properties is necessary and sufficient for its having a temperature of n°. On this basis, the term “temperature” can be identified with, and thus defined  in terms of, 666 certain molecular properties. This brings statements of the form ┌x has temperature n°┐ into systematic connection with powerful and well-organized bodies of scientific theory, thereby increasing the predictive and explanatory import of such statements. It also gives greater precision to such statements: previously they were defined either in terms of instrumental operations whose outcomes were not a function only of the relevant object’s temperature (whether a column of mercury rises by a certain amount in a thermometer is only partly determined by the temperature of the substance in which the thermometer is immersed) or, even worse, were understood  in strictly phenomenological terms (in terms of what the object in question “felt like”). 
         The pre-scientific  usage of the term “temperature” lacked the uniformity of usage characteristic of rigorous discourse and, at least arguably, failed to determine a unique concept. The process of assimilating that term, and other terms in its category (e.g. “heat”, “freezing”), into science generated a situation exactly parallel to that described a moment ago in connection with “length.” What we have said about “length” and “heat” is true of “mass”, “acid”, and practically any expression denoting an explanatorily significant class of phenomena (or objects). Thus, given any one of the these terms, an argument exactly analogous to that given in connection with “length” points to the existence of a  breakdown of the distinction between analytic and synthetic truths. 


Evaluating Hempel’s argument 


           Let us start with a purely exegetical point. Hempel’s primary concern is not to discuss the viability of the analytic-synthetic distinction, but only to describe scientific methodology. (His remark about the analytic-synthetic distinction is almost made in passing.) From that viewpoint, Hempel’s analysis is unexceptionable. But we can accommodate Hempel’s correct methodological point without rejecting the traditional view that some truths are neither analytic nor synthetic and without therefore embracing the subsequent revisions of classical logic that would be demanded by a rejection of that view. 
            First of all, we must distinguish reference-fixing from meaning-giving. An operational definition can be seen not as giving the meaning of “length” (or “temperature” or “mass”…) but rather as fixing its referent. Suppose that Smith is the one person who came to our party yesterday wearing a ridiculous looking plaid sportcoat; and suppose that Smith is also the one person who gave money to the charity that Brown started. Each of the statements: 


(5)  “Smith is the one person who gave money to the charity that Brown started”


and 


(6) “Smith is the one person who came to our party yesterday wearing a ridiculous looking plaid sportcoat.”


Fixes the referent of Smith. There is some x such that, given either  (5) or (6), “Smith is bald” means: x is bald. At the same time, (5) does, whereas (6) does not,  entail that Smith gave money to Brown’s charity; and (6) does, whereas (5) does not,  entail that that Smith wore a plaid  sportcoat on a certain occasion. Each of (5) and (6) is a correct definition of “Smith”. At the same time, given the statement “Smith is bald”, it follows from (5), but not from (6), that a bald person gave money to Brown’s charity. So we seem to have a situation where “Smith gave money to Brown’s charity” both does, and does not, entail “a bald person gave money to Brown’s charity.” So we have a situation that precisely parallels that described in connection with “length.” 
       But obviously there is no breakdown of the analytic-synthetic distinction. The content of (5) is perspicuously given by the statement: 


(5*) Somebody x uniquely gave money to Brown’s charity and “Smith” names x, 


and the content of (6) is perspicuously given by the statement: 


(6*) Somebody x uniquely wore a ridiculous plaid sportcoat on a certain occasion, and “Smith” names x. 


What (5*) and (6*) make clear is that, where each of (5) and (6) is concerned, the definition of “Smith” actually being given is simply: “Smith” names x, for some x. The reason that (5) does, whereas (6) does not, entail that somebody gave money to Brown’s charity is that (5) is not just a definition: it consists of a synthetic statement (“somebody x uniquely gave money to Brown’s charity”) conjoined (as it were) with a definition (“x is Smith” or “x is named ‘Smith’”). The purely definitional component of (5) is given by a bare singular proposition (x is named “Smith”); the remaining part of (5) is part of the pre-definition, as opposed to the definition per se, of “Smith.” What we just said about (5) is true of (6). So, ultimately, each of (5) and (6) defines “Smith” in the same way, namely: “Smith” names x, for some x.  But (5) and (6) create different pre-definitional information, and this creates the conundrum (or illusion thereof) just described. 
      For obvious reasons, expressions cannot be defined in a vacuum; definitions must be made in terms of phenomena that are known to both speaker and auditor. But it doesn’t follow that those phenomena always enter constitutively into the definition itself. In some cases, they are among the means used to give the definition, and are not internal to the definition itself. 
      What we just said about “Smith” is true of “length”, “mass”, “heat”, “hardness”, and other such terms. Each of (5) and (6) can be seen as fixing the referent, not giving the meaning,  of the term “length.” If this is right,  then the content of (1) is given by the statement: 


(1*) There is some property P such that anything x (of the appropriate shape) has P exactly if x can be brought into congruence with object y, and “length L” refers to P. 
 
And the content of (2) is given by the statement: 


(2*) There is some property P such that anything x (of the appropriate shape) has P exactly if it takes light n nanoseconds to travel from one end of x to the other, and “length L” refers to P. 


    So where each of (1) and (2) is concerned, the strictly definitional component is given by the bare singular proposition: “the expression ‘length L’ refers to P.” For exact analogues of the reasons given in connection with “Smith.” It is true that (1) doesn’t have the same analytic consequences as (2). But this doesn’t indicate that a statement can simultaneously entail, and fail to entail, some other statement. It merely corresponds to the banal fact that different synthetic statements have different consequences. 
       The distinction between reference-fixing and meaning-giving has far-reaching implications as regards scientific methodology. One example of this concerns a doctrine called “operationalism.” According to this doctrine, a term T is scientifically meaningful iff it is operationally definable, i.e. if for any object (or ordered n-tuple of objects) x, there is some observable phenomenon E and some observable operation O such that T describes x iff E results when O is applied to x. 
        Hempel (1965: 123-134) argued compellingly that operationalism is untenable. But the term “operationalism” is ambiguous, depending on whether the term “define” is taken in the reference-fixing or meaning-giving sense. If it is taken in the latter sense, Hempel’s arguments against operationalism are entirely cogent. But those arguments are not cogent if  “define” is taken in the former sense. At the same, “operationalism” is eviscerated if it is taken to be the view that an expression T denotes a scientifically respectable concept exactly if observable outcomes of observable procedures may fix the referent of T. It is easily seen that, relative to that definition of “definition”, there is no unique operational characterization of any phenomenon that has observable effects and that, consequently, operationalism is reduced to the triviality that, in some cases, a theoretical (or otherwise unobservable) phenomenon may have an observable effect. So Hempel’s arguments against “operationalism” are cogent, so long as that term is taken in a way that does not eviscerate it. 
      
The ambiguity of “ambiguity” 


          But even if we leave aside everything just said – even if we set aside the distinction between meaning-giving and reference-fixing – we must still reject Hempel’s argument concerning the analytic-synthetic distinction. If “length L” is defined in two non-equivalent ways, then ┌x has length L┐ will be ambiguous between two non-equivalent propositions. That sentence may entail a given statement – e.g. “it takes a beam of light n nanoseconds to travel from one end of x to the other” – on the one, but not the other, of those disambiguations. But this would no more warrant a revision of our views concerning the analytic-synthetic distinction than is warranted by the fact that, on exactly one of its two disambiguations, xxx [comma inserted] “John went to the bank” entails that John went to a financial institution. 
       The term “language” is ambiguous between “diachronic” and “synchronic” meanings, to use Saussure’s (1966) terminology. The statement: 


(7)  “The English language came into existence after the year 1100 A.D.” 


is true on one disambiguation, but false on another. If by “the English language” is meant the set of semantic rules that, at this instant in time, characterize the language spoken in Australia, England, and so on, then that statement is false. But that claim is true if by “the English language” is meant a series of sets of semantic rules such that, first, the set of rules operative in Australia, New Zealand, and so on, is a member of that series and such that, second, there is a certain kind of spatiotemporal continuity between any two installments in that sequence. So (7) is false on the “synchronic” meaning of “the English language”, but true on the “diachronic” meaning of that expression. 
      Words change their meanings. (There is “semantic shift”, as linguists put it.) This inevitably creates ambiguity since, during the period of semantic shift, some people continue to use the term in the old way. (In fact, semantic shift usually, though not necessarily, occurs in consequence of an absence of uniformity of usage.) But while the ambiguities associated with words like  “bank” or “dumb” are easily recognized as such, and thus tend not to lead to confusion, the ambiguities created by semantic shift are less likely to be recognized as such, and what are in fact purely terminological differences come to be seen as having a substantive dimension. (We might say that “bank” is an instance of “synchronic ambiguity”, since its ambiguity is not a reflection of change in its usage, and that “temperature” is an instance of “diachronic” ambiguity, since its ambiguity between molecular, phenomenological, and other concepts is a reflection of language-change.) Synchronic ambiguities are (relatively) stable: “bank” has meant both river’s edge and financial institution for hundreds of years.  By contrast, diachronic ambiguities are unstable, almost by definition, and they typically quickly give way uniformity of usage  and thus to synchronic non-ambiguity. 
        For obvious psychological reasons, if a term is used non-uniformly on Monday, and uniformly on Tuesday, people will tend to regard as deviant those Monday-usages of the term that don’t conform to its Tuesday-usage. Semantic shift thus tends to create  the illusion that, during the unstable interim-period, people were simply using the expression in question wrongly. 
      A related point is that people tend to mistake continuous changes for identities. So because semantic shift usually happens continuously, there is often little recognition that it has occurred. This creates the illusion that the term has not changed meaning, and the differences between pre- and post-shift usage are then seen as embodying changes of a substantive, as opposed to purely verbal, nature. 
     Hempel’s argument overlooks the ambiguity of the word “ambiguity.” Scientific terms are in a state of flux, since they are re-defined in consequence of changes in scientific theory. This creates ambiguity. But because, for the reasons just described, the ambiguities in question are not comparable to those characteristic of paradigms like “bank” and “dumb”, we don’t recognize them as such. As a result, what is in fact an innocent fact (e.g. that, at a certain point in time, “temperature” was ambiguous between optical and tactile concepts) appears to have far-reaching ramifications for logic (“no sharp line between analytic and synthetic truth”). 
        We must also keep in mind that even if Hempel has shown that the analytic-synthetic distinction breaks down where some expressions are concerned, nothing he has said warrants the view that it breaks down universally or that it otherwise breaks down in a manner that would vitiate our use of that distinction.  
        
Chapter 17 Fodor’s second argument for conceptual atomism 


            Here is Fodor’s argument: 


         Suppose that the concepto knowledge were conceptuallyo complex, i.e. that it consisted of other conceptso. In that case, for obvious reasons, it would consist of the conceptso belief, true, justified, and perhaps also the conceptso non-accidental and reliable. Supposing that the concepto knowledge does consist of these other conceptso, it follows straightforwardly that cognitive operations with that the  concepto knowledge should demand more intelligence and more energy than cognitive operations with conceptso like justification, belief, and truth. After all, thinking knowledge would necessarily involve thinking justification, truth, and so on, but not vice versa. So thinking knowledge would necessarily be more demanding, in terms of intelligence and energy than thinking any of these constituent conceptso. 
            But the empirical data doesn’t bear this out. Experiments show that people process claims about knowledge more quickly and effectively than they do claims about justification, belief, and the like. The non-experimental empirical data is consistent with this. Most three year olds make true claims involving the concepto knowledge. (“I know that dogs bark.” “I know that I have to go school tomorrow.”) But, apart from the odd prodigy, no three year old ever talks about justification.  
     What we just said about the concepto of knowledge seems to be true of conceptso generally. Any four year old can grasp true propositions about money (“I have a dollar in my pocket”) and about linguistic communication (“Daddy just told me to leave his office”). But how many four year olds could grasp the conceptso of which, if our philosophical analyses are right, those conceptso decompose? How many four year olds could grasp the conceptso into which John Searle, for example,  analyses the concepts of money and linguistic communication? And supposing that they can grasp these constituent conceptso, will their cognitive operations with them be as expeditious or as accurate as their thoughts about the concepto of money?  Surely not.[184]
      


        I would now like to present two counter-arguments. These two arguments are similar  and also overlap in content. One is to the effect that Fodor’s argument involves a failure to distinguish between “conceptual” and “non-conceptual” cognition. The other is to the effect that Fodor’s argument involves a failure to distinguish between personal and sub-personal cognition. It may be that the second argument is just a re-articulation of the first. 


Our first counter-argument 


        You obviously grasp conceptso. You grasp the conceptso knowledge, justification, truth,  causation, and various others. But does all cognitive activity consist in the manipulation of conceptso? Is all mental activity conceptual? Dogs and cats have minds, and those minds process information. But do dogs and cats grasp conceptso? A dog can be aware of an individual stick, an individual bone, and individual person. But does a dog grasp the conceptso stick, bone, and person? Many would answer by saying “no.” If that is right, then not all cognitive activity involves concepto manipulation and, in fact, conceptual activity would be a very evolved and derivative form of cognitive activity.  
          Of course, what we’ve said so far hardly constitutes an irrefutable proof that there is non-conceptual cognitive activity. But right now I would like to operate on the plausible assumption that there is such activity. That said, we will momentarily encounter some good reasons to accept that assumption; and in chapters 22-23, we will encounter what I regard as conclusive evidence of its correctness. 
          What is the difference between  grasping instances of a concepto and grasping the concepto itself? What is the difference between grasping individual instances of (say) redness and grasping the very concepto of redness?
         Here is the answer that I would propose. To grasp a concepto is to grasp what different concrete situations have in common. To grasp the concepto redness (or squirrel or rock…) is to have some understanding of how red (or squirrelly or rocky…) situations resemble each other. If this is right, then grasping conceptso is not a pre-requisite to grasping instances of conceptso. The opposite is the case: grasping situations is a pre-requisite to grasping conceptso. 
       Suppose that you see what is in fact an instance of redness. Even if you have a concept of (say) redness, it isn’t as though your perception is the result of your exercising this concept. Innumerably many chromatically different possible situations correspond to your concept of redness. Given only that you are thinking of some object as being red, your mental activity leaves it quite indeterminate what the actual color of that object is. This suggests that your sense-perceiving a situation cannot possibly consist in your exercising the concepts that you have.[185]
      What we just said about your concept of redness is true of practically any other concept. (I say “practically” in acknowledgement of a class of exceptions that we will deal with in a moment.) It seems to be of the essence of concepts that they apply to many qualitatively different situations. This must be understood aright. Your concept of redness doesn’t just apply to objects of different shapes and sizes and temperatures: it also applies to objects that have different colors. Similarly, your concept of triangularity doesn’t just apply to objects of different colors and sizes; it also applies to objects that have different shapes. (It is obvious how these points are to be generalized.) By contrast, a sense-perception is not color- or shape-indeterminate.[186] This suggests that one’s having a sense-perception is not the same thing as one’s exercising various concepts. Given that sense-perceptions obviously have content, it seems to follow that some content-bearing mental activity is non-conceptual. 
        There is a point that we must consider before we take the next step in our argument. As McDowell (1994) points out, you do have concepts that, if exercised, would completely determine the color of the situation that you are considering. Suppose that you are looking at some red object, and you think to yourself:  I want a car whose color is that exact shade of red. Let C be the concept corresponding to the italicized expression. C completely determines the color that you have in mind. And, of course, we could imagine similar concepts that completely determine a certain size or shape or temperature or degree of conductivity…Given this, it might seem sense-perception does consist entirely in an exercise of concepts. 
      But this is not the case. Concepts like C presuppose the having of sense-perceptions (or, in any case, the having of mental imagery). Unless the occurrence of “that” in that exact shade of red is associated with a sense-perception (or, at least, a mental image) of a specific red situation, C won’t pick out any shade of red. One might counter-respond by saying that the just mentioned perception is itself constructed out of concepts of the kind that McDowell describes. But this would be both implausible and viciously regressive. So while McDowell may be right to say that we can construct a concept that completely determines a certain color (or size or temperature…), any such concept is parasitic on the existence of non-conceptual, but nonetheless content-bearing, mentation. 
         This line of thought suggests that concepts are conceptualizations of non-conceptualo content. A hamster can see any instance of redness as well as any person. But people do, whereas hamsters do no, grasp the concepto of redness. This is because people do, whereas hamsters do not, have an understanding of what it is that various different situations have in common.[187] 
      Given a set of concepts C1…Cn, there are  many different conceptso C* such that C* is constructed of C1…Cn. For example, the concept smart, brown, politically liberal cow is constructed out of the conceptso smart, brown, cow, and so on. So at least some conceptso are constructed out of other conceptso. But if the line of thought just put forth is correct, all conceptso are ultimately constructed out of non-conceptualo contents, and one’s grasp of a concepto is a conceptualization of one’s grasp of non-conceptualo content. The immediate analytic structures of some conceptso (e.g. smart, brown, politically liberal cow) are to be understood in terms of  other conceptso. But, in the final analysis, the analytic structure of a concepto is to be understood in terms of non-conceptualo contents. 
        Given this, it is easy to reconcile the presumption that the concepto knowledge has analytic structure with the fact that the conceptso into which it supposedly decomposes (e.g. justification, truth, reliable mechanism, belief) are much harder to manipulate. First of all, the analytic structure of the concepto knowledge is found not in other conceptso, but in the non-conceptual contents out of which that concepto is constructed. So Fodor is wrong to assume that, if the concepto of knowledge has analytic structure, it is given by a bi-conditional that has conceptso on both sides of the main-connective. Fodor’s argument thus implodes, given that it depends on that assumption. 
      Fodor is probably right to say that the concepto of knowledge is easier to manipulate than the conceptso belief, justification, non-deviant causal mechanism, and so on. But that is easily explained in terms of the fact that those conceptso are of a higher-order than the concepto of knowledge. The more general a concepto is, the more intellectual wherewithal is needed to grasp it.  Practically any three year old grasps the concepto of a whole number. Practically any twelve year old grasps the concepto of a fraction. But only a few sophisticates understand what it is that all and only whole numbers, fractions, real numbers, imaginary numbers, quaternions, relation numbers… have in common. The concepto number is thus of a higher order of generality than the concepto whole number.
         What exactly is it for one concepto to be of a higher order of generality than another? As we’ve seen, any concepto ultimately decomposes into non-conceptual contents. But, as we’ve also seen, some conceptso immediately decompose into others. Of course,  a concepto may decompose into conceptso that in their turn decompose into other conceptso that, in their turn, decompose into non-conceptual contents. There is clearly no limit to how many levels of conceptualo decomposition may mediate between a concepto and the non-conceptualo contents into which it decomposes. C is a of a higher order than C* iff more levels of conceptualo decomposition mediate between C and its non-conceptualo decomposition than mediate between C* and its non-conceptualo decomposition. For one concepto to be more “abstract” than another is for it to be of a higher-order than the other. The concepto of knowledge seems to be less abstract than the concepto of justification. If this is right, it is no wonder that the former is easier to grasp and to manipulate than the latter. The concepto of money seems to be less abstract than the concepto of a stable political order. If this is right, then it is no wonder that three year olds grasp the first concepto but not the second. 
       The evidence that Fodor cites may show that one’s knowledge-concept doesn’t decompose into a justification-concept. But this doesn’t show that the concepto of knowledge has no analytic structure; and it doesn’t show that one’s concept of that concept doesn’t involve a grasp of that concepto’s analytic structure. This is because it is a distinct possibility that a concepto’s analytic structure is to be found in its non-conceptualo, as opposed to its conceptualo, decomposition. In Chapters 22-23, we will see that this possibility is an actuality. 
         Also, leaving this last point aside, if our second criticism of Fodor’s argument is cogent, the experimental data cited by Fodor is perfectly compatible with the supposition that one’s knowledge-concept decomposes into one’s justification-concept.  
          Let us end this section by drawing some consequences of the position just defended. It has generally been thought that so-called “conceptual analyses” give the decompositions of conceptso: to analyze a concepto is to say of what other conceptso it consists. [188] We will see in Chapter 24, when we are discussing Peacocke’s analysis of conception, that this is definitely not the case, and we’ve already seen some reason to believe this. If what we’ve said so far is correct, an instance of what we typically refer to as a “conceptual analyses” (e.g. a circle is a closed planar figure of uniform curvature) shows that each of two different conceptso is a correct conceptualization of a given bundle of non-conceptualo content. The concepto circle is a conceptualization of non-content. So is the concepto closed planar figure of uniform curvature.  And both are conceptualizations of the same non-conceptualo content. 
          We must remember that there are often different, equally correct, analyses of a given concepto. The statement: 


(a) x is a triangle iff x is the area bounded by three lines such that any two of them intersect, but such that not all three of them intersect 


provides an adequate analysis of the concepto triangle; and so does the statement: 


(b) a triangle is a three-sided, straight-edged, closed figure.


 It is demonstrable that the concepto triangle is capable of infinitely many, non-trivially different analyses. This fact is inexplicable if we say that conceptualo analyses showed how conceptso decomposed into other conceptso. It is not possible for the concepto xxx triangle to decompose into the concepto side, and also to fail to thus decompose. But given that both (a) and (b) are adequate analyses of the concepto triangle, this is what we must say if we take the view that an analysis of a concepto shows how it decomposes into other conceptso. One could resist this by denying that both (a) and (b) are genuine analyses of the concepto triangle – by insisting that, for example, (a) constituted an analysis whereas (b) did not. But such a position would be completely arbitrary; and it would be inconsistent with the fact that what counts as an illuminating an analysis is a function in large part of the context – of what xxx our starting assumptions and dialectical objectives are.
       We can avoid both self-contradiction and arbitrariness by saying that conceptualo analyses show that there are two different, but equally adequate, ways of  conceptualizing a given bundle of non-conceptualo information. In that way, we don’t have to take the arbitrary view that either (a) or (b) xxx is not an adequate analysis; and we don’t have to take the self-contradictory view that the concepto triangle both does, and does not, decompose into the concepto side. As we will see in Chapter 24, this approach also enables us to explain how conceptualo analyses can be informative; and we will also see how the same is not true of the view that an analysis of a concepto shows how it decomposes into other conceptso. 
          If these remarks are correct, it is clear what we must say about analytic conditionals, for example: 


(c) any instance of knowledge is an instance of true justified belief. 


      Given that (c) is correct, it does not follow, pace Fodor (1998), that the concepto knowledge decomposes into the conceptso belief, justified, and true. The concepto knowledge is a conceptualization of a certain bundle of non-conceptualo content. The concepto justified true belief is a conceptualization of that same data. But the concepto justified true belief is not a conceptualization only of that data: it also conceptualizes data not conceptualized by the concepto knowledge. That is why, even though (c) is true, the corresponding biconditional (x is knowledge iff x is an instance of true justified belief) is false. Much of Chapter 24 will be spent substantiating the analysis just put forth. 
       Fodor assumes that there is no conceptualo structure at all where it isn’t possible to give correct, analytic biconditionals. Supposing that there is no analytically correct, non-trivial biconditional of the form x is knowledge iff x falls under C, it follows, according to Fodor, that the concepto knowledge has no analytic structure at all. In the previous chapter we encountered one reason to hold that this position is mistaken; and if the view that we have been urging is correct, we have just encountered another. The concepto knowledge surely does have analytic structure. When a Gettierologist judges that a certain situation constitutes a counterexample to a proposed analysis of that concepto, it is on the basis of what an intuition tells him about the structure of that concepto. Suppose, for example, that I propose the following analysis of that concepto: 


(d) x is knowledge iff x is a true, justified belief that is made by somebody who is wearing a blue shirt. 




      It is easy to think of situations where somebody wearing a blue shirt generates a justified true belief that is not knowledge. (xxx The situations described by Gettier are easily adapted to shows this.) But how do you know that a given situation constitutes such a counterexample? Because your intuition tells you so; and your intuition obviously constitutes some kind of insight into the structure of that concepto. (Such xxx an intuition doesn’t embody the outcome of empirical research: xxx you don’t have to do empirical work to know that a given situation is a counterexample to (d). So we are obviously dealing with an insight into the structure of the concepto in question.) Thus, Fodor’s position that the concepto of knowledge has no structure is implausible in the extreme. 
        At the same time, Fodor may be right to say that it is not possible to give an adequate analysis of that concepto. But this is easily explained, given the position we are advocating. By a “conceptual analysis”, Fodor means a statement of the form x is knowledge iff x falls under concepto C. We’ve seen some reason to hold that the analytic structure of a concepto is not to be found in its liaisons with other concepts, and is rather to be found in its relations to non-conceptualo content. If this is right, there is obviously no reason a priori to expect that there holds some biconditional of the kind just described.[189] 
         


Our second counterargument 


         Every cognitively normal person is able to make extraordinarily delicate judgments about other people’s emotions, about art and music, and about the behavior of physical bodies. But only the most erudite people can even begin to articulate the grounds for these judgments. One could conceivably take the view that it is only when one can articulate the grounds for one’s beliefs that those beliefs are principled. But such a view would be radically implausible.[190] It is more reasonable to say what we are naturally inclined to say, namely: such judgments are at least sometimes principled, but the principles in question are not always easily articulated and they often fall outside the scope of introspective awareness. 
         Consider the following scenario. Jones listens to performances of thousands of different pieces, one third of which are unmistakably instances of rock ‘n’ roll, the other two thirds of which are unmistakably not xxx instances of that genre. Jones has no difficulty distinguishing the pieces that are instances of rock ‘n’ roll from those that are not. 
       When Jones classifies a piece as being rock ‘n’ roll, he does so on the basis of its melodic, rhythmic, and contrapuntal properties. (We are setting aside the skeptical possibility that Jones is simply making lucky guesses over and over again.) In classifying a given piece as rock ‘n’ roll, Jones is not making a conjecture; he is not making an inductive leap into the future. Rather, he is conceptualizing the data that is already at his disposal. Given that piece X has such and such musical properties, it thus follows conceptuallyo or analytically that it is an instance of rock ‘n’ roll. Of course, it is not analytic that X has such and such properties, and it is not analytic that X is an instance of rock ‘n’ roll. But given that X has such and such properties, it follows conceptuallyo, and not inductively or probabilistically, that it is rock ‘n’ roll. This shows that the concepto of rock ‘n’ roll has analytic structure, and also that Jones’ classifications embody a knowledge of that structure.  
        Before we proceed, we should note that the points just made furnish a refutation of Fodor’s first argument for atomism. Would Jones be able to define the term “rock ‘n’ roll”? No. It is unlikely that anyone is able to give an unexceptionable definition of that term.[191] But it obviously doesn’t follow that the concepto of rock ‘n’ roll music lacks analytic structure or that Jones’ concept of that concepto doesn’t involve an acute understanding of what that structure is. It is interesting and significant that the term “rock ‘n’ roll” is hard to define. But what we are to conclude from that fact is not that the concepto of rock ‘n’ roll xxx lacks analytic structure. Exactly similar points hold in connection with the concepto of knowledge. This shows that Fodor’s first argument involves a non-sequitur. Xxx In a moment, we will consider two hypotheses as to what that non-sequitur might be. xxx 
         Let us return to our evaluation of Fodor’s second argument by developing the scenario described a moment ago. Jones studies musicology, and comes to be able to give a partial definition of the term “rock ‘n’ roll.” He learns that a rock ‘n’ roll song has such and such rhythmic properties, xxx and that it tends to comprise certain chord progressions and xxx modulations (e.g. if it starts out in a given key, it will probably modulate to the sub-dominant, and then to the dominant). 
         Jones may never be able to operate with the terms “dominant” or “12:3 rhythm” as efficiently or skillfully as he is able to operate with the term “rock ‘n’ roll.” But, as we’ve seen, it doesn’t follow that the concepto of rock ‘n’ roll music lacks analytic structure; and it doesn’t follow that Jones’ grasp of that concepto consists in anything other than a knowledge of that structure. Fodor’s argument clearly involves a non-sequitur. 
      In the previous section, we discussed one possibility as to what this non-sequitur might be.[192] But there is another possibility. In light of the researches of Chomsky, Marr, and many other cognitive scientists, it is overwhelmingly likely that along certain dimensions what is sub-personally known vastly exceeds what is personally known. It is also likely that, in the sub-personal realm, information is transmitted and processed exponentially faster and more adroitly than it is at the personal level. There is also reason to believe that the information involved in sub-personal cognition is of a higher grade than the information involved in cognitive processes occurring at the personal level.[193] xxx
       Given that at the personal level one can grasp the concept of knowledge without grasping the concept of justification, it doesn’t follow that one can grasp the first tout court without grasping the second. So given only that, at the personal level, Smith grasps the concepto of knowledge but not that of justification, it doesn’t follow that he doesn’t grasp the latter at the sub-personal level. If we said that everything that wasn’t grasped at the person level wasn’t grasped at all, xxx we’d have to throw out cognitive science in its entirety. 
        Further, given only that, at the personal level, Smith’s knowledge-thoughts are more dexterous or energy efficient than his justification-thoughts, it doesn’t follow that the concepto of knowledge isn’t to be understood in terms of that of justification. Since any case of understanding has deep sub-personal roots, it could be that Smith does understand the concepto of knowledge in terms of that of justification, but that this understanding is to be found at the sub-personal realm of cognitive activity. 
      Also, the fact that justification-thoughts presuppose more cognitive wherewithal than knowledge-thoughts could be a reflection of the structure of one’s sub-personal knowledge of these various conceptso. It could be that, given this structure, one’s sub-personal knowledge of the one concept is more easily accessed by the personal realm  than is one’s sub-personal knowledge of the other. In general, once we concede that there is sub-personal cognitive activity, the empirical data that Fodor cites doesn’t force us to part with the idea that one grasps the concepto knowledge in terms of the concepto justification. (Ironically, Fodor himself is one of the most passionate and effective advocates of the view that there is sub-personal cognition.)
        People who cannot discourse about a concepto are not necessarily completely oblivious to it. People who couldn’t even begin to discourse about the concepto of justification show astonishing subtlety in distinguishing cases of justified belief from cases of unjustified belief, and thus clearly have a rich, intuitive understanding of that concepto. The evidence that Fodor cites shows that people may be much more skillful in using words like “knowledge” and “sentence” than in using words like “justification” and “assertion.” This evidence thus suggests that a discursive, verbally represented understanding of the one concepto may be easier to achieve than a comparable understanding of the other. But it is a commonplace of psychology that what is cognitively most pervasive is often what is last to be given discursive representation. It takes a highly trained and extraordinarily gifted person to paint what everybody sees or to put into words what everybody knows. 
          Fodor may be right to say that, from the viewpoint of the personal level of cognition, the concepto of justification is quite recherché, while the concepto of knowledge is quotidian. But that tells us very little as to how those conceptso are generally cognitively represented. From the viewpoint of the personal realm of activity, the concepts that are cognitively most fundamental are the hardest to master and to articulate. If we focus on what people say about those conceptso, it is easy to believe that they are completely oblivious to them. But an acute awareness of those concepts is revealed in their judgments and general conduct.  
          Psychologists sometimes distinguish between “procedural” and “declarative” knowledge.[194] I know that Paris is the capital of France. This is “declarative” knowledge. I know how to tie my shoes. This is “procedural” knowledge. My ability to speak English is also procedural knowledge, and so is a composer’s ability to write music. It seems that the same is true of a person’s ability to determine whether a composition is a fugue and to read other people’s facial expressions. It is not out of the question to suppose that all of the knowledge that we describe as “instinctive” or “intuitive” is procedural knowledge.[195] 
           Sub-personal knowledge is often expressed in terms of procedural as opposed to declarative knowledge.[196] It is hard to articulate procedural knowledge. It is astonishingly hard to verbalize how to tie a double-knot. (It is easy to show somebody how to do so. But telling them is another matter altogether.) In fact, I would guess that one could easily produce xxx counterexamples to any attempt to articulate what it is that all and only instances of tying double-knots have in common. But it is obviously not an option to say that the concepto of tying a double-knot has no internal structure; and it is not an option to say that one’s grasp of that concepto doesn’t involve an understanding of what that structure is. 
          What we just said about one’s ability to tie a double-knot is true of one’s ability to use words. Few, if any, can say when exactly it is appropriate to use the words  “the” and “of” and “and.” Further, whereas any English-speaker can use these words faultlessly, most would have a devil of a time using the expressions in terms of which their appropriate use is explicated -- e.g. “c-command”, “NP-deletion”, “dominant node” – or even understanding those expressions to begin with. But unless Chomsky and other cognitive scientists are very wrong, it doesn’t follow that people are altogether ignorant of the structures of the conceptso corresponding to theoretical terms like “c-command.” What follows is that they have difficulty re-producing at the personal level the knowledge that they already have at the sub-personal level. 
           Fodor himself is acutely aware of the distinction between declarative and procedural knowledge, and also of the distinction between personal and sub-personal knowledge. But this particular of argument of Fodor’s fails to take these distinctions into account, and for that reason is far from probative. 
         In this chapter, we’ve distinguished between: 


(i) conceptual and non-conceptual knowledge, 
(ii) personal and sub-personal knowledge, and
(iii) procedural and declarative knowledge. 


        We’ve already seen some reason to hold that there is overlap between the extensions of the conceptso non-conceptual knowledge and sub-personal knowledge. But given only what we’ve seen, it would be premature to say that these two conceptso have identical extensions. It remains a possibility that at least some sub-personal knowledge is conceptual in nature. Indeed, if Chomsky’s views are at least approximately correct, the sub-personal realm is replete with manipulations of conceptso. 
        We’ve also seen that the concepto of procedural knowledge is closely related to the concepto of sub-personal knowledge. But that connection is probably not one of co-extensiveness. Much knowledge-how is personal knowledge. At the personal level, I know how to speak English, how to tie my shoes, and how to ride a bike. If cognitive scientists are right, this knowledge-how expresses sub-personal knowledge-that. For example, my ability to speak English derives from a sub-personal understanding of conceptso like NP-deletion and c-command.[197] But given that at least some knowledge-how is personal, it follows that the extensions of the conceptso sub-personal knowledge and procedural knowledge do not coincide. At the same time, it doesn’t follow that those extensions are completely disjoint; for it remains a possibility that some knowledge-how is sub-personal. 
       It is not clear exactly what the connections are between the conceptso sub-personal knowledge, non-conceptual knowledge, and procedural knowledge. But what is clear is that Fodor’s argument is vitiated by a failure to take these conceptso into account. This is ironic since few thinkers, if any, have done as good a job as Fodor in defending theories that posit sub-personal cognition.[198]


Chapter 18 Fodor’s third argument for conceptual atomism 


             
         Here is Fodor’s third argument:


        For the sake of argument, suppose that conceptual non-atomism is correct. In that case, for any concept C that you have, you have C in virtue of having various other concepts C1…Cn. So, for example, if you have a concept of triangularity, you have that concept in virtue of having concepts of straightness, flatness, number, and so on. If you have a concept of Socrates, you have that concept in virtue of having concepts of space, time, causality, hemlock, and so on. 
       But, supposing that non-atomism is correct, how exactly is your concept of triangularity constituted by your concepts of straightness, flatness, and number? How exactly is your concept of Socrates constituted by your concepts of hemlock, sarcasm, and personhood? 
        The answer is that, if non-atomism is right, your believing that x is a triangle consists in your believing that x is a closed, planar, three-sided, straight-edged figure (or, at any rate, in your having some other comparable belief, e.g. that x is the area bounded by three straight lines such that any two, but not all three, of them intersect). Your believing that x is Socrates consists in your believing that x is a unique dialectician to have died of hemlock poisoning (or in your having some other comparable belief). In general, if non-atomism is correct, whether you have a concept of a given entity is a function of what you believe.     
       This means that non-atomism has a number of obviously false consequences. Suppose that you believe of Socrates that he was a talented wrestler in his youth. In that case, if non-atomism is correct, your believing that x is Socrates consists in your believing (inter alia) that x was a talented wrestler at some point. In that case, anything that is not a talented wrestler ipso facto fails to satisfy the description encoded in your concept of Socrates. So anything that was not a talented wrestler fails to meet the preconditions that, given the structure of your concept, would have to be met for you to believe it to be Socrates. It follows that you couldn’t possibly learn, or even come to believe, that  Socrates was not a talented wrestler. 
       If non-atomism is right, what you believe about the things that your concepts are concepts of determines what your concepts are concepts of. A corollary is that your beliefs about a given thing are frozen. What you believe about a given object cannot change. A related corollary is that two people cannot have different beliefs about a given object. Yet another corollary is nobody can ever be wrong about anything: if an object doesn’t satisfy the description associated with some concept of yours, then that concept is not a concept of that object. So nobody can ever have a wrong belief about something of which they have a concept. Thus, nobody can ever have a wrong belief. 
        Of course, what a person believes about a given object can change. People can have different beliefs about a given object. And people can have erroneous beliefs about a given object. Non-atomism is false since it is inconsistent with these obvious truths.[199] 
    


       For the sake of argument, suppose that my having a concept of the number two consists in my knowing the truth of the existence-claim: 


(2) There is some x such that x is the unique successor of the number one. 


       Given that I have a concept of the number two, I can then go on to have all manner of beliefs, both true and false, about that number. I can believe falsely that Smith has two mansions (when he in fact has none); I can believe falsely that two is not a prime number; and so on. 
      A corollary is that, given that you and I both have concepts of that number – in other words, provided that each of us knows the truth of some proposition like (2) -- there is no limit to how much we may disagree about it. I may believe that Smith has two mansions, and you may disagree. I may believe that the number two is the class of all pairs of objects; you may disagree.
       To be sure, if non-atomism is right, then in order for both of us to have beliefs about the number two, we must share some beliefs. For us to agree or disagree about the number two, we must both accept (2) or, at any rate, some other comparable existence-claim. This puts limits on how much, from a non-atomist’s viewpoint, two people can disagree about the number two. We cannot disagree as to whether it is the successor of one; nor can we disagree as to whether it is a number.[200] 
      But it does not follow from the non-atomist’s position that you and I have to be complete lock-step as to what we think concerning that number. Nor does it follow that a person’s beliefs about that number cannot change. All that follows from the non-atomist’s position is that certain core beliefs cannot be given up. 
       But this is not an unreasonable requirement. Indeed, its negation seems  unreasonable. Could you really believe of the number two that it wasn’t a number, or that it was actually the successor of four (as opposed to one)? It seems that, if you believe of x that it is not a number, you ipso facto don’t believe that it is the number two, and that if you believe of x that it is greater than four, you ipso facto don’t believe it to be the immediate successor of one. 
        Fodor argues that, if one concedes even this much, one must also concede that everything a person believes about that number is constitutive of his concept of it, and that a person cannot change his beliefs about it – he cannot come to believe that Smith has two cars, and then later come to believe that Smith actually has only one car. But that argument doesn’t survive scrutiny.
 
Our response to Fodor (continued)


         In some cases, one’s concept of a thing has a linguistic (or, more precisely, a meta-linguistic) component. As we saw earlier, sometimes one’s concept of Socrates consists in one’s knowing the truth of some claim like: 


(3) There is some x such that x is uniquely somebody whom Smith and Jones are now avidly discussing, and “Socrates” refers to x. 


        Under these circumstances, two people’s core-beliefs about Socrates xxx may be very different. Xxx The content of Green’s concept of Socrates is given by (3). Xxx But, supposing that Aaronson is a speaker of Urdu, the content of his concept of Socrates is given by: 


(4) There is some x such that x is uniquely somebody whom Professor Charles was excoriating a moment ago, and “Sukrat” refers to x.


       So it seems that, contrary to what I argued a moment ago, what two people believe about a given thing can differ without limit – two people can both think about Socrates, even though they don’t even agree that “Socrates” refers to him. (At least one of those individuals may not know the English word for Socrates.) 
       The idea that this consideration warrants a rejection of any part of our analysis is yet another expression of the failure to distinguish literal from cognitive meaning, and of the pernicious effects of modeling the one on the other. Suppose that my concept of Socrates consists in my knowing (3). Under that circumstance, I cannot, indeed, come to believe that Smith and Brown were not talking about Socrates: as Fodor says, in so far as (3) is constitutive of my concept of Socrates, I cannot come to believe that Socrates doesn’t have the characteristics referred to in that proposition. For exactly similar reasons, supposing that your concept of Socrates consists in your knowing the proposition: 


(5) There is somebody x such that x is the main protagonist in a book I am now reading, called The Republic, and “Socrates” refers to x, 


you cannot come to believe that Socrates was not the main protagonist of the republic. (We have already seen why this claim is in no way discrepant with Kripke’s (1972) semantic insights.) As we’ve noted, supposing that non-atomism is correct, two people cannot agree or disagree about a given object unless there are at least certain existence-propositions as to whose truth they are in agreement. So how his is this to be reconciled with the points that we endorsed not two paragraphs ago? 
      This question is not hard to answer, given the points made earlier concerning conception and literal meaning. We’ve already seen how I have a concept of Socrates in virtue of knowing (3), and how you have a concept of Socrates in virtue of knowing (4). Further, we’ve already seen how, for some x, ┌Socrates has phi┐ literally means x has phi, notwithstanding that no one can grasp that bare proposition (except in so far as it is embedded in the riches of a descriptive-existential proposition). At this point,  we need to remember what we said about what it is for somebody to mean proposition P by sentence-token S. Suppose I sincerely and literally say “Socrates was wise.” In that case, what I mean by that sentence-token is what the sentence-token itself literally means (viz. the bare, singular proposition x was wise, where x is Socrates). To be sure, what “Socrates was wise” conveys to me is some existence-claim more or less like: 


(6) There is some x such that Smith and Jones are discussing x and “Socrates” refers to x, and “Socrates is wise” means: x is wise.[201] 


        But when I sincerely utter “Socrates was wise”, what I am affirming is confined to what is to the right of the semantic-operator. We’ve discussed at length how people instinctively keep non-linguistic (pre-semantic) information to the left of the relevant operators, keeping only the relevant linguistic (semantic) information to their right. Supposing that you are the person to whom I utter that sentence, you must find your way to its literal meaning by way of your concept of Socrates. (We are supposing that you speak English.) This concept, though different from mine, will lead you to the same literal meaning; and when you affirm or deny (or otherwise operate with) “Socrates is wise”, what you are affirming or denying is exactly what I affirmed. The miracle of language is precisely that it allows people who have different concepts of a given thing to communicate about that thing. The peculiarities of the individual’s concept of that thing become irrelevant. 
         Let us bring these points to bear on Fodor’s view. First, Fodor is right to say so far as (3) constitutes my concept of Socrates, I cannot cease to believe that Socrates is not an object x such that, on the occasion in question, Smith and Brown were not talking about x. But, given that fact, there is no limit to what I may come to believe or disbelieve about Socrates. I can come to believe that he studied in Egypt, and I can later come to retract that belief. Further, what we just said about me is true (mutatis mutandis) of you. Given that (5) constitutes your concept of Socrates, you cannot come to believe that Socrates was not the protagonist of The Republic; but given this fact, there is no limit to what you can subsequently come to believe, or cease to believe, about Socrates. Finally, because each of us knows what is meant by tokens of “Socrates was wise”, even though we grasp that literal meaning in different ways (corresponding to the differences in our respective concepts of Socrates), that does not affect our ability to mean the same thing by utterances of that proposition. For some x, the proposition x was wise is what both you and I affirm through sincere utterances of “Socrates was wise.” And so long as I know some proposition like (3) and you know some proposition like (5) – in other words, so long as both of us know some proposition (not necessarily, or even probably, the same one) that enables me to compute the literal meaning of tokens of “Socrates was wise” – there is no limit to how much you and I may disagree about Socrates. So even though both of our respective concepts of Socrates are given by descriptively rich existence-claims, and are therefore to be understood in strictly non-atomist terms; and even though those existence-claims are very different; and, finally, even though you and I may therefore have little or no agreement as to what properties Socrates had; our ability to communicate with each other about Socrates is in no way threatened. So contrary to what Fodor argues, non-atomism is in no way compatible with either (i) the fact that one can alter one’s beliefs about a given thing, (ii) the fact that one can  have any number or erroneous beliefs about a given thing, (iii) the fact that two people to have very different beliefs about a given thing. 
 
Is non-atomism committed to inferential role semantics?


       Fodor argues that conceptual non-atomism is identical, or equivalent, with a doctrine to the effect that, if x has content C, x’s having that content supervenes on, or is identical with, x’s having a certain inferential role. So x is Smith’s belief that O is a triangle exactly if, in virtue of having x, Smith is disposed to make certain inferences, e.g. he is disposed to infer O has three sides and O is flat and so on. Let (IRA) be our term for the doctrine just described, since that doctrine gives an inferential-role account of mental content.[202] 
       According to Fodor, conceptual non-atomism is either identical with (IRA) or at least presupposes the truth of that doctrine. Supposing that a concept of flatness, of straightness, of the number three, and so on, are constitutive of one’s concept of triangularity, that is because for one to believe that x is a triangle  just is to believe that O is flat, three-sided, and so on. So given non-atomism, it seems reasonable to say that x (some brain-state) is one’s belief that O is a triangle exactly if, in virtue of having x, one beliefs, or is disposed to infer, that x is flat, three-sided, straight-edged, and so on. It thus seems that non-atomism and IRA are identical or at least equivalent. 
       Supposing that this is correct, and also that Fodor’s argument against non-atomism is cogent, it follows that IRA has the same problems as non-atomism, and must therefore be rejected. We have already seen that the second of these suppositions is false. But let us set that aside for now, and let us focus on the question: is non-atomism identical with IRA? It is worth knowing the answer to this question even if, as we have argued, Fodor’s arguments against non-atomism are misguided; for it might turn out (and, in fact, it will turn out) that IRA has problems that warrant its rejection and that warrant the rejection of non-atomism, if non-atomism presupposes IRA.  
        First of all, Fodor is entirely right to reject IRA. It is obviously false to say that a brain-state (or anything else) has a given content in virtue of its inferential role. Since there are inferences only where there is already content, nothing can have content in virtue of its inferential role. So far as, in virtue of having x, I have a tendency to infer that O is flat or three-sided, that is because x is already a belief that O is a triangle (or, in any case, that it is some belief that warrants, or that I at least believe to warrant, the belief that O is flat and three-sided). If x has no content, then nothing can be inferred from it. It is therefore absurd to suppose that anything content in virtue of its inferential role. 
        In any case, the version of non-atomism that is being advocated in this work  is not equivalent with IRA, and doesn’t presuppose the truth of IRA. (Henceforth, we will use the term “non-atomism” to refer only to that specific kind of non-atomism.) According to non-atomism, my concept of the number two coincides with a belief in some existence-claim – some claim like (2). And supposing that B is the brain-state realizing that belief, my believing that n=2 doesn’t consist in its being the case that, in virtue of having B, I am disposed to infer that n is greater than one. My believing that n=2 is identical with my believing that n is the successor of one: the latter is not inferred from the former, and B’s being a belief that n=2 does not consist in its having any inferential role. 
       Of course, given that B is a belief that n=2 (i.e. that n=the successor of one), I am disposed to make certain inferences: I am disposed to infer that n is even, that n is less than three, and so on. But, for the reasons given a moment ago, it would be absurd to say B’s being such a belief consisted in its having a certain inferential role, and it would be false to equate non-atomism with such a view. 
 
Transitional role semantics


        Nonetheless, there is a doctrine that is similar to IRA that is not absurd (but that we argue to be false, on the grounds that it is a version of functionalism). Suppose that, in virtue of having x, I have a disposition not to infer, but only to form the belief, that O is flat, closed, three-sided, and so on. In that case, it might plausibly be said that x is, or realizes, a belief that O is a triangle. The idea, appropriately generalized, would be this. Let  x be some brain-state (or other characteristic) of person P. There are certain beliefs B1…Bn such that x has content C exactly if, in virtue of having x, P is disposed to form all, or at least some chosen subset of, B1…Bn. The content of a brain-state (or anything else) supervenes not on its inferential, but on its transitional, role. This doctrine provides a transitional-role analysis of mental content. Let us therefore refer to it as TRA. 
          Christopher Peacocke advocates a version of TRA. In due course, we will discuss the viability of his analysis and of TRA-analyses generally. But right now I would like to address a narrower question. Supposing, if only for the sake of argument, that TRA is correct, does that doctrine have the defects that Fodor ascribes to non-atomism? Supposing that TRA is correct, does it follow that I cannot change my beliefs about Socrates, or that two people cannot have disagreements as to whether Socrates was a good orator or not? 
         No. What we said about non-atomism (in the context of defending it against Fodor’s third argument) is true mutatis mutandis of TRA. Let B be some brain-state of mine; and suppose that, in virtue of having B, I am disposed to accept O is flat and O is three-sided, and other such propositions. In that case, according to TRA, B is (or realizes) a belief that O is a triangle.  Now suppose now that I come to believe (falsely) O is green. In that case, given a belief that x=O, I do indeed have a disposition to believe that x is green. But does it follow that I am incapable of grasping the very idea of O’s not being green? Does it follow that I mistakenly believe greenness to be definitive of O? No. Once again, we must distinguish between, on the one hand, the information needed to lock onto a concept (or individual) and, on the other hand, the information that one ascribes to that concept in the aftermath of that lock-on. Supposing that TRA is right, given only that, in virtue of having B, I have a disposition to believe O is flat, O is three-sided, and so on, it follows that I grasp the proposition O is a triangle. Those initial dispositions fix what B’s content is; they guarantee that B realizes a belief in the proposition O is a triangle. Given that I have that belief, I am at liberty to form new beliefs, both true and false, as to what kind of a triangle O is and as to what bearing O’s being a triangle has on other (alleged) facts. I can form the belief that O is a green triangle, and then later retract that belief (when I find out that I was wearing green spectacle when I was looking at O). I can form the belief that O’s being a triangle necessarily involves at least one of its angles having a measure of 90°, and I can later retract that belief. I cannot, it is true, reject the idea that O’s being a triangle involves its being three-sided or flat. But with those qualifications, and others of a similar nature, I can form any belief at all about O’s triangularity. So by itself, TRA does not have any of the unwelcome properties ascribed by Fodor to non-atomism (or to IRA). 
      What we just said, in connection with TRA, about the proposition O is a triangle is true of the concepto of triangularity. First of all, that concepto is (or can be seen as) an open proposition, namely x is a triangle. (In this context, unlike previous ones, “x” is being used as a variable, as opposed to an arbitrary constant.) Suppose that, in virtue of having brain-state B*, along with the belief that O* is four-sided, I am disposed to form the belief O* is either not three-sided or not straight-edged or not planar…Or suppose that, in virtue of having B*, along with the belief that O* is three-sided and planar, I am disposed to form the belief: it is possible, but not certain, that O*  is a closed figure whose interior angles add up to 180°. Notice that each of these dispositions is conditional. If, in virtue of having B*, I have enough of these conditional dispositions, then according to TRA (or at least one version thereof) B* realizes a concept of triangularity.  
          B*’s being associated with the dispositions like the one just described fix B*’s content. Once that content is fixed, I am at liberty to form all manner of true and false beliefs about triangularity: I can accept,  and later reject, the idea that all triangles are green or that some (Euclidean) triangles have interior angles adding up to more than 180°. It is true that I am not at liberty to believe that there are four-sided or non-planar triangles. But within those limits, I am can believe practically anything about triangles. So TRA does not appear to be vulnerable to analogues of the criticisms that Fodor directs towards non-atomism and IRA. 
        This is not to say that TRA is correct. (We will argue against TRA in Chapter 23.) But given only what Fodor says, there is no reason to reject TRA. In general, all forms of non-atomism – whether or not they involve either inferential- or transitional-role accounts of mental content -  presuppose that there are some limits as to what one believe or  fail to believe so far as the objects of one’s concepts are concerned. But, contrary to what Fodor holds, it doesn’t follow that, according to non-atomism, every belief that one has about a given object becomes constitutive of one’s concept of it. 


Why non-atomism is prima facie guilty of vicious regressiveness 


        There is a significant problem with non-atomism, but it isn’t one of the problems attributed to it by Fodor. Let us start by considering our specific version of non-atomism; we will subsequently show that what we say in connection with our analysis is true of non-atomism generally.
       According to our analysis, my concept of Socrates consists in my knowledge of some existence-claim. But in order to grasp an existence-claim, one must already grasp various conceptso. To grasp the proposition somebody x was uniquely a great dialectician to die of hemlock-poisoning, I must grasp the concepts hemlock dialectician, and so on. We seem to be launched on an infinite and vicious regress if we say of our grasp of those conceptso what we said of our grasp of Socrates. To avoid that regress, we must say that, ultimately, conception does not consist in knowledge of existence-claims. But in that case, our analysis is erroneous.  
       All versions of non-atomism analyze the having of a given concept in terms of the having other concepts. For example, Peacocke (1992, 1996) says that brain-state B is one’s concept of addition exactly if, in virtue of having B, one is disposed to make certain judgments. Each of those judgments involves grasping some proposition, and thus involves grasping the various concepts of which that proposition is composed. So conception is analyzed in terms of conception, and we thus appear to be stuck with a vicious regress (or circle). 
       This point is an extremely important one, and we will deal with it at length. Further, we will find that it does invalidate certain kinds of non-atomism. We will also see that, even though it does not invalidate our version of non-atomism, it does force us to make substantive additions to that analysis. Drawing heavily on Evans’ (1982) distinction between “conceptual” and “non-conceptual” content, we will make those additions in Chapters 22 and 23. There are different kinds of concepts. There are concepts of properties; there are concepts of hyper-properties (properties of properties); and there are concepts of individuals. As we will see, what we refer to as “properties” are really hyper-properties. There are important differences between our concepts of individuals, on the one hand, and our concepts of properties, on the other; and when we take these into account, the regress described a moment ago vanishes. But it is crucial that we address the objection to our analysis just considered since we will otherwise remain oblivious to these important (and, we will see, independently verified) stratifications in the concepto of a concept. 
 
Terminological point 


       From now on, the word “concepto” (and its derivatives: “conceptso”, “conceptualo”, and so on) will vanish from our lexicon. This is because will be discussing concepts in the psychological sense only, and not, except occasionally, concepts in the platonic sense. In the rare instances when we do discuss the latter, we will use the word “concept” (no sub-script), since the context will make it clear what is meant. 


Appendix to Chapter 18 The sub-personal and the sub-conscious 


        As previously noted, a number of philosophers reject the very concept of sub-personal mentation, believing it to be incoherent and not merely uninstantiated. The best and most influential arguments for this view are to due to Evans (1985: 322-344), Searle (1984, 1992), and Wittgenstein (1958). Let us consider these arguments, starting with Evans’. 


(EA)       As we’ve discussed, thought it systematic. If you can think Bob is ambivalent towards Mary and Seymour hates Ted, then you can think Mary hates Seymour and Bob is ambivalent towards Ted. Put another way: if one grasps the concepts loves, ambivalence, Ted, and so on, then one can grasp any permutation of those concepts. A person can think any (viable) permutation of the concepts that he grasps.[203] There is an important corollary. Suppose that, after issues relating to the performance-competence distinction have been taken into account,  a person cannot think some proposition consisting of concepts C1…Cn. In that case, given that thought is systematic, it follows that one doesn’t grasp at least one of those concepts. 
       We must make one last preliminary distinction. For obvious reasons, of both a psychological and a logical nature, one doesn’t think every permutation of every subset of the set of concepts that one grasps. But given any particular permutation of any particular such subset, one doesn’t have any special barriers to thinking it. In some cases, it may be difficult to do so. Maybe Smith grasps each of the relevant concepts, but he lacks the intelligence to think some particular arrangement of them; maybe Smith has the requisite degree of intelligence but has a psychological resistance to thinking that particular permutation. But these are obviously performance-related issues, and one can coherently consider what Smith’s mind would be like if it weren’t subject to these performative problems idealize, but were structurally the same as it is now. Here is an illustration. Suppose that Smith grasps Emily hates Frank and also Mom loves Dad. But, because of his psychological defenses, Smith is incapable of grasping Mom hates Dad. We can coherently imagine a mind structurally more or less identical with Smith’s that could think Mom hates Dad. Smith’s inability to think this thought doesn’t correspond to some systemic fact about his cognitive architecture, but only to his inability to exploit resources of that architecture.  
        If indeed there is sub-personal mentation, the concepts involved are categorically sealed off from the concepts available to consciousness and, more generally, to the personal level of mentation. If cognitive scientists are right, then our sub-personal minds are continually solving simultaneous equations that would be unsolvable at the level of personal ideation for anyone other than, and possibly including, the world’s best mathematician. If cognitive scientists are right, there is a whole realm of concepts belonging to the sub-personal stratum that are incapable of being deployed at the personal level. Of course, cognitive scientists grant – nay, they insist – that one’s sub-personal possession of these concepts has effects on consciousness. It is because one can solve prohibitively difficult differential equations that one has visual perceptions; it is because one can apply the most intricate sets of rules that one can learn, and then use, language. But even though every moment of conscious life embodies the effects of sub-personal mentation, of thus of one’s sub-personally grasping various (to the personal mind) abstruse and exotic concepts, one’s sub-personal concepts are sealed off from one’s personal concepts. So suppose that Smith can sub-personally, but not personally, grasp the concept continuous function that cannot be differentiated at any point, and that he can personally, but not sub-personally, grasp the concepts Fred and completely baffling concept. In that case, Smith will not be able to grasp the proposition: the concept of a continuous function that cannot be differentiated at any point is completely baffling to Fred. Smith’s inability to grasp this proposition has nothing to do with purely performance related issues. We are obviously dealing with some kind of systemic block. But systematicity demands that Smith be able to grasp just this proposition. Since the supposition that there is sub-personal mentation demands that systematicity be violated – indeed, that it be violated routinely – the very concept of such mentation is incoherent. 


       
         xxx I believe that Evans is entirely to hold that thought is systematic and that, leaving aside performance-based problems, any person is able to grasp any permutation of the concepts that he or she grasps. But given only that thought is systematic, it doesn’t follow that each of two separate cognitive units must be able to grasp any concatenation of concepts that belong either to the one unit or the other. So it doesn’t follow that one xxx must be able to combine a concept that one grasps at the personal level with one that grasps at the sub-personal level. 
         Suppose that Smith grasps the concepts Bob, Jane, and loves and that Jones grasps the concepts Howard, Mary, and hates. Given only this information, the fact that thought is systematic doesn’t demand that anyone or anything be able to grasp the proposition Jane hates Howard or Mary loves Jane. What systematicity does demand is that Smith be able to think Jane loves Bob and Bob loves Jane, and that Jones be able to think Howard hates Mary and Mary hates Howard. 
     In the argument just presented, replace each occurrence of  “Smith” with an occurrence of “Smith’s xxx personal level of mentation” and replace each occurrence of “Jones” with an occurrence of “Smith’s sub-personal level of mentation.” (If you wish, you may also replace the expressions “Howard”, “Mary”, and “hates” with occurrences of expressions denoting concepts that, one might feel, are more appropriately associated with sub-personal thought: e.g. heavy NP-shift, c-command, differential equation.)  The resulting argument shows that systematicity does not demand that concepts grasped by a given person at the sub-personal level necessarily be capable of being combined into units that can be grasped by that same person at the personal level. Systematicity demands that concepts within a given cognitive sphere or module be permutable. It doesn’t demand complete interpenetrability of every cognitive module.[204] 
     We should also point out that, if cognitive scientists are right, sub-personal concepts combine and recombine with one another at least as freely as their personal counterparts. In fact, given how much information-processing is sub-personal, it seems xxx clear that sub-personal concepts are much more promiscuous than their personal counterparts[205], and that the former are therefore less counterexamples to systematicity than the latter. 
      Evans takes it for granted that, were they to exist, sub-personal concepts would be frozen – incapable of being used except in certain stereotyped ways. Given his (probably correct) view that anything that was thus frozen would lack one of the essential properties of a concept, he infers that there can be no sub-personal mentation. But Evans’ initial assumption is wrong, given that sub-personal concepts, supposing that they exist, are very much not frozen. Evans’ argument involves a failure to distinguish a concept’s frozen from its being encapsulated, xxx i.e. confined to a certain cognitive module or sphere, xxx and Evans’ argument implodes when this distinction is made. 
       We have seen that there is reason to doubt the cogency of Evans’ argument against the view that there is sub-personal cognitive activity. But the thesis that forms Evans’ point of departure is a correct and deep one. In the section following the next one, we will see that Evans’ point gives us another reason to reject CTM. We will also find that (ironically) it helps us combat one of Searle’s attacks on the idea that the there is sub-personal cognition. 


Searle on the sub-personal: the homunculus problem


        A more formidable challenge to the view that there is sub-personal mentation is given by John Searle. According to Searle, the thesis that there is sub-personal mentation is guilty of a version of  “homunculus fallacy.” Here is a paraphrase of his argument. 


        Supposing that it exists, sub-personal mentation consists in the following of rules – in the performing of derivations in accordance with various logical and methodological strictures. (In any case, the sub-personal mentation actually posited by cognitive scientists like Chomsky and Marr consists in acts of rule-following. Whether sub-personal mentation, supposing it to exist, must consist in such acts is a question we will set aside.) There can’t be rule-following without a rule-follower. So if there is sub-personal thought, that means that there is a sub-personal rule-follower (to whom we will refer as RF). But then we must explain how it is that RF can think. We generate a vicious regress if we say that RF’s cognitive achievements supervene on cognitive performances that are buried in his sub-personal psyche. On the other hand, if we say that we can explain RF’s ability to follow rules, and otherwise think, without imputing sub-personal though to him, we are conceding the explanatory uselessness of the idea that there is such thought.[206] 
        
          Suppose that brain-state B realizes my thought that Socrates was wise, and that brain-state B* realizes my later thought that somebody was wise. As we’ve discussed, for me to have inferred that somebody was wise from my belief that Socrates was wise, it is not enough that B cause B*. It is necessary that B’s being a thought that Socrates was wise be what is causally responsible for B*’s subsequent existence and, in particular, its being a thought that somebody was wise.
       In fact, we’ve seen that even if this condition is met, I still might not have inferred the one proposition from the other. There is, we saw, some special causal relation R such that (given that B and B* realize, respectively, my thought that Socrates was wise thought and thought that somebody was wise) I have inferred somebody was wise from Socrates was wise exactly if B’s being a thought that Socrates was wise generates B* in manner R. 
      Given this, suppose that, in fact, B’s being a thought that Socrates was wise does generate B* in manner R. In other words, suppose I have inferred somebody was wise from Socrates was wise. (Suppose that the inference is made at the personal level.) Where am I in all of this? Where is the person who makes the inference? If by a person, we mean some kind of an unpropertied entity underlying the causal transaction just described, then that person is inert. By the same token, so far as that person is causally involved, it is by way of his instantiating certain properties. (In this case, those properties would be those involved in having brain-states realizing certain kinds of beliefs and involved the one brain-states brining about the second in a certain kind of way.)
        So far as people are causally involved in anything, it is in virtue of their instantiating properties. But in that case, it is really property–instances, not people, who are doing the causal work, except in so far as  systems of interacting property-instances are constitutive of people.[207] Suppose that mysterious entity makes it be the case that thought T (Socrates was wise)  is followed by thought T* (somebody was wise) and not by thought T** (somebody was bald). In that case, so far as that mysterious entity is xxx doing any causal work, it is by way of its instantiating a certain desire. Past that point, that entity drops out. But that means that what is doing the work is an instance of desire. Positing an entity that “joins” the thoughts is useless. Even if such an entity does exist, that joining can be accomplished only through the addition of more thoughts xxx. 
      Also xxx , positing such an entity is unnecessary. Given that B (or, more accurately, B’s being a belief of a certain kind) brings about B* in manner R, it follows that an inference has been made. We don’t need to bring in an unpropertied agent. We don’t need to adopt the view that there is “agent causation”, i.e. that there is a mysterious spirit or unifying force beneath the thoughts that, by some miracle, can synthesize the thoughts without itself instantiating any property and thus without abiding by the general principle that it is instances of properties, and not bare particulars, that are causally potent. 
       The inference just described occurred at the personal level. We saw that there was an inference, but there wasn’t any inference-maker existing apart from the inference. This doesn’t mean that people don’t make inferences. Obviously they do. But it means that we cannot understand the making of inferences in terms of the activity of some mysterious entity that exists apart from its own thoughts.
       Suppose that B** is your belief that somebody was wise. For the sake of argument, suppose that B precedes B**, where B is defined as before. Obviously B’s being a thought that Socrates was wise cannot R-cause B**’s occurrence. xxx (In other words, B’s being such a thought cannot bring about B**’s occurrence in manner R.) Obviously xxx that fact is constitutively linked with the fact that B and B** realize thoughts had by different people. Instead of saying that B’s inability to R-cause B** is a consequence of the fact that they mediate thoughts belonging to different people, we may suppose that their belonging to different people consists in this fact. Suppose arguendo that B’s being a belief that Socrates was wise could R-cause B**;  suppose that, because of some feat of neural surgery, our two brains were so linked that this were a possibility. In that case, the boundaries between our minds would to that extent be blurred. In general, it seems that for two thoughts or brain-states to belong to different people is for them to be thus causally sequestered from each other, and that for two thoughts or brain-states to belong to the same person is for them not to be so sequestered.[208] 
        To put it succinctly: at the personal level, inference-making doesn’t involve an inference-maker -- at least not an inference-maker who is distinct from the act of inference-making in question. This is because inferences, like all mental events, are to some degree constitutive of one’s mind and, therefore, of one’s self. 
         This isn’t to say that non-mental (purely biological) entities are not thus constitutive. Nor is it to say that statements like “John inferred that Bob had four cars” are synonymous with, or otherwise analytically reducible to, statements about “bundles of perceptions.” (Statements about tables are not analytically reducible to statements about molecules, xxx even though 666 molecules are constitutive of tables.) It is merely to register the fact that a person is not a kind of empty vessel which can be occupied by thoughts, and that thoughts (and inferences, in particular) are ingredients of the causal sequence on which a person’s existence supervenes. 
         Given that rule-following at the personal level doesn’t involve a rule-follower, it would obviously be deeply arbitrary to suppose that rule-following at the sub-personal level required a rule-follower. Searle’s argument thus turns out to involve a false view as to what it is for a person to make an inference (or follow a rule); it involves the view that this involves the intervention of some mysterious entity underlying instances of properties, and that when this entity intervenes, it does so in propria persona and not by way of its instantiating any properties.[209] 


     
Searle’s dispositionalism 


          Searle has another argument to the effect that behavior and conscious psychological phenomena ought not to be explained in terms of sub-personal cognitive processes:
           
      Let us start with a short story. Using a paper and pencil, you divide two multi-digit numbers. (So you are doing “long-division.”) During the period of time that you are carrying out this operation, the distance of Alpha Centauri with respect to your hand is increasing uniformly. So, during that period, the shape of your hand is a function of its distance from Alpha Centauri. The motions of your hand therefore accord with that rule, even though you are obviously not following it. The rules that you are following have to do with facts about symbolism and mathematics that have nothing to do with the distance of your hand from Alpha Centauri. 
      Human conduct – what noises people make and how they move their bodies – may well be in accordance with the rules described by Chomsky, Marr, and other cognitive scientists. But it doesn’t follow that anyone is following those rules. So far as anyone thinks otherwise, he is failing to distinguish between following a rule, on the one hand, and acting in accordance with a rule, on the other.
       Of course, given only how people move their bodies, it doesn’t follow that they are not following the rules described by Chomsky. But to explain human behavior, there is no need to suppose that they are following those rules. So far as human behavior is not to be explained in terms of what is occurring at the level of consciousness, it can be entirely explained in terms of physiology. You ask me “how did your interview go?” I respond by saying: “I thought that I answered some of the interviewer’s questions creditably; but in other cases, my answers were spurious and the interviewer was visibly dissatisfied with them.” According to Chomsky, various unconscious cognitive processes mediated between auditory input and verbal output. But there is no need for such an extravagant hypothesis, given that a complete explanation of your response is obviously to be found in your physiological structure. There is simply no need to posit the manipulations of representations posited by Chomsky, and there is nothing to be gained by positing them. There are conscious mental phenomena, and there is pure physiology; and between the two, everything that needs to be explained can be explained.[210] 


       
        Searle is obviously right to distinguish between following a rule and acting in accordance with a rule. But, beyond that, Searle’s argument has little force. 
         First of all, given only that there are two ways of explaining some phenomenon, it doesn’t follow that one of those explanations is superfluous. Physics gives us one explanation as to why Smith’s heart is racing. Biology gives us another explanation. But it doesn’t follow that either explanation is wrong or even that either explanation is unnecessary. Contrary to what Carnap (1934) argued, it is extremely unlikely that the information embodied in biological explanations could be recovered by strictly physical explanations. As Jackson and Pettit (2004d) show, higher-level explanations capture principled regularities that lower level explanations cannot capture, a consequence being that the former are richer in certain kinds of information than the latter. For this reason, as Jackson and Pettit make clear, higher level explanations are not merely inferior versions of lower-level explanations. Economic explanations are not approximate psychological explanations. Physiological explanations are not approximate microphysical explanations. And xxx psychological explanations are not approximate physiological explanations. So given only that there is a strictly physiological explanation as to why I utter a certain noise, it doesn’t follow that other explanations are not possible or that other explanations are not necessary. In particular, it doesn’t follow that Chomsky’s story is either wrong or unnecessary. 
       For the moment, let us consider a psychological explanation that does not involve the supposition that there are unconscious (let alone sub-personal) psychological entities. You tell me that you want to drive to the store and you ask me where the car keys are. I tell you that they are on my desk. You promptly walk in the direction of my desk. Given what modern neuroscience tells us, there is every reason to believe that your bodily movements can be understood in strictly physiological terms. At the same time, your conduct can be understood, at least up to a point, in terms of what you desire (to drive to the store) and what you believe (that the car keys are on my desk). Given only that a physiological explanation is possible, it would be absurd to reject the psychological story. It would be equally absurd to reject Chomsky’s account of verbal behavior, given only that a physiological explanation of that behavior is possible.  
       Of course, there are some obvious differences between the explanations offered by folk-psychology and those offered by Chomsky. Consider my explanation of the fact that you promptly start walking in the direction of the desk. I do not have any direct awareness of the specific instances of belief and desire posited by that explanation. But I have direct knowledge of cases where behavior relevantly like yours was caused by mental states relevantly like those that I ascribe to you. After all, I know that your conduct is similar to my own conduct on past occasions and that, on those occasions, my conduct was caused by mental states similar to those that I am now imputing to you. Of course, my explanation may be wrong and even ill-founded. (It may be that you have a history of feigning interest in driving to the store when, in fact, you have no such interest.) But there is little doubt that some instances of that kind of explanation are correct. By contrast, nobody has any direct knowledge of the processes posited by Chomsky. In fact, nothing that anyone is directly aware of bears any significant resemblance to any one of those processes. 
       But given only these points, it doesn’t follow that such processes don’t exist. We are not directly aware of anything similar to the phenomena posited by quantum physics. But there is good reason to believe that such phenomena exist. 
        Searle has two objections to make to this last point. First, the concept of unconscious mental activity is an incoherent one: there can no more be unconscious mental phenomena than there can be square circles. Second, there is no empirical support for the view that, when I speak, the sounds that I am making result from my sub-personally following various syntactic rules.  In any case, there is as little empirical support for it as there is for the view that the behavior of my hand when I write results from my following some rule concerning Alpha Centauri’s state of motion. 
      We will deal with the first objection in the last section of this chapter. Right now, let us focus on the second one. The problem with this objection is that it erroneously assumes that the possible evidence in favor of the hypothesis that individual X is following rule R coincides with the possible evidence in favor of the hypothesis that X is acting in accordance with R. 
       Suppose we notice that Smith absolutely never walks on the grass. In light of this, consider the following hypotheses: 


(H1) Smith is deliberately following the rule stay off the grass. In other words, he is (at some cognitive level) aware of that rule, and he is following it, and not just acting in accordance with it. 


(H2) Smith is not following the rule stay off the grass. He is following an entirely different rule, namely: don’t walk on anything green. 


(H3) Smith isn’t following any rule. Smith is an inanimate robot on whose forehead there is photosensitive cell that causes Smith to avoid walking on green surfaces.


     No two of these hypotheses are confirmationally equivalent.  In other words, it is not the case that any evidence that confirms (or disconfirms) any one of these hypotheses equally confirms (or disconfirms) the other. Ceteris paribus (H2) is more probable than (H1) if we find that Smith doesn’t walk on green carpets. Ceteris paribus (H3) is more probable than either of (H1) or (H2) if we find that Smith never walks on green surfaces during the day, but that he does walk on such surfaces at night – even if they are surfaces that any cognitively and perceptually unimpaired human would know to be green (e.g. a golf course). It is only within narrow limits that those three hypotheses are confirmationally equivalent. 
       Let us now consider a fourth hypothesis: 


(H4) Smith is following the rule: either stay off the grass or become a square circle. 


     Despite what we might initially think, the possible evidence in favor of (H4) does not coincide with that in favor of (H1). If Smith has very strange beliefs about mathematics and about what people are capable of, he might walk on the grass even though he is attempting to comply with the rule described either stay of the grass or become a square circle. But ceteris paribus he will not walk on the grass if he is attempting to comply with the rule stay off the grass. 
      Setting aside concerns of a generally skeptical nature, it is often possible to establish beyond a reasonable doubt that another person has or lacks a given concept. (For example, you can establish with reasonable certainty that a student of yours doesn’t have the concept of a fractal.) Therefore, it could in principle be established that Smith lacked the concept square circle, but that he had the concepts needed to grasp the rule stay off the grass. Supposing that we learned this about Smith, his avoidance of green surfaces would provide support for (H1) but not for (H4). 
       Let R be the rule earlier described that assigns a certain configuration to my hand depending on its distance from Alpha Centauri. For reasons similar to those just given, the hypothesis that: 


(H5) JM is following R


is not confirmationally equivalent with the hypothesis that: 


(H6) JM is attempting to divide 174 by 13. 


     Given certain reasonable background assumptions, (H5) xxx is strongly disconfirmed by my not responding a certain way to questions like “name the five stars that are closest to the Earth.” But given those same background assumptions, (H6) xxx is not disconfirmed by that same data.
        Also, if I were trying to follow R, it is virtually impossible that I would succeed in doing so. Given that I am not superhumanly intelligent, I couldn’t possibly know at each instant in the relevant time-interval how my hand was supposed to be moving. Second, even if I did have that knowledge, my hand-movements would necessarily fail to keep pace with that knowledge, given that there is a time-delay (albeit a small one) between the brain-event mediating my intention to move my hand and my subsequent hand-movement. 
        My mis-adding two twenty-digit numbers is consistent with the hypothesis that my behavior is guided by the rules of arithmetic, but it is not consistent with the hypothesis that my behavior accords with those rules. My never drawing a perfect circle is consistent with the hypothesis that my behavior is often guided by the rule draw a perfect circle, but it is not consistent with the hypothesis that my behavior accords with that rule. 
       When Chomsky says that we “follow” certain syntactic rules, he means that our cognitive and physical activity is guided by such rules. That hypothesis is confirmationally very different from the hypothesis that our conduct accords with such rules. One reason why those hypotheses are different is that there is necessarily a gulf between “performance” and “competence.” Because we have limited energy, memory, and intelligence, our attempts to follow rules don’t always succeed. So it is perfectly consistent with Chomsky’s view that, on at least some occasions, our thought and conduct do not perfectly accord with the rules that, according to Chomsky, we are following. It is precisely because being guided by a rule doesn’t involve acting in  perfect accordance with it that Chomsky distinguishes between performance and competence.
        We can now weigh in on the debate between Chomsky and Searle. Chomsky noticed that our overt behavior – the noises and ink-marks that we produce, the movements that we make – is consistent with the hypothesis that linguistic activity results from our following certain kinds of rules. On this basis, Chomsky hypothesized that our linguistic activity results from our following rules of that kind. Searle grants that our linguistic activity may accord with the rules that Chomsky describes. But, he argues, this gives us little or no reason to hold that we are actually following those rules.  
        What Searle doesn’t realize is that the evidence that supports the hypothesis that we are following rules involving notions like c-command and heavy NP-shift is xxx very different from the evidence that supports that hypothesis that we are simply acting in accordance such rules. So supposing that R is a rule that involves such notions, the hypothesis that


(H7) Smith is following rule R


is not confirmationally equivalent with the hypothesis that:


(H8) Smith’s linguistic activity accords with rule R. 


      
        For example, (H7) is, whereas (H6) is not, consistent with the supposition that Smith’s behavior doesn’t always accord with R. In fact, depending on the circumstances, (H7) is consistent with the supposition that Smith’s behavior never accords with R.
         Let us illustrate these ideas by assigning a definite value to R. Supposing that S is a sentence of the form ┌…the phi the psi… ┐, let R be the rule that says how S’s meaning depends on the values of phi and psi. (Examples of sentences having that form are “he saw the woman the old man warned him about”  and “she threw paint on the car the man fixed.” So R says how the meaning of the former depends on the meanings of “woman” and “old man”, and it says how the meaning of the latter depends on the meanings of “car”,  “man”, and “fixed.”) 
        Smith’s being unable to assign the right meaning to the sentence “the girl the cat the dog the boy fed bit saw fell” is inconsistent with (H8) but perfectly consistent with (H7).  In fact, if Smith is following R, it is a virtual certainty that his linguistic activity will not always accord with that same rule, given the distinction between competence and performance. So if Smith’s activity were to accord perfectly with R, that would be evidence that he was not following that rule. 
      Conceivably, Searle might respond by saying the following: 


       Maybe you are right to say that X is following R is confirmationally different from X is acting in accordance with R. And maybe you are right to say that, in some cases, the empirical evidence is more consistent with the first hypothesis than it is with the second. But it doesn’t follow that we have to embrace the dubious view that we are sub-personally following rules. After all, the hypothesis X is following R is confirmationally indistinguishable from X’s behavior is in rough accordance with R. So why not just say that people are not sub-personally following rules but that, for strictly physiological reasons, they can be describes 666 as acting in rough accordance with certain rules? It seems to me that this is the most cautious and theoretically conservative path. And it is demonstrably no less better supported by the empirical evidence than Chomsky’s hypothesis that we are actually (albeit sub-personally) following various recherché rules. 


               
         The problem is that X is following R is in fact confirmationally different from X is acting in rough accordance with R, 666 and those confirmational differences favor Chomsky’s view. 
         Let R be some arithmetical algorithm. Ceteris paribus, I am more likely to follow R correctly when I am adding small numbers than when adding big ones. Ceteris paribus, I am more likely to follow R correctly when I am well rested than when I am severely sleep deprived.  Ceteris paribus, I am more likely to follow R correctly when the relevant numerals are clearly visible than when they are hard to see. 
         The presence of a performance-inhibiting factor can typically be established independently of the degree of success of the relevant performance. Your views as to whether I am well rested probably don’t have to be based on the success of my attempts to add numbers. The same is, of course, of your views as to whether I can see the relevant numerals and also of your views as to whether those numerals denote large or small numbers. 
          A corollary is that the absence of a performance-inhibiting factor can typically be established independently of someone’s performance. Smith says that he is a world-class sight-reader. But every time I ask him to sight-read an easy piece, his performance, xxx while passable, is not that of a world class sight-reader.  In other words, his attempts to comply with the relevant musical rules are not characterized by the level of success that would probably characterize those of a world-class sight-reader. Xxx There are various possible 666 explanations as to why Smith’s performance is mediocre that have anything more than an infinitesimally small chance of being correct. One is that he is not a world-class sight-reader. Another is that, although he is a world-class sight-reader, he was suffering from an acute vitamin B deficiency every time I asked him to play. Yet another is that somebody paid him a million dollars to simulate the performance of a mediocre sight-reader. Xxx If Smith really is suffering from a vitamin B deficiency, or somebody has paid him off, that can usually be established with reasonable certainty. In any case, the hypothesis Smith is a world-class sight-reader but he was suffering from a vitamin B deficiency every time I asked him to perform is confirmationally very different from the hypothesis Smith is a mediocre sight-reader, and his mediocre performance perfectly reflects his actual level of ability. 
          In light of these points, consider the following two hypotheses: 
     
         (a) X’s behavior is in approximate accordance with R. So far as X’s behavior accords with R, it is because X is actually following that rule. So far as X’s behavior deviates from R, it is because X’s performance is not up to his competence. 


         (b) X’s behavior is in approximate accordance with R, but X is not following R.   


          (a) and (b) are confirmationally very different. If X is actually following R, then his not perfectly according with R is to be explained in terms of the presence of some performance-inhibiting factor. Xxx Because the presence or absence of such a factor can be established with reasonable certainty, xxx the hypothesis that xxx Smith’s performance is to be explained in terms of his imperfectly following R is confirmationally different from the hypothesis that his performance is not to be explained in terms of his following R. For similar reasons, the hypothesis that our linguistic activity involves our following rules involving concepts like verb-deletion and heavy NP-shift is confirmationally very different from the hypothesis that our approximate compliance with such rules is not to be understood in terms of our following such rules. 
         Chomsky’s hypotheses are therefore not evidentially interchangeable with hypotheses that don’t explain our behavior in terms of our following rules of the kind just described. So the question whether Chomsky is right is an empirical one. (There is a qualification to this. Searle maintains that the concept of sub-conscious thought is simply an incoherent one. If he is right about this, then the question whether Chomsky is right is not a strictly empirical one, and is at least partly conceptual. Searle holds that  the concept of subconscious mental activity is in fact incoherent. [DELETE] We will examine Searle’s position, as well as his argument for it, in the last section of the present chapter.) 666
         An important point made by Gareth Evans (1985: 322-344) helps make it clear that: 


(H7) Smith is following rule R


is confirmationally very different from:


(H8) Smith’s linguistic activity accords with rule R, 


        
and thus helps make it clear that Chomsky’s position is less frail than Searle makes it out to be. 
       Evans points out that concepts and aptitudes are not frozen. If you speak Chinese there isn’t going to be any one Chinese sentence that you understand. Of course, it is perfectly possible to know the meaning of just one Chinese sentence. Somebody who doesn’t speak Chinese can be told what some one Chinese sentence means, or he can figure it out on the basis of context. But a genuine knowledge of Chinese will necessarily be “productive”, i.e. it will be expressed in an ability to understand a multiplicity of different Chinese sentences.
         Somebody who can hit just one sequence of keys cannot play the piano. 666 If you can play Mozart’s sonata in A-minor, then you can learn to play the sonata in C-minor. This isn’t to say that you will play the sonata in C-minor as well as you can play the sonata in A-minor; and it certainly isn’t to say that you can learn to play any piano piece that has ever been written. (Many pianists who can play Mozart cannot play Liszt.) But it is to say that, if you try to learn the sonata in C-minor, you won’t find that you hit a wall: you won’t find that you are completely incapable of playing the relevant sequence of notes. 
        What we just said about aptitudes is true of concepts.[211] It isn’t as though somebody who grasps the concept of addition can add three and five, but can’t add any other two numbers. And it isn’t as though one’s knowledge that 3+5=8 will be confined to any one context. Suppose that Jones can figure out that Ted has a total of eight shoes on the basis of the information that Ted has exactly three shoes in one closet and exactly five shoes in another closet, and no shoes that are not in either of those two closets. In that case, Jones is going to be able to figure out that Larry has eight houses on the basis of the information that he has exactly three houses in Jamaica and exactly five houses in Brazil, and no houses that are not in Jamaica or Brazil.[212]   
           If somebody’s writing “12+15=27” results from his following the rules of arithmetic, then he necessarily grasps the concepts involved in that rule, and his grasping those concepts will be expressed in ways other than his writing that particular inscription. In fact, it will be expressed in ways other than his writing any inscription. Given that Smith grasps the concepts constitutive of R, he is going to make certain noises to his stock-broker that he wouldn’t otherwise make; he is going to refrain from buying the luxury car that he always wanted, and will instead buy an economy car; and so on. His grasp of those concepts will not find expression only in his tokening sentences of arithmetic.[213]  
        If Smith’s writing “12+15=27” does not result from his following the rules of arithmetic and semantics, then he doesn’t necessarily grasp any of those concepts; and he won’t necessarily engage in any of the behaviors just described. So (H7) and (H8) are supported by very different bodies of evidence. Of course, those two bodies of evidence overlap. By itself, Smith’s writing “12+15=27” equally confirms both hypotheses. But if he was really following the rules of arithmetic, and thus grasps the concepts  twelve, addition, fifteen, and so on, then his behavior after writing that inscription will soon start to diverge from the behavior of somebody who doesn’t grasp those concepts. 
         The idea that Smith’s behavior would not thus diverge involves the idea that Smith’s grasping the concepts twelve, addition, fifteen, and so on, doesn’t involve his grasping any other concepts. But that idea is false. One’s grasping any one of those concepts involves grasping various others. Further, the behavioral consequences of grasping one concept are (ceteris paribus) different from the behavioral consequences of grasping any 666 other concept. Therefore, the hypothesis that Smith is really adding twelve and fifteen is rich in predictive implications not had by the hypothesis that Smith is merely acting in accordance the rules governing the addition of those numbers. By the sake token, if the hypothesis that Smith is adding those numbers is wrong, it is extremely unlikely that Smith’s behavior will be consistent with it for any length of time. After a certain point, it becomes only a skeptical possibility that Smith wasn’t actually following arithmetical rules. 
         It is not hard to see the relevance of this to the debate between Chomsky and Searle. If Smith is really following R, then he obviously grasps the concepts involved in it. In that case, his grasping those concepts will come out in ways that are independent of his following that particular rule. A corollary is that if Smith is not actually following R, there will soon be a wealth of evidence showing as much. In respect of its confirmational properties, the hypothesis that Smith is following R is radically different from the hypothesis that his conduct merely accords with it; and unless Smith really is following that rule, it is extremely unlikely that he will act as though he is. 
         Let us sum up. 666 Given any rule at all, the hypothesis that someone is following that rule is confirmationally different from the hypothesis that he is merely acting in accordance with it. A corollary is that, for any two distinct rules, the hypothesis that someone is following the one is confirmationally different from the hypothesis that he is following the other. Chomsky shows that there is considerable evidence for a number of hypotheses of the form X sub-personally follows R. Searle argues that the very same evidence confirms X is acting in accordance with R. That simply isn’t true, as we’ve seen, and we must reject this particular argument of Searle’s. 
         We have seen reason to believe that Searle’s criticisms of Chomsky’s cognitive realism are unfounded. But many of the views that motivate those criticisms are correct. Given the points that we’ve developed in this section, it is possible to separate what is true from what is false in Searle’s important (but misguided) “critique of cognitive reason.”[214] 
        Searle holds (correctly) that calculators per se are not following rules. My calculator always displays a “13” after I punch in “6+7=ENTER.” But it doesn’t follow that my calculator is really doing addition. All that follows is that my calculator is behaving like something that is doing addition. Further, Searle argues (correctly), the calculator isn’t adding, at least not in virtue of its engaging in behavior of the kind just described. 
         But Searle makes some false claims on the basis of these correct ones. First, he contends that a thing’s acting like something that follows R isn’t non-trivial evidence that it really is following R.  In fact, the opposite conclusion is to be drawn. The reason we must hold that the calculator isn’t really adding is specifically that its behavior is ultimately not like that of something that really does add. To be sure, where expressions denoting certain operations on small numbers are concerned, calculators and people do behave similarly, at least up to a point. (I say “up to a point”, because the behavior of calculators differs significantly from that of people even within those limits.) But past that point they don’t behave similarly, as the following story may help illustrate. 
       Timmy is four years old. He speaks English perfectly, and is cognitively normal for the most part. But he is unusual in at least one respect. He has completely memorized his addition and multiplication tables, and he has also perfectly assimilated the algorithms for the multiplication, division, and addition of multi-digit numbers. If asked a question like “what is 8×9?”, he can readily produce the right answer; and if asked “what is 87×96?”, he can generate the right answer after a minute or so. But Timmy simply cannot give the right answer to the question: “if Jones has exactly two shoes, and Brown has exactly two shoes, then how many shoes do Smith and Brown have altogether?” Timmy is equally incapable of answering any comparable question.
        Under these circumstances, there would be much to be said for the view that Timmy did not really grasp the concepts of addition, multiplication, and so on. We would explain his ability to rattle off sums and products by saying that he had memorized  the relevant tables. And we would explain his ability to crank out the products and sums of multi-digit numbers by imputing to him a kind of meta-linguistic knowledge that simulated actual mathematical knowledge. Timmy knows how to operate with the symbols “87×96” and “83×845.” But xxx he doesn’t know how to operate with the corresponding mathematical concepts. 
        Timmy’s behavior is very similar to that of a calculator. In fact, Timmy’s behavior is more like that of a calculator than that of practically any other human being. Timmy’s behavior is not like that of someone who really grasps the concepts of arithmetic. The same is therefore true of the behavior of a calculator. Searle is entirely right to hold that calculators don’t calculate (or so I have argued). But he is wrong to hold on this basis that X’s acting like something that follows rule R is little or no evidence X really is following R.   
         An analogy may be helpful. When we think of gravity, we tend to think of things falling down. So when we see images of astronauts floating about in a spacecraft, we have a tendency to think that there is no gravity in outer space. But this is obviously not the right conclusion to draw. In certain extremely narrowly defined contexts, one of the more obvious effects of gravity is to make things fall. But it doesn’t follow that there is no gravity where things aren’t falling. Our tendency to transition from the astronaut is floating to there is no gravity in the spaceship reflects the peculiarities of the circumstances under which we came to acquire the concept of gravitational attraction. Given how we came to acquire that concept, we see as definitive of the presence of gravitational attraction what is in fact one of infinitely many possible expressions of its presence. 
        For obvious reasons, when we think of arithmetical knowledge, we tend to think of people manipulating numerals. Our culture and educational system being what they are, there is indeed a reasonably good correspondence between a knowledge of arithmetic and an ability to manipulate certain expressions in certain ways. What we don’t always realize is that somebody’s manipulating the aforementioned expressions in the aforementioned ways is evidence of arithmetical knowledge only to the extent that it correlates with many other behaviors that don’t fit our stereotype of  somebody who knows arithmetic. If we strip away those other behaviors, leaving only the symbolic manipulations, we have somebody (or something) that doesn’t act like a true arithmetician. Calculators act just like these faux-arithmeticians. So given only that calculators only simulate arithmetical knowledge, there is no reason to deny that acting like an actual arithmetician is good evidence that one really is an arithmetician. 
       Of course, what we just said about arithmetical rules is true of all rules. So if, as Searle seems to grant, we act like things that follow rules involving concepts like c-command and dominant node, then there is good evidence that we really do follow those rules.  
       Before continuing, I would like to address a possible objection to the argument just presented (it is not one that an opponent of CTM, such as Searle, would make): 


         You begin with some correct points, but end up with a very wrong one. Here are the correct points. If Timmy really knows arithmetic, then he should be able to figure out how many houses Bob has, given the information that Bob has two more houses than Charles and that Charles has three houses. Given only that Timmy can manipulate the right symbols in the right way, it doesn’t follow that he grasps arithmetic; for it could be that he knows how to manipulate the symbols even though he has no idea what they mean. In general, if a person grasps arithmetic, that knowledge will be expressed in ways other than his or her being able to rattle off sums and products. 
         So far so good. But the cracks in your argument become obvious the moment we ask the question: Why is a person’s arithmetical knowledge expressed in these various other abilities? Why is a person who grasps arithmetic able to make judgments about the number of houses that Bob owns and about the number of shoes that Mona bought? Because a person grasps the concepts house, shoe, buy, and so on.  But given that calculators don’t grasp these concepts, it would be absurd to suppose that their knowledge of arithmetic would be expressed in their making judgments involving these concepts. 
      Let C be some concept that Martians grasp but that human beings do not grasp. It would be absurd to suppose that our arithmetical knowledge would be expressed in our making judgments involving that concept. Our arithmetical knowledge is expressed in terms of the concepts that are out our disposal, not in terms of those that are not. Similarly, a calculator’s behavior is expressed in terms of the concepts that are at its disposal, not in terms of concepts – e.g. boat, house, and shoe – that are not. My calculator’s concept of addition interacts with the few other concepts at its disposal at least as well your concept of addition interacts with the various concepts at your disposal. 
         As you say, the behavior of my calculator is different from of a person who knows arithmetic. But this is precisely what we would expect, given that people grasp various concepts that calculators do not – just as we would expect a Martian’s knowledge of arithmetic to be expressed differently from a person’s knowledge of that domain, supposing that Martians grasp concepts that people do not. So you have failed to show that a calculator’s behavior is relevantly different from that of something that really understands arithmetic. Supposing that calculators really do know arithmetic, their behavior is exactly what we would expect it to be, given that they have such a limited repertoire of concepts. In any case, you have failed to show otherwise. 






           This objection inadvertently exposes a reason to hold that, even after the relevant background-facts are taken into account, a calculator does not act like an actual arithmetician.  Suppose that Smith knows arithmetic but that he doesn’t know any of the symbolic conventions that (in our culture) are associated with a knowledge of arithmetic. So Smith doesn’t know that “1” denotes 1, that “×” stands for the operation of multiplication, and so on. For the very reasons given by the objector, it would obviously be absurd to suppose that Smith’s knowledge of arithmetic would be expressed in his writing down “7×9=63”, “1+12=13”, and so on. And if Smith did produce such inscriptions, then (supposing that we didn’t revise our views as to his symbolic knowledge) we’d have to assume that they were not expressions of his arithmetical knowledge.  
           It would be absurd to suppose that somebody grasped the fact that “1” denoted one, that “×” stood for the operation of multiplication, and so on, but that he didn’t grasp the concept of denotation. And it would be absurd to suppose that somebody grasped the concept of denotation but that he didn’t grasp the more general concept of representation. Once it is granted that somebody knows the symbolic conventions associated with arithmetic, it is de rigueur to grant that he also grasps various other notions – notions that even CTM-hardliners would be unwilling to impute to calculators. 
         Given these points, suppose that your calculator really does grasp the concepts of arithmetic. Unless it is granted that the calculator grasps the relevant symbolic conventions, along with the concepts that would be needed to have such a grasp, it 666 [space issue] would be absurd to suppose that the computer’s arithmetical knowledge would be expressed in its tokening expressions “7×9=63” and “1+12=13.” That supposition is as 666 absurd as the supposition that a calculator’s arithmetical knowledge would be expressed in terms of judgments about boats and houses. So if any case is to be made that, after their limited conceptual backgrounds are taken into account, calculators really do act like things that know arithmetic, it must be assumed that calculators have a rich backlog of semantic knowledge. In that case, there must be some independent evidence, i.e. evidence other than their tokening expressions of arithmetic, that they in fact grasp such concepts. But there is no such evidence; there is no independent evidence that 666 calculators grasp any of the semantic or meta-semantic concepts that 666 we xxx would expect of a creature that knew those conventions. They cannot see or hear or otherwise perceive anything that would give them any reason to believe that “1” denoted one, that “×” denoted the operation of multiplication, and so on. Apart from the fact that they token arithmetical expressions, they do nothing that would suggest that they have a grasp of what it is for one symbol-token to have a certain location with respect to another symbol-token. If they have semantic knowledge, that knowledge is completely ex nihilo, and has none of the moorings in other 666 concepts that, for reasons both empirical and purely logical, we would reasonably expect such concepts to have. 666 Thus, in view of the relevant background facts, it is especially unlikely that calculators act like things that actually know arithmetic. The objector’s point is therefore quite misguided. 
         Of course, the argument just presented presupposes a non-atomistic conception of concepts. It presupposes that, if one has one concept (e.g. a concept of the fact that “1” denotes the number one), one has others (e.g. the concept of representation). And, what is related, that argument presupposes that a concept of x  cannot be realized wholly by a causal relation to x. For, given a causal conception of conception, one could maintain that calculators grasp the relevant symbolic conventions: xxx for it could be maintained that the right kind of causal connection obtains between the social fact that tokens of “1” denote one and that the calculator produces just such tokens. This is at least part of the reason that sophisticated advocates of CTM, such as Fodor, advocate conceptual atomism as well as a strictly causal conception of conception. But we have seen xxx that those 666 doctrines are false. 
           There is one last point to make in connection with Searle’s view we have no good reason to think that X really is following R, given only that X acts like something that follows that rule. Despite everything that we just said, there is no denying that – albeit within extremely narrow horizons – calculators do act like things that really do add, subtract, and so on. As we’ve noted, Searle makes the xxx correct point that calculators don’t perform any of these operations. Xxx But having made this correct point, he overlooks another correct point of comparable importance. Xxx Even though xxx calculators are not themselves performing arithmetical operations, their behavior is still appropriately understood in terms of the performance of such operations. The calculator’s behavior has a special connection to the concepts of arithmetic: and the connection is not merely that the calculator’s behavior is easily predicted by taking the (false) view that the calculator is actually performing arithmetical operations. Xxx A person can use a calculator to add two numbers. Therefore xxx the activities of calculators are constitutive of actual cases of computation, even though calculators do not themselves compute. Xxx Further, calculators are built by people who know arithmetic and who wish to embody that knowledge in their creation. So to the limited extent that calculators act like things that add and subtract,  that 666 fact is to be understood in terms of the fact that something really is adding and subtracting. Of course, that something is not the calculator itself; that something is the human being who uses (or builds) the calculator. Nonetheless, given only that calculators don’t really compute, there is no reason to deny that a thing’s acting like something that computes is evidence that actual computation is occurring. Contrary to what Searle seems to hold, the fact that the calculator is acting like something that computes is not evidentially innocuous:  it does correspond to the fact that something (though not the calculator itself) really is computing. [215] 
        In light of these points, 666 let us consider the case of the human being whose behavior is like that of something which is following various rules concerning concepts such as initial phrase-marker and NP-postposing. The fact that somebody acts like something that follows such a rule is good evidence that such rules are in fact being followed. In any case, we have seen no reason to deny this and at least some reason to accept it. The rule-following to which the calculator’s behavior corresponds doesn’t have to be attributed to the calculator itself; it can be off-loaded onto a person behind the calculator. But nothing comparable is possible in the case of the human being who is acting like something that follows rules involving the concept of NP-postposing (unless you believe that we were created by a being that follows xxx such rules). So to the extent that our behavior suggests actual instances of rule-following, that rule-following must be attributed to us.  
           Wittgenstein (1958: § 201) famously said: “no course of action could be determined by a rule, because every course of action can be made out to accord with the rule.” Given only that something acts as though it is following a rule, there is no reason to believe that it really is following that rule: after all, given only how it acts, there are infinitely many other rules that it could, at least in theory, be obeying. Maybe I am not following the rule add one. Maybe I am following the rule add a million and then subtract 999,999. Maybe I’m following some other rule. Maybe I’m following no rule at all.
       Wittgenstein’s point does not have the ramifications that it is often thought to have. As we saw, the hypothesis that I am following the rule add one is confirmationally very different from the hypothesis that I am following the rule add a million and then subtract 999,999. For example, it can be established that, although I can add one, I have extreme difficulty adding and subtracting large numbers. In that case, given the rapidity with which I am generating the right numbers, it is a virtual impossibility that I am obeying the rule add a million and then subtract 999,999.
          Suppose that I behave in a way that is characteristic of somebody who is adding one. Wittgenstein is obviously right that, given only my overt behavior, it is technically possible that I am following the rule add a million and then subtract 999,999 or that I am following no rule at all. But that possibility isn’t a significant one, unless one or more radically counter-inductive assumptions are granted. It is a counter-inductive possibility that, although I am physiologically just like other people, my thought processes bear no resemblance to anyone else’s. It is also a 666 counter-inductive possibility that, even though the condition just described holds, my mental states nonetheless eventuate in behavior that isn’t appreciably different from that of other people. Of course, if a scenario of the kind just described is to hold, then we have to make the additional counter-inductive assumption that facts about physiology completely fail to fix facts about psychology. So to validate Wittgenstein’s view, one has to assume the truth of a purely skeptical possibility that is embedded within another purely skeptical possibility that is embedded within another skeptical possibility. It thus doesn’t appear that Wittgenstein done anything more than make the innocuous point that nothing concerning a person’s psychological make-up is logically entailed by truths about his overt behavior. Contrary to what Wittgenstein holds, when we set aside purely skeptical possibilities, so and so’s behavior is good evidence that he is following the rule add one, and not some other rule. 
         Wittgenstein is right that, given only some one act xxx on so and so’s part, the hypothesis that so and so is following the one rule (add one) is not more likely than the hypothesis that he is following some other rule (add a million, then subtract 999,999). Given any hypothesis that isn’t logically false (e.g. Smith’s house is a square circle), that hypothesis is equiprobable with many hypotheses that we regard as outlandish provided that we focus on a small enough data-sample. But when we consider the data-samples that actually motivate our judgments, the likelihood of 666 a bent hypothesis (e.g. Smith isn’t adding one: he is adding a million and then subtract 999,999) is small. 
        So far as it doesn’t depend on the truth of counter-inductive, purely skeptical possibilities, Wittgenstein’s position goes through only if it is assumed that there is an extremely strict connection between one’s grasping a given concept and one’s acting in a certain way. If the only evidence that I were following the rule add one, as opposed to  add xxx  a million and then subtract 999,999, were my acting in some specific way, on some specific occasion, then there would indeed be no reason to believe that I wasn’t following some other rule or that I wasn’t following any rule. After all, xxx any one act on my part (e.g. my writing a “1000” xxx after an occurrence of “999+1”) is no less consistent with my following a bent rule (add a million and then subtract 999,999) than with my following the obvious one (add one). But if I really am following a bent rule, then there is going to be some independent evidence of that fact. It is extremely unlikely that I would follow a bent rule on that one occasion, but that I would otherwise be functioning in the ordinary way. More likely, my following a bent rule on that occasion will be part of a history of following xxx bent rules. And that 666 fact that will come out, so long as we don’t myopically confine our attention to the vanishingly small part of my life during which I am producing that particular inscription.  
       A comparison might be helpful here. If a person is eating chicken not because he is hungry, but because he believes that doing so will protect him from lethal galactic rays, then there is probably going to be independent evidence of that fact. He probably has a history of mental illness. He probably won’t obey the usual rules of decorum while eating. He may well be wearing unusual clothes that, in his view, protect him from the lethal rays.
      Of course, we can normalize the behavioral expressions of these bent beliefs by imputing additional bent beliefs to our subject. Maybe he believes that, unless he has good table manners, the protective effects of chicken-consumption are neutralized. Maybe he believes that the clothes that people ordinarily wear are the best possible kind of protection against the lethal rays. But there will independent evidence for each of these bent beliefs. If that person believes that cotton fabric protects him from lethal radiation, he will probably have other very unusual beliefs about cotton and about radiation; and those unusual beliefs will probably leak out in some very unusual forms of behavior. Of course, we can normalize the behavioral expressions of these bent beliefs by epicyclically imputing yet further bent beliefs to our subject. But barring additional epicycles, each of these imputations will disconfirmed by other behaviors on the part of the subject. 
        Considered in isolation, a given act can have any number of different psychological antecedents. But if a given belief is the actual antecedent of some act, there will probably be evidence other than that act that the subject has that belief. And once that independent evidence is taken into account, it becomes nothing more than a skeptical possibility that the subject doesn’t have that belief. Wittgenstein’s view thus 666 goes through only if it is implausibly assumed that to each belief there corresponds some one kind of behavior. 
           Xxx A brief summary will help us close this argument.  “Smith’s writing a ‘998’ after an occurrence of ‘997+1=’ is no indication that he is following the rule add one: he could be following any rule -- or no rule.” Taken at an extremely abstract level, this claim seems reasonable. But when we take into account the relevant background facts, it ceases to be anything more than a skeptical possibility that he is following the rule add a million and then subtract 999,999. Unless we deliberately turn a blind eye to all but a tiny portion of the relevant data, the hypothesis that Smith is following a bent rule is not equiprobable with the hypothesis that he is following the usual rule. For exactly similar reasons, supposing that we act as if we are following rules of the kind that Chomsky describes, the hypothesis that we really are following such rules is decidedly more probable than the hypothesis that we are not doing so.  
      
 Wittgenstein and the sub-personal 


           John McDowell (1998), Gordon Baker, and PMS Hacker (Hacker and Baker: 1980, 1984b, 1985) make it clear that, in their view, the concept of sub-personal mentation is incoherent.[216] All of these authors are self-described Wittgensteinians; and there is no doubt that, in their antagonism towards the sub-personal realm, they are being 666 true to Wittgenstein’s thought. Even though there is no passage where Wittgenstein explicitly discusses the concept of sub-personal mentation, he put forth two arguments that make it clear that he would have regarded the very notion of sub-personal mentation as incoherent. It is on the basis of those arguments, and of the general currents in Wittgenstein’s thought of which they are distillations, that the previously mentioned authors reject the concept of sub-personal thought. These arguments are now known as the  “private language” and “rule-following” arguments. Let us now consider these arguments, starting with the former.[217] 


The Private-language Argument[218]


          Wittgenstein’s so-called “private language” argument is meant to show that there cannot be a private language that is not a mere translation of a public language. 
          Let me say what is meant by the italicized qualification. Obviously a person could create a private code for himself. I want to keep a diary. I know that my housemates will read it. So I invent a private code that they won’t understand. I replace each letter with the cube of the number giving the place of that letter in the alphabet. So instead of “b”, I write “8”; instead of writing “e” I write “125”; and so on. This private code is obviously parasitic on the existence of a public language. Wittgenstein doesn’t deny that there can be private languages in this sense. Wittgenstein denies that there can be private languages that are not thus parasitic.
          Before we give Wittgenstein’s argument, let us say a word on why it is thought to be important. It is widely thought that if there is sub-personal mentation, it is mediated by some kind of language. This view is held both by advocates and opponents of cognitive science. If this is right, then there can be no sub-personal mentation, supposing that Wittgenstein’s argument is indeed cogent (Fodor 1975, Dennett 1978: 91-95, Pylyshin 1984, Fodor and Pylyshin 1988). Advocates of cognitive science say that there is sub-personal mentation and thus some kind private language; and they say that the Private Language Argument must therefore contain some kind of error (Fodor 1975).[219] Opponents of cognitive science say that the Private Language is cogent and that, consequently, there is no private language and thus no sub-personal mentation. 
       Here is my reconstruction of the Private Language Argument: 




         Smith doesn’t speak a language. But he decides that he wishes to record his thoughts, and thus decides to construct a language for himself. He assigns meanings to a number of expressions. In particular, he stipulates that:


(*) “glump berka der”


is to mean:


(**) Today it snowed. 


Smith does all of this on a Monday. That same day, before he forgets any of the semantic rules that he has created, Smith writes (*) in his diary. (His intention, of course, is to write down a sentence that means: today it snowed.)  On Wednesday, Smith looks at what he wrote on Monday. In the intervening two days, he has forgotten what (*) means. But he thinks that he remembers what (*) means; he is convinced that (*) means: 


(***) yesterday it was sunny. 
    
     Here we can take one of two positions. On the one hand, we can say that Smith misunderstood the inscription of (*) that he was looking at: (So (*) really means: today it snowed. Since Smith thinks otherwise, he is wrong.) On the other hand, we can say that (*) now really does mean (***). 
     But it is not hard to show that the first option is untenable and that we must therefore accept the second. Suppose that, one day, every English-speaker in existence suddenly came to believe that the sound “blue” meant red and that the sound “red” meant blue. (To simplify discussion, let us suppose that any books or records containing any indication of the previous usages of those terms were suddenly destroyed.)  In that case, “blue” would mean red and “red” would mean blue. Of course, if I alone believe that “blue” means red and “red” means blue, I will be wrong. But I would be wrong only because there would be millions of other people whose usage of those terms didn’t correspond to my belief. 
     Given that Smith is the only speaker of his language, his deciding that (*) actually means (***) is comparable to the case where every English speaker suddenly takes 666 “red” to mean blue; it is not comparable to the case where I alone 666  reverse the meanings of “red” and “blue.” Smith’s usage of a given expression (of his language) sets the standard. It would therefore be absurd to say that Smith has misunderstood an expression of that language. That would be like saying that the word “probably” really means demonstrably (i.e. capable of being shown to be true on strictly deductive grounds), since that is what “probably” meant five hundred years ago, and that every English speaker alive today is therefore wrong to take “probably” to mean having more than a 50% (but less than a 100%) change of being true. 
      If this is right, then Smith cannot possibly be wrong as to what an expression of his language means. Any expression of his language means what he thinks it means. In that case, there is no wrong way to use any expression of that language. (Of course, matters would be different if other people started using those expressions. But, by hypothesis, the language in question is spoken only by one person.) If there is no wrong way to use any expression of a language, then none of those expressions has any meaning. “Snow is green” is meaningful because there are right and wrong ways to use it. If somebody learning English as a second language says “snow is green”, obviously intending to say snow is not green, we can correct him: we can say that he used that sentence wrongly. But this is not an option in Smith’s case. 
     A private language is one whose constituent expressions cannot possibly be used wrongly, and it is therefore one whose expressions don’t have any meaning at all. Of course, it is absurd to suppose that there could exist a language whose expressions were categorically meaningless, since a language just is an assignment of meanings to expressions. Therefore, it is absurd to suppose that there could be a private language. Thus, cognitive science is incoherent in so far as it demands that there be such a language. 
 
 
       This argument involves a failure to make three distinctions: first, the distinction between non-identical, but historically connected, languages; second, the distinction between the consequences of breaking a semantic rule and the social consequences of those consequences; and, third, the distinction between a condition’s being constitutive of a language and a condition’s being causally necessary for the continued existence of a language.
       The language that we speak is historically connected with the language that Chaucer spoke, and they are both referred to as “English.” But the set of semantic rules constitutive of the one language obviously doesn’t coincide with the corresponding set for the other language. Strictly speaking, we are dealing with two different languages, albeit ones that are similar and also genetically related.[220] 
     So supposing that (*) has changed its meaning, it follows the language Smith was using on Monday is distinct from the language. Let LM be Smith’s Monday-language, and let LW be Smith’s Wednesday-language. It may be true that (*) means whatever Smith thinks it means, given that he is the only person who gives meaning to that expression. But it doesn’t follow that the view he has on Wednesday as to what (*) meant on Monday is necessarily correct. So it doesn’t follow that Smith is always right in his views as to what LM’s expressions mean.  What follows is that, on Wednesday, Smith is right to as to what is meant by the LW-homonyms of LM’s expressions. It may be true that, for any time t, Smith is necessarily right as to what is meant by the expressions of Lt. But it doesn’t follow that, for any later time t*, Smith is right at t* as to what was meant by the expressions composing Lt. All that follows from Wittgenstein’s argument is that Smith is right about the meanings of the expressions composing Lt*, where Lt* is a language that sounds like Lt but may be characterized by different rules and may thus not be identical with Lt. 
        Wittgenstein equivocates on the term “language.” Sometimes he uses it to refer sometimes to sets of semantic rules, and sometimes he uses it to refer to series of such sets. Wittgenstein’s argument implodes when this equivocation is exposed. 
       In Wittgenstein’s defense, it might be said that our argument has merely evaded the problem, not solved it. LM is so useless, so incapable of transmitting information from Monday-Smith to Wednesday-Smith, that it doesn’t deserve to be described as a “language.” 
       But whether LM is thus useless is 666 an empirical question – and it is one whose resolution seems not to favor Wittgenstein’s argument. Clearly Smith could use LM to relay messages to himself. Suppose that, on Friday, Smith remembers the semantic rules that he laid down on Monday and that, on that basis, he decodes his diary-entry from that day. In that case, LM did do its job – it did relay information from Monday-Smith to Friday-Smith. 
      Of course, LM’s being able to function in that way presupposes that Smith remembers the relevant rules. But that is true of any language at all. If I forget the semantic rules of English, then English-utterances won’t mean anything to me. In general, such utterances are meaningful only in so far as people remember the relevant semantic rules. Of course, if I forget what some word means, other people are available to remind me of its meaning. (That is why “furtive” is meaningful, even though many people 666 don’t know what it means.) But that doesn’t point to some ontological difference between English and LM. Where both languages are concerned, semantic rules are sustained by human memory and nothing besides. If every English speaker suddenly forgot how to speak English, then that language would cease to exist (except perhaps in the irrelevant sense in which Latin and Sanskrit still exist).
      Of course, because English is spoken by millions of people, whereas LM is only used by one, the former can survive the faulty memory of any one of its users, whereas the latter cannot. But, to echo what we said a moment ago, this doesn’t indicate some ontological difference English and LM. In each case, it is human memory, and human memory alone, that endows expressions with content. In the one case, those memories are duplicated many times over and there are therefore more back-up mechanisms waiting to step into the breach left by any one person’s faulty memory. But that shows only that the continued existence of English is causally better guaranteed than that of LM. 
        During the time that it stands, a house that stands for a week is no less a house than one that stands for a year. The difference between English and LM is that, for what are basically sociological reasons, the former is more enduring than the latter. It isn’t that the preconditions for meaning have been met in the one case but not the other. This is clearly indicated by the fact, previously noted, that there is nothing absurd in supposing that Smith could use LM to communicate with himself. 
        Wittgenstein’s thus argument seems to conflate the concept of a condition’s being causally necessary for the existence of a language and a condition’s being necessary for there being a language (i.e. a set of meaningful expressions) to begin with. A related point – I will leave it open whether it is equivalent with, or merely similar to, the one just made  -- is that 666 Wittgenstein’s argument seems to conflate 666 the concept of a language’s continuing to exist with 666 the concept of a language’s coming into existence. [221]


Consequences of the misuse of expressions versus consequences of such consequences


       Wittgenstein points out that if somebody misuses an expression belonging to a public language, there are consequences. If I tell my doctor “I feel enervated”, when what I mean is I feel overly energized, he will give me the wrong medication (assuming that he knows what “enervated” means and believes that I know what it means). As Wittgenstein points out, nothing comparable happens in Smith’s case. Wittgenstein holds that, for this reason, the concept of a rule doesn’t apply to Smith’s situation. A “rule” that can be broken with impunity is no rule at all. Since Smith has carte blanche to break the so-called rules of LM, it follows that there are no such rules. 
     This line of thought confuses the consequences of breaking a semantic rule with the consequences of those consequences. Suppose that Jones promises to give me a million dollars if I manage to solve a difficult math problem. The solution to the problem is 712. I believe that the solution is 418. But I don’t speak English well, and I say “the solution is 712”, thinking that I have said the solution is 418. Jones gives me a million dollars. 
     Here I broke the rules of English-semantics. (I misused an expression.) Because I broke the rules of English semantics, Jones took me to mean the solution is 712 when what I meant was: the solution is 418. So by itself my breaking the semantic rules of English had a negative consequence: I was misunderstood. In its turn, that consequence – negative though it was – had another consequence; and the goodness of the second consequence obviously outweighed the badness of the first. But my being misunderstood was, by itself, a negative consequence of my linguistic incompetence. 
      A brief digression through meta-ethics may clarify the principle at work here. Bad consequences that are outweighed by good ones do not, in virtue of that fact, cease to be bad. Suppose that I catch a cold and thus cannot make my flight. The plane that I would have flown on crashes. By itself, my catching a cold is a bad thing: surely physical illness is a bad thing. That bad thing had a consequence which, for its part, was very positive. But it would be absurd to say that, because it had a good consequence, my being physically ill was good in and of itself. Similarly, it would be absurd to say that in and of itself my being misunderstood by Jones was a good thing. Being misunderstood is a bad thing, even though, like practically any bad thing, it may happen to have a good consequence. 
       If I misunderstand a sentence-token of my private language, a bad thing has happened: one person failed to make himself understood to another – Monday-JM failed to make himself understood to Wednesday-JM. For many reasons, Monday-JM won’t be given any penalties over and above being misunderstood for his failing to make himself understood to Wednesday-JM. There will be no court-hearings, no community-service, and no expulsion from the Rotary club. But there will be a penalty: in being misunderstood, Monday-JM was ipso facto penalized. So Wittgenstein is quite wrong to say that the rules of a private-language can be broken with impunity.
        If Smith misinterprets an expression of LM 666, there is a negative consequence: Smith has not made himself understood to himself. (Monday-Smith failed to relay a message to Wednesday-Smith.) Of course, that consequence will not, in its turn, have any social consequences. But Smith did incur a significant penalty for misinterpreting an utterance of (*): there didn’t have to any second (or third…) party for this to happen. Wittgenstein may (or may not) be right to say that there are no rules where everything is permitted. But, as we just saw, not everything is permitted where LM is concerned. 
     Also, it doesn’t seem true that there are rules only where there is some kind of enforcement. There aren’t necessarily any penalties for mis-adding numbers. (As we just saw, mathematical incompetence may be rewarded.) Of course, certain kinds of  social rules cannot exist where there is no possibility of punishment. (If there is no penalty for dumping one’s garbage in a certain lake, then – so one might argue – there is no rule prohibiting it. Even this, I think, is false, as I have argued elsewhere. But let us set this aside.) But Wittgenstein cannot use that fact to show that linguistic rules presupposes a plurality of people. After all, what he is trying to show is precisely that linguistic rules fall into the category of social rules (or, at any rate, of those social rules whose existence presupposes the possibility of punishment).[222] 


Why it doesn’t matter whether the Private Language argument is cogent 


       We have seen that the Private Language is fallacious and therefore proves nothing. But why is it thought that, if it were cogent, it would warrant the rejection of the idea that there is sub-personal mentation? Why would sub-personal mentation necessarily involve a language? 
      As we’ve seen, Fodor thinks that all thinking – and therefore all sub-personal thinking – involves a language. His view is that, if sub-personal mentation were to exist, it would necessarily involve some kind of internal code, by means of which different cognitive modules would communicate with one another. Many cognitive scientists agree with Fodor about this.[223]  
     We’ve considered Fodor’s arguments on behalf of the idea that there must be a language of thought, and we’ve seen that those arguments are untenable. We’ve also seen positive reasons to think that there is no language of thought. 
       But contrary to what both some cognitive scientists and Wittgensteinians think, the non-existence of a private language doesn’t have any bearing on the question whether there is sub-personal thought or, therefore, on whether the theories posited by Chomsky, Marr, and other cognitive scientists are correct. Those theories demand that there be sub-personal exchanges of information among different cognitive sub-systems. But it doesn’t follow that those exchanges involve a language. Given only that information-exchanges between people typically involve a language, it doesn’t follow that the same is true of information-exchanges within a single person. 
     Computationalists often seem to say that any representational system is ipso facto a language.[224] But if that is correct, then thesis that we think in language is reduced to the triviality that we have thoughts. So to the extent that it is not trivial to suppose that there is a language of thought, there must be non-linguistic modes of exchanging and encoding information. 666 Given this, there is no obvious reason why cognitive science must hold that mental operations are linguistic. A consequence is that, even if it were cogent, the Private Language Argument would have no bearing on the viability of that discipline. 
      Computationalists are actually conceding too much to Wittgenstein. Wittgenstein appears to have held that there can be no thought outside of a communal context, given that there can be no language outside of such a context. (Wittgensteinians are violently opposed to the idea that there can be non-communal thinkers. They think that Robinson Crusoe either doesn’t think – at most, he has thought-like non-thoughts[225] – or that, so far he does think, his previous membership in some linguistic community is constitutively involved in this.[226]) But there is no reason to hold this. In fact, if one does hold this, then one is committed to the view that everything that is true or false is ipso facto linguistic. And, as we’ve seen, that view is either trivial or false. 
      We may conclude that Wittgenstein’s Private-language Argument is fallacious and also that, even if it were cogent, that fact would have no bearing on whether theories such as Chomsky’s are correct. 


The rule-following argument[227] 


     Consider the rule: 


(S) You must stop at stop-signs. 


        Smith is driving along. He sees a stop-sign. He knows of S and therefore stops his car. 
       One analysis of this situation is as follows. S is some kind of abstract or hyper-real object, and Smith’s knowing about S consists in his beholding this object. He applies the information given to him in this platonic insight to his current situation. Because he applies this information correctly, he decides to stop his car. 
        Here is what Wittgenstein says. For the sake of argument, suppose that the analysis just given is correct. If Smith applies his knowledge of the aforementioned hyper-real object in a haphazard or arbitrary manner, he will make the wrong decision: he will decide not to stop. Smith must therefore apply his knowledge of this object in a principled manner. This means that he must follow some principle or rule S1 that says how to apply S. But by the same logic, he must then follow some rule S2 that says how to follow S1. We have generated a vicious regress. 
        Consider the function F(x)=x2. You haven’t considered each of the ordered pairs constitutive of this function. For example, you have not (let us suppose) considered F(937). How would you find out the value of F(937)? One is tempted to answer this by saying: “To grasp F(x)=x2 is to be aware of some platonic entity, and one figures out the value of F(937) through a principled application of the information embodied in this awareness.” In other words, one applies the first principle by knowing some second principle. But then the question that we asked in connection with the first principle arises in connection with the second, and we are no closer to explaining how you are able to produce the right answer. 
      Wittgenstein then seems to suggest that principled behavior isn’t to be explained in terms of grasping anything at all. One sees; one reacts. There is no intervening grasp of platonic entities. One just does it. 
      Wittgenstein makes it clear that, in his view, there is a distinction between principled and unprincipled behavior. But he seems to think that the difference lies not in anything that is internal to the subject’s psyche. As Wittgenstein himself puts it, if God were allowed only to see inside people’s minds, He wouldn’t always be able to distinguish between somebody who happened to make a correct guess as to the value of F(937) and somebody who genuinely figured that value out. Wittgenstein insists that the difference lies not in the individuals themselves, but in the way in which they are embedded in their respective social environments. (Wittgenstein is thus a content-externalist.) 
       One conclusion that is drawn from the rule-following argument is that the ability to follow rules – to apply functions, execute algorithms, and generally think and act in a principled manner – presupposes that one is embedded in a certain way in certain social practices – in particular, those involving the use of symbols. Of course, a pre-condition for one’s being thus embedded is that one have sense-perceptions, be able to interact with others, learn to use symbols, and so forth. If this is right, then it makes no sense to say that cognitive achievements like language-learning and perception-generation presuppose that one already have the ability to follow rules. 666 And in that case the hypotheses put forth Chomsky and Marr are incoherent, since the instances of rule-following posited by those theories are pre-social.
 
Evaluating the rule-following argument 


        Wittgenstein’s argument involves a failure to register distinctions of scope. There isn’t a distinction between grasping (S) and knowing how to apply it; and knowing how to apply (S) doesn’t involve grasping some second principle. 
        A correct analysis of the matter lies in the following principle:


(S*) To grasp S just is to knows of anything x having certain properties (red, hexagonal…) that one is ipso facto supposed to stop at x.
 
Before we continue, we must distinguish (S*) from two other statements: 


(S**) To grasp S just is to know that, given anything x having certain properties (red, hexagonal…), one is ipso facto supposed to stop at x.


and 


(S***) Given anything x having certain properties (red, hexagonal…), to grasp S just is to know that one is ipso facto supposed to stop at x.


     If (S***) is right, then given every stop-sign x in the world, anyone who grasps (S) is aware of x individually, i.e. any such person knows of each stop-sign x in existence that one is supposed to stop at x specifically. Since that is false, so is (S***). 
      (S**) is false for the reason that Wittgenstein himself gives: (S**) explains the grasping of principle (S) in terms of the grasping of some second principle (given anything x that is red, hexagonal, and so on, one is supposed to stop at x). So, just as Wittgenstein argues, (S**) merely passes the buck, leading to a vicious regress. 
      But Wittgenstein’s argument doesn’t apply to (S*); and (S*) doesn’t falsely presuppose that each person who knows (S) is acquainted with every individual stop-sign. (S*) is to the effect that a person’s knowing (S) consists in his knowing of anything x that he encounters (or otherwise considers) and that he believes to be red, hexagonal, and so on, that x is, in virtue of having those very properties, such that one is to stop at it. Given that (S*) is true, knowledge of how to apply S is built into knowing S. There is no need to invoke knowledge of a second principle. Nor is there need to invoke a knowledge of every stop-sign in existence. 
        Smith is driving along and he sees what is in fact a stop-sign. But he doesn’t realize that he is seeing a stop-sign. Because of unusual lighting conditions, his visual perception leads him to believe that what he is seeing is round and yellow, as opposed to yellow and hexagonal. So Smith doesn’t stop. Does this mean that Smith doesn’t grasp S? 
        Of course not. To grasp S is for it to be the case that, for any object x that one considers, and that one believes to have the relevant properties (red, hexagonal…), one knows that, in virtue of having those properties, x is such that one must stop at it. Grasping S obviously doesn’t involve being infallible, or even reliable, at distinguishing things that are stop-signs from things that are not. Grasping S consists in its being the case that when one believes (whether truly or falsely) of an object that it has certain properties, one believes that one is ipso facto to stop at it. 


An alternative formulation of our analysis 


    Here is a different way of articulating our thesis. This re-articulation is not needless repetition: for it will help us map what we have said about relatively simple rules, like (S), onto more complex one, like F(x)=x2.  
      Grasping S consists in its being the case that, if one believes x to have certain properties (red, hexagonal…), and if one believes y to be a case of stopping at x, then one believes that, in virtue of those facts, the pair <x,y> is to be assigned to some class C; and in its also being the that if one believes x to have certain properties (red, hexagonal…), and if one believes y to be a case of not stopping at x, then one believes that, in virtue of those facts, the pair <x,y> is to be assigned to the complement of C. So grasping S consists in one’s believing that, for some class C, <x,y> falls into C if y is a case of stopping at x, where x is an object that is red, hexagonal, and so on, and that otherwise <x,y> falls into the complement of C. 
      Thus, one’s grasping S consists in two conditions being met: 


(*) One believes, of any two cases that one considers where (so one thinks) somebody stops his vehicle at a certain kind of object, that those two cases ipso facto to be co-classified (i.e. put into some one class). 


(**)  One believes, of any two cases that one considers where (so one thinks) somebody has failed to stop his vehicle at a certain kind of object, that those two instances are ipso facto to be denied membership in the class just mentioned (i.e. that they are both to be put into the complement of that class).  


      Notice that each of these conditions can be met where a given person is concerned, even if that person is incompetent in the way of distinguishing things that are stop-signs from things that are not. But notice also that, if a person’s grasping S consists in those two conditions being satisfied in that person’s case, then there is an internal relationship between grasping S, on the one hand, and knowing that one is to stop one’s car at the red, hexagonal object in front of one. There is no need to apply one’s grasp of S. There is no need to invoke some second rule – or, therefore, a third or a fourth….— to see how (if at all) the principle bears on a particular situation. 


Extending our analysis to more difficult cases 


       These points map onto the mathematical case. (In this context, the term “square” will be used in its arithmetical sense -- as in “16 squares 4”, not “that table is square.”) A preliminary point will help make it clear why this case parallels the one just discussed. First of all, suppose that Smith grasps that concept. Further, Smith believes (correctly) that 4 squares 2 and that 16 squares 4. Smith also believes (correctly) that 5 does not square 3 and that 18 does not square 7. In virtue of having these beliefs, Smith believes that the pairs <4,2> and <16,4> fall into some class C such that the pairs <5,3> and <18,7> fall outside of C. Grasping the concept of a square undeniably involves believing that, if two ordered pairs both have certain properties, they are ipso facto to be put into some one class, and also that if two such pairs lack those properties, they are both ipso facto to be denied membership in that same classification. 
     Given this, I propose that one’s grasping the concept of a square consists in two conditions being met: 


(*) One believes, of any two ordered pairs that one considers to have certain properties, that those two pairs are ipso facto to be put into some one class. 


(**)  One believes, of any two ordered pairs that one considers to lack those same properties, that those two pairs are ipso facto to be denied membership in that same class.


      Supposing that this analysis is right, one’s grasping the concept of a square doesn’t involve one’s knowing exactly which ordered pairs have the relevant properties (just as grasping S doesn’t involve knowing which objects are stop-signs or, therefore, which cases of car-stoppings are cases of somebody’s stopping at a stop-sign). Further, supposing that our analysis is right, there is no need to apply one’s grasp of the concept of a square. There is no need to invoke some second rule – or therefore a third or a fourth….— to see how that principle bears on a particular ordered pair. If one believes that a given pair has the relevant properties, then one ipso facto believes it to fall into a certain privileged class. 
     There is an obvious objection to this: 


     For a pair <x,y> to have the relevant properties just is for y to square x. So in order for somebody to believe that a pair has the relevant properties, he must already grasp the concept of a square. 


      
       To see why this is not the case, we need only remember what we said earlier about the non-conceptual basis of conceptual knowledge. You hear a song on the radio. You know that it is an instance of rock ‘n’ roll – not jazz, not classical, not hip-hop. You classify that song as rock ‘n’ roll on the basis of its properties – its harmonic and melodic modalities, its rhythms, and so on. Each of these properties can be characterized independently of the concept of rock ‘n’ roll, and you can grasp any one of these properties without having that concept. If Bach were to come back from the dead one day and hear that song, he would know that it had those melodic, harmonic, and rhythmic properties. But he would not, at least not immediately, have the concept of rock ‘n’ roll. 
      If a piece falls under the concept rock ‘n’ roll, that is in virtue of its having properties that are ultimately not to be understood in terms of its falling under that, or any other, concept. A closely related point is that conceptual knowledge supervenes on non-conceptual knowledge. Your knowing that a certain piece falls under the concept rock ‘n’ roll is ultimately to be understood in terms of your grasping information that is not to be understood in terms of that piece’s falling under that, or any other, concept.
        In general, conceptual truths 666 supervene on non-conceptual truths 666, and conceptual knowledge supervenes on non-conceptual knowledge. Conceptual truths must be seen as articulations of non-conceptual truths, and conceptual knowledge is an articulation of non-conceptual knowledge. If one grasps a concept – be it the concept of rock ‘n’ roll or of exponentiation – one grasps it in terms of content that is ultimately non-conceptual. 
        The operative word here is “ultimately.” It is not hard to see the non-conceptual basis for a truth of the form that song is an instance of rock ‘n’ roll. One hears the sounds – the melodies and harmonies, and the timbres of the instruments that generate them – and one superimposes a judgment (that is rock ‘n’ roll) on that mass of raw, non-conceptual information. But some judgments are often at many removes from their non-conceptual bases. The concept of exponentiation is grasped in terms of that of multiplication. The concept of multiplication is grasped in terms of that of addition. The concept of addition is grasped in terms of the successor-relation. From a mathematical viewpoint, the successor relation seems to an ultimate and indefinable concept. (Set-theorists would disagree. But they take other concepts as ultimate and indefinable, e.g. the concept of set-membership. Supposing that set-theorists are right, everything we are saying about the successor-relation is true mutatis mutandis 666 of that other concept, whatever it may be.) But even though the successor-relation is a primitive concept, it isn’t a primitive piece of information. Non-primitive concepts are conceptualizations of other conceptualizations. Primitive concepts are conceptualizations of non-conceptual information. 666 Primitive concepts are not primitive information, and cognitive manipulations of primitive concepts are manipulations of non-primitive, but also non-conceptual, units of information. Of course, these points need to be both clarified and substantiated. (Some of the needed clarification and substantiation will happen in Chapters 21-23.) But if they are even approximately correct, they break the vicious circle described by the objector.
                                                                                                                                                                                                        
Summary of our critique of the Rule-following Argument 


       Applying a concept doesn’t involve knowing of each individual object – or even of each individual object that one considers -- whether it falls under that concept or not. (Wittgenstein is obviously right about that.) But applying a concept C doesn’t involve grasping some second concept C* such that C* is concept of how to apply C. To grasp C is to believe, of any two objects x and y that one considers, that x and y are to be put into some one class if they share certain properties, and are to be denied membership in that same class if they lack those same properties. Knowledge of a concept is thus knowledge of a conditional proposition, one of the form: 


(*) If x and y share property P, then (but not otherwise) they are to be co-classified. 


  For it to be unclear “how to apply” a concept C is for it to be unclear whether the object (or situation) in question satisfies the antecedent of (*) (or, more precisely, of the specialization of (*) that gives the content of one’s concept of C). There is a never a gap between  grasping a concept and knowing how to apply it. But there is sometimes a gap between  grasping a concept and knowing whether to apply it.  Given a grasp of a concept C, one ipso facto knows of any object x satisfying the relevant boundary conditions whether C(x) is true or not. But one often doesn’t know whether those boundary-conditions obtain. 
      Since there is no gap between grasping a concept and knowing how to apply it, Wittgenstein’s regress is blocked. Of course, there is a gap between grasping a concept and knowing whether some object meets the relevant boundary conditions. You can grasp the rule stop your car at signs having certain properties (red, hexagonal…) without seeing that the sign in front of you has those properties. (Maybe you aren’t wearing your glasses; maybe you are color-blind.) But doesn’t mean that you have to figure out how to apply your knowledge of that law to know what you should do if it should turn out that there is a sign with those properties in front of you. Knowledge of what to do, in the event that there is such a sign, is built into your grasp of that concept. It is obviously irrelevant that you do not know, for each object (or even for object that you consider), whether it is red, hexagonal, and so on. We must distinguish conceptual from pre-conceptual knowledge; we must distinguish knowledge of a concept from knowledge as to whether the preconditions for a concept’s applicability have been met.  For exactly similar reasons, you can grasp the rule F(x)=x2 without knowing of each pair of numbers, or even of each pair of numbers that you consider, whether one squares the other. But, contrary to what Wittgenstein appears to argue, this doesn’t mean that some kind of vicious regressiveness is embedded in the concept of a concept. It corresponds only to the innocuous fact that it isn’t always obvious whether a given object satisfies the antecedent of a conditional proposition.
 
The personal unconscious 


       The concept of sub-personal mentation has proven to be an extraordinarily fruitful one, and we have seen why the philosophical arguments advanced against it are less than probative. This might be a good place to discuss the philosophical arguments that have been directed against the concept of unconscious mentation generally. The latter arguments are, I believe, more easily disposed of than the former. 
        Ultimately, there is but one argument against the notion that there can exist unconscious mentation[228]: 


        It would make no sense to say that desks were not physical objects. A desk is a paradigm case of such an object. Leaving aside cases of insincerity or linguistic incompetence, anyone who said “desks are not physical objects” would be proposing a  666 redefinition of the term “physical object.” 
      Somebody who says that there are unconscious mental states is producing a comparable redefinition of the term “mental state.”[229] Conscious states are paradigm-cases of psychological entities. To think of an object as being psychological is to think of it as being relevantly like those entities that form our experiences: it is to think of it as being a surge of joy, a perception, an urge, and so on. Our experiences are constituents of consciousness -- you don’t experience what you don’t feel, and a feeling is some kind of “modification” (for lack of a better word) of one’s consciousness. Thus, anything that is “relevantly like” an experience of ours must itself be a constituent of consciousness. We eviscerate the concept of mind if we admit that there are mental entities that are not constituents of consciousness, just as we eviscerate the concept of physicality if we admit that desks, rocks, and trees are not physical objects. 
       Of course, there are dispositional mental entities – e.g. beliefs, aspirations, propositional attitudes generally, as well as character traits -- and these cannot be identified with constituents of consciousness. (Although it has conscious manifestations, my belief that 1+1=2 is not itself comparable to a tickle or a pain: it doesn’t vanish when I lose consciousness.) But this isn’t really a significant problem for the view that mentality is identical with consciousness. A belief that 1+1=2 is nothing more than a disposition to have certain conscious states, e.g. a disposition to think Smith must have two apples upon being told Smith used to have one apple and he has now been given a second one (and he never ate, or otherwise parted with, the first one). That disposition can be understood in strictly neurological terms.
     In general, in so far as beliefs, character traits, and so forth, are distinct from their conscious manifestations, they are to be understood in strictly physiological terms: as physiological propensities to have certain conscious states. There is nothing distinctively psychological about them. Hearts, livers, and bile-ducts give rise to conscious states. But it would obviously be absurd to say that such things were components of one one’s mind. It would be similarly absurd to say that, because they give rise to conscious states, neural structures are veritable components of the mind. [230] 
      Anything that is distinctively mental is a conscious state. Everything else is pure physiology. So far as there are non-occurrent so-called psychological states, we are dealing either with contents of consciousness or with strictly physiological entities that give rise to such contents. 




       This view is untenable, the reason being that it implicitly denies the existence of beliefs, aspirations, and propositional attitudes generally.
         666 Right now I am conscious of the moon. (I can see it through the window behind my computer.) But the moon is not a constituent of my consciousness. Obviously those who identify mentality with consciousness do not mean that something is a part of a person’s mind only if he is conscious of it. They mean that something is a part of a person’s mind only if that thing is a constituent of his consciousness. 
         There is no denying that beliefs, character traits, and so on, are mental entities. There is also no denying that my belief that 1+1=2 is not a constituent of my consciousness. For the sake of argument, let us take a dispositionalist view as to the nature of that belief, i.e. let us regard that belief as being mere physiology, so far as it isn’t identical with the conscious states or overt behaviors that manifest it. Let B be the brain-state (or neural-structure) that mediates that belief, i.e. this disposition or set of dispositions. 666
      In light of this, suppose I am told “Bill used to have exactly one apple; he didn’t eat it or otherwise lose possession of it; and he has just been given another apple.” In response I say: “In that case, Bill now has two apples.” (Let us suppose that I produce this utterance for the right reasons: I produce it because I know what those sounds mean, and I know that, under the circumstances, the meaning that they bear is one that can correctly be affirmed.) As we discussed earlier, it cannot be B simpliciter that causes me to produce that utterance. (It is not the rock that breaks the window – it is the rock’s moving with a certain velocity…) If it isn’t B’s encoding the proposition that 1+1=2 that causes me to produce the utterance just described, then we don’t have a case where my utterance manifests a belief. Given that B mediates my belief that 1+1=2, and given that my utterance of “Bill has two apples” was produced intelligently – i.e. it was produced in consequence of my having the relevant beliefs and not in consequence of, say, my having some kind of involuntary laryngeal spasm –  it follows that it must have been B’s encoding a certain kind of information that led me to  produce that utterance. If, instead, it was B’s having a certain mass or degree of conductivity or morphology, then (unless B’s encoding the right kind of information is realized by its having a certain conductivity or morphology…), my utterance no more manifests a belief than would an epileptic fit.[231] The right kind of disposition is not enough: the disposition must be grounded in the right kind of psychological condition. 666
     This isn’t to say that my belief that 1+1=2 is not a physiological entity or (more precisely) that it is not identical with some physiological entity’s having some physiological property. 666 It isn’t to say that B’s encoding the relevant information isn’t identical with, or otherwise reducible to, B’s having some property that falls within the scope of physics (or biology). It is to say that if B’s encoding the relevant information is realized by its having some physical (or biological) property, then some physical (or biological) property realizes the psychological property of encoding a certain piece of information. 666
       Now we can close the argument. B’s having those psychological properties cannot be identified with my being in any conscious state. (Therefore are two reasons for this. First, B has those properties even while I am unconscious. Second, any conscious state is, at most, a causal consequence of B’s having those properties, and must therefore be distinct from B’s having those properties.) Since, as we have just seen, B’s having those properties is not identical with any disposition, it follows that B’s having those properties is a bona fide unconscious entity.[232] 


Chapter 19  Some arguments for the Symbolic Conception of Thought 


      We’ve seen some reasons to hold that SCT is false, and in Chapters 22-23 we will find confirmation for this view. But Fodor (1975) provided five razor-sharp arguments on behalf of SCT, and we must take these into account before we come to any definitive conclusions as to whether that doctrine 666 is true or false. 


Argument #1 for SCT: the resemblance between thought and language 


        Thought resembles language. Sentences can be true or false; the same is true of thoughts. Sequences of sentences can be valid or invalid; the same is true of sequences of thoughts. It would not be hard identify further similar commonalities between thought and language. Given how much our thoughts resemble linguistic symbols, it seems reasonable to say that our thoughts are such symbols. Nothing that you’ve said could possibly put it in doubt whether thought and language are similar in the ways just described or, consequently, whether thoughts may legitimately be thought of as enough like symbols to be referred to as such. Your analysis of public symbols is obviously compatible with the fact that thoughts, like linguistic expressions, can be true, valid, and so on. So contrary to what you have argued, your analysis is compatible with the supposition that thoughts are enough like symbols to be referred to as “symbols” without thereby rendering that term ambiguous. 




        Here is what this amounts to: anything that is true, false, or otherwise representational, is ipso facto symbolic. But if we take that position, then the thesis that we think in symbols becomes the platitude that our thoughts are true, false, and otherwise representational. The thesis that thoughts are symbol-tokens is vacuous unless it is taken to mean that thoughts and symbol-tokens have properties in common other than the properties of being true, false, and otherwise representational. Given what we’ve seen, there is no evidence that thought and language have any significant commonalities apart from those just mentioned. We will find confirmation for this position when, in Chapters 22 and 23, we discuss Evans’ distinction between “conceptual” and “non-conceptual” content.
     


Argument #2 for SCT: the systematicity of language 


         xxx Languages are systematic: a natural language can express any viable permutation of the concepts expressed by any sentence belonging to it. If a language can express the proposition Tom loves Mary, then it can also express the proposition Mary loves Tom. To take another example: If a language can express the proposition: supposing that they were anatomically capable of playing the piano, penguins would find Bach’s contrapuntal compositions easier to perform than Schumann’s non-contrapuntal compositions, then it can also express the proposition: supposing that he were anatomically capable of playing the piano, Schumann would find Bach’s non-contrapuntal compositions easier to perform than penguins’ contrapuntal compositions. Languages are “systematic.”
       Like language, thought is systematic. This property of thought is easily explained if it is supposed that we think in a language. The systematicity of thought provides some evidence that we think in a language. 
      
       Xxx To speak English is to have internalized various semantic rules.  A precondition for being able to manipulate these rules is that one’s thought be systematic. This is a matter of logical, as opposed to causal, necessity. Your understanding “Tom loves Mary” consists in your being able to compute the identity of the proposition meant by that sentence (or, strictly speaking, occurrences thereof) on the basis of the relevant semantic rules. The very act of applying those rules to a new sequence of expressions is itself an instance of the systematicity of thought. 
       Further, knowledge of the recursive rules involved the assignment of Tom loves Mary to “Tom loves Mary” can only be understood in combinatorial terms, and such knowledge therefore presupposes cognitive systematicity. Consider the expression “loves.” That expression must be defined contextually: an utterance of ┌x loves y┐ is true iff x loves y. (Of course, this point is not self-evident. In a moment, we will see why it is true.) Since “x” and “y” are variables, understanding the rule just described consists being able to substitute different constants for those variables. It involves being able to understand the result of substituting “Bob” for “x” and “Samantha” for y; and, by the same token, it involves being able to understand the result of substituting “Samantha” for “x” and “Bob” for y.
        In response to this,  one might say that it is possible to understand “loves” without being able to understand different sentences of the form ┌x loves y┐ and, consequently, that an understanding of that expression is not to be understood in combinatorial terms. But such a position would be most counter-intuitive.  For the sake of argument, suppose that Smith can understand only one substitution-instance of the formula ┌x loves y┐ – he can understand “Bob loves Mary”, but not “Mary loves Bob”, or “Harry loves Ethel.” 666 In that case, Bob knows that the sound “BOBLOVESMARY” means  Bob loves Mary. But he isn’t able to parse that sentence; and what he understands is therefore “BOBLOVESMARY”, not “Bob loves Mary.” From his viewpoint, “loves” is no more a “part” of that sentence that “BLOVE” or “SMA” or “OBLO.” Smith cannot distinguish semantic from phonetic constituency. Given this, it is hard to make the case that “loves” is in his lexicon in the sense in which it is in your lexicon.
      We said a moment ago that “loves” must be defined contextually. What is our argument for this? We just provided an implicit argument for it. Let us now make that argument explicit. A non-contextual definition – e.g. “loves” denotes the relation of loving – wouldn’t give the syntactic properties of “loves”; it wouldn’t explain why “Tom loves Mary” is meaningful, whereas “Tom, the relation of loving, Mary” is not. To understand an expression is to know, not only what it refers to (supposing that it refers to anything), but also how it syntactically combines with other expressions. Contextual definitions provide this information; non-contextual definitions do not. (So far as non-contextual definitions do provide such information, it is because they are being tacitly equated with contextual definitions. If I say “the property of loving” denotes the property of loving, you tacitly understand that “the property of loving” is not interchangeable with “loves.” You know that “the property of loving is instantiated” is meaningful, 666 and that “loves is instantiated” is not. This syntactic knowledge lies in your knowing how “the property of loving” grammatically combines with other expressions; and any proposition to the effect that a given expression has such and such syntactic properties is ipso facto contextual, since it necessarily 666 has the form sentences of the form…are true iff…) To understand an expression is to know its combinatorial, and not merely its referential, properties. Having such knowledge involves knowing how to combine it with other expressions, and a pre-requisite to one’s having such knowledge is that one’s thinking be systematic. So the systematicity of language is to be understood in terms of that of thought, and not vice versa. Given that language is systematic, it is viciously regressive to suppose that thought is linguistic, and the systematicity of thought thus bars us from accepting (SCT). We already saw why the standard SCT-counter-response is untenable. 
         We just saw that a certain amount of cognitive systematicity is needed to grasp any contextual definition, e.g. ┌P or Q┐ is true if P is true or Q is true. By the same token, given a certain amount of cognitive systematicity, a group of people can create semantic rules build systematicity into their modes of communicating with one another. This confirms our suggestion that linguistic systematicity is a special case of cognitive systematicity, and not vice versa. 
       Of course, no English-speaker can understand every meaningful permutation of any group of English expressions. But, as Chomsky (1988) plausibly argues, that has to do with issues relating to 666 performance, not with competence.  Also, once the linguistic rules described in the last paragraph have been activated, there is no limit at all as to how complex sentences of that language can be. Given contextual definitions like the one just described, there are sentences of English, such that those sentences are too long for any human to understand and such that it is a theorem of English-semantics that those sentences are true. So whether or not people are able to understand an English sentence that is 87,000 words-long, it remains a fact that the systematicity of English is a reflection of the corresponding cognitive simplicity of its users (and creators).[233]  
         In conclusion, the systematicity of language is to be understood in terms of the systematicity of thought; and it thus seems viciously circular to attempt to understand the systematicity of thought in terms of that of language. 
         
A second argument against argument #2 


        The statement that languages are necessarily perfectly systematic is false. We can imagine a language L that has a single, semantically simple symbol that means Mary hates Bob, but that doesn’t have distinct symbols for Mary, Bob, or the relation of hitting. In that case, even though L can express the proposition Mary hates Bob, it cannot necessarily express the proposition Bob hates Mary. 
         There doesn’t seem to be any reason in principle why a language might not consist only of semantically simple expressions that expressed whole propositions. Such a language wouldn’t be systematic at all. So given only the supposition that a representational medium is a language, it doesn’t follow that it is systematic. Thus, given only the supposition that we think in a language, we don’t have any explanation as to why thought is systematic.
         Of course, given the supposition that we think in a language along with the supposition that the language in question is systematic, we do have such an explanation of the fact that thought is systematic. But it must then be explained on empirical grounds why that internal language is systematic. And in that case, the supposition that we think in a language explains the systematic character of thought only to the extent that there is some other, independent explanation of that fact. Therefore, the systematicity of thought is to be explained in terms of that other, independent explanation, and the supposition that we think in a language becomes completely gratuitous.
         As we’ve just seen, given only that we use languages, it doesn’t follow that we use systematic languages. So it is an open, empirical question why the languages that we use are systematic. Here is one possible answer to that question. We cannot say what we have to say through a language that is unsystematic; an unsystematic language wouldn’t do justice to our thoughts – just as a palate consisting only of two colors wouldn’t do justice to Cezanne’s artistic vision. For this reason, we prefer language L to language L* if ceteris paribus L is more systematic than L*. Given this preference of ours, we tend to use systematic modes of expressions. 
       Unless thought were systematic, it is hard to see why ceteris paribus systematic languages would do a better job than non-systematic languages of expressing our thoughts. Once again, it turns out that the systematicity of language is to be understood in terms of that of thought. 
                 
 Argument #3 for SCT: the productivity of language 


             If a public language (e.g. English or Spanish) can express the proposition snow is white and also the proposition grass is green, then it can express propositions consisting of those propositions, e.g. grass is green and snow is white, grass is green or snow is white, and so on. Languages are productive: languages can express molecularizations of the sentences belonging to them. Thought has a similar property. If a person can think grass is green and snow is white, then she can think grass is green and snow is white. Given that language is productive, the productivity of thought is easily explained by supposing that we think in a language. 


 
         First of all, the productivity of language seems to be an aspect of its systematicity.[234] Productivity is the permutability of sentences; systematicity is the permutability of expressions in general. Given that productivity is a kind of systematicity, it follows that everything we just about the latter is true of the former and, therefore, that Fodor’s third argument has the same defects as his second. 
        Also, the premise of argument #3 is false or, in any case, is only contingently true. As we saw, there is nothing absurd in the supposition that a language L might contain a primitive expression meaning Bob loves Mary, but no expression meaning Mary loves Bob. Given obvious extensions of what we said a moment ago, in connection with argument #2, it follows that argument #3 does not go through. 
  
Argument #4 for SCT: grasped but unaffirmed propositions


        When you say “either snow is white or penguins are mammals” or “if penguins are mammals, then some mammals live in Antarctica”, you are not asserting that penguins are mammals. Not every assertible constituent of an utterance is itself asserted. 
       Similarly, not every believable constituent of a thought is itself believed. You can believe either snow is white or penguins are mammals without believing either disjunct. Given that language has a corresponding property, this property of thought is  plausibly explained by assuming that we think in a language. 
       
         Given what we’ve said so far, the obvious criticism of this argument is that this property of language is to be explained in terms of the corresponding property of thought, and not vice versa. I believe that this criticism is cogent, and that there are special reasons to think that this particular argument of Fodor’s is guilty of explanatory error just cited. 
         Before we develop our criticism of argument #4, we need to clarify some points concerning the concept of sentential-constituency. It would be deeply arbitrary to say that the occurrence of “snow is white” in 


(*)  “snow is white and grass is green”, 


 were in a different grammatical category from its counterpart in: 


(**)“snow is white or grass is green.”


In particular, it would be arbitrary to say that the occurrence in (*) did have assertoric force, whereas its counterpart in (**) did not. (*) and (**) make different statements, of course. But that isn’t because “snow is white” has assertoric force in one of them but not the other. It is because of the specific meanings of “or” and “and.” For exactly similar reasons, the occurrence of “snow is white” is no more asserted in “it is true that snow is white” than it is in “it is false that snow is white.”      
       What this shows that is that any sentence that is a constituent of another sentence ipso facto lacks assertoric force – even if, because of the verbiage in which that occurrence is embedded, the proposition meant by that occurrence is affirmed.  A corollary is that any sentence-occurrence that has assertoric force automatically forms a sentence (or sentence-token, to be more precise) unto itself. More generally, any sentence-occurrence that has any kind of force – be it assertoric, imperatival, interrogative, exhortatory…-- is a sentence unto itself, and is not a constituent of another sentence. 
       There is one last preparatory point to make. Obviously only sentences can be asserted. You can’t assert “Socrates” or “red”, unless your utterance is elliptical for a complete sentence, e.g. “the color of my new shirt is red” or “Socrates is my favorite philosopher.”
      In light of these points, let us ask: what does it mean to say that not every assertible constituent of a sentence is itself asserted? Given that any constituent of a sentence is ipso facto unasserted, and given that nothing other than a sentence can be asserted, it means nothing more, and nothing less, than that there are complex sentences. It means, in other words, that there are sentences that are composed of other sentences. 
         Similarly, to say that thought has a property parallel to the one just described is to say nothing more, and nothing less, than that there are complex thoughts -- thoughts that consist of other thoughts. 
        This brings us to what appears to be a fundamental difference between thought and language. As we’ve discussed, there is a definite sense in which a sentence has minimal units of significance. But, by all appearances, the same is not true of thought. (In this context, “thought” refers not just to discursive mentation, but to anything mental that is representational.) Your current visual perception of this book doesn’t decompose into minimal units of significance. In any case, if it does so decompose, that would have to be demonstrated by an extraordinarily non-obvious line of argumentation. 
         Fodor aspires to explain the previously discussed property of thought (that not every constituent of what is believed is itself believed) in terms of the corresponding property of language (that not every assertible constituent of an assertion is itself asserted). This is certainly a reasonable hypothesis. But it is not an independently corroborated one, i.e. it isn’t borne out by data other than the data that motivated it. After all, when we look at mental activity other than verbal activity, we are struck by the differences, not the similarities, between mental and linguistic representation. 
         An advocate of SCT could respond by saying that sense-perceptions actually do have a sentence-like structure, even though their phenomenologies may suggest otherwise. But that position seems ad hoc. Also, it is question-begging in this context, since Argument #4 is meant to show that SCT is right, and therefore cannot assume its truth or that of any doctrine whose truth is predicated on that of SCT. (In Chapters 22 and 23, we will argue that the position just described not only seems false, but actually is so.)
         But it isn’t just sense-perceptions that are prima facie counterexamples to Argument #4. Thoughts themselves appear to be such counterexamples. One can say “Socrates” (without its being elliptical for a whole sentence) or “or” or “because.” Of course, such one-word utterances are ill-formed: but there is nothing impossible about them. (Indeed, they are a pre-condition for multi-word well-formed utterances.) But one cannot think just Socrates. One must think Socrates was bald or Plato admired Socrates.[235] This suggests that thoughts are not built up out of discrete parts corresponding to the ultimate constituents of sentences. A thought that Socrates admired Plato therefore seems not to have a decomposition comparable to that of the sentence “Socrates admired Plato.” This is a point we will soon develop. 
       An advocate of SCT might respond by saying: xxx “If SCT is right, then mental representations (i.e. thoughts and perceptions) do have a structure similar to that of a sentence; and if SCT is right, then you can just think Socrates.”  But, for reasons analogous to those discussed a moment ago, such a response would be question-begging in this context. 
        There is another problem with  Argument #4. What does it mean to say: 


(a) “snow is white” 


is a “constituent” of


(b) “either snow is white or grass is green”?  


The obvious answer is to say that the former is a component of the latter (or, more precisely, that any token of the latter has a token of the former as a component). But what does it mean to say that a token t of (a) is a “component” of some token t* of (b)? It obviously won’t do to say that t is a spatiotemporal part of t*. The underlined part of:


(c) “either snow is white or grass is green” 


is a spatiotemporal part of that sentence-token. But it isn’t a part of it in any semantically significant sense; it isn’t a part of (c) in the same sense as the bold-faced portion. 
         When we say that the bold-faced part is a constituent of (c), we mean that the derivation-tree for the former is a part of the derivation-tree for the latter. We mean, in other words, that the (structured) set of semantic rules that assign meaning to the first is a subset of the set of the rules that assign meaning to the second. We’ve already seen how, where public languages are concerned, the concept of a semantic rule is to be understood (at least in part) in psychological terms. The same is true of the concept semantic constituency (i.e. of one expression’s being a constituent of another), given that this concept is to be understood  in terms of that of a semantic rule. This suggests that semantic constituency is to be understood in terms of facts about thought, and not vice versa. In its turn, this confirms our larger point that, because the central concepts of semantics are to be understood in psychological terms, xxx it is impossible to establish enough meaningful parallels between thought and language to warrant an acceptance of SCT without trivializing that doctrine.


Argument #5 for SCT: induction and the simplicity-metric 


      Let us consider yet another argument given by Fodor on behalf of SCT. This argument, it will be seen, is in a different vein from the four just considered. We will refer to it as “Fodor’s argument from induction” (FAI):
    
  (FAI)    Obviously much of our thinking consists in the making of inductive inferences. But Goodman showed that any data that warrants an intuitively reasonable inductive inference also warrants an intuitively unreasonable one. Let D be the fact that every emerald observed before time t has been green. Given D, it is reasonable to infer that: 


(G) all emeralds are green. 


But D confers no less weight on that reasonable hypothesis than it does on the unreasonable hypothesis that:


(B) all emeralds are grue, 


       where x is grue just in case x is green before time t and blue after that time. 
       Nonetheless, there is presumably there is some legitimate, as opposed to purely subjective, reason to prefer (G) to (B). In general, notwithstanding Goodman’s correct point, there must be some reason to reject those hypotheses that we characterize as “counter-inductive” in favor of those that we characterize as “inductively reasonable.” (I am taking it for granted that somebody who prefers (G) to (B), given (D), is ceteris paribus better at inductive reasoning than somebody who has the opposite preference.) The difference lies in the fact that, given our various background beliefs, accepting (G) instead of (B) would lead to a simpler and more integrated body of beliefs than would accepting (B) instead of (G). Given our various background beliefs, considerations of simplicity warrant our believing (G) as opposed to (B), even though by itself (D) confers no more weight on (G) than it does on (B). 
        Given data D1…Dn, hypothesis H is ceteris paribus preferable to hypothesis H* if acceptance of H is theoretically simpler than acceptance of H*. (Of course, theoretical simplicity must be distinguished from psychological simplicity. Theoretical simplicity is a property of the relationship between hypothesis and data. Psychological simplicity is a property of the relationship between belief in a hypothesis and belief in data.) We  seldom make bent inductions: when our inductions are wrong, it is (almost) never because they are in the same category as (B). This means that ceteris paribus we prefer simple to complex hypotheses. This in turn means that we have some way of comparing hypotheses in respect of how simple they are (or, more precisely, in respect of how simply they can be assimilated into our existing beliefs). Thus, encoded in our thinking is some kind of “simplicity metric”, without which we would make bent, wrong inductions.  
        Simplicity, in the relevant sense, is to be understood in terms of the syntaxes of sentences. Suppose that L is a scientifically viable method of coding hypotheses into sentences and that, given any proposition P, there is a unique sentence S(P) of L that encodes P. [To facilitate our exposition of Fodor’s argument, let us prescind from the fact that, in this context, use of the term “scientifically viable” might constitute vicious circularity, given that it is a near synonym of “inductively viable.”] In that case, H’s being simpler than H* is expressed in (S)H’s having some syntactic property that S(H*) does not. In general, there is some syntactic property PHI such that, given any two hypotheses x and y, x is simpler than, and thus ceteris paribus preferable to, y just in case S(x) has PHI to a greater degree than S(y).[236] 
         
        
          Everything said up until the very last paragraph of (FAI) is extremely reasonable. For reasons that I give elsewhere[237], I believe that much (though obviously not all) of that material is wrong. But let us suppose, if only for argument’s sake, that everything said prior to the last paragraph of (FAI) is correct. Does it follow that simplicity is to be understood in terms of syntax? 
      No. Let us start with a point that might initially seem off-topic. Obviously people can articulate at least some of their beliefs (e.g. I can express my belief that it is raining by saying “it is raining”). So there is obviously a “semantic characterization” of many true propositions. (More exactly, given a language L that can express propositions P1…Pm, there is a semantic characterization of Pi in L.) 
        But it doesn’t follow that the concept of assenting to the proposition that it is raining is to be understood in semantic or otherwise linguistic terms. Maybe it is so to be understood (though we have seen reason to believe otherwise). Indeed, that is what Fodor would say. But given only that we can express our thoughts in language, i.e. given only that there is “semantic characterization of thought”, it doesn’t follow that our thoughts are themselves linguistic expressions. 
        Similarly, given only that there is a syntactic characterization of inductive reasonableness, it doesn’t follow that our being inductively competent consists in our being sensitized to sentences of some kind. What follows is only that this competence can be given sentential expression.[238] 
       We must remember our earlier points about syntax. To say that S has a certain syntax is to make a statement about the semantic rules that assign it meaning. So to say that there is a syntactic characterization of  inductive reasonableness is to say that there is a possible language L satisfying the following two conditions: 


(i) L is rich enough to express any inductively sound argument. 


(ii) Let  S1…Sn be the sentences, or sequences of sentences, belonging to L that express inductively sound arguments. There is some property PHI such that the derivation tree of Si has PHI just in case 1≤i≤n. 
 
        Thus, for some property PHI, the statement there is a syntactic characterization of inductive reasonableness in language L is equivalent with the statement for any sentence S belonging to L, S expresses an inductively reasonable claim exactly if S’s derivation-tree has PHI. So sensitization to syntax is sensitization to facts about how sentences are assigned meaning.
        So far as one’s thinking is driven by facts about how expressions of language L are assigned meaning, one’s thinking is about L, and not in L. So supposing that we think in a language, it would be viciously regressive to say that our thinking were driven by a sensitivity to facts about how its expressions were assigned meaning. Since sensitization to syntax is sensitization to facts about how sentences are assigned meaning, it follows that, so far as we think in a language, our thinking is not driven by the syntaxes of its expressions. 
       The only way to block this would be to say that, where that internal language is concerned, the term “syntax” has a meaning entirely different from the homonym of that term that is used in connection with public languages. But in that case, the statement “thinking, and therefore the making of inductions, is a syntax-driven affair” ceases to have any identifiable meaning.
       For reasons discussed earlier, it would be no use to counter-respond by saying that our thinking is syntax-driven in that it is morphology-driven, and morphology can be aligned with syntax. 


Chapter 20 A positive argument against SCT 


         We have seen some reasons to doubt the cogency of Fodor’s arguments on behalf of SCT. But given only that Fodor’s arguments don’t go through, it doesn’t follow that SCT is wrong. But there are some reasons to think that SCT is in fact wrong. 
        The standard argument against SCT is this. Given any expression belonging to a public language, what that expression means is derivative of human thought. Therefore it is viciously regressive to suppose that thought is itself linguistic.[239]  
         Xxx I believe that the argument just given is cogent. (In a moment we will consider some possible objections to it.) But the premise of that argument is liable to be misunderstood. Given only that word-meaning is parasitic on human thought, it doesn’t follow that Grice’s analysis of meaning is the right; it doesn’t follow that, if E has meaning M, that is because people mean M by E. Nor does it follow that human thought directly fixes what expressions mean. (There are very long sentences of English that have definite meanings but that have never been contemplated. So far as human thought fixes the meanings of such sentences, it does so by way of fixing the meanings of their constituents.) Nor, finally, does it follow that human thought single-handedly fixes what expressions mean. (Putnam is right: on Twin-Earth, tokens of “water” refer to XYZ, not H2O. But, as Putnam (1975) argued[240], Bob and Twin-Bob have exactly the same thoughts. ) What follows is that what people think is part of what fixes what expressions mean. (How it fixes it, and to what extent, is another question.) xxx This is obviously a reasonable point and, if it is right, then it is viciously regressive to suppose that we think in a language. 
       The SCT counter-response is to say that the meanings of Mentalese symbols are not fixed by thought. But in that case it becomes questionable whether the so-called symbols of Mentalese deserve to be referred to as such, given how different they are from things that we know to be symbols. 
       At this point, communication between advocates and opponents of SCT tends to stop. But my feeling is that, were it to continue, the debate might well take the following direction. Advocates of SCT would respond to the criticism stated a moment ago by saying that they are indeed extending the concept of a symbol, but that scientific progress consists in making principled extensions of this sort: surely physics wouldn’t have come as far as it has if physicists insisted on operating within the confines of the layperson’s concepts of temperature, mass, energy, and so on. 
        The anti-SCT counter-response would be to say that SCT has over-extended the concept of a symbol, and that what it is doing in connection with the concept of a symbol  isn’t comparable to what physics has done in connection with concepts of temperature and mass. 
       But at this point the debate is quite murky. Who is to say when an extension of a concept (or term) is justified and when it isn’t? I would like to make an attempt to break this stalemate. 


The different meanings of the word “language”


          There are three important distinctions that relate to the study of language. (When I say “important”, I don’t necessarily mean “valid.” As we will see, one of them is quite spurious. The other two are legitimate.) They all bear a certain resemblance to one another, and are seldom carefully distinguished. But in this context they must be distinguished at all costs. 
        Saussure (1966) distinguished “langue” and “parole.” The former refers to language per se, and the latter refers to the use of a language. 
         David Lewis (1975) distinguished between LANGUAGES and languages*. (He used a different notation to mark this distinction.) LANGUAGES are sets of purely platonic objects: function-theoretic pairings of properties, individuals, and the like, with physical types or tokens. It is evident that such pairings are themselves platonic entities, and thus have no spatiotemporal co-ordinates. Languages*, on the other hand, are constituted by patterns of behavior and thought – by people producing certain noises and ink-marks in response to various stimuli. According to Lewis, the word “language” is ambiguous between LANGUAGES and languages*; and the word “meaning” is comparably ambiguous, sometimes referring to a purely function-theoretic relation (e.g. a function that assigns truth to an utterance of “that cat is mangy” exactly if there is a unique contextually salient cat x, and x is mangy) and other times referring to a psychological phenomenon (as in “what I meant is that you should buy some new clothes”). 
      By way of anticipation, Saussure’s distinction is legitimate, whereas Lewis’ is not. Let us now discuss the third distinction (one we will find to be valid and, indeed, of the highest importance)  – that between distinct, but historically connected, languages. 
       If we think of languages as sets of semantic rules, then the referent of the word “English” in 1980 is not identical with the referent of the homonymous word in 2006, thanks to (for example) the introduction of various new terms relating to the internet. At the same time, there is obviously a legitimate disambiguation of “the English language” on which that expression has not changed its referent in the last twenty-six years. Let us say that “the English language” refers to the same “languageH” (the sub-script stands for “historical”) as the homonym of that expression twenty-six years ago, but that “the English language” refers to a different “languageSR” from its homonym twenty-six years ago (the sub-script stands for “semantic rule”). 


An erroneous conception of language 


      Here are some views that might initially seem reasonable: 


Lewis’ term “LANGUAGE” refers to the same thing as Saussure’s term “langue”, and  Lewis’ term “language*” refers to the same thing as Saussure’s term “parole.” “LANGUAGE” and “langue” both refer to languagesSR; and “language*” and “parole” both refer to languageH.


    
      This is false. The term “linguistic meaning”, I will argue, never refers to function-theoretic pairings, and the term “language” never refers to a set of such pairings. The statement “a language is a set of function-theoretic pairings of individual, properties, and so on, with physical tokens (or types)” is false on every disambiguation of the term “language.” 
      Lewis is right to say that the word “language” is ambiguous. But it is not ambiguous in the way that he thinks. Similarly, Lewis is obviously right to distinguish between semantic and psychological meaning. But he is (so I will now argue) wrong to think that the former is a purely function-theoretic relation.  
        Obviously Saussure is right to distinguish between languages and the use people make of them. But a language is as much a spatiotemporal entity as the use people make of it. Langue and parole are both spatiotemporal entities. Not all spatiotemporal entities are identical with events. Given that an event is a change in spatiotemporal conditions, it follows that not all spatiotemporal entities are events. A langue is a spatiotemporal condition. Parole is a series of events. But both langue and parole are spatiotemporal entities. 
       Here we must head off a source of deep confusion. Lewis is, I believe, entirely right to say that a language is a set of semantic rules. The English language is the set consisting of rules like: “Socrates” refers to Socrates, “Plato” refers to Plato, and so on. The English language is not a series of noises and ink-marks; it is not even a series of ink-marks and noises coupled with the socio-psychological conditions that caused them. When I say “that rabid dog is running towards us”, my utterance is caused by (inter alia) my awareness of existing semantic rules, the same being true of any other utterance of any language. If utterances constituted language, this would not be possible. The psychological state that was the proximal cause of my producing that utterance was itself a causal consequence of the existence of the English language: ceteris paribus, if it weren’t for the existence of the English language, I would not have had that mental state; and the dependence referred to here is causal, not logical or analytic or constitutive. Thus, the mental state that precipitated my saying “that dog is running towards us” is not constitutive of the English language: if that mental were thus constitutive, then we couldn’t coherently register the obvious truth that its existence as a causal consequence of that of the English language. So even though Lewis is (so I believe, and so I will argue) entirely wrong as what semantic rules are, he is right to think that a language is a set of such rules.[241] 
      Even though the mental state that is the proximal cause of my saying “a rabid dog is running towards us” is not constitutive of the English language, it doesn’t follow that no mental states are thus constitutive. Being a non-platonic object, the English language is,  I will argue, constituted by psychological facts. (It is also constituted by the social and environmental facts in which these psychological facts are embedded.) But the psychological constituents of language are distinct from the immediate psychological antecedents of utterances. 
      A comparison may be helpful. You and I are roommates. We both want to live in a neat and hygienic environment. If we are to live in such an environment, various chores must be done on a daily basis – somebody must vacuum, do the dishes, and so on. We explicitly agree that I will do those chores on even numbered days of the month  and that you will do them on odd-numbered days of the month. Here we have an arrangement whose existence is obviously constituted, in part, by certain psychological entities. 
       On November 4th, I look at the calendar and realize that it is my chore-day. I thus bolt into action – I start vacuuming, doing the dishes, and so on. Here the proximal cause of my doing these chores is my having a certain awareness: I realize that, because it is an even day of the month, I must do various chores if I am to honor my agreement with you. But that realization is not constitutive of the agreement that you and I have. That realization presupposes that agreement, given that the latter is a cause of the former. So even though our agreement that I do laundry on certain days obviously has psychological constituents, the immediate psychological causes of my doing laundry on any given day are not constitutive of that agreement. 
         Indeed, we can go further in this direction. Causes are distinct from their effects and causes thus cannot be constitutive of their effects (or vice versa). Given this, suppose we say that my realizing, on November 4th, that I must do chores is constitutive of our agreement. In that case, we are forced to say that our agreement was in no way a cause of my doing chores on that day. But that is absurd. The fact that we entered into that agreement is obviously part of what causes me to vacuum, do the dishes, and so on. (It is not an immediate cause or a total cause; but it is obviously a cause.)  
      A language is no more a platonic or function-theoretic entity than the agreement just discussed. Any language is constituted by various understandings that hold among people. Any language thus has at least some psychological components. But it does not follow that the immediate psychological causes of one’s utterances are constitutive of language. Indeed, if we said that the immediate causes of my uttering “that dog is running towards us” are constitutive of language, then we would be barred from saying that the existence of a given language was in any way causally responsible for my producing that utterance. But surely the fact that the English language is alive (i.e. that it is not in the same category as Sanskrit or Latin) is a partial cause of my producing that utterance. Some of my mental states are constitutive of the English language. My knowledge of certain social and psychological facts is constitutive of the English language. (This isn’t to say that there is no possible world where English exists but I do not. A given molecule can be a constituent of a cloud even though there are possible worlds where that cloud exists but that molecule doesn’t. Similarly, my having certain bits of knowledge is constitutive of the English language, even though there are worlds where English exists and I do not, and even though there will be a time when the English language exists and I do not.) But the psychological states that immediately cause my utterances are not constituents of the English language. 
      Parole is not identical with what we referred to as “languageH.” Parole is xxx language- use, not xxx language-change. Given a set of semantic rules, parole is the use of those rules. Parole is not the replacement of that set with another such set. Of course, parole is causally responsible for language-change. It is because of xxx how people use words that “probably”  now means capable of being shown to have a greater than 50% chance of being true”, whereas it used to mean capable of being shown to have a 100% chance of being true. But it obviously doesn’t follow that parole is constitutive of language change. “EnglishH” refers to an evolving sequence of sets of semantic rules – one that includes the semantic rules governing the language that Chaucer spoke and also governing the language that we speak. Given what we just said, it follows that use of English expressions is not constitutive of any of the sets including in EnglishH and a fortiori is not constitutive of EnglishH itself. 
      It may help if we take a brief detour through metaphysics. What we typically refer to as “events” are hyper-changes: they are changes in the manner in which things change. If a woodsman splits a log in two, there has been an event. But it isn’t as though, prior to that event, the log’s existence involved an absence of change. The log’s existence supervenes on innumerable changes xxx (e.g. displacements of sub-atomic quanta of mass-energy). But these changes are all internal to a structure. When the woodsman splits the log, this structure is altered. So the woodsman’s act is an event not because it introduces change where there was previously none, but because it altered the framework which change takes place. His event was a change in the manner of change. Conditions are framework-internal changes; events are framework-external changes, i.e. they are changes in the manner of change. 
        A set of semantic rules is a structure. A usage of an expression belonging to that structure is indeed an event, but it is a structure-internal event: it is comparable to the subatomic mass-energy displacements that constitute the log prior to its being split in two. A language-change is, of course, is identical with or realized by a series of events that are not structure-internal since, by definition, such events alter the relevant structure. Here are our woodsman-analogy breaks down. The woodsman’s act is entirely external to the structure of events constitutive of the log, whereas the events that realize language change are necessarily on the periphery of the events constitutive of semantic rules. But what is important in this context is that, in so far as a series of events change a language – in so far as they add a semantic rule or change what some expression means – those events are not constitutive of any existing set of semantic rules, and are therefore not constitutive of any existing language (on one important disambiguation of that term). This truth is obscured by xxx the fact, just noted, that the events that constitute language-change are in some respects (historically, psychologically, semantically) continuous with those that are internal to a set of semantic rules. 
        
Summary of our findings thus far 


       A set of semantic rules is not a set of platonic entities; it is not a set of function-theoretic assignments of properties, individuals, and so on, to physical tokens. A set of semantic rules is constituted by psychological entities of some kind (understandings that hold among people), and also by the social and environmental underpinnings of those entities.
        Of course, the proximal cause of any utterance is a psychological entity. (You see a rabid dog running towards you. Because of your semantic knowledge, you respond by saying:  “there is a rabid dog running towards me!” The distal cause of your utterance is an external state of affairs – some dog running towards you. But the proximal cause is your perception of that state of affairs.) But such proximal causes are never constitutive of the semantic rules that make up a language. 
        So even though a language is constituted by psychological entities, and also by understandings among people that implicate facts about their shared socio-physical environment, a language is nonetheless not constituted by speech-acts or by the psychological states that proximally cause such acts. Speech-acts, as well as their immediate psychological antecedents, are effects of the existence of semantic rules, and are therefore not constitutive of such rules. Since languages are constituted by such rules, it follows that neither speech acts nor their proximal causes are to any degree constitutive of language. 
          Lewis’ “language*” is not Saussure’s parole, and Lewis’ “LANGUAGE” is not Saussure’s langue. As Lewis defines them, the terms “language*” and “LANGUAGE”  don’t refer to anything that is actually referred to by the term “language.” Lewis’ terms refer, respectively, to language-use and to sets of platonic entities. We’ve just discussed why the term “language” never refers to language-use. In the upcoming section, we will see why “language” never refers to sets of platonic entities. 
         Language-change is not to be identified with language-use. This fundamental truth is obscured by the fact that the set of events constitutive of language-change overlaps to a large degree with the set of events constitutive of language-use.
        The word “language” is indeed ambiguous – but not in the way that Lewis thinks. The expression “the English language” sometimes refers to set of semantic rules that are operative at a given time, and  it sometimes refers to a series of such sets. In the sentence “people use language to communicate with one another”, the word “language” is being used in the first way. In the sentence “languages change over time”, it is being used in the second way. In the first case, the word “language” refers to a condition that obtains during a relatively short period of time. In the second case, it refers to a series of such conditions. In each case, the word “language” refers to a spatiotemporal phenomenon. In neither case, therefore, does it refer to anything platonic.
       Henceforth, we will use the term “language” – and “English”, “Spanish”, “Chinese”, and so forth – to denote single sets of semantic rules, not sequences of such sets.  
  
Why the function-theoretic approach to language is wrong 


         So far I have asserted without argument that semantic rules are spatiotemporal entities and are therefore not to be understood as mathematical functions from physical tokens to truth-values or properties. It is not hard to supply the needed argument. 
        Given any two objects, there is some set or ordered pair consisting of them. The ordered pair <”Plato”, Richard Nixon> exists no less than the ordered pair < “Plato”, Plato>. There  is no semantic rule that assigns Richard Nixon to “Plato.” Obviously, the existence of the just mentioned ordered pair is not enough for that. By parity of reasoning, the semantic rule that assigns Plato to “Plato” cannot be identified with the ordered pair < “Plato”, Plato>. 
      There is a rule or function that assigns truth to the sentence “Plato was wise” exactly if Plato was wise. But there is also a function that assigns truth to the sentence “Plato was wise” exactly if Richard Nixon was wise.  There is no English semantic rule to the effect that “Plato was wise” is true exactly if Richard Nixon was wise. So given only that there is a function of the kind just described, it doesn’t follow that there is a semantic rule assigning truth to “Plato was wise” exactly if Richard Nixon was wise. It follows that semantic rule assigning truth to “Plato was wise” exactly if Plato was wise cannot be identified with a function that assigns truth to that sentence (or, more exactly, to tokens thereof) exactly if Plato was wise. For exactly similar reasons, the semantic rule that assigns the proposition, or meaning, Plato was wise to (occurrences of) “Plato was wise” cannot be identified with any ordered pair (with, for example, the ordered pair < “Plato was wise”, Plato was wise> or with any mathematical function that assigns that proposition to instances of that physical type. 
       Obviously the semantic rule that assigns Plato was wise to “Plato was wise” does exist. But, as we have just seen, that semantic rule cannot be identified with a mathematical function or, equivalently, with an ordered pair of some kind.[242] 
        One might counter-respond by saying: 


      Given only that the pair <“Plato”, Richard Nixon> exists, it does follow that “Plato” refers to Richard Nixon, i.e. it follows that it refers to it in some possible but unused language. And given that there is an abstract function that assigns truth to “Plato was wise” just in case Richard Nixon was wise, it does follow that “Plato was wise” means Richard Nixon was wise, i.e. it follows that it means it in some possible but unused language. 


       The expression “possible but unused language” is a veritable synonym of “non-existent, but possibly existent, language”, and this counter-response is therefore purely verbal. 
        For the sake of argument, let us suppose that the objector is right; let us suppose there is some language, albeit an unused one, containing a semantic rule R whereby  “Plato” refers to Richard Nixon. Right now people couldn’t possibly use R. Right now, if you used “Plato” to refer to Richard Nixon, you would simply be mis-speaking. 
        Of course, we could imagine the English language evolving in such a way that “Plato” became a name for Richard Nixon. But that evolution would involve creating conditions that allowed people to refer to Richard Nixon as “Plato.” It wouldn’t consist in people simply using R. If it exists, R is not available for the using. And if it ever becomes available for the using, that is not by virtue of the mere existence of the ordered pair < “Plato”, Richard Nixon>, but because the system of communication used by speakers of English will have undergone some kind of structural change. But in that case, it is the resulting structural condition, not the ordered pair, that makes it possible to refer to Richard Nixon as “Plato.” At no point does anyone manage to refer to Nixon by using that ordered pair. 
      What we just said about that ordered pair is true of any abstract structure – it is true of an abstract function that assigns truth to ┌Plato has phi┐ exactly if Richard Nixon has phi. The idea that semantic rules are purely function-theoretic entities is thus a non-starter. 
 
The Gricean approach


         Given only that the function-theoretic analysis of meaning is wrong, 666 it doesn’t follow that the concept of expression-meaning is to be understood in terms of that of speaker’s meaning. It is the other way around: the concept of speaker’s meaning must be understood in terms of that of expression-meaning. 
       As Searle showed (1969), one can affirm that Plato was wise with the sounds “Plato was wise” only if the latter already means the former. In general, one can affirm P by means of S only if S already means P. 
        Of course, to affirm P, one doesn’t have to use an expression that has P for its literal meaning. I may convey the proposition your wife is having an affair with the sentence “sometimes things aren’t as they seem.” But that is because, the circumstances being what they are, there is an existing symbolic relationship – albeit not one 666 of literal meaning -- between that sentence and that proposition. 
       A consequence is that one can try to affirm only that Plato was wise with the sound “Plato was wise” only if one believes that the latter means the former. In other words, one can mean the proposition Plato was wise with utterance of “Plato was wise” only if one believes that the latter already means the former. In general, one can mean P with S only if one believes that S already means P.
       It doesn’t follow that, in order to mean P with an utterance of S, one must believe that S literally means P. (Here we need only echo what we said a moment ago.) I can 666 mean the proposition your wife is having an affair with the sound “sometimes things aren’t as they seem.” But that is because I believe that, the circumstances being what they are, there is an existing symbolic relationship – albeit not of literal meaning -- between that sentence and that proposition.
         So one cannot affirm P with S unless S already means P; and one cannot even try to affirm P with S unless one believes that S already means P. Thus, in direct opposition to what Grice held, the concept of speaker’s meaning is thus to be understood in terms of that of expression-meaning.[243]
        Griceans respond to this by saying that expression-meaning is “conventionalized” or  “fossilized” speaker’s meaning. According to this view, Grice’s analysis shows how it is that “snow is white” came to mean snow is white. But now that “snow is white” has that meaning, we don’t have to suppose that what it means coincides with what people mean by it. Its meaning is to be understood not in terms of speaker’s meaning, but rather in terms of conventions. In their turn, those conventions are to be understood in terms of speaker’s meaning. This is Simon Blackburn’s view.[244]        
      But to say that linguistic meaning is “fossilized” or “conventionalized” speaker’s meaning is to admit that linguistic meaning is constituted by conventions, and it is thus to admit that linguistic meaning is ultimately not speaker’s meaning. Thus, if speaker’s meaning is conventionalized speaker’s meaning, then Grice’s analysis provides, at most, a causal or historical explanation as to how it is expressions came to have the meanings they currently bear. But here we are not looking for a causal-historical explanation as to how E came to have meaning M. We are looking for an analysis of what it is for expression E to have meaning M, and such an analysis is not to be found in the supposition that linguistic meaning is fossilized speaker’s meaning. 
       We have to distinguish the question “what is it for ‘snow is white’ to mean snow is white?” from the question “how did ‘snow is white’ come to mean snow is white?” The view that linguistic meaning is conventionalized speaker’s meaning provides no answer to the first question, and is thus irrelevant as a hypothesis as to the nature of linguistic meaning. We may conclude that Grice’s view is wrong. 
          But we’ve already seen why, given the erroneousness of Grice’s view, it does not follow that the function-theoretic view is the right one. There is a third view: semantic rules are relatively stable psycho-sociological conditions. We’ve already seen the merits of that view. Thus, a false dichotomy is involved in the inference, implicit in much modern semantics, from “Grice was wrong” to “languages are platonic abstracta.” 
       
 Chapter 21 Another argument against LOT: the concept of non-conceptual content 


       There is one problem with LOT that we haven’t yet discussed. In my view, it is the most significant of the many problems with that doctrine. (In this context, the term “sentence” will cover both sentence-types and sentence-tokens.)
         Consider the sentence: “the cat is on the mat.” The meaning of that sentence is what is referred to as a “proposition.” Presumably, propositions have structures at least approximately like those of the sentences that express them.[245] 
        In fact, this last statement appears to be a tautology. A sentence must belong to this or that particular language – it must be a sentence of Chinese or English or French. Where there isn’t a systematic way of assigning propositions to sentences, there is no language. Where there is such a system, there is ipso facto a function that establishes an isomorphism between sentences and proposition. And where there is such a function, there is ipso facto a resemblance between sentences and propositions. 
        In any case, it seems overwhelmingly likely that the proposition expressed by “Caesar killed Brutus” has a constituent corresponding to Caesar, to the relation of killing, and to Brutus. [246] (As we will see later, there is more to that proposition than that – otherwise it wouldn’t be different from the proposition Caesar killed Brutus or from the unordered set (Caesar, the relation of killing, Brutus). But we will deal with these issues later in this chapter.)
      The fact that sentences decompose into a finite number of discrete parts constitutes a serious problem for LOT. Much information is not digital. Consider your current visual perception. It doesn’t decompose into minimal units of significance. Suppose you actually saw Smith punching Jones. Your perception of that event involved a perception of various segments of the cigar. But Smith was not a minimal or otherwise discrete part of the representational content of that perception; and no concept, or Fregean sense, of Smith was such a constituent. What we just said about Smith is true of Jones and the relation of punching. Indeed, it is true of anything that is the semantic content of any one of the expressions composing a sentence that describe the state of affairs in question. 
        Your perception of Smith involved perceptions of parts of Smith’s body. Indeed, it involved a sequence of such perceptions. Each of these perceptions involved yet other perceptions. Of course, you don’t have an infinitely high-resolution perception of Smith: you don’t see his micro-structure. But even though your perception of Smith does break down, it doesn’t break down into discrete units of significance. Even if your perception does have minimal parts – even if (as Hume implausibly maintained) there are minima visibile – these very much seem not to combine in a way at all comparable with the way in which “Smith”, “Jones”, and “punched” combine into the sentence “Smith punched Jones.” It is thanks to the operation of recursive rules that components of that sentence combine into a meaningful whole. But it is hard to believe that similar recursions are what combine your perception of Smith’s knee with your perception of Smith’s shirt with your perception of…into a visual perception of Smith punching Jones. I will argue that such recursions are indeed not operative.
      Our sense-perceptions are analogue-representations. The information that forms the mind-world interface is analogue, not digital. Unless appearances here are radically deceptive, that information does not have a (unique) decomposition into meaningful significant units. 
       Most information is not digital. We will see that digital information is parasitic on analogue information. The former is a “digitization” of the latter. The latter is not an “analogicization” of the former. 
         Sentences are, by definition, digital structures. A sentence consists of a finite number of minimal and mutually discrete units of significance. So far as thought is mediated by sentences, cognitive content has a digital, not an analogue, structure. Given this, it is hard to see how a visual perception could consist of a sentence-tokening or a set of such tokenings. 
       In any case, to make a case that perceptions did have such a structure, one would either have to use an extremely broad conception of “sentence” – one that, for reasons similar to those discussed earlier, would trivialize the claim in question – or one would have to have made some fantastic discovery about the structure of visual perception: a discovery that could not possibly be made on the basis of a visual perception’s phenomenology, and that would have to be made on strictly theoretical grounds. But since a visual experience is a bit of phenomenology, it is hard to see how contrary to what phenomenology tells us any theory could possibly show us that it had a structure contrary the one it appears to have. At any rate, it is a highly reasonable -- though, conceivably, defeasible -- presumption that perceptions don’t have structures comparable to sentences. 
         It is also hard to believe that all post-perceptual mental content is digital or, therefore, sentential. Of course, some post-perceptual output is sentential. (We say things in response to what we see, hear, and so on; and such utterances are, by definition, sentential.) But much of it is not. We dream, we fantasize, dream, we create paintings: these involve the generation of analogue, not digital, representations. 
      Conceivably, one could say that, intervening between input and output – between our perceptions and (say) the dreams that oftentimes “replay” those perceptions – are strictly digital processes. The idea would be that perceptual information is immediately digitized; that digital information interacts with other stored information; and then dreaming, or otherwise visually imaging, involves a “re-analogicization” of that digital information. But, it may safely be said, such a hypothesis is not a very natural one; and it seems more reasonable to suppose that, to at least some degree, at least some post-perceptual information is analogue 
       Also, our emotional, aesthetic, and ethical reactions seem not to have sentential structure. They seem to be amorphous and lacking in structure, at least from the viewpoint of someone who takes sentences as paradigms of information-bearing structures. Of course, some have said that aesthetic and emotional reactions are meaningless – that, in liking Mozart’s music more than Salieri’s, one’s ideation is to no degree principled and is only causally related to the stimuli that produced it. But such a view would strike many as a less than accurate representation of the facts. 
        One could make the following objection to this last argument: 


        You are confusing aesthetic and moral reactions per se with the phenomenological expression of such reactions. Obviously the pleasant feeling that Mozart’s music creates in you doesn’t have a digital structure. But that feeling is merely a phenomenological expression of an underlying judgment that is not comparably amorphous. 


       But the phenomenology is surely constitutive of the aesthetic reaction, and is not merely an effect of it. This is not to say that every affective response you have to a piece of music is constitutive of a genuinely aesthetic response to it. A piece of music can trigger an emotional reaction that has nothing to do with your estimation of its merits. But it is hard to believe that all music-induced phenomenology is in this category. It seems that a being that had no phenomenological reaction to a piece of music (apart from those that are purely perceptual) would fail to have an aesthetic reaction to it. So it is not an option to say that one’s aesthetic reaction to a performance of the 21st piano concerto has a digital structure, given that the phenomenological aspects of one’s reaction obviously don’t have such a structure.
      At the same time, it is very unnatural to say that aesthetic reactions are strictly subjective. Aesthetic reactions track objective realities. Within limits, one is right to like certain compositions more than others. Schubert’s music is liked much more now than it was in his life-time (even after we set aside the social conditions that made it hard for him to have music widely performed). Surely this is because Schubert was ahead of his time musically, and not because people just happened to have a change in taste. 
        Given that aesthetic reactions strongly appear not to have a sentential structure, what we must say is not: “aesthetic reactions are completely subjective; no musical compositions are better than others; no one is a better composer than anyone else.” Rather, we what must say is: “awarenesses of objective fact are not always embodied in sentential or para-sentential structures.”
        In my judgment, the nihilistic views about aesthetics and ethics that were advocated by the positivists were expressions of the view that anything truth-evaluable must be sentence-like. Given how counter-intuitive it is to suppose that no musical compositions are better than others, or that no acts are morally better or worse than others, this alone should make us re-think the idea that mental content is sentential or para-sentential.
       But what is more important than any of the arguments just given is the obvious fact that our perceptions, and para-perceptual entities such as mental images, very much seem not to have a structure remotely comparable to that of sentences. Given that such experiences are obviously representational, it becomes hard to see how mental representations could categorically be sentential in nature. And supposing that we are right to hold that perceptions have a non-digital, non-sentential structure, we are clearly not dealing with just any class of exceptions to LOT. We are dealing with a class of exceptions that strike at the root of that doctrine, given how important perceptions are to our understanding of external reality. 
         I would now like to show that sentential contents must be highly derivative representations and that, in fact, they must be distillations of non-digital information. My arguments will be strictly metaphysical in nature, and will not rely on the results of experimental or even introspective psychology.


The McDowell-Evans debate 


         Let us begin with a few points about the history of the problem that we will be discussing. Gareth Evans (1982: 122-129) deserves credit for making the distinction between “conceptual and “non-conceptual” content. By “conceptual”, Evans meant “propositional”; and by “non-conceptual” he meant, “non-propositional.”
       Given this distinction, the question immediately arises as to whether we are dealing with two fundamentally different kinds of content or only with two different conceptions or representations of what is, ultimately, some one kind of content. Evans held that “non-conceptual” content is not conceptual content in disguise – that it must be understood on its terms, and not in terms of the sentences (or propositions) in terms of which it can, to at least some degree, be embodied. 
         Evans’ argument for this position is as follows. Perceptions are much more “fine-grained” than sentences. What you see is never just red. It is always some hyper-specific shade of red. Since language uses broad rubrics like “red”, it fails to do justice to the structure of perception. 
       McDowell (1994) has a famous counter-argument. We can refer to anything that we see – e.g. any specific shade of red – with a demonstrative expression (“that exact shade of red”). In this way, according to McDowell, Evans’ argument is neutralized. 
       Of course, McDowell is quite right that one can refer to anything that one sees. But it doesn’t follow that the structure of a sentence is at all like the structure of a perception. If anything, the exact opposite follows. Suppose that I use the expression “that exact shade” to refer to some specific shade of red that I am seeing. The expression “that shade of red” obviously doesn’t have a structure comparable to my perception of the red surface in question. The former decomposes into the words “that”, “shade”, and so on. The latter does not so decompose. 
         One can invent new words to refer to specific shades of red (and sounds and fragrances and…) that one experiences. For example, I might stipulate that “R” is to refer to some specific shade of red that I am now seeing. Being a simple expression, “R” has no semantic structure. But surely my perception of the red surface in question is not completely without any articulations. 
       The spuriousness of McDowell’s argument is seen by giving an argument exactly analogous to it. Pointing to some elephant, I say “that elephant weighs over a ton.” Here I have used to a demonstrative expression to pick out some specific elephant. But my perception of the elephant obviously doesn’t have a structure comparable to that of “that elephant.” Given only that I can refer to specific objects and property-instances that I see, it doesn’t follow that sentences are representationally similar to perceptions. So it doesn’t follow that perceptions are not fundamentally different from sentences; and it doesn’t follow that the contents of perceptions are not fundamentally different from the contents of sentences (propositions).
        Also, even though they often refer to what is maximally specific, indexical expressions operate by way of general rubrics. I point to a red rose and say “that shade of red is lovely.”  My utterance of “that shade of red” refers to some specific shade of red. But it secures that reference by using the sortal terms “shade” and “red.” So even though that utterance refers to some specific shade of red, it semantically decomposes into a part whose semantic content is the concept red, another part whose semantic content is the concept shade, and so on. But a perception of a shade of red does not have a comparable decomposition. 
       In this context, we must take care to distinguish tokens from types. A token of ┌that phi┐ may have for its content a specific shade of red. But the content of the corresponding type is given by the rule: 


(T) A token of ┌that phi┐ refers to the contextually salient phi 


or, equivalently: 


(T*) If, in context C, there is exactly one salient object x having phi, then a token of ┌that phi┐ in C refers to x. [247]


        A token of “this shade of red is darker than that shade” may compare two maximally specific, perceptually present shades. But the rules that assign meaning to such a token involve only general rubrics, e.g. red and distal object. So, from a semantic viewpoint, that token is built out of general categories. But the content of your visual perception of a dark red car next to a light red car seems not to decompose into the concepts dark, light or red. In fact, the content of that perception seems not to decompose into any concept into which the semantics of a sentence-token used to report that content would decompose. So even if a sentence-token attributes a specific property to a specific object, the content of that token decomposes into general categories. Since the same appears not to be true of sense-experience, we have reason to believe that there are fundamental differences between linguistic and perceptual representations. 
        McDowell (1994) has another argument against the viability of the distinction between conceptual and non-conceptual content. People can say what they see, hear, and so on. I see Smith punching Jones. I can report this fact: I can say “Smith punched Jones.” Perceptual content can be verbalized. Therefore the information borne by sentences must either be identical with, or significantly similar to, that borne by perceptions.[248] 
         This argument is really a generalization of the first argument, and it is therefore no surprise to see that it involves the same non-sequitur. Given only that we can articulate what we sense-perceive, it doesn’t follow that sentential content is structurally similar to perceptual content. A curve can be represented as a series sequence of line-segments. But a curve is not a sequence of line-segments. 
          One might counter-respond by saying the following: 


     But any finite series of line-segments is, at best, an approximate representation of a curve; and any non-approximate representation of a curve would have the same structure as that curve.  


       But this exposes an even deeper problem with McDowell’s second argument. It very much seems that any sentence is, at best, an approximate representation of the information borne by any sense-perception. Suppose that I see Smith punch Jones, and I then say “I saw Smith punch Jones.” First of all, I cannot just see Smith. I can see Smith only by seeing a state of affairs involving him. Similarly, I cannot see any instance of the relation of punching except by seeing a state of affairs in which such an instance is embedded. 
       Consequently, if I say “I saw Smith punching Jones”, my statement is, at best, an extremely approximate and course-grained representation of the content of my visual perception. Of course, that statement does put some limits as to what the representational content of my perception was. But I am by no means pinpointing that content. (If I were to draw a giant box around a small rock, I would be putting some limits as to the size of that rock, but not very specific ones.) 
        Of course, the approximateness of my verbal representation can be lessened. I can say: “I saw Smith punch Jones; and Smith was wearing a green shirt and he looked sweaty and upset…” By adding more and more verbiage, I can narrow the gap between sentential and perceptual content. But it very much seems that, given any finitely long verbal description of what I saw, some content will always be left out – just as, given any finite number of line-segments, the exact shape of the curve will not be represented. It thus seems that Evans’ fineness of grain argument ultimately prevails. (Later I will try to substantiate our intuition that any finitely long sentence will always leave out some perceptual content.) 
         McDowell might counter-respond by pointing out that I can use a demonstrative-expression to refer to the exact content of my visual perception. I can say, for example,  “I will never forget the content of this visual perception.” But this counter-response wouldn’t support McDowell’s position, since the expression “this visual perception” doesn’t have a structure remotely comparable to its referent. 
        As Russell (1956) pointed out, at least one of the expressions composing a sentence must correspond to a universal. So the content of any given sentence is built up out of general rubrics. Since the same appears not to be true of the content of any sense-perception, it would seem that sentential content is structurally different from perceptual content. 
         
Some other differences between iconic and sentential representations 


        It is not hard to find support for the view that perceptual content is fundamentally different from sentential content.[249]  Consider the operations that can be performed on sentences – disjunction, conditionalization, negation, generalization, and so on. These operations cannot be performed on maps or on other graphical representations. You cannot form the disjunction of two maps. 
          Of course, maps A and B can be disjoined if you stipulate that A and B are equivalent to sentences (or series of sentences) S and S*, and that juxtaposing those two maps in a certain way tokens the disjunction of S and S* But in that case, as Rescorla (2003) points out, A and B are no longer functioning as maps. By the same token, A and B would cease to function as sentences if you were to consult the internal structure of A to find out how to drive to Bakersfield.[250] None of the recursive operations that can be performed on sentences can be performed on maps. 
        But this is only a special case of the more general principle that no recursive operation that can be performed on expressions of any kind can be performed on maps.  A sequence of maps doesn’t compose a sentence. Of course, one could stipulate that an expression meaning x is larger than y results if a map of x is placed to the right of a map of y. But such a juxtaposition of maps would not itself be a map and, in that context, the two maps in question would be functioning as maps. 
       These points about maps correspond to points about visual perceptions. Like maps, visual perceptions are analogue-representations. Two visual perceptions cannot be conjoined or disjoined or negated. More generally, none of the recursive operations that can be performed on expressions can be performed on visual perceptions. This suggests that the information encoded visual perceptions is fundamentally different from the information encoded in sentences. 


        


Chapter 22 Propositional structure and the ineliminability of non-conceptual content 


         I would now like to develop the arguments given in the previous chapter. Consider the sentence (or sentence-token): 


(*) “Smith has red hair.” 


        It is said that “Smith” denotes an “individual.” Notice that, etymologically, “individual” means undividable. But from a metaphysical and also a representational point of view, so-called individuals, like Smith and Jones, are anything but undividable. (If, like Plato, you believe that souls are indivisible, then assume that “Smith” and “Jones” refer to rocks or plants.) And yet from a linguistic point of view they are undividable: “Smith” and “Jones” are minimal, undividable units of significance. 
        In this section, I want to show that LOT cannot be right, the reason being that language must necessarily represents as fundamental what is extremely derivative from the viewpoint of how we mentally represent the world. Even though, linguistically, “Smith” is a minimal unit of significance, Smith himself is best thought of, not as an “undividable” or even as a thing at all, but rather as a property of sequences of sets of properties of properties. And even though “red” is semantically basic, neither the property of redness nor any instance thereof is in any sense fundamental. Instances of properties, I will argue, are abstract commonalities holding among situations; they are not components of situations. The world isn’t built up out of instances of properties; and our perceptions of the world are not out representations of such instances. (Your perception of the red square doesn’t consist in a perception of an instance being red conjoined with a perception of squareness.) But any sentence necessarily decomposes into units that represent these highly derivative entities (if “entity” is even the right word: see below) as basic. 
  
Properties versus hyper-properties 


        First of all, the term “red” doesn’t denote anything of which there could possibly be a spatiotemporal instance. No fire-truck or rose or pool of liquid is just red: it is some specific shade of red. (There are no general terms indicating the exact shade of any specific red object. One must use demonstrative expressions to indicate any maximally specific shade of red – any kind of redness that can actually be seen.) 
       What we generally refer to as “properties” are actually properties of properties. Suppose that R1 is the specific shade of red object had by object x1 (some fire-truck), that R2 is the specific shade had by x2 (some rose), and so on. R1 is something of which there could be, and are, instances in the spatiotemporal world; the same is true of R2, R3, and so on. By contrast, the thing denoted by “red” is something that R1…Rn have in common. So “red” denotes a property of properties, not a property simpliciter. 
       There is no denying that R2 is a bona fide case of a property. In virtue of having that specific shade of red, the rose surely has a property. Of course, what we just said about R2 is true of Ri, for any i. At the same, each of R1…Rn is itself an instance of redness. Thus, redness is a property of properties; it is a hyper-property. 
       There is some property that all and only those objects instantiating R1 have in common, the same being true of Ri, for arbitrary i. So far as there is some property that all and only red objects have in common, that is by virtue of there being some property that all and only R1…Rn have in common. x1 (the fire-truck) and x2 (the rose) don’t have quite the same color. Strictly speaking, they have different colors. (Language is approximate in so far as it puts them in the same color-category.) 
          In any case, it is a datum that x1 and x2 differ chromatically. It is a datum that the difference between them is comparable to, though much smaller than, the difference between a blue and a green object. The difference between x1 and x2 is to the chromatic difference between a diamond and an emerald what the difference between 3.1 and 3.2 is to the difference between 2 and 978,965. We are dealing with different degrees of some one kind of difference. 
       So x1 and x2 have different colors. (Anyone who described  x1 and x2 as “having the same color” would be speaking either loosely or inaccurately.) So far as x1 and x2 are similar in respect of color, it is because R1 and R2 have something in common. So far as they both fall under the rubric “red”, it is because their colors have a common property. So “red” denotes property had in common by different colors. Redness turns out to be a property of properties.[251] 
          What we just said about “red” is true mutatis mutandis of any predicate that one would find in any natural language. So far as there exist natural-language predicates that denote properties of spatio-temporal entities, as opposed to properties of such properties, it is in virtue of the occurrence of some demonstrative expression (“that exact shade of red”) or some artificial extension of a language (such as our introduction of the predicates “R1”, “R2”, and so on). 
      Neologisms such as “R1” must be defined by means of demonstrative expressions (e.g. expressions like “that color”). As we saw in the last chapter, even though a token of “that exact color” picks out R1, or some other specific color, it secures that reference by way of general rubrics (e.g. color and distal object). So the content of an expression either decomposes into general rubrics or it must be understood in terms of such rubrics. For reasons that we’ve already considered, this suggests that sentential (and therefore propositional) content is fundamentally different from perceptual content. 


Why property-instances are abstract entities


        Let r1 be a specific instance of R1. r1 is not a constituent of the situation in which it is found. There will never be an instance of color without an instance of shape or an instance of temporal (or spatial) location. Language separates out what are, in actuality, completely inseparable. The color of the rose cannot be detached from its shape or its location. 
       Situations are not assemblages of property-instances. On the table, there is an object that is square and green. Let S be this situation. S is not composed of an instance of greenness (or of some specific shade thereof), and an instances of squareness, and an instance of being on the table. When we verbally describe the situation, we use different terms to denote these different property-instances. But the composition of the sentence isn’t comparable to the composition of the situation. 
       There couldn’t be an instance of squareness that wasn’t an instance of a certain size and instance of having a certain location. We use sentences to describe situations. But situations are not structured in the same way as sentences. The question then arises as to how sentences can be even approximately accurate representations of situations. Ian Hacking (1975) refers to this as the “articulation problem.” 
      What we just said about situations is true mutatis mutandis of our perceptions of them. Seeing that there is a box of a specific color and shape on a specific table does not consist in producing a mental representation of multiple property-instances and then assembling them. Your seeing the box on the table does not, and could not, consist in your having a mental representation of some specific shade of green, and also of some specific shape, and then somehow putting these representations together. 
       Of course, you don’t have to see the box as green. You might see it as red. But what we just said (mutatis mutandis) would apply to this situation: your seeing the box wouldn’t consist in your combining a mental representation of an instance of squareness with a representation of an instance of redness. Perceptions are not assemblages of representations of property-instances. 
         
The consequences of these points for SCT


       But if we thought in a language, your seeing the box would consist in exactly such an act of assemblage. Any sentential representation of S will separates out what cannot possibly be separated in S itself, or in any perceptual representation thereof. A sentential description of S will inevitably have one word denoting one property-instance, a separate word denoting a separate-property instance, a separate denoting the table (or, at any rate, separate words denoting the various property-instances constitutive of the table). It makes no difference, in this context, what kinds of properties the expressions in question denote. They can denote bona fide instances of spatiotemporal objects (e.g. they can denote specific colors and specific shapes); or they can denote properties had in common by such specific properties (“green”, “rectangular”). Either way, what will be fused in the situation, and in any perceptual representation thereof, will be separated in the sentence. 
       An obvious consequence is that a linguistic representation of the situation consists in cobbling together distinct expressions that denote what are, in the situation and also in a perception of the situation, inseparable entities (for lack of a better word). So supposing that mental representation consisted in the tokening of sentences, seeing S would consist in your (at some level) assembling a visual representation out of an expression denoting a specific color, and a separate expression denoting a specific shape, and so on. But, as we’ve seen, it is literally absurd to suppose that this is how it works. 


The concept of a property-instance 


     Since instances of properties are not detachable parts of situations, they are better thought of as ways as “dimensions of similarity.” For two situations to instantiate some property is for them to be similar in some respect. Their being similar doesn’t follow from their instantiating that property. Rather, I will argue, their being similar along some dimension is their both instantiating that property. 
      Obviously expressions like “instance of squareness” and “instance of R1” (where R1 is a maximally specific shade of red) meaningful. But given any instance of any property – given anything that can be described as an “instance of R1” – that instance cannot be distinguished, except in a purely notional sense,  from various instances of what are obviously different properties. Given some specific instance of R1, that instance cannot be distinguished, except via a process of abstraction, from a certain shape and from a certain location. So to the extent that it denotes an isolable entity, a token of “that instance of R1”, or of “that instance of red”, denotes a kind of abstraction, and does not denote a constituent of the spatiotemporal world. (What is such a constituent is the situation in which that instance is embedded.)       
       According to Russell (1905, 1918), a significant noun phrase that denotes a “purely notional” entity is one that doesn’t denote anything, and that must be understood contextually. “The average person” is obviously a significant expression. We could say that it denotes a purely “notional entity” or an “idealization.” But this would just be a dodge. When you say that “the average person needs more than four hours of sleep a night”, you are not saying that an idealization needs more than four hours of sleep a night: abstract objects don’t sleep. There is no x such that you are saying of x that x specifically needs only four hours of sleep. 
       Evidently, “the average person” isn’t significant by virtue of picking some object out. It is significant by virtue of the fact that there is a rule assigning meaning to sentences of the form ┌…the average person…┐[252]
        If, as we’ve argued, expressions like “instance of red” and “instance of R1” denote (so to speak) purely notional entities, then they don’t denote anything and must be understood contextually. 
       Another example may be appropriate. The expression “the temperature of this object” is obviously significant, and that is why it can be a part of meaningful utterances, e.g.: 


(a) “the temperature of this object is greater than the temperature of that object.” 


But no occurrence of “the temperature of this object” denotes an entity. (a) doesn’t say that one thing is greater than some other thing. The definite descriptions in (a) are to be understood contextually. And when we produce a sentence that perspicuously represents the proposition affirmed by (a), the result is a sentence that says how two things compare in some respect. I would suggest that what is true of the expression “the temperature of this object” is true in general  true of expressions that, so to speak, refer to instances of properties. Such expressions don’t refer to anything; and the propositions affirmed by sentences containing them concern how one situation compares, in some respect, with some other situation.[253]
         Any sentence 666 belonging to anything that is uncontroversially a language contains at least one expression referring to a property. So if, as advocates of LOT hold, we think in sentence-tokens, then any (truth-evaluable) mental representation consists xxx of a sequences or juxtaposition of discrete entities, at least one of which denotes an instance of a property. My seeing the green round thing on the table consists in (inter alia) some word-token denoting an instance of a certain color being juxtaposed with a word-token denoting an instance of a certain shape. But such a view doesn’t seem to be true to the actual composition of my perception. 


Expressions denoting individuals 


        What we said about property-instances, and our mental representations thereof, applies with extra force to so-called individuals. Let us once again consider our paradigm:


  (*) “Smith has red hair.” 


       Semantically, “Smith” (the expression, not the person) is a simple entity, the same being true of any proper noun. But from the viewpoint of metaphysics and also of perceptual representation, Smith is not a simple entity. In fact, it isn’t even clear if, from those viewpoints, he is an entity at all.[254] (Once again, if you believe that people are indivisible, or otherwise metaphysically special, then suppose that “Smith” refers to a rock or a carrot.) 
          During any given interval of time, Smith’s existence supervenes on the occurrence of innumerable events – psychological, metabolic, cellular, molecular, atomic, and ultimately sub-atomic. At any given instant, i.e. during any arbitrarily small period, Smith’s existence can thus be though of as a set of states of affairs.  (Here the word “set” is being used in a loose sense.) Thus Smith’s existence as a whole, i.e. from this birth to his death, is realized by a sequence of sets of states of affairs. So Smith is anything but a simple entity. 
         Given any event E involving Smith, E’s occurrence supervenes on those of innumerable lower-level states of affairs. More precisely, E occurs in virtue of the fact some causal sequence, consisting of a series of sets of states of affairs, acquired some property that it didn’t previously have. So if it is true, “Smith suddenly realized that 7+5=12” holds in virtue of the fact that some pattern of mass-energy displacements took a new turn. In terms of metaphysics (though not of semantics), the occurrence of “Smith” in that sentence parses out. 
        Smith is only notionally separable from the various processes that constitute him. For the reasons given a moment ago, it follows that occurrences of “Smith” ultimately parse out – like occurrences of “the rod’s having a temperature of 78°” is true of “Smith” and “the average man.” 
         We saw earlier why Smith must be represented in terms of a description, even though (if direct-reference theorists are right) “Smith” is semantically simple. So, in thought, Smith is not represented as simple. This point of ours, as well as our arguments for it, may not meet with universal acceptance.  But what cannot reasonably be debated is that, in perception, Smith is represented only in so far as some situation in which he is embedded is represented. Thus, considered as an isolable entity, Smith is a non-entity from the viewpoint of sense-perception. 
      
Revisiting the distinction between data and meta-data


         This line of thought relates to a point that we defended in Chapters 4. When someone says that he saw Smith, he is making a judgment about what was given to him in a visual perception; he is not giving a mere report as to what was given to him.[255] What was actually given to the percipient in sense-perception is, at most, some piece of existential information that Smith satisfies. 
        Let us discuss the nature of the judgment just referred to. (Doing this will involve a brief repetition of points made in Chapter 1.) Smith has an identical twin, Twin-Smith. Twin-Smith is now in Finland. You are now in Delaware, and so is Smith. You know all of this. You see Smith. As we discussed, given only the information encoded in your visual perception, you could just as well be seeing Twin-Smith. When you say (correctly) “I saw Smith, not his twin”, you are not merely reporting what you saw; you are making a judgment about what you saw, and that judgment incorporates your knowledge that Twin-Smith is in Finland. What is given to you in sense-perception is not Smith is wearing a green shirt but is (so far as it can verbalized) more along the lines of:  something x, standing in a certain place, and having such and such features, is wearing a green shirt. When you judge that you saw Smith, you are judging that Smith is the one who satisfies that description, i.e. that he is the right value of “x.” 
        But what is it for Smith to satisfy this description? Smith’s satisfying that description consists in its being the case that the state of affairs that is given to you in your perception has a certain continuity with other states of affairs; and Twin-Smith’s not satisfying that description consists in its not being the case that the state of affairs that is given to you in your perception has that same kind of continuity with those states of affairs. 
         Smith is not hidden behind a veil consisting of some state of affairs. Given only that you must judge that you are seeing Smith, and that this fact cannot be encoded in strictly perceptual information, it doesn’t follow that your senses are imperfect or that sense-perception is a flawed medium. What follows is a fundamental metaphysical fact about Smith. Smith’s being the person in the green shirt consists in its being the case that there is some state of affairs that has a certain continuity with other states of affairs. 
       Suppose that your sense of sight is maximally good – that you see as well as it is nomically possible for any being to see. And suppose that you witness every moment of Smith’s life from birth to death. For the reasons given a moment ago, your saying “I saw Smith today” on Monday will not be a case of your simply reporting what was given to you in your Monday-perception. Even though you see everything that there is to be seen, the information encoded in your Monday-perception will be given by an existence-claim that, in principle, could be satisfied by somebody other than Smith. Even under these idealized circumstances, when you say “I saw Smith on Monday”, your statement reflects your knowledge that the state of affairs that you saw yesterday has a certain continuity or causal relation with various other states of affairs. Suppose you confined yourself only to the information encoded in the visual perception that you had yesterday; suppose that you merely reported its contents, and made no meta-perceptual judgments -- even ones that, given your extraordinarily high degree of knowledge, would be extremely conservative. You still wouldn’t use the word “Smith” or any equivalent. Your reportage would be given by an existence-claim. That reportage would describe a situation, but it wouldn’t contain any mention of Smith. And Smith’s satisfying that existence-claim would consist in its being the case that the situation just mentioned stood in a certain relation (a relation involving some kind of causality or continuity) to other situations.[256] 
       With a few exceptions, what we just said about Smith is true of practically anything. It isn’t true of abstract entities. Maybe it isn’t true of instantaneous, sub-atomic mass-energy displacements. But it is true of tables, vases, people, and cats. In fact, it is true of any spatiotemporal entity that lasts for any amount of time.  
      Let us now discuss the relevance of this to LOT. Every human language contains proper nouns (e.g. “Smith”) and noun-phrases (e.g. “the guy over there wearing the green shirt”) that can substitute for proper nouns when the latter are not available. Nothing that is at all like a public language would lack expressions of the kind just discussed. If a representational medium doesn’t contain nouns (or noun-phrases) that refer to enduring entities like Smith, then that representational medium will be very different from anything that is a clear case of a language. 


Why no language could possibly mediate perception or cognition


          Earlier we briefly discussed some reasons why any language must contain expressions denoting broad rubrics, as opposed to perceptible entities. Here we will develop those points. 
          Suppose that there is some proper noun N whose semantic content is some specific situation. Two people who have not both personally witnessed that situation cannot use that noun to communicate with each other – unless, of course, they have some way of indicating what is meant by that noun that does not presuppose both their having witnessed that situation. That second method of communication must itself involve some symbol (or set of symbols) S.  What we just said about N would be true of S: if S’s semantics cannot be understood in terms of situations that both people have personally experienced, then its usefulness as a means of communication between those two people involves some third symbol (or set of symbols) S*. 
        Sooner or later, we must arrive a system of communication that does not presuppose experiences of numerically identical situations. We therefore need a system of communication whose building blocks refer to what is common to different situations: a system whose basic units refer, not to concrete entities, but to abstract commonalities among concrete states of affairs. 
         Given a system of communication of the kind just described, there is no difficulty creating ways of referring to specific situations, even to specific psychological events – events that cannot possibly be experienced by distinct individuals. But reference to such situations will be achieved through symbols that indicate commonalities among distinct situations. I can refer to a specific experience by saying “the pain I am feeling right now, in this part of my foot”; and this expression is meaningful and intelligible to others. But the expression through which I refer to this experience is constructed out of expressions that don’t refer to anything specific and that have for their meanings abstract commonalities holding among different states of affairs. 
         The more a system of communication depends on its users having shared experiences, the less able that system is to say what is not already known. The more abstract the significations of the expressions composing a system of symbolism, the less a system of communication depends on its users having shared experiences. This means that ceteris paribus the more powerful a system of communication is, i.e. the more able it is to impart what isn’t already known, the more abstract the significations of its most basic expressions must be. Ceteris paribus, the more powerful a language is, the less its basic expressions are connected with anything that is found in the spatiotemporal world or, therefore, with anything that can be perceived or otherwise experienced.[257] 
       Thus, languages necessarily invert the structure of though. And given the concept of what a language is, and of what it is for one language to be more powerful than another, it is not an option to say that thought is mediated by a language or indeed by anything that is not as unlike a language as a representational medium could be. 
          What we just said about inter-personal languages is true of intra-personal languages, supposing that they exist. Any instance of communication involves transmitting information to a place (so to speak) where it was previously absent. This may involve the transmission from one mind to another or from one part of a given mind to another part of that same mind. So far as a language’s basic expressions denote concrete situations, that language is intelligible to different entities only to the extent that those entities have had experiences of identical entities. But so far as the latter condition is met, the need for communication plummets, given that, by hypothesis, the sender and the recipient are both in possession of the exact same empirical data. 
       So to the extent that communication between different parts of a mind xxx is necessary, the communiqués in question would be constructed out of expressions that have highly abstract entities for their semantic contents. This means that they would have for their contents things that couldn’t possibly be perceived or otherwise experienced, in any literal sense of that word. So it seems that, whether we are dealing with inter- or intra-personal communication, language inverts the structure of cognitive content. (At any rate, it inverts the structure of one very fundamental kind of cognitive content: the content of experience. It is possible that it is true to some other kind of cognitive content: the kind that one has in virtue of being a linguistic creature.) LOT is therefore inconsistent with the most basic facts about the nature of language.


Individuals as properties of worlds


        In this section I will argue that what we refer to as “individuals” – people, rocks, trees, vases – are better thought of as properties of worlds. This will confirm the points already made about the viability of LOT. It will also provide a basis for the positive answer that we will give (in the next chapter) to the question “what are propositions and how, if it all, are they different from the information encoded in our perceptions?” 
           Suppose that S1…Sn are the various mass-energy displacements occurring in the space-time region occupied by Smith. In that case, any possible world that comprises S1…Sn comprises Smith. So Smith’s existence is realized by or supervenes on the occurrence of  S1…Sn. At the same time, we don’t want to say that Smith is identical with any such sequence; for presumably Smith could have had experiences and done things other than those which he in fact had and did. 
        Nonetheless, Smith is not modally infinitely elastic. There are surely some limits as to how he might have differed. To be sure, he didn’t have to become a lawyer; he could have become an actor instead. But Smith couldn’t have been a rock or a carrot.
        Less trivially, if Kripke’s (1972: 110-115) plausible views on the essentiality of origins are correct, Smith couldn’t have had parents different from those that he actually had. More generally, in any possible world where he exists, Smith’s beginnings must be much the same as they are here. So supposing that s1…sm are the events that, in actuality, initiated Smith’s existence, any possible world where Smith exists is one that comprises either s1…sm or events that are (in some respect) significantly like them. Smith exists in a world W exactly if certain events or states of affairs hold in W – exactly if, to use Kenneth Taylor’s (1998) suggestive expression, W’s “quantum” is “rippled” in a certain way. 
      There is a different way to put this. (Here I am going to use a metaphor that I will soon re-use in my effort to give a precise answer to the question “what are propositions and how, if it all, are they different from the information encoded in our perceptions?”) Suppose that God wanted to make Smith exist in some world W. He would have to wrench W’s quantum in the right way; He would have to make sure that certain mass-energy displacements (or, in any case, certain lowest-level phenomena of some kind of other) occurred. Given a world W* whose lowest-level occurrences are e1…en and where Smith doesn’t exist, it is not an option – even for God -- to make Smith exist in W, if W’s lowest-level occurrences are qualitatively just like e1…en. Just as a metal-worker must dent a sheet of metal in a certain way if he is to ensure that it will be a suitable auto part (of a certain kind), so God must dent W if he is to ensure that Smith exists there. Just as the metal-worker must make the sheet of metal instantiate some property that it didn’t previously instantiate, so God must make W’s quantum instantiate some property that it didn’t previously instantiate. 
         Smith is to worlds what a certain shape is to physical objects (e.g. sheets of metal). Smith is a property of worlds, for Smith to exist in a world is for that world to instantiate that property. 
        Here we must remember what we said about property-instances. Yesterday I saw a green shirt, and I thus saw an instance of green. But I didn’t just seen an instance of green. In seeing such an instance, I necessarily saw an instance of shape; and that instance of shape necessarily had various other properties. So even though I saw an instance of green yesterday, what I really saw was a green situation. In saying that “I saw an instance of green”, I am abstracting from what was actually perceptually given to me.
      Similarly, in saying that I saw Smith, I am abstracting greatly from what I actually saw. What I actually saw was obviously not just Smith, but was rather some complex situation. So far as that situation involved Smith, it was not because Smith was an ingredient of it, but rather because that situation had the right relations with other situations (relations of both of causation and, to a lesser degree, of resemblance). So far as he is an isolable entity, Smith is a feature, not a constituent, of situations. 
        Thus, so far as “Smith”, or any other equivalent term, is a basic constituent of a language, that language represents as basic what is in fact an extremely abstract property of situations. Such a language represents as basic what can only be grasped by abstracting from data that is itself abstracted from perceptual experience.  
          The only things that are not abstract – the only things that are seen or touched - are situations. Situations are not articulated in a way that corresponds at all closely to verbal descriptions of them. The rubrics used by language – “Smith”, “pain”, “red” – do not correspond to anything that could possibly be encountered in a visual or otherwise sensory experience. For this reason, any medium that is at all language-like inverts the structure of cognitive content, at least in so far as that content is perceptual or para-perceptual; and SCT is to that extent incorrect.  
        
Chapter 23 Conceptual content and the structure of the proposition 


          As we noted, Evans held that there is “non-conceptual” content. Others have disagreed. We’ve seen some reasons to think that Evans is right. But to arrive at a definite resolution of this dispute, we must make it maximally explicit what is, or could be, meant by the term “non-conceptual content.” 
          It is a truism that sentences have meaning. (In this Chapter, “sentence” is to be taken to mean “sentence-token”, wherever appropriate.) Further, it is a truism – a matter of terminology – that these meanings are propositions. The question “is there non-conceptual content?” seems to amount to this: “Are there representational entities whose content is not a proposition (or set of propositions) and, further, whose content is, in some fundamental way, not even proposition-like?”
       We’ve already seen that the answer to this question is: “yes.” But, in the present author’s view, no unexceptionable answer to the question “what are propositions?” has ever been produced. And so long as that question remains unanswered, the opponent of non-conceptual content can take refuge in the obscurity of the notion of propositionality.
       I believe that, given some of the points made in the last chapter, we can develop a creditable analysis of what propositions are, and can further undermine the credibility of the view that there is no non-conceptual content. 


What are propositions? The traditional answers


          Let us briefly discuss some of the existing answers to the question “what are propositions?” First, there is Russell’s answer. The proposition meant by “Smith punched Jones” is some kind of a structure that consists of Smith, the relation of punching, and Jones. (Let us set aside the problems relating to the tense-marker.) 
       The problem with this answer is that, while it may be right, it is excessively vague. We want to know what exactly the just-discussed structure is. The most obvious answer to this last question is: “that proposition is the set (Smith, the relation of punching, Jones).” 
      I do not think that, historically, anyone has given this exact answer. But it is worth considering because the problems with the answers that have been given can be understood, up to a point, in terms of the problems with this answer. 
         First of all, if the proposition meant by “Smith punched Jones” is the set (Smith, the relation of punching, Jones), then the proposition meant by “Jones punched Smith” must also be that set. In that case, those propositions would be identical. They are not; so the proposition meant by “Smith punched Jones” is not that set. In general, the problem with the answer being discussed is that it cannot distinguish between distinct propositions that have the same constituents. 
       Many (probably most) contemporary authors do hold that the proposition meant by “Smith punched Jones” is a set. They deal with the problem just discussed by saying that it is a structured set (R. Moore 1995: 101, Cresswell 1985: 446-452, King 1995, 1996, 1997, Perry 2000: 213). So Smith punched Jones is the ordered pair <<Smith, Jones> the relation of punching>, whereas Jones punched Smith is the ordered pair << Jones, Smith> the relation of punching>. In general, propositions are structured sets; and distinct propositions that have the same constituencies are different structurings of those constituencies. 
       There are two problems with this position. The proposition Smith punched Jones is true or false. But the set  <<Smith, Jones> the relation of punching> is neither true nor false.[258] 
         This problem is not necessarily insuperable: if we identify some relation R such that <<Smith, Jones> the relation of punching> has R with respect to all and only those worlds where Smith punched Jones is true, then we can identify <<Smith, Jones> the relation of punching> with that proposition, and we can identify its being true (or false) with its bearing (or failing to bear) R to our world. (Of course, care must be taken that our choice of R doesn’t render this analysis of propositionality trivial or circular.) But advocates of this view have identified no satisfactory value of R. (As we will see, some attempts to do so have been made. But they are not satisfactory.) Consequently, this analysis of propositionality remains programmatic. 
     There is another problem. For the sake of argument, suppose that Smith punched Jones is in fact identical with some structure consisting of Smith, Jones, and the relation of punching. The structure in question cannot consist of Smith’s standing in the relation of punching with respect to Jones. If the proposition Smith punched Jones were identical with some structure consisting of Smith, Jones, and the relation of punching, and that structure were anything like the structure of a situation where Smith punched Jones, then the very existence of that proposition would demand its truth. But that proposition obviously could be false. So if we identify that proposition with a structure consisting of those three things, we must make sure that the structure in question is not the structure does not consist of Smith’s standing in the relation of punching with respect to Jones.
       But if the way in which that proposition arranges Smith, Jones, and the relation of punching is so different from the way in which those three things would be arranged in an instance of Smith punching Jones, then it becomes unclear at an intuitive level why that structure is the right one.[259] 
     The obvious response is to say that the arrangement in question is not a physical relationship, but some kind of abstract relationship. But in that case, the problem we discussed earlier re-arises. Given some particular abstract relationship, why is that relationship so special? If that abstract relationship has no counterpart in a case of Smith’s punching Jones, then why say that Smith punched Jones is a structure that involves interrelating Smith, Jones, and punching in that particular way? Until we are told exactly what that structure is, the view in question (Smith punched Jones is a structures consisting of Smith, Jones, and punching) is analysis-schema, not an analysis proper. 
       It seems that two issues are being muddled by those who identify propositions with structures of this kind. We can represent the structure of the sentence “Smith punched Jones” in different ways; for example, we can use a tree-diagram or we can use an expression like “<<Smith, Jones> the relation of punching>.” (Again, we are setting aside niceties relating to the tense-marker.) In fact, linguists often do represent sentential-structure in this way. 
      But this doesn’t tell us anything that we didn’t already know concerning the structure of that proposition. As many, most famously Wittgenstein (1922), have pointed out, given that sentences express propositions, there must be some structural similarity between the sentence and the proposition. But until the exact similarity-relation is identified, we only have an innocuous truism, not an analysis.   
      The ordered pair <7,5> isn’t true or false. Given that ordered pairs (and n-tuples) are not in general true or false, why do they suddenly acquire this property when their members are Smith and Jones, as opposed to numbers? Obviously the ordinal properties of <<Smith, Jones> the relation of punching> are meant to indicate some kind of structure – some kind of structure not had by Jones punched Smith. But, as we said a moment ago, given only that Smith punched Jones can be coded in that ordered pair, we know nothing that we didn’t already know as to the identity of that structure. In any case, we know nothing more than we already knew about it, given our pre-existing knowledge that it can be coded in the sentence “Smith punched Jones” or in a tree-diagram of a certain kind. 
 
Frege’s view 


           Frege’s (1891, 1892) view regarding the proposition Smith punched Jones is that it is a structure of some kind or other. (He said very little as to what exactly that structure would be.) But Frege denied that it is Smith and Jones per se that are constituents of that structure, and he held that it is senses of Smith and Jones that are such constituents. 
          In Chapter 3, we saw why, if the semantic content of “Smith” is a sense, then the proposition meant by “Smith punches Jones” becomes an existence-claim, as opposed to the atomic proposition that it obviously is. This is not to mention that, given Kripke’s (1972) points, it isn’t really an option to say that the semantic content of “Smith” is a sense. From this viewpoint, Frege’s view is a step backwards from the view that Smith punches Jones is an ordered n-tuple of the kind just discussed. 
         Frege made a point that could be interpreted as being attempt at a partial answer to the question “what is the proposition Smith punched Jones?” Frege said (correctly, no doubt) that this proposition has as a constituent the “concept” x punched y. The proposition Smith punched Jones is what results when the variables (or empty-spaces) are “saturated” with Smith and Jones (or with the corresponding senses). 
       There are at least two problems here. First, as Davidson (1967) said, until we are told what “saturated” means, Frege has given us only a metaphor. Obviously the word “saturate” is being used metaphorically. Frege has told us that a proposition is what results when that concept is completed in some way or other by (senses of) Smith and Jones. But he hasn’t told us what the nature of that completion is. And until we know that, we don’t know anything that we didn’t already know. 
        There is another problem. What is the concept x punched y? Sometimes Frege answers this by saying that it is what is had in common by all and only Smith punched Jones, Mary punched Fred, Larry punched Harry, and so on. So concepts are abstract features of propositions; they are what different propositions have in common. 
        But, in  that in case, propositions cannot be composed of concepts. There is, of course, an obviously parallelism between this point and the point we made earlier concerning the constituencies (or lack thereof) of concrete situations. So if we see Smith punched Jones as having the concept (or relation) of punching as a constituent, then we cannot see that concept as being abstracted out of propositions. 
         This shows that the constituents of propositions cannot themselves be understood in terms of propositions. We cannot say that Smith (or redness or pain or…) is what is had in common by all and only those propositions that (in English) are expressed by sentences of the form ┌…Smith…┐ (or ┌…red…┐ or ┌…pain…┐ or…). 
        In its turn, this fact gives us yet another reason to hold that the contents of our mental states are ultimately not proposition-like. To grasp Smith punched Jones, I must presumably grasp its constituents. Trivially, I grasp those constituents by way of mental states whose contents are propositions or by way of mental states whose contents are not propositions. In the latter case, there is non-propositional content. 
         In the former case, we seem to have a vicious regress. Grasping a proposition involves grasping its constituents, and grasping any one of its constituents involves grasping one or more other propositions. Given the reasonable supposition that no proposition can be a proper constituent of itself, it readily follows that one must grasp infinitely many propositions to grasp a single one. But it is implausible to suppose that one’s grasping Smith punched Jones involves one’s grasping infinitely propositions. 
         Also, given that one cannot grasp a proposition without grasping its constituents, it is viciously circular to suppose that mental representations categorically have propositions for their contents. It must therefore be assumed that, ultimately, the contents of our mental representations of propositional constituents are non-propositional.  (Of course, the contents of such representations are sometimes propositional, given that some propositions have other propositions as constituents.  Hence the word “ultimately” in the second to last sentence.) We have seen that there is independent support for this position. 
  
Propositions as the sets of their logical consequences 


         According to Carnap (1937) and Clarence Lewis (1946) , a proposition is the class of its logical consequences. This thesis is often expressed in terms of sentences: “the content of a sentence is the class of its analytic [or logical] consequences.” [260] 
       There are some serious problems with this view. Xxx First of all, the statement “propositions are classes that contain their logical consequences” is viciously circular, given that those consequences are themselves propositions. 
         One way to block this vicious circularity would be to say that the consequences of a proposition are not propositions. Whatever merits this position has, it is obviously not an option for someone who denies that there is any fundamental difference between propositional and non-propositional content. 
        There is another problem with the view under examination. Presumably the proposition Smith punched Jones has one constituent corresponding to Smith, one corresponding to Jones, and one corresponding to the relation of punching. (This is not to deny that it has other constituents. But it presumably has at least those three.) A related point is that the sentence “Smith punched Jones” surely has a decomposition not wholly unlike that of the corresponding proposition. But it hard to see how the class of logical consequences of Smith punched Jones could have a structure at all like that of that sentence or that proposition. 
        This fact is important from the standpoint of somebody who wants his theories to explain, or at least be consistent with, the fact that languages can be learned and that propositions can be grasped. As Fodor (1975, 1998) makes clear, anyone who understands “Smith punched Jones” can also understand “Jones punched Smith.”[261] Anyone who can understand “Mary is tall”, and “Fred is short” can also understand “Fred is tall” and “Mary is short.” These facts are hard to explain unless it is assumed that the things meant by “Fred is tall” and “Fred is short” have a constituent in common corresponding to the word “Fred” – unless, to generalize this point, it is assumed that the things meant by sentences at least typically have discrete constituents corresponding to the expressions composing those sentences. The class of logical consequences of “Fred is tall” (or of Fred is tall) does not have any discrete part corresponding to “Fred.” In any case, it would take considerable artifice to find any such part.                  
   
Why these points are consistent with our analysis of properties and individuals 


      The points just made might seem in tension with the analysis given in the last chapter. Such expressions, we argued, are to be understood contextually; they are not to be understood by pairing them off with the right entities, since such entities are not to be found. But in the last paragraph we argued that the thing meant by “Fred is tall” must have a constituent corresponding to Fred (and to tallness). 
       Given an analysis due to Richard Montague (1974), this tension is easily eliminated. If Montague is right (as I believe he is), Russell conflated two different notions. He conflated the idea of having a referent with that of having an isolable meaning. 
        Consider the sentence “something snores.” For the reasons that Russell and Frege gave us, “something” doesn’t refer to some ambiguous object. On this basis, Russell said that it has “no meaning in isolation” and must therefore be defined contextually. But given only that an expression must be defined contextually, it doesn’t follow that it has “no meaning in isolation.”[262] We can see the expression “something” as having for its semantic content a function that assigns truth to a property (or concept) phi exactly if phi is instantiated.  
        We don’t want to say that “something” refers to such a function, given that “something snores” doesn’t say of some function that it snores. But not all forms of signification are identical with reference. 
      Actually, it was Frege who gave a cogent argument for this last point. Consider an arbitrary sentence – e.g. “Smith punched Jones.” One might be tempted to say that “punched” refers to the relation of punching. But if we replace the occurrence of “punched” with an expression that uncontroversially does refer to that relation, e.g. “the relation of punching”, the result is  “Smith, the relation of punching, Jones.” Since that string of words is not a sentence, it follows that the occurrence of “punched” does not – at least not merely – refer to the relation of punching. So unless one takes the demonstrably false view that meaning is categorically identical with reference, there is no barrier to saying that “something” has for its meaning a discrete entity, notwithstanding that “something” cannot be defined denotatively and must therefore be defined contextually. 
       In general, given only that some expression “parses out”, it doesn’t follow that it doesn’t have a discrete signification. In fact, given any expression E that parses out, the method that Montague uses in connection with quantifiers (like “something”) is easily adapted to show that E has a function for its meaning. 
        Our point in the previous chapter was not that Smith doesn’t exist or that there aren’t instances of pain. Our point was not that there is no isolable entity of any kind corresponding to the word “Smith” or to “this instance of pain.” It is that no isolable constituents of the spatiotemporal world correspond to such expressions. The things meant by those expressions are much more abstract than is usually thought. As we saw, any instance of pain -- even an instance of some maximally specific kind of pain -- is really a commonality holding among states of affairs. That maximally specific kind of pain, in its turn, is a commonality holding among such commonalities. The property pain is a commonality holding among such commonalities among such commonalities. Similar remarks are true of “Smith.” 
      This shows that “Smith” and “this instance of pain” don’t have isolable spatiotemporal significances. But it doesn’t show that they don’t have isolable significances tout court. They do have such significances, these being the commonalities just discussed. So given only our views as to what Smith is, and as to what properties and property-instances are, we are by no means barred from holding that “Smith” and “this instance of pain” have isolable significances. Our view was that those significances are not spatiotemporally discrete entities – and that view is an independently plausible one. 


Propositions as sets of their logical consequences (continued) 


       We’ve already discussed two difficulties for the view that the proposition Smith punched Jones is identical with the class of its logical consequences. There is another well known problem. Smith punched Jones has the same logical consequences as Smith punched Jones and 1+1=2, even though those are distinct propositions. 
        Given this fact, it is not an option to say that Smith punched Jones is identical with the class of its logical consequences. If we were to hold onto the view that propositions are identical with classes containing their logical consequences, we would  have to say that Smith punched Jones was identical with some ordering of those consequences and that Smith punched Jones and 1+1=2 was identical with a different ordering of those same consequences. In general, we would have to say that propositions were orderings of their own logical consequences, and that analytically equivalent propositions were different orderings of the same propositions. Otherwise, equivalent propositions would be no more distinguishable than the unordered sets (2,4,6) and (4,6,2). 
           But here there arises an analogue of a problem already discussed. It isn’t clear what the right structuring would be; and the view just discussed is entirely programmatic until that structuring is identified. So the view in question is, from that viewpoint, comparable to the view that Smith punched Jones is <<Smith, Jones>, punched>. The former view, like the latter, is correct only given some as of yet unknown fact about the structures of propositions. But knowledge of the identity of that structure is precisely what we want from an analysis of propositions. 


The possible-worlds approach


          This view combines elements of all of the views thus far discussed. It is the view that a proposition is a function from worlds to truth-values. So Smith punched Jones is a function that assigns truth to worlds where Smith punched Jones and falsity to worlds where Smith didn’t punched Jones (but where Smith and Jones exist), and either falsity or no truth-value to worlds where either Smith or Jones doesn’t exist. This view is the core of a doctrine called “possible world semantics” (PWS)[263] 
       Any adequate assessment of the merits and demerits of PWS would be quite an involved task.[264] Fortunately, given our purposes, only a few brief remarks are necessary. If by a “world” is meant a set of propositions, then it is viciously circular (and regressive) to say that propositions are functions from worlds to truth-values. If we say that worlds are non-propositional representations, then we are conceding that there is non-propositional content – this being exactly the point that we are trying to establish in this chapter. If we say that worlds are concrete entities, like our world, then PWS involves the dubious view that, for each possible proposition, there is an actual world where it is true. 
       PWS also has the problem that it cannot distinguish between 1+1=2 and triangles have three sides, given that those propositions are true in the same possible worlds. Advocates of PWS deal with this by saying propositions are structured assignments of truth-values to worlds (Lewis 1975, Cresswell 1985: 446-452). So even though 1+1=2 and triangles have three sides assign the same truth-values to the same worlds, they do so in different ways. In one case, the concept of addition is involved in the assignment; in the other case it is not. In one case, the concept of triangularity is involved in that assignment; in the other case it is not. 
        Supposing that this is right, propositions end up being individuated by their internal structures. Even though Smith punched Jones and 1+1=2 assigns the same truth-values to the same worlds as Smith punched Jones and triangles have three sides, they have different internal structures; and for this reason they are different propositions. Given this, proposition-individuation can, and must, be understood entirely in terms of a proposition’s internal structure. We have no idea what Little Timmy’s belief is if we know only that his belief is true in every world. That belief could be any one of the following: 


(i) 1+1=2
(ii) there are continuous functions that cannot be differentiated at any point. 
(iii) There are infinitely many primes. 
(iv) Arithmetic is incomplete. 
(v) Triangles have three sides. 


          If we want to know what Timmy believes, we need to know the identities of constituents of the proposition believed in, and we need to know how those constituents are arranged in that proposition. But given that information, there is no need to know in what worlds that belief is true, since we already have all the information we need to answer the question “what is the identity of the proposition that Timmy believes to be true?” 
       Of course, given an answer to that question, we know in which worlds that proposition is true and false (i.e. to which worlds it assigns truth and falsity). In other words, we know what is sometimes referred to as the “extension” of that proposition.  But, as we’ve just seen, a proposition’s extension is, by itself, useless in the way of indicating that proposition’s identity, since infinitely many distinct propositions will have the very same extension. 
     So if it is to avoid falsely identifying 1+1=2 and triangles have three sides, PWS must see propositions as being individuated by their structures. But in that case, the extensions of those propositions drop out; and PWS ends up being a version of the theory, already considered, that a proposition is a structure of some kind.  PWS thus ends up collapsing into (a close relative of) the view that Smith punched Jones is the ordered pair <<Smith, Jones>, punched>. 
          There is yet another problem. Suppose that there is only one concrete world. In that case, snow is green and coal is purple assign the same truth-values to the same worlds, since they both assign falsity to this world and this world is the only one. So if those propositions are to be given different extensions, we must 666 embrace the dubious view that there are, indeed, different concrete worlds. (We’ve already discussed why it is not an option, at least not in this context, to identify worlds either sets of propositions or with non-propositional representations.)[265] 


David Lewis’ analysis: propositions as properties of worlds


          According to David Lewis (1986), a proposition is a “property of a world.” Let P be the proposition Smith punched Jones. That proposition is true in some possible worlds and false in others. For that proposition to be true in a world W is for W to have certain properties; it is, to use Taylor’s expression, for W’s quantum to be rippled in a certain way. 
        Here is another way of thinking about it. Suppose that God is given a blank world W and that he wants P be true in it. What will he do? He must do more or less the same thing as an artist who wants to paint a portrait on what is now a blank canvass. An artist cannot just project an image of Lincoln onto a canvass. He must do so one drop of paint at a time. And even if an artist could instantaneously project Lincoln onto a canvass, that would consist, not in his not having to put the requisite thousands of paint drops on the canvass, but in his being able to put them all there simultaneously.  
        Similarly, even God cannot just make P be true in W. He must do so by wrenching W’s quantum into shape – by guaranteeing the occurrence of the right micro-events. Even He cannot make P be true in a world W whose micro-constituents are qualitatively identical with those of a world W* where P is not true. Even God must comply with metaphysical necessities. As Wittgenstein (1922) said, even God cannot create a world where one and one don’t make two.
        In wrenching W’s quantum into shape, what is God doing? He is making a dent in it – he is doing to it what the artist does to a canvass or, to use a more apt analogy, what a metal-worker does to a sheet of aluminum. He is making it instantiate the right property. So for P to be true in W is for W to instantiate a certain property. (The property in question is not, it will be noticed, the trivial one of being a thing x such that P is true in x. The property in question can, and ultimately must, be understood independently of P and, indeed, of any one of its constituents.) So P is a property of worlds, and P is true in a world if that world instantiates it. What we said about P is true mutatis mutandis of any proposition. Therefore propositions are properties of worlds. 


Evaluating Lewis’ analysis


           There is much truth in this analysis, and it is dramatically better than the others we considered. The analysis that I will propose draws heavily from it. But there are two reasons why Lewis’ analysis is unacceptable as it stands. 
           If I say to you “Smith punched Jones and 1+1=2”, I am not telling you anything about how this world differs from others that I am not telling you by saying either “Smith punched Jones” or “Smith punched Jones and triangles have three sides.” (At the same time, in uttering any given one of those sentences, I am giving you information – though not spatiotemporal information – that I would not be giving you in uttering either of the others.) So if Smith punched Jones is a property of worlds, i.e. if it is a way that certain worlds are, that property is not different from Smith punched Jones and triangles have three sides or Smith punched Jones and 1+1=2. 
         Incidentally, Lewis (1986) is aware of this, and he bites the bullet. He takes the logical positivist view that the three propositions just mentioned are actually identical. But it is probably best to assume with most philosophers that such a view is not correct, and to proceed accordingly.
        Some abbreviations will help us state another problem with Lewis’ analysis. Let P1 be the proposition Smith punched Jones; let P2 be the proposition Smith punched Jones and 1+1=2; and let P3 be the proposition Smith punched Jones and triangles have three sides. 
         No two of P1, P2, and P3 have the same decomposition. But, as we just saw, given any one of those propositions, there is no property that a world W has in virtue of that proposition’s being true in W that W doesn’t have in virtue of in virtue of either of the other proposition’s being true in that world. So if they are properties of worlds, any two of P1, P2 and P3 are identical and thus have identical decompositions. So Lewis’ analysis cannot accommodate the fact that distinct propositions can be analytically equivalent. Nor can it accommodate the related fact that any proposition has a unique decomposition into a finite number of discrete parts. 
       
Our analysis: propositions as sets of properties, truth as instantiatedness


      We’ve considered a number of answers to the question “what is a proposition?” and found them to be inadequate, at least for our purposes. I would like to propose a different answer.  
     The core of our view is present in Lewis’ analysis: propositions are properties, and they are true when instantiated. Truth is instantiatedness. Actually, we will see that  propositions are sets of properties, not properties per se, and that for a proposition to be true is for a set of properties to be instantiated. But there is obviously a deep kinship between our proposal and Lewis’.
       There is a plant next to my desk. Let D be that plant. D is green. Hence the proposition: 


(*) D is green


is true. What is involved in (*)’s being true? It is true in virtue of the fact that various properties are instantiated. The property of being a certain kind of object (a plant) is instantiated in a certain place and time, and the property of being green is instantiated by that object.[266] 
        If various properties are instantiated in a certain place, at a certain time, then (*) is true. If those properties are not instantiated in that place, at that time, then (*) is false. This suggests that (*) is a set of properties, and that for (*) to be true is for the members of that set to be instantiated. 
         The problem is to identify a set that has the right ordinal or structural properties. More exactly, the problem is to identify a set that satisfies two requirements. First, (*) is true exactly if all the members of that set are instantiated. Second, facts about the membership of that set can be put into an intuitively satisfying correspondence with facts about the decomposition of sentences like “D is green” (and “that plant over there is green”) and therefore with facts about the decomposition of (*). This problem can be solved 
       Let us begin with a point that we discussed a moment ago, when we were evaluating Lewis’ analysis. There is some property – we will refer to that property simply as “#1” -- that a world has in virtue of the fact that (*) is true in it. That very property (#1) is had by a world in virtue of that fact, in it, any one of the following is true in that world: 


(i) D is green and 1+1=2,
(ii) D is green and triangles have three sides, 
(iii) D is green and there are infinitely man primes, 


and so on. 
        #1 cannot be identical with (*). This is an immediate consequence of the considerations that put forth in defense of our rejection of Lewis’ analysis. At the same time, (*) is true in W iff #1 is instantiated. 
        Given this, I propose that DP is identical with a set S one of whose members is #1, and I propose that each of (i)-(iii) is a set that has #1 as a member. I further propose that for any given one these propositions to be true is for the members of the corresponding set to be instantiated. But, to account for the decompositional differences holding between any two of the four propositions in question, I will also propose no two of these sets have exactly the same  members (even though they share #1 along with, as we will see, some other properties). 
       For a moment, let us speak as semanticists, and not as metaphysicians. As semanticists, our inclination is to say that “D is green” decomposes into (inter alia) “D” and “green.” In any case, our inclination is to say that “D” and “green” are well-formed parts of “D is green” and, consequently, that these expressions correspond to isolable constituents of (*), i.e. of what is meant by “D is green.” And, as semanticists, our inclination is to say that each of these morphemes corresponds to some discrete and ultimate constituent of what is meant by (*). 
      We’ve already discussed why the things that we refer to as “individuals” – vases, plants, people, animals, and so on – can be thought of as properties. That is how we will think of them in this chapter. Given this, let #2 be the property corresponding to “D”, and let #3 be the property corresponding to “green.” Finally, let S be a set that contains all and only #1, #2, and #3. 
        Given that S comprises #1, it immediately follows that (*) is true if the members of S are instantiated. In fact, the converse follows as well. If #1 is instantiated, then so are #2 and #3. So (*) is true exactly if all of #1, #2, and #3 are instantiated. 
       Notice that S has one part corresponding to “D”, another part corresponding to “green”, and a third part corresponding to a certain way of “combining” those two parts.  A world instantiates #1 iff it instantiates #2 and #3 and also a third property P that satisfies the following conditions. The instantiating of P involves (i.e. is sufficient for) the instantiating of #2 and #3. The instantiating of both #2 and #3 is necessary, but not sufficient for the instantiating of P. (Even if D exists in a world W, and the property of being green is instantiated in W, it doesn’t follow that D is green in W. It could be that, in W, D is purple and it is some other object that is green. So, as we said, the instantiating of both #2 and #3 is necessary, but not sufficient, for the instantiating of P.) 
        (*) is thus a structure that has the following properties. It has an isolable part corresponding to D, and an isolable part corresponding to the property of being green; and it also has a part that in some way combines those two parts – that combines them in such a way that, for (*) to be true, it is not enough that something or other be green or that D have some property or other, but that D specifically have the property of being green specifically. 
        S has an analogous structure. It has one part corresponding to D, another part corresponding to the property of being green, and a third part (#1) that combines the first two in a certain way. When all of the members of S are instantiated in a given world W, it follows that three things are the case in that world: 


(a) D exists; 
(b) there is an instance of the property of being green; and 
(c) D instantiates that property. 
  
         We may naturally identify (*) with S, and (*)’s being true in a given world with the members’ of S being instantiated in that world. 


The unity of the proposition 


          It is obvious that (*) involves some way of “combining” or “synthesizing” D with the property of being green. The problem is that it the nature of this synthesis has never been identified. (It has always been described to us through metaphorical terms, such as “saturation” and “juxtaposition.”) Given our analysis, we are in a position to identity the nature of this synthesis. 
         First of all, when it is said that (*) “consists of” D and greenness, or (equivalently) that D and greenness are “combined” in a certain way in (*), the terms “consist of” and “combine” obviously don’t denote spatial relations. Rather, I would argue, they denote abstract relations of dependence. Here it may help if we switch to an example that has more relational structure than (*). (We will come to back (*) shortly.) Consider the proposition: 


(**)  Smith hit Jones


Obviously (**)’s existence presupposes, and thus depends on, that of Smith and Jones (and also the relation of hitting). Further, if (**) is true, then so are the propositions something hit Jones, and Smith hit something, and also something hit something. The truth of (**) thus depends in a certain way on facts about Jones, Smith, and the relation of hitting. 
      There is more to say in this vein. (Here we must keep it firmly in mind that Smith and Jones, land so-called individuals generally, can be thought of as properties.) (**)’s existence presupposes, not just that of Smith, Jones, and the relation of hitting, but also of a certain “synthesis” (whose nature has yet to be described) of these three things. And (**)’s being true in W involves more than there being instances in W of Smith, Jones, hitting, Smith’s hitting somebody, and somebody’s hitting Jones. Those instances be combined in W. After all, if Smith hit Brown, and Aaron hit Jones, then all of the properties mentioned will be instantiated in W, but (**) won’t necessarily be true there. 
        In any case, there is considerable evidence for our view that the concept of propositional constituency is to be understood in terms of the concept of dependence. X is a constituent of proposition Y iff Y depends on X in a certain way. Of course, this is extremely vague, given that there many ways that one thing can depend on another. But it is just a jumping-off point for our analysis of propositional structure; and that analysis will replace this vague statement with a precise one. 
        Before we continue, we should deal with an apparent problem with our analysis. The proposition: 


(***)  if Smith hit Jones, then Smith hit somebody 


can be true without Smith’s hitting anyone or Jones’ being hit by anyone or, in fact, anyone’s hitting anyone. But notice that this is a molecular proposition, and that, as such, it affirms a relationship not between Smith and Jones, but between propositions. Notice that those two propositions – and not Smith, Jones, or the relation of hitting -- are the immediate constituents of (***).  Notice also that, just as the truth of Smith hit Jones depends on facts about its immediate constituents, so the truth of (***) depends  on facts its immediate constituents. So given only that (***) doesn’t imply any particular fact about Smith or Jones or the relation of hitting, there is no reason to reject our view that constituency-relations are to be understood in terms relations of dependence. In any case, we will deal with molecular propositions in a moment. 
         Let us once again look at (*). (*)’s existence presupposes that of D. (Remember how (**)’s existence presupposes that of Smith and Jones). (*)’s being true in W involves there begin instances in W of D and of the property of being green. (Remember how (**)’s being true in W involves there being instances of Smith’s hitting somebody, somebody’s being hit, and so on.)  
         Now let us look at S in light of these facts. S’s existence presupposes that of D (and, of course, of the property of being green). In order for all of S’s members to be instantiated in W, it is necessary that both D and the property of being green be instantiated there. But, as we discussed, this is not sufficient. 
       So far, then, there are significant parallels between (*) and S, and also between (*)’s being true and S’s being such that all its members are instantiated. 
       After this point, it becomes hard to determine to what extents facts about S parallel facts about the structure of (*). This is because we know so little about the latter. So far as we have such knowledge, it is given vague statements such as those already discussed, e.g. 


(#) where propositions are concerned, the concept of constituency is to be understood in terms of that of some kind of dependence, 


        But by identifying (*) with S, and (*)’s being true with S’s members all being instantiated, we can fill in these gaps in our understanding, without violating our pretheoretic intuitions, vague though they may be, as to the nature of propositional structure.
          (#) was our starting point. But (#) is obviously unacceptable as it stands. The truth of (*) is probably constitutively, and not just causally, dependent on facts about physical law – on facts about protons, electricity, gravitation, and so no. It is very hard to believe that D – that very plant – could exist in a world governed by different physical laws or forces, or in a world that didn’t comprise electrons or protons or any of the micro-particles found in our world. So it is very hard to believe that D could exist in a world where there were no gravitation. But clearly the concept gravitation is not a constituent of (#), at least not in remotely the same sense as the concept green or the concept D; and the same is true of the concepts electricity, proton, photosynthesis, and so on. So though it may be true, even truistic, (#) is not enough; it doesn’t tell us why D is a constituent of (*), whereas the concept of electricity is not. 
        But our analysis can help solve this problem. D is a member of S. (When discussing S’s membership, we referred to D as #2; but obviously that isn’t important.) Similarly the property of being green (#3) is a member of S. By contrast, the concepts of electricity, gravitation, and so on, are not members of S. So by identifying S with (*), we replace (#) with a precise and clear statement – a statement that agrees with (#), so far as the latter goes but that, unlike (#), isn’t unclear or otherwise exceptionable. 
       If S’s members are instantiated, that entails (inter alia) that D is instantiated and that the property of being green is instantiated. By contrast, it doesn’t entail any statements regarding gravitation, electricity, or photosynthesis -- even though, quite possibly, the members’ of S being instantiated is constitutively dependent on facts about gravitation, electricity, and so on. 
        In conclusion, if we identify propositions with sets of properties, and a proposition’s being true with all of its members being instantiated, then we can give clear, precise, and extensionally correct answers to important questions relating to propositional structure. 
  
Another illustration of our analysis 


       Before we deal with molecular proposition, it may be appropriate to give one illustration of our analysis of atomic propositions. This is because (*), the proposition in terms of which we illustrated our analysis, has minimal relational structure; and it is thus worthwhile to show that our analysis doesn’t break down when applied to relationally richer propositions. Given this, let us consider (**) once more. 
        It is pretty clear that Smith, Jones, and the relation of hitting are constituents of it. It also seems clear (though this point has a more theoretical quality) that (**) also has as constituents the “propositional functions”: Smith hit y, x hit Jones, and x hit y.  
       It is also clear that these things must be “combined” in some special way if (**) is to result. It is clear that not just any arrangement of those entities will do. 
       Frege explained why this last requirement must be met. We briefly discussed Frege’s argument in the last chapter. Here we must develop what we said. 
       Consider the following list of expressions: 


(**F) Smith, Jones, the relation of hitting, Smith’s hitting something y [or: the propositional function Smith hit y], x’s hitting Jones, something’s hitting something.


(**F) isn’t a sentence; it doesn’t encode a proposition. Further, a sentence will not result no matter how many referring terms we add to (**F). Suppose that “COM” denotes the special (and, as of yet, unidentified) way that Smith, Jones, etc. must be combined if (**) is to result. If we add “COM” to (**F), what results is:


(**F2) Smith, Jones, the relation of hitting, Smith’s hitting something y [or: the propositional function Smith hit y], x’s hitting Jones, something’s hitting something, COM. 


 (**F2) is no more a sentence, and no more encodes a proposition, than (**F). Obviously no expression would result from (**F2) no matter how many more denoting expressions we added to it. In general, a sentence is not a (mere) list or heap of referring-terms. So a sentence is more than a list of referring terms. 
     What does “Smith hit Jones” have that each of (**F) and (**F2) lacks? “Smith hit Jones” is grammatical, whereas the other two are not. In “Smith hit Jones”, the expressions are appropriately inflected and they occur in the right order. This is not the case with respect to either (**F) or (**F2).[267] 
      We’ve seen that we can’t turn (**F) into a sentence by adding more referring terms. We’ve also seen that it is facts about grammar – inflections, word-order, and the like – that are needed to turn (**F) into a sentence. It seems, then, that grammatical morphemes do not, at least not generally, refer. The ordinal information that they encode is not to be understood in terms of their referring to anything. 
      Let us turn our attention back to (**). We’ve seen that among its constituents are: Smith, Jones, the relation of hitting, Smith’s hitting something y [or: the propositional function Smith hit y], x’s hitting Jones [the function: x hit Jones], and something’s hitting something [the function: x hit y]. But what we haven’t seen is how these things must be combined if a proposition is to result. And – what would seem to be a related point – we haven’t seen exactly what it is that the inflections in “Smith hit Jones” do. (In this context, I will use the term “inflection” to refer to all grammatically significant facts – e.g. word-order, intonation, and so on.[268]) We’ve seen that they “combine” the constituents just mentioned in some way or other; we’ve seen that they don’t do so by referring to anything; and we’ve seen that, as a result of their performing this (as of yet under-described) feat of “combining”, a proposition is meant by “Smith hit Jones.” But we haven’t put our finger on the identity of this mode of combination. But, given what we said in connection with (*), we may, I think, be able to do so. 
        Let us begin with Lewis’ insight. There is some property – we will call it simply “#1*” – that a world has in virtue of the fact that  (**) is true in it. For analogues of reasons already discussed,  a world W instantiates #1 in virtue of its being the case that, in W, any one of the following is true: 


(i) Smith hit Jones and 1+1=2
(ii) Smith hit Jones and triangles have three sides. 
(iii) Smith hit Jones and there are infinitely many primes. 


Obviously this list goes on ad infinitum. 
        So given that (**) is not identical with any of the propositions on that list., (**) is cannot be identical with #1*. But it is surely suggestive that (**) is true exactly if #1* is instantiated. 
     Given this, let S2 be a set one of whose members is #1*. As we’ve discussed, Smith and Jones can be thought of as properties. Let #2* and #3* be those properties. It goes without saying that the expression “being hit by Smith” (which corresponds to the function Smith hits y) and “hitting Jones” (x hits Jones) and also “hits” (x hits y) correspond to properties. (Following tradition, we can think of the relation of hitting as a property of ordered pairs.) Let #4*, #5*, and #6* be those properties. Finally, let S2 be a set that has for its members all and only #1*-#6*. 
        For obvious reasons, if #1* is instantiated, then so are #2*-#5*. And, as we’ve already discussed, (**) is true (in a given world) exactly if #1* is instantiated. It follows that (**) is true in a world exactly if all of #1*-#6* there. So, thus far, there is no reason not to identify S2 with (**), and (**)’s being true with S2’s being such that all its members are instantiated. 
        Further, S2’s constituency is comparable, in an obvious way, to the constituency of (**), at least in so far as we know anything about the latter. We know that Smith, Jones, the relation of hitting are “constituents”, in some sense of the word, of (**). We also have reasons, given to us by Frege (and, since his time, by many others) to suspect that the functions x hits Jones, Smith hits y are also constituents (in some sense of the word) of (**). Further, we know that (**) is what results when these (or some subset of these) various entities are “combined” in some mysterious way. S2 has a constituent corresponding to each of the constituents of (**), and the mysterious operation of “combining” just mentioned can be understood in terms of facts about S2’s membership. 
        S2 has a discrete part correspond to Smith, to Jones, to hitting, and so on. And we know exactly how #1*-#6* -- the parts corresponding  to the Smith, Jones, and so on – relate to S2: they are members of it. That is as clear a relationship as we can hope to find. So, thus far, facts about S2’s composition correspond to what we know about (**)’s composition – with the qualification that, in the case of S2, it is extremely clear what those compositional facts are.  
       We know that for Smith, Jones, and so on, to be “constituents” of (**) is for the truth of the latter to have some kind of dependence on facts about the former. But we don’t know what exactly that kind of dependence is. This problem vanishes if we identify (**)’s being true with S2’s being such that all its members are instantiated. If all S2’s members are instantiated in W, then Smith hits somebody in W, Jones is hit by somebody in W – and, of course, somebody hits somebody in W, not to mention that Smith and Jones exist in W. Similarly, (**)’s being true in W involves Smith’s hitting somebody in W, Jones’ being hit by somebody in W, and so on. So to the extent that we know anything about the dependence-relation that holds between a proposition and its constituents, our analysis is on the right side of the relevant facts. 
       At the same time, as we discussed, not all dependence-relations correspond to relations of propositional constituency. Smith’s hitting Jones is (we may suppose) constitutively dependent on various facts about neurons. But the concept neuron isn’t a constituent of (**). Further, if Smith hit Jones, that logically entails that Smith put some kind of pressure on Jones’ body. But the concept pressure isn’t a constituent of (**). So it isn’t enough to say: X is a constituent of proposition Y iff Y’s being true involves, or is otherwise metaphysical dependent on, some fact about X. Though true, that statement is too broad, and it doesn’t say why the concept of a neuron is not, whereas the property of hitting is, a constituent of (**). 
       But if we identify (**) with S2, this problem is managed. The concepts (or properties) neuron and pressure are not members of S2. So if we identify (**) with S2, it is clear why the concepts neuron and pressure are not constituent of (**), even though states of affairs instantiating those properties are metaphysically or logically necessary for the truth of (**). Further, if all of S2’s members are instantiated, that entails that somebody or other hit Jones, but it doesn’t entail anything having to do with neurons. 




An apparent problem for our analysis


        Here it might seem that we run into a problem. If S2’s members are all instantiated, that does entail, at least arguably, that Smith put some kind of pressure on Jones and that Smith thus altered the balance of forces acting on Jones. But the concepts pressure, balance of forces, and so on, are not constituents of (**). So it might seem that there is been a breakdown in our attempt to understand (**)’s structure in terms of facts about what is entailed by the supposition that all of S2’s members are instantiated. 
         But there hasn’t really been a breakdown. There is an obvious sense in which the truth of Smith hit something is, whereas any proposition about pressure or force is not, an immediate consequence of the supposition that S2’s members are instantiated. One’s making the latter supposition is identical with (inter alia) one’s supposing that Smith has the property of hitting something, that Jones has the property of being hit by something, and so on. By contrast, one’s  supposing that S2’s members is obviously not identical with one’s making suppositions about alterations of the balance of forces involving Jones. So even though the supposition that S2 is instantiated entails both Smith hit something and also Smith altered the balance of forces acting on something, these two entailments differ from each other in some fundamental respect. Our analysis enables us to say exactly what that difference is. Indeed it practically amounts to a description of that difference. Our analysis therewith enables us to say why the property of being a force is not, whereas the property of hitting is, a constituent of (**). 


The bearing of our analysis on LOT


        Before we discuss molecular propositions, let us discuss the bearing that our analysis of propositionality has on the viability of LOT. If our analysis is right, a proposition is a set of properties. Given what we said earlier, this means that any proposition is at an extraordinarily high number of removes from anything that could be the content of any experience (i.e. any perceptual or sensory experience). Let us now spell out why this is so. 
     We’ve already seen why, so far as they cannot be identified with concrete situations, property instances are (contrary to what is generally thought) abstract commonalities among situations, and are therefore abstract. We’ve also discussed why terms like “red” are not properties of things whose instances can be encountered in experience, but are rather properties of such properties. We had to invent special terms – “R1”, “R2”, and so on – to denote the maximally specific shades of red that one sees. What is true of “red” is true of any expression with a fixed, as opposed to context-dependent, reference. Context-dependent expressions, e.g. “that exact shade of red”, can denote properties had by situations that can be experienced, i.e. seen, heard, touched, and so on. But context-dependent expressions must be built of context-independent ones; and the latter, as we’ve discussed, necessarily have abstract things for their significances.  
      We’ve also discussed why terms like “Smith” and “Jones” are not as dissimilar as one might think from terms like “red” and “pain.” The former, no less than the latter, fail to have concrete situations for their semantic contents, and instead have for their semantic contents abstract commonalities among situations or worlds. 
       If our analysis of propositions is correct, then a proposition is a set consisting of various properties. And in most cases those properties are really hyper-properties (properties of properties, or properties of properties of properties, or…) The only cases where the constituents of a proposition are mere properties, as opposed to hyper-properties, are the cases where those propositions are to expressed using demonstrative expressions like “that particular shade of red” (or neologisms like “R1”). For a proposition to be true is for the properties that are members of it to be instantiated, i.e. it is for all of those (hyper-)properties to have the higher-order property of being instantiated. 


Molecular propositions 


      Earlier we saw that molecular propositions might pose a problem for our analysis. Let us allow an imaginary objector to articulate exactly what that problem would be: 


     Consider the proposition: 


(N**) “Smith did not hit Jones.” 


      Surely (N**) has Smith, Jones, and the relation of hitting as constituents. In fact, (N**) has all of the constituents had by (**). (At the same time, (N**) has an extra constituent, corresponding to the operation of negation.) But for (N**) to be true is not for those properties to be instantiated. Indeed, it is for those properties, or at least some of them, not to be instantiated. This makes it questionable whether you have analyzed propositions correctly and, therefore, whether there is any merit to your anti-LOT use of the concept of a proposition. 




        (N**) is a molecular proposition. It is the proposition: it is not the case that Smith hit Jones. (N**) has two immediate constituents. These are (**) and the concept of negation. Jones is not an immediate constituent of (N**). (N**) is a statement about (**). (N**) says of some proposition that it isn’t true. If our analysis is correct, this is equivalent to saying that the members of S2 are not instantiated. 
      At the same time, we want to hold onto the idea that a proposition is a set of properties, and that for a proposition to be true is for the members of that set to be instantiated. In other words, we don’t want to understand the concepts proposition and truth one way where atomic propositions are concerned, and a different way where molecular propositions  are concerned. So we must show that (N**) is some set SN of properties, and that (**N) is true iff all of SN’s members are instantiated. This can be done. 
      Remember #1* -- the property had in common by all and only those worlds where (**) is true. As we discussed, #1* is a certain way that a “quantum” can be rippled. Now consider all the worlds that aren’t rippled that way – that have ripples incompatible with the truth of (**). Let #N1 be that property. 
     Of course, in this context we described #N1 negatively. We described it in terms of some proposition’s not being true. But, to echo a point made by Frege (1918), it doesn’t follow that #N1 is itself any more “negative” than #1. Any given state of affairs can be described positively or negatively. We can say “Brown failed to make it to the finish line” (negative characterization) or “Brown collapsed before the finish line” (positive characterization). The first sentence describes a state of affairs in terms the falsity of some proposition (Brown made it to the finish line); the second describes that same state of affairs but not in terms of the falsity of some proposition. Similarly, suppose we were so naturally aggressive that the normal course of events was to hit other people, and that it was more disruptive to our psychologies and cultures when people refrained from hitting others than when they actually did so. In that case, we might have a special verb “to frit”, meaning to refrain from hitting. So “Smith frit Jones” would mean: Smith refrained from hitting Jones (despite there being innumerable internal and external pressures acting on Smith that would tend towards his hitting Jones). In that case, the state of affairs that, in actuality, is expressed by (**) would be expressed negatively, i.e. by the sentence “Smith did not frit Jones.” So #N1 is quite as “positive” a property as #1, and there is no threat of vicious circularity in our use of “Smith hit Jones” to identify #1. This is because we were using that sentence only to identify that property; and, as we just saw, that same property could have been identified without using the sentence “Smith hit Jones” or any synonym. Given this point, let us move on.  
      Let SP be the property of being identical with S2 or, if you prefer, with (**). The property of being identical with a set can be instantiated even if the members of that set are not. The property of being identical with is instantiated in any world where that set exists, it being irrelevant whether the members of that set are instantiated. Let Z be the set whose sole member is the property of being a gold object in New Zealand weighing more than a million lbs. Z exists in this world (and, arguably, in every world). The property of being identical with Z is instantiated in this world, even though its member is not. 
      Finally, consider the property of not being instantiated. This is, of course, a property had by properties. (It is had by the property of being a mansion on Earth made out of solid gold.) It is thus a higher-order property (in fact, it is of an even higher-order than most of the properties we have considered). Let NEG be this property. 
      Let S3  be the set that consists of NEG, Z, and N1. (N**) is true in all and only those worlds where N1 is instantiated. Given any world where N1 is instantiated, it follows, for obvious reasons, that each of Z and NEG is instantiated. So (N**) is true in a given world iff all of S3’s members are instantiated  in that world. Further, S3’s membership corresponds with the decomposition of (N**), at least in so far as the latter is perspicuously represented by sentences expressing that proposition, e.g.


(&)  “it is not the case that Smith hit Jones.” 


(&) has two immediate, proper constituents, namely: “that Smith hit Jones” and “it is not the case.” So if we count “it is not the case that Smith hit Jones” as a constituent (an improper one) of itself, (&) has three immediate constituents. Similarly, S3 has three members; and each of these members corresponds in an obvious way to the three main constituents of (&). So facts about S3’s membership neatly correspond to facts about the decomposition of (&) and therefore, presumably, to that of (N**); and facts about the conditions under which S3’s members are instantiated correspond neatly to facts about the conditions under which (N**) is true. So there is every theoretical incentive to identify (N**)’s being true with its being the case that the members of S3 are instantiated. Thus, far from warranting the rejection of our analysis, consideration of (N**) confirms it. 
      What we said about (N**) is true mutatis mutandis of all molecular propositions. I discuss this at length in another work (Kuczynski 2005c), where I also discuss the structure of analytic propositions. But given that our concern here is mental representation – specifically, the viability of LOT – it isn’t necessary that we consider the concept of propositional structure in such detail. And given only what we’ve said thus far about propositions, the implausibility of LOT has been adequately demonstrated. 
      
 Chapter 24 Peacocke on concept-possession 


          Like us, Christopher Peacocke rejects conceptual atomism. Further, Peacocke has ably defended a version of non-atomism. The purpose of this chapter is to evaluate Peacocke’s analysis. To do this, we will have to use some of the points that we’ve developed over the last two chapters. That is why we were not able to discuss Peacocke’s important work in an earlier chapter.
        Let us start with a point about terminology. In Chapter 16, we distinguished between “conceptso” and “concepts.” The latter are psychological entities; the former are platonic abstracta. In this chapter, we will once again use these terms in this way. 
        Let there be some concepto C satisfying the following conditions. A belief in P coupled with a belief in Q leads directly, i.e. not by way of an inference, to a belief in P C Q; and a belief in P C Q leads directly to a belief in P and a belief in Q. In other words, given a belief in P and in Q, one is “primitively compelled”, as Peacocke puts it, to believe P C Q; and given a belief in P C Q, one is primitively compelled to believe P and also to believe Q. 
       Under these circumstances, says Peacocke, we may conclude that C is the concepto of conjunction and also that you grasp that concepto. The concepto of conjunction has certain “possession conditions”, as Peacocke puts it, and you grasp that concepto because you satisfy those conditions.[269]
         It is obvious how to apply Peacocke’s analysis to various other conceptso. Let C be a concepto satisfying the following conditions. If you believe x falls under C, then you are primitively compelled to believe x is a closed figure, x has three-sides and x’s sides are straight; and if you believe all of those three propositions, then you are primitively compelled to believe x falls under C. In that case, C is the concepto of a triangle. 
        There are some apparently compelling reasons to accept this analysis. First of all, intuition recoils at the notion of someone who believes that x is a triangle but has no disposition to believe that x is three-sided. To believe that x is a triangle just is (so it would seem) to believe (inter alia) that x is three-sided. This suggests that one’s grasp of a concepto necessarily involves a mental representation of the fact that certain transitions are valid. This representation cannot be identical with a tendency to infer that x is three-sided (or closed or planar…) from the fact that x is a triangle, since the ability to make such an inference presupposes a grasp of the concepto of triangularity. For the same reason, this mental representation cannot consist in one’s knowledge that x is a triangle entails x is closed (or x is planar…) Given this, it seems reasonable, if not de rigueur, to suppose that this mental representation is constituted by a set of dispositions of the kind described by Peacocke – inferentially unmediated dispositions to transition to certain beliefs, given certain other beliefs. 
       Fodor (1998: 74) makes the following objection to this line of thought (this is a paraphrase, not a quotation): 


        You say that “intuition recoils” at the view that one could believe x is a triangle without believing, or at least being disposed to believe, that x is three-sided. But that intuition may just reflect the fact that it is obvious, at least to us, that triangles have three-sides. If you know that your friend Smith is miserable whenever it rains, then you are likely to believe that Smith is miserable if you already believe that it is raining. But it would be absurd to say that your concept of Smith is constituted by your having this disposition. And given only that you are likely to believe that x is three-sided if you already believe that x is a triangle, it is comparably absurd to suppose that your concept of triangularity consists in your having this disposition. 
    
           But in light of what Peacocke says about conceptso, there is a compelling response to this. If x is identical with Smith, that is not in virtue of the fact that x is unhappy when it rains. But C is the concepto of triangularity only if x falls under C entails x is closed, x has three sides and x has interior angles that add up to 180°. So, whereas Smith is not individuated by the fact that he is unhappy when it rains, the concepto of triangularity is individuated by the fact that it has these analytic liaisons with these other conceptso. For C to be the concepto of triangularity just is (so it would seem) for C to be such that anything falling under it falls under these other conceptso. Given this, it makes little sense to suppose that one could grasp the concepto of triangularity without mentally representing at least some of these entailments. For the reasons given earlier, it thus seems necessary to suppose that a grasp of that concepto consists in a set of “inferentially unmediated” dispositions of the kind that Peacocke describes. 
         In a word, if we give any weight to the intuition that a grasp of a concepto is inseparable from an appreciation of the validity of certain patterns of inference, it certainly appears that we have little choice but to accept Peacocke’s analysis.
        George Rey put forth some criticisms of Peacocke’s view. I will discuss what I believe to be Rey’s two most significant criticisms. One of those criticisms is spurious. But the other is cogent, and Peacocke’s analysis must therefore be rejected. We will also find reasons of our own to reject Peacocke’s analysis, as well as the arguments just provided for it.   


          
Rey’s first criticism (the spurious one)


          Since Peacocke’s analysis sees conceptso as being individuated by their analytic structures, it obviously presupposes that there is an analytic-synthetic distinction. Quine famously denied that there is an analytic-synthetic distinction, and many agree with Quine on this. So, as Rey points out, Peacocke’s position is wrong if Quine is right. Rey believes that Quine is right, or at least that he may be right; and he therefore holds that Peacocke’s position is either false or tenuous. 
          As we saw in Chapter 16, Quine is not right. Nonetheless, the basic idea behind Rey’s criticism is not an unreasonable one. But the inadequacies that Rey ascribes to Peacocke’s position are better understood in terms of Kripke’s work than they are in terms of Quine’s. Peacocke’s position demands not only that some conceptso have some analytic structure, but that any two non-identical conceptso have different structures. So the concepto Socrates must have a distinct structure from the concepto Plato. We know from Kripke that “Socrates was bald” doesn’t entail anything not entailed by “Plato was bald.” Given this, a case can certainly made that the conceptso corresponding to “Socrates” and “Plato” do not differ in respect of analytic structure. 
        In connection with this, it should be pointed out that Peacocke always illustrates his position in terms of conceptso belonging to arithmetic or mathematical logic: he never relates his analysis to conceptso like bird or Socrates or tree. Given this, it is hard to escape the feeling that Peacocke’s position fails to hold for anything other than a few artifacts and, therefore, that it probably doesn’t hold at all. 
         
Evaluating this criticism 


      This criticism presupposes the truth of a conception of conception and of linguistic understanding that we have found to be quite indefensible. Kripke is right that ┌Socrates has phi┐ doesn’t entail anything not also entailed by ┌Plato has phi.┐ But, as we saw in Part I, we cannot read facts about conception and mental representation off of facts about literal meaning. Having a concept of Socrates consists precisely in knowing the truth of some description that singles out Socrates. I grasp the literal meaning of “Socrates was wise” through an existence-claim; I grasp “Plato was wise” through another existence-claim; and those claims are very different in terms of analytic structure. When we look at what is actually grasped, we find that we don’t have an example of two distinct propositions that have the same analytic structure. We find two different propositions that have very different analytic structures; and we find that, so far as those propositions differ, it is in virtue of the fact that one of them is about Socrates while the other is about Plato, i.e. it is in virtue of the fact that, in the place where one of them comprises a concepto that Plato uniquely instantiates, the other comprises a concepto that Socrates uniquely instantiates. So we have two different conceptso that have very different analytic structures. This is exactly what Peacocke’s analysis needs. So Rey hasn’t yet exposed any real problems with that analysis. 
        Also, as we discussed in Chapter 11, the very idea of two propositions having the same analytic structure is of questionable coherence. (Let use the word “content” to denote either propositional or non-propositional information.) Suppose that contents c1 and c2 are such that, for any content c3, you can infer c3 from c1 in manner M exactly if you can infer c3 from c2 in manner M. In that case, c1 and c2 are presumably one and the same. Rey’s criticism implicitly involves a rejection of this presumption and is therefore probably false. So we may conclude that Rey’s criticism of Peacocke’s view has little force. 


Rey’s second criticism (the cogent one)


       Let us start with a story. Smith believes that n=32.  He non-inferentially transitions from that belief to a belief that n=9. Trivially, there are two different views to take vis-à-vis Smith’s transition. On the one hand, we can say that it was either valid or invalid. On the other hand, we can say that it was neither valid nor invalid. 
       Let us elucidate this second option. If I think “Socrates is wise” at 3:00 p.m., and think something was wise at 3:01 p.m., I haven’t necessarily made a valid inference. In fact, I haven’t necessarily made a valid inference even if my thinking Socrates was wise is what caused me to think something was wise. This can be shown in terms of a story that we told in Chapter 15. A hypnotist programs me to believe something was wise whenever my heart-rate goes above 100 BPM. When I discover that Socrates was wise, the resulting epiphany leads to tachycardia and thus, given the hypnotist’s programming, to my forming the belief that something was wise. Here no inference occurred.
       By the same token, if I believe that something was wise at 3:00 p.m., and a minute (or second) later form the belief that nothing was wise, I am not necessarily guilty of inferring a proposition from its negation. This can be shown through an obvious adaptation of the story just told.
          For similar reasons, given only that Smith transitions from a belief that n=32 to a belief that n=9, it doesn’t follow that his transition is valid; and if he transitions from a belief that n=32 to a belief that n=6, it doesn’t follow that his transition is invalid. 
         If we say that Smith’s transition is either valid or invalid, then we are saying that it is answerable to norms. More specifically, we are saying that it must be consistent with the content of Smith’s belief that n=32. But in that case, Smith’s making that transition cannot be constitutive of his believing that n=32. In general, since there is normativity only where there is already a fixed content, norm-governed transitions cannot be constitutive of content.  
       So if Peacocke’s analysis is to be correct, the transitions of which he speaks must not be answerable to any norms. The problem is that at least some transitions that are not norm-governed are not constitutive of anyone’s grasp of any concepto. The story we told a moment ago shows this. At 3:00 p.m. I form the belief that Socrates was wise, and I non-inferentially transition to a belief that something was wise. Given only this much information, it doesn’t necessarily follow that the concepto of existential generalization is implicated in that transition. It could be that I am only carrying out the hypnotist’s instructions. So if Peacocke’s position is to hold up, he must say that some, but not all, non-inferential transitions are constitutive of conception. 
        But how are the right non-inferential transitions to be distinguished from the wrong ones? Are the mechanisms underlying the right ones sturdier than those underlying the wrong ones? Not necessarily. It could be that the mechanism involved in my carrying out the hypnotist’s instructions is as sturdy as a connection can be.  Are the right transitions those that happen reliably? Not necessarily. It could be that every non-inferential transition that I make is the result of post-hypnotic suggestion. The difference between a principled and an unprincipled transition cannot be understood in purely statistical terms. Speaking statistically, unprincipled transitions may be much more common than principled transitions. 
       One might counter-respond by saying that all other things being equal one is more likely to make a principled than an unprincipled transition. But this is to little avail. In this context, the term “all other things being equal” seems to mean: “so long as one isn’t under hypnotic suggestion or any other compulsion which results in an unprincipled transition.” So the counter-response in question becomes the innocuous claim that one makes principled transitions -- except when one doesn’t. 
       There doesn’t seem to be any non-arbitrary way of distinguishing the non-inferential dispositions that are constitutive of conception from those that are not thus constitutive. So Peacocke’s theory is either arbitrary or false. It is arbitrary if it says that only some non-inferential dispositions are constitutive of conception, and false if it says that all of them are. 
 
Other problems with Peacocke’s view 


         According to functionalism, brain-state B’s realizing a belief that Socrates was wise consists in its having certain consequences, e.g. its leading to a belief that something was wise. But if that is right, then B’s realizing such a belief cannot be what generates those consequences. 
      Peacocke’s analysis is a form of functionalism. It is in virtue of its having certain effects that B realizes a belief that Socrates is wise. But in that case, it is hard to see why the just mentioned problem with functionalism isn’t a problem for Peacocke’s view. 
        Admittedly, Peacocke doesn’t hold that all of the states of affairs generated by B determine what content it has. He seems to hold that the only relevant effects are those that B immediately generates. 
         But this doesn’t help. Suppose that B leads to B2, which realizes a belief that something was wise, and that B2 leads to B3, which realizes a belief that something was sentient. If Peacocke’s analysis is right, B2’s having that effect is constitutive of its being a belief that something was wise. So B2’s having that effect is constitutive of something that is constitutive of B’s being a belief that Socrates was wise. For similar reasons, B3’s being a belief that something was wise is constitutive of something that is constitutive of B’s being a belief that Socrates was wise. At any given juncture, we encounter, at most, something that is constitutive (either directly or indirectly) of B’s being a belief that Socrates was wise. At no juncture, therefore, do we encounter anything could be an effect of B’s being such a belief. Never do we encounter anything that is an effect of my belief that Socrates was wise. 
        This brings us to another issue. If Peacocke is right, conceptso are individuated entirely by their analytic liaisons. So conceptso are relations to other conceptso. Any given concepto is a node in a network that, in its turn, consists in nothing but more conceptso.  
       It is hard to see how this picture can allow conceptso to make any contact with anything non-conceptualo. Right now, physicist Smith is having various perceptions. On the basis of these perceptions, along with a correct understanding of the conceptso electron, proton, weak force, and so on, Smith makes a correct inference as to the sub-atomic structure of object X. In general, what we perceive is relevant to how we understand at least some relations among conceptso. Not all relations among conceptso are to be understood in strictly conceptualo terms. But this would not be the case if any given concepto were a node in a structure that consisted of nothing but conceptso (and their mutual relations). 
        Hilbert famously gave purely formal definitions of terms like “line”, “point”, “parallel with”, and so on. Each of these terms was defined in terms of the others. None was defined in terms of anything that had any sensory or para-sensory content. So long as one thinks of the totality of conceptso as forming a purely formal structure, such as Hilbert’s formalization of geometry, one may not be guilty of saying that any given concepto is to be understood solely in terms of its relations to other conceptso. But conceptso are not purely formal entities. There are right and wrong ways to conceptualize experience. I am right to think that plant is green, wrong to think that plant is red, and even more wrong to think that Martian is red. If conceptso were to be understood strictly in terms of their mutual relations, no conceptualization of any experience would be any better or any worse than any other. Conceivably one might say the following in response to this: 


   Any experience can be conceptualized in any way that one wishes. It is not conceptso per se that rule out certain conceptualizations of experience. It is conceptso plus certain auxiliary statements that do so. Those auxiliary statements link conceptso to experience and thus provide experiential models of them, just as statements about light-beams bouncing off mirrors can model statements about triangles. 


    But this point of view rebuts itself. It is a datum that I am right to think grass is green and wrong to think penguins wear top hats. So the “auxiliary hypotheses” that the objector mentions must themselves be internal to the structure formed by the totality of all conceptso. 
      Of course, a given perception 666 may warrant different beliefs, depending on what on what one already believes. If I believe that I am looking at myself in a normal mirror, perception P warrants the conclusion that I am eleven feet tall. If I believe that I am looking at myself in a mirror that is warped in a certain way, perception P warrants the view that I am six feet tall. But if any experience, or series of experiences, can correctly be conceptualized in any way at all, then it won’t  matter what other experiences I’ve had. Under that circumstance, those other experiences will fail to provide a benchmark in terms of which I am to know how to conceptualize P. So to the extent that P warrants the view that I am of this as opposed to that height, it is because experiences other than P are to be conceptualized in certain ways and not in others. It is not an option to say that the principles linking conceptso to experience are external to those conceptso themselves. 
      Whether a concepto is instantiated is typically to be decided on experiential grounds. It is only the basis of sense-perception that I can know whether somebody is wearing a blue-shirt, xxx i.e. it is only on the basis of sense-perception that I know the concepto blue-shirt wearer is instantiated. But in order for experience to warrant such a belief, the concepto blue-shirt wearer must already be such that certain kinds of experiences warrant the view that it is instantiated. Even though it is an empirical matter whether a given concepto is instantiated, it is not ultimately an empirical matter what kinds of experience would warrant the view that it is instantiated. Given the structure of the concepto blue-shirt wearer, it doesn’t follow that somebody is wearing a blue shirt. But given the structure of that concepto, it does follow that if one were to have certain sense-experiences, one would be right to believe that concepto to be instantiated. 
         Most empirical judgments can be overturned by later experiences. (I say “most” because, arguably, some judgments about phenomenology are not corrigible.) But this proves only the trivial point that empirical judgments are not analytic. It doesn’t show that it is not analytic whether a certain kind of experience would confirm a certain empirical judgment. In fact, it shows the opposite. So far as an empirical judgment is capable of being over-turned by future experience, that is because, given the conceptso involved in the proposition affirmed by that judgment, it is already determined what experience would have to be like in order to warrant a rejection of that judgment. 
         If Peacocke’s analysis is right, any given concepto’s structure is to be understood strictly in terms of that concepto’s relationships to other conceptso. Peacocke’s analysis is therefore inconsistent with the fact that there are right and wrong ways to conceptualize experience; and it is inconsistent with the related fact that, ultimately, whether a certain kind of experience would warrant an empirical judgment is not itself an empirical matter.  
         To evade this charge, Peacocke would have to say that sense-experience was itself some kind of conceptualization. But this is not a reasonable position. (Nor would Peacocke take it. Peacocke is acutely aware of the distinction between conceptualo and non-conceptualo content, and he rightly holds that perceptual content is non-conceptualo.[270]) My thinking that Tom is wearing a blue-shirt is very different from my seeing a state of affairs that involves Tom’s wearing a blue shirt. The first is a conceptualization of various experiences. The former is not.[271]  
        Also, if we say that sense-experience is some kind of conceptualization, then we are stuck with the question – a conceptualization of what? If experience is to provide any basis for any conceptualizations, then experience becomes, as Davidson (2001: Chapter 10) put it, a “frictionless spinning in a void.”
        McDowell (1994) argues that, because sense-experience warrants certain conceptualizations, it must itself be conceptual. McDowell is right to emphasize that a theory of experience must allow that facts about conceptualo structure determine what judgments we can legitimately make on the basis of a given experience (or set of experiences). But it doesn’t follow that sense-experience is itself nothing other than a kind of incessant conceptualization. Given that a person can be represented by a grid consisting of black and white boxes, it doesn’t follow that a person is such a grid. 
        
An outline of an alternative to Peacocke’s analysis


        Let us start with some facts. I am disposed to believe x has more than two sides if I believe x is a triangle. I am disposed to believe m is larger than n if I believe m is what results when some positive number is added to n. Given a grasp of any concepto C, one’s beliefs tend to track C’s analytic structure. Peacocke’s analysis is meant to accommodate this important fact; and at first it seems to do a reasonable job. 
         But we’ve also seen that Peacocke’s analysis is probably false. What should replace it? We need to produce a theory that, like Peacocke’s, accommodates the datum just mentioned but that, unlike Peacocke’s, doesn’t strip the mental causal potency and that, unlike Peacocke’s, doesn’t strip conceptso of experiential import. 
       I believe that the elements of a solution may lie in some points that we made in the last two chapters. First of all, conceptso are not so different from properties. For x to have the property of triangularity just is for x to fall under the corresponding concepto. In fact, to many authors, the words “property” and “concept” are interchangeable. 
        Admittedly, this line of thought must be qualified. The concepto successor of one is obviously different from the concepto predecessor of three. (This is because thinking x is a successor of one is different from thinking x is a predecessor of three.) But the property of being a successor of one doesn’t seem to be different from the property of being a predecessor of three. (This is because anything that has the one property ipso facto has the other: so being a successor of one is not different from being a predecessor of three.) Nonetheless, it does seem at least approximately true to say that conceptso just are properties. If only to facilitate exposition, let us proceed on the assumption that this is right. (Later we will argue that this assumption is correct.) 
        In light of this, let us remember what we said about properties. Property-instances turn out to be abstract objects, contrary to what has generally been assumed. Properties themselves are commonalities holding among such abstract objects. The properties that are expressed by most natural-language predicates – e.g. “red”, “hot”, “square-shaped” – turn out to be commonalities holding among these commonalities: they turn out to be hyper-properties. The only natural-language expressions that denote bona fide first order properties are tokens of certain demonstrative expressions (e.g. “the exact color of that rose”). 
       These metaphysical points have epistemological parallels. Representations of property-instances turn out not to be cognitively fundamental. Representations of situations are fundamental; and property-instances are understood in terms of situations – they are what situations have in common. Similarly, representations of properties per se are understood in terms of what such commonalities have in common. 
         This suggests that our concepts of properties are descriptive in nature. But concepts are described not in terms of other properties, but rather in terms of situations. To grasp a property is to see what situations have in common. (More precisely, it is see what is had in common by commonalities that hold among commonalities….that hold among situations.) A cognitive representation of a property just is an understanding of what different situations (or commonalities that hold among commonalities…that hold among situations) have in common. This suggests that properties are cognitively represented descriptively. 
          Our analysis is consistent with the fact that conception tracks analytic structure. But this structure will not always be represented propositionally. This is because grasping conceptso (or properties) is obviously a pre-requisite to grasping propositions, given that the latter are constructed out of the former.[272] 
        Of course, there are some conceptso such that, to grasp them, one must first grasp some proposition or other, e.g. the concepto of being a thing x such that x is tall and snow is white or x is short and snow is green. But it is viciously regressive to say that conceptso must always be represented in terms of propositions. Ultimately conceptso are understood in non-propositional terms. For similar reasons, they are (ultimately) understood in non-conceptualo terms.
       Mental representations of properties are descriptive xxx. But the descriptions in question xxx are not constructed (only) out of propositions or conceptso. They are (also) constructed out of representations out of concrete situations. Let us say that a representation (a perception or mental image) of a situation is a “situation-representation.” (In this context, the term “mental image” needn’t refer only to visual images.) 
        Given these points, suppose that Smith grasps the concepto triangle and that he also grasps the concepto straight-edged figure. We need to account for the fact that Smith is likely to believe an object to fall under the second concepto if he believes it to fall under the first. Our analysis enables us to do so. For Smith to grasp either concepto is for him to understand what various situations have in common. For x’s being a triangle to entail its being straight-edged is for the one class of situations to be less inclusive than, but otherwise coincident with, the other; and for Smith to be aware of this entailment is for him to be aware of that inclusion-relation.[273] Given what conceptso are (namely, commonalities among commonalities among....situations); and given what it is to grasp a concepto (namely, to be aware of the existence of such commonalities); it follows automatically that Smith is in a position to believe x is straight-edged if he believes x is a triangle; and it also follows that Smith will believe the second, given a belief in the first, in so far as he is rational and in so far as he is not inhibited by performance-related factors. 
     But, if our analysis is right, it would be false to say that Smith’s grasping the one concepto consisted in his grasping the other. In virtue of the grasping the first concepto, one can grasp the second: but one needn’t do so. The kind of knowledge that is constitutive of a grasp of the concepto straight-edged is constitutive of a grasp of the concepto triangle. But a grasp of the concepto straight-edged is not itself constitutive of a grasp of the concepto triangle. 
       This is exactly what we want. In so far as one’s grasp of the concepto straight-edged is constitutive of one’s grasp of the concepto triangle, one’s believing x is a triangle cannot cause one to believe x is straight-edged. After all, if one’s grasp of the  first concepto is constituted by one’s grasp of the second, then thinking x is a triangle involves thinking x is straight-edged: the first thought is the second thought – plus certain other thoughts (e.g. x has three sides and x is closed). Since nothing can stand in any causal relation with respect to itself or any part of itself, it follows that one’s thinking x is a triangle cannot have a causal relation to one’s thinking x is straight-edged. Our analysis doesn’t have this problem. 
      As we just saw, Peacocke’s analysis demands that your thinking x is a triangle actually involve your thinking x is straight-edged and three-sided and closed. This makes it hard to explain why propositions like triangles are three-sided, straight-edged, closed figures can be informative. Our analysis doesn’t have this problem. 
       At the same time, our analysis accommodates the fact that, if you believe that x is a triangle, you all but believe that x is straight-edged. According to our view, your belief that x is a triangle is a conceptualization of certain set of situation-representations, and your belief that x is straight-edged is a conceptualization of a certain set of situation-representations that includes the first set. So if you believe that x is a triangle, you either believe that x is straight-edged or you need only conceptualize what you already know to generate that belief. This position is consistent with our intuition that there is a constitutive relation between believing x is a triangle and x is straight-edged. But it is also consistent with the fact that  if x is a triangle is a triangle, then x is straight-edged is not as trivial as if x is an unmarried male, then x is unmarried. 
        Of course, as analytic statements go if x is a triangle is a triangle, then x is straight-edged is fairly trivial. But obvious extensions of this line of thought show how there can be analytic statements that are decidedly non-trivial – how there can be statements like a circle is a closed two-dimensional figure of uniform curvature and a set S is infinitely large exactly if its members can be put into a one-one correspondence with the members of a proper subset of S.
       These points give us some insight into the so-called “paradox of analysis.” [274] Some background will help us identify this paradox. An adequate conceptualo analysis is given by a true biconditional statement. An example would be: 


(k) x is a circle iff x is a closed, two-dimensional figure of uniform curvature.


 But not just any true biconditional will do. For example, 


(k*) x is a circle iff x is a circle


is not an analysis. This is because it is trivial. And x is a unique contemporary U.S. President iff x is George W. Bush is not a conceptualo analysis, even though it is non-trivial and true. This is because it is not analytic. So an analysis is given by a true, analytic, and non-trivial biconditional; and a partial analysis (e.g. if x is a circle, then x has a uniform curvature) is given by a non-trivial, analytic conditional. 
       Now we can state the paradox of analysis: How can a correct analysis be informative, given that the concepto on the left side of the biconditional must be identical with the concepto on the right? If the concepto closed, two-dimensional figure of uniform curvature is different from the concepto circle, then (k) fails to delineate the structure of the latter, and thus fails as an analysis. But if those conceptso are identical, then (k) should be as trivial as (k*). 
        What are we to say about this paradox? First of all, conceptualo analyses don’t state conceptualo identities. The concepto circle is not identical with the concepto closed, two-dimensional figure of uniform curvature. Those conceptso are different conceptualizations of the same situation-representations. Therefore, xxx given a few obvious adjustments, what we said in connection with the conceptso triangle and straight-edged explains why (k) is both non-trivial and true. 
      If we don’t distinguish between conceptualo and non-conceptualo content, it is xxx quite impossible to explain how there can be such a thing as conceptualo analysis. Analyses expose internal, necessary relations between conceptso. But, as we just noted, they don’t expose conceptualo identities. Given this, if we say that all content is conceptualo, then we must say that conceptualo analyses expose the “depths” or the “structures” of conceptso. 
      But that statement is easily shown to be false. The concepto class of all points equidistant form a given point in a plane is different from the concepto closed planar figure of uniform curvature. This is equivalent to saying that the kind of thought that you have in virtue of thinking that x falls under the one concepto is different from the thought you have in virtue of thinking that x falls under the other. In light of this, suppose we say that conceptualo analyses (when true) expose the “depths” or the “structures” of conceptso. In that case, we are saying that when you think: 


(i) x is a class of all points equidistant form a given point in a plane,


the content of your thought xxx actually includes the proposition: 


(ii) x is a closed planar figure of uniform curvature. 


       But when you think (i), you aren’t necessarily thinking (ii). When I think Sam is short and Mary is tall, the proposition Sam is short is a part of the content of what I am thinking. (ii) is no part of the content of what I am thinking when I think (i). 
       One may say that, when I am thinking (i), I am “implicitly” thinking (ii). But, if taken as a psychological hypothesis, this is highly doubtful. If taken as a non-psychological, strictly logical thesis, it is just a misleading way of saying that (ii) is a correct analysis of what I think when I think (i). 
     If one holds that conceptualo content is the only kind, then the paradox of analysis becomes unsolvable. But that paradox is quite solvable if we distinguish between conceptualo and non-conceptualo content. A concepto is a conceptualization of content that is not itself conceptualo; and an analysis of a concepto (a conceptualo analysis) is a re-conceptualization of that same non-conceptualo content. 
        In this way we  accommodate the fact that there is an internal connection between the conceptso circle and closed figure. But we are not forced to say the one concepto has the other as a veritable ingredient; and we are thus not forced to say that, when you think circle, you necessarily think closed figure. At the same time, we have explained why, if one grasps the first concepto, one has all but grasped the second, thereby explaining why conceptualo analysis produces a feeling of recognition – of seeing what one has already seen, through from a new perspective -- as opposed to a feeling of discovery de novo.  
      
Conceptso versus properties 


      To facilitate the exposition of our argument, we assumed that conceptso are identical with properties. According to this view, the concepto of being a triangle is identical with the corresponding property. This is not an unreasonable view, and some philosophers hold it. But it is one that must at least be qualified. The concepto closed three-sided, straight-edged, planar figure one is obviously different from the concepto area bounded by three straight-lines such that any two of them, but not all three of them, intersect. But it is hard to see how those conceptso could correspond to different properties. Supposing that x falls under the concepto closed three-sided, straight-edged, planar figure and y falls under the concepto area bounded by three straight-lines such that any two of them, but not all three of them, intersect, there isn’t necessarily any difference between x and y. In fact, x and y could be numerically identical. Where there are no differences, there are no differences in properties. It seems that we have one property and a multiplicity of conceptso. 
         This doesn’t mean that conceptso are not properties. But it means that the statement conceptso are identical with properties must be qualified, lest it entail the falsehood that the concepto even prime is identical with the concepto successor of one. A point made by Frege (1954: 60-61) points us in the direction of what I believe to be a correct understanding of the relationship between conceptso and properties. If you say “x is a triangle”, you are ascribing a property to x. But for any individual x, the sentence ┌triangles are closed figures, but x is not a closed figure┐ is not self-contradictory. So there is no individual x such that, if you say “triangles are closed figures”, you are saying anything about x. 
          This suggests that statements like:


(T) triangles are closed figures


ascribe properties not to individuals, but to other properties. Of course, the property of being a closed figure is a property of individuals, not of properties. After all, the property of triangularity does not itself have the property of being a closed figure. The property ascribed by (T) to the property of triangularity is not that of being a closed figure, but is rather that of being such that any of its instances is a closed figure. Thus, conceptso are to properties what properties are to individuals.
         We saw in Chapter 21 that properties are commonalities that hold among commonalities (that hold among commonalities…) that hold among situations. I thus propose that conceptso are commonalities holding among the commonalities just mentioned. In other words, conceptso are higher-order properties. Given that both (T) and 


(C) circles are closed figures


are true, the property of being a circle has a property in common with the property of being a triangle. They both have the property of being such that their instances are closed figures. The concepto closed three-sided, straight-edged, planar figure obviously has a different composition from the concepto area bounded by three straight lines such that any two of them, but not all three of them, intersect. That is why they are different conceptso. But both conceptso correspond to a property that is unique to the property of triangularity. The property of triangularity is uniquely such that all and only its instances are closed, three-sided, straight-edged, planar figures; and the property of triangularity is also uniquely such that all and only its instances are areas bounded by three lines any two of which, but not all three of which, intersect. An individual falls under the one concepto if it falls under the other. But this is not because that individual has a different property corresponding to each of those different conceptso. It is rather because a property (that of being triangular) had by that individual has a different property corresponding to each of those different conceptso. We have thus made some case for the view, presupposed by our analysis of analysis, that conceptso are properties.
        
Chapter 25  Semantics versus Psychology 


        In this chapter, we will once again stop using the term “concepto” (and any derivatives thereof, e.g. “conceptualo”), since context will make it clear whether we are discussing concepts in the platonic sense or concepts in the psychological sense.
        It seems reasonable to suppose that one must know the semantic rules of any language that one knows and that linguistic ability is therefore posterior to cognitive ability.  If this is right, then it is obviously viciously regressive to suppose that we think in a language. Advocates of SCT deal with this by saying that one doesn’t have to know the semantic rules of a language whose expressions mediate one’s own thoughts. It is necessary only that one be “built to conform” to those rules. 
      In this chapter, we will see some reason to believe that, given a correct analysis of the concept of a semantic rule, there can be no language where there is no knowledge of semantic rules and that SCT is therefore guilty of vicious regressiveness.


The background
        
         Why does “snow is white” mean snow is white and not grass is green? In general, 


(EM) Why do our expressions mean what they do? 


        Grice had a certain view about this. But that view is not tenable, since it is subject to innumerable examples. To deal with this problem, Griceans have proposed modifications of Grice’s theory. But in addition to having an epicyclical and ad hoc quality, those modifications are themselves subject to counterexamples.[275] 
         Further, as Searle (1969: 42-50), xxx and other authors make clear, there are systemic problems with Grice’s analysis. If I think that there is no pre-existing symbolic relationship between “Socrates was wise” and the proposition that Socrates was wise, then I cannot mean the latter by an utterance of the former. In general, a person cannot mean X by Y unless he believes there to be an existing symbolic relationship between X and Y. Since the essence of Grice’s theory is that linguistic meaning is derivative of speaker’s meaning, it seems that there is little hope for Grice’s theory or for any elaboration of it. That is why few currently advocate Grice’s theory of meaning. 
        But given only that the Gricean theory is incorrect, it doesn’t follow that semantic relations are to be understood in non-psychological terms. We saw in Chapter 20 that they cannot in fact be understood in this way.
         I would now like to propose a third view. According to this view, semantic relations are to not to be understood in terms of what people mean, but they are to be understood in terms of what people think.  
         
Some conditions that a semantic theory must satisfy 


    A semantic model cannot be viciously circular, i.e. it cannot itself use the notion of meaning. Suppose that somebody put forth the following hypothesis: 


(H) Tokens of “snow is white” mean snow is white because people agree among themselves that “snow is white” is to mean snow is white. 


         At first, this view doesn’t seem particularly unreasonable. After all, you and I could agree to let “Skippy” be our code-name for a friend of ours. But (H) will not do as a general hypothesis as to the nature of expression-meaning. This is because (H) itself uses the concept of expression-meaning, and it thus presupposes an antecedent understanding of that concept. 
        Let us extend this line of thought. Suppose that somebody put forth the following hypothesis: 


(HT) Tokens of “snow is white” are true iff snow is white because people agree among themselves that “snow is white” is to be true iff snow is white. 


       Superficially, (HT) seems better than (HM). The concept of truth seems to be pre-linguistic. A cat can truly believe that you are about to feed it. A dog can truly believe that you are about to kick it. In general, non-linguistic creatures have true and false beliefs. And, of course, they can also have accurate (true) and inaccurate (false) perceptions. So true and false mental states are obviously antecedent to language.[276]
        Further, the notion of linguistic truth is plainly derivative of that of propositional truth. The proposition there is water on Earth was true long before there were any creatures or, consequently, any language.[277] So given the fact that truth is not a distinctively linguistic notion, it might seem that (HT) is not guilty of vicious circularity. 
       But this is a mistake, and (HT) is viciously circular. The notion of truth is, indeed, not a distinctively linguistic notion. But the very question -- or, at least, one of the very questions -- that a semanticist must answer is “what is it for an expression to be true?” The question “what is it for ‘snow is white’ to mean that snow is white?” is scarcely different from the question “what is it for ‘snow is white’ to be true iff snow is white?” So even though truth is a pre-linguistic notion, (HT) is still viciously circular; for the very question that we are trying to answer is, in effect, “what is linguistic truth, and what is it for an expression to be true under such and such circumstances?” 
          The first thing anyone trying to answer (EM) must do is to find some notion such that the concepts of expression-meaning (and expression-truth) can be non-circularly understood in terms of that notion. There is such a notion: it is the notion of success. 


The concept of linguistic success 
  
        Let us set aside language for the moment, and let us instead discuss the game of tennis. The game of tennis is being played in a given context exactly if, in that context, certain things count as success as other things count as failure. If you hit a certain ball that has bounced no more than once on your side of the court into your opponent’s side of the court, and your opponent fails to do the same thing (mutatis mutandis), you have won a point, and you have thus had a success of a certain kind.  (It is obviously irrelevant that points are measured in multiples of fifteen.) If you have a certain number of successes of this kind before your opponent, then you have another kind of success (you win a game). If you have a certain number of successes of this kind before your opponent, then you have another kind of success (you win a set). And so on. 
        For a game of tennis to played in a context C just is for it to be the case that, in C, these things count as success, and that not doing them counts as failure. A game of tennis is being played in C exactly if those success-conditions and failure-conditions are operative, i.e. are instantiated, in C. So the game of tennis itself is a property had by situations exactly if, in them, those conditions apply. And a particular tennis-match, i.e. an instance of the game of tennis, consists in the instantiation of those conditions. 
         Here we have to be careful. It is not as though the game of tennis exists first, and these rules subsequently impose some kind of structure on this antecedently existing entity. There is no such thing as tennis until it is the case that, in certain situations, one enjoys a certain kind of success iff one hits a ball (that has bounced no more than once in a certain place) over a certain kind of net, and the person standing on the other side of that net fails to do the same thing. 
        The concept of success, in this context, is thus not to be defined  in terms of the game of tennis. On the contrary, the game of tennis is to be defined in terms of that concept, and that concept is to be taken as a primitive.[278]
        Of course, that concept is not primitive tout court.  From a psychoanalyst’s perspective it may not be primitive and may represent, for example, a symbolic re-enactment of some primordial situation. But, for the reasons just given, the concept of success, in the relevant sense, is primitive with respect to the concept of the game of tennis. 
       Here we must remember Searle’s (1969) distinction between “constitutive” and “regulatory” rules. People bought and sold stock long before there was a law prohibiting insider trading. Therefore that law isn’t constitutive of the practice of buying and selling stocks; it merely regulates that practice. Here we are dealing with a “regulatory” rule.  
         But the rules discussed a moment ago are in a different category. It isn’t as though people were playing tennis first, and those rules were subsequently imposed on this activity. Rather, those rules constitute the game of tennis. As Searle (1969: 33-42) points out, the rules of tennis, chess, and other games are rules in the constitutive, not the regulatory, sense. Searle also suggests that semantic rules are rules in the constitutive, not the regulatory, sense. I believe that Searle is correct, and I would now like to develop this suggestion. 


Applying these points to semantics 


        Given these points, we can outline what I hope is a defensible analysis of the concept of a semantic rule. For the sake of simplicity, let us initially consider only assertoric utterances. 
           There is some point of view from which an utterance of “Socrates was wise” is a success just in case Socrates was wise, and from which, more generally, an utterance of the form ┌Socrates has phi┐ is true iff Socrates has the property phi.
      This doesn’t meant that if you say “Socrates was wise”, and he in fact was wise, anything particularly desirable will happen to you. True utterances don’t necessarily bring one wealth, fame, or happiness. But it does seem to be a simple fact that, from one important perspective, an utterance of “Socrates was wise” is a success exactly if Socrates was wise, and an utterance of “Socrates was not wise” is a failure under that same circumstance. 
        Here we have to recall a distinction that we made when discussing Wittgenstein’s Rule-following argument: the distinction between linguistic success per se and the consequences of such success. A detour through the game of tennis may once again be useful. If you beat your wealthy and vain father-in-law at tennis, you have enjoyed a kind of success (tennis-success). But the consequences of your tennis-success may be disastrous: he disinherits you, fires you from your sinecure at his firm, and so on. 
       Similarly, if you say “Socrates was wise”, you deserve credit for a kind of success (linguistic success). But the consequences of that success may outweigh the success itself. For some reason, your boss hates anyone who thinks that Socrates had any redeeming characteristics. So he fires you when you say “Socrates was wise.” And had you instead said “Socrates was not wise”, the consequences of your linguistic failure might well have been outweighed by success of a non-linguistic kind. 
          Comments very similar to those made a moment ago about tennis are true of language. It isn’t as though the English language exists first, and then there come into existence various facts about success- and failure-allocation of the kind just described. It isn’t as though the English-language exists first, and then it comes to be that one enjoys success if one utters “Socrates was wise” iff Socrates was wise and, more generally, if one utters a sentence of the form ┌…Socrates…┐ iff Socrates has property…x…The English language doesn’t exist until it is the case that, in certain situations, one enjoys a certain kind of success iff one fulfills conditions of the sort just described. 
       (The statements giving the success-conditions of language are double-conditionals, making them harder to follow than the corresponding statements for tennis. But apart from that, there is an obvious parallel between the two types of statements.) 
       So for English to be spoken in a given context C just is for it to be the case that (inter alia) an utterance in that context of ┌x is red┐ is a success exactly if x is red, and an utterance in that context of “Socrates was not wise” is a failure exactly if Socrates was wise. The concept of success, in this domain, is not to be understood in terms of the English language. On the contrary, the English-language is to be understood in terms of the concept of that kind of success, and that concept is thus to be taken as a primitive in this context. Of course, that concept is not primitive from a psychological perspective. But it is primitive with respect to the concept of the English-language.


Why the concept of language is not to be understood in terms of the concept of truth 


       It is typically thought that the concept of language is to be understood in terms of the concept of truth, not of success. There are two reasons why this is not the case. Any attempt to understand linguistic meaning in terms of truth is bound to result in a theory that is either viciously circular or that fails to distinguish actual from merely possible semantic rules. As we saw in Chapter 20, we cannot explain the fact that “Socrates snored” means Socrates snored by saying that the relevant semantic rule is a function that assigns truth to an utterance of “Socrates snored” exactly if Socrates snored. After all, there is a function that assigns truth to an utterance of that same sentence exactly if Socrates did not snore. This shows that the mere existence of a function of the kind described is insufficient for the existence of an operative semantic rule. (A “non-operative” semantic rule is no more an actual semantic rule than a possible individual is an actual individual.) So a theory that identified semantic rules with functions from utterances to truth-values fails to distinguish semantic rules from their possible, but non-operative, counterparts. 
      In response, one might say, as Lewis (1975) does, that an operative semantic rule is a function that people use.  But then we must ask: what is for people to use a function that assigns truth to utterances “Socrates snored” iff Socrates snored? It is presumably for there to be an understanding among people that utterances of “Socrates snored” are to be considered true iff Socrates snored. But, as we saw a moment ago, such an understanding is itself to be understood in terms of the existence of semantic rules. An agreement that utterances of “Socrates snored” is to be assigned truth iff Socrates snored is not significantly from an understanding that such utterances are to mean Socrates snored; and obviously such an understanding is itself to be understood in terms of the concept of a semantic rule, and thus cannot in their turn provide an analysis of that concept. So if we identify semantic rules with functions from utterances to truth-values, our theory is either viciously circular or it fails to distinguish operative from non-operative semantic rules. 
          There is a second reason why the concept of a semantic rule is not to be understood in terms of the concept of truth. Many well-formed utterances are neither true nor false. Because of this, their semantics cannot be understood in terms of the concept of truth, at least not in any direct or natural way. But their semantics can be understood in terms of the concept of success. If I ask “did Socrates snore?”, my utterance is a success, in the relevant sense, exactly if, in response to it, the person I am addressing correctly affirms (or correctly denies) the proposition that Socrates snored. If I say, “Socrates, snore!”, my utterance is a success exactly if, in response to it, my auditor Socrates snores. 
          There are obviously appropriateness-conditions for questions and imperatives.[279] The question “was Socrates wise?” isn’t true or false; it doesn’t have truth-conditions. But it is obviously a meaningful utterance, and any viable semantics must accommodate that fact. It is obviously an important part of the semantics of “was Socrates wise?” that the person to whom an utterance of that sentence is directed is, in some sense, supposed to correctly affirm either that Socrates was wise or that Socrates was not wise. It is not as though the sentence “was Socrates wise?” first had a semantics, and then there arose this fact as to how auditors of tokens of it are to react to it. No – quite obviously, this fact about how auditors are to react to is constitutive of its semantics. The semantics of questions -- and by obvious analogues of the argument just given, imperatives, optatives, and so on – are to be understood in terms of the concept of success.


The meanings of sub-sentential expressions 


           The meanings of sub-sentential expressions, e.g. “Socrates”, are to be understood in terms of their affect on the success-conditions of utterances in which they occur.[280] As we’ve discussed, an assertoric utterance of “Socrates was wise” is a success, in the relevant sense, exactly if Socrates was wise. More generally, ┌Socrates has phi┐ (or, equivalently, ┌…Socrates…┐) is a success exactly if Socrates has phi (or, equivalently, exactly if…Socrates…). Going up another level of generalization, E refers to O exactly if (assertoric) utterances of the form ┌…E…┐ are true exactly if O has the property…x…
          So even though an utterance of “Socrates” does not by itself have success-conditions (leaving aside cases where such an utterance is merely elliptical for a whole sentence), the semantics “Socrates” is to be understood in terms of the success-conditions of sentences of which it is a part. 
         In response to this, it might be said that “Socrates” is to be defined non-contextually – that the semantics of “Socrates” is given by the non-contextual definition: “Socrates” refers to Socrates. But it would be meaningless to say that “Socrates” referred to Socrates but then to deny that, in virtue of having the form ┌Socrates has phi┐, a sentence had anything to do with Socrates or, more precisely, with Socrates’ having phi. When we say that “Socrates” refers to Socrates, we are saying that ┌Socrates has phi┐ is true iff Socrates has phi, that an appropriate answer to ┌does Socrates have phi? ┐ is a correct affirmation of that Socrates has phi or that Socrates does not have phi, that an appropriate response to an utterance of ┌Socrates, have phi! ┐ consists in Socrates’ coming to have phi in consequence of that utterance, and so on.[281] 
       Of course, not everyone will agree with every aspect of what was just said. But what seem uncontroversial is that there is a certain kind of success S, such that it is constitutive of the semantics of “Socrates was wise” that assertoric utterances of it have S if Socrates was wise, and lack S otherwise. It is clearly constitutive of the semantics of assertoric sentence-tokens of the form ┌Socrates has phi┐ that any such token is a success exactly if Socrates has phi. Similar remarks apply to questions of the form ┌does Socrates have phi?┐ and to imperatives of the form ┌Socrates, have phi! ┐ 
        Supposing that M is the actual semantics of “Socrates”, it would be very artificial to maintain that the word “Socrates” first had M and that, subsequently, the facts just described (regarding the allocation of success and failure to uses of “Socrates”) were superimposed on that semantic fact. It is much more natural to suppose that “Socrates” has M in virtue of the fact that these success-conditions are instantiated. 


The concept of linguistic success (continued)


           Even though a token T of “was Socrates wise?” isn’t true or false, there is still some proposition P such that T is a success, in the relevant sense, exactly if P is true. As we discussed, T is a success exactly if the person to whom it is directed correctly affirms either that Socrates was wise or its negation. So the verbiage to the right of the “exactly if” in the last sentence picks out the appropriate value of P. 
         Obvious adaptations of what we just said are true of all tokens of the form ┌…Socrates…┐, and not just of tokens of that form that are in the interrogative mood. 
And what we just said about “Socrates” is true of all utterances. 
       This is not to say that all expressions refer. (In Chapter 22, we saw why, in light of an argument of Frege’s, it is not possible to maintain that expressions refer.) But it is to say that, given any meaningful expression e, e’s semantics is given by some proposition to the effect that, for any utterance T of the form ┌…e…┐, there is some proposition P such that T is a success exactly if P is true. No matter what views one has as to the semantics of “and” or “or” or case- or tense-markers, no one will deny that the semantics of such an expression is given in its entirety when it is said when it is appropriate to use sentences containing them. Supposing (what isn’t strictly true[282], but may serve as a convenient simplification) that a token of ┌P and Q┐ is true iff P is true and Q is true, then one knows everything there is to know about the semantics of “and”, it being irrelevant whether one also thinks (as Montague did) that “and” refers (to a function from pairs of sentences to truth-values) or whether one thinks (as the early Wittgenstein did) that it does not refer to anything. If two people agree as to whether the biconditional given a moment ago is correct, then they ipso facto agree as to the semantics of “and” – even though they may disagree as to the nature of what it is they are agreeing about. (Hilbert and Frege agreed that 7+5=12, even though they disagreed as to the nature of what it is that they are thereby agreeing about.) 
      All of this may be distilled into the following statement: 


(*) There is a certain kind of success S such that E is a symbol of a public language (e.g. Urdu, English, Spanish) exactly if, given any token T of the form ┌…E…┐, there is some proposition P such that T has S exactly if P is true. 
     
      For reasons already given, S is to be distinguished from monetary success, professional success, and any other garden-variety success.
        If (*) is even approximately right, then for something E to be a symbol of a public language is for it to be the case that E satisfies the following condition: given any utterance T of the form ┌…E….┐, there is some proposition P such that T has S exactly if P is true. Given that success and failure presuppose the existence of thought, it seems to follow that the existence of a thought is indeed a pre-requisite to that of anything having any significant resemblance to a symbol of a public language. 
         This shows that if (*), or anything like it, is correct, then thought is prior to language, and that SCT is in fact guilty of the vicious regressiveness of which it is often accused. 


How to give a non-circular account of linguistic meaning 


        I would now like to indulge in what might at first seem like a fruitless and fanciful digression. Strictly for the sake of argument, suppose that somebody proposed the following hypothesis: 


(HB) Tokens of “Bob is at the store” mean Bob is at the store because there is an agreement among people that, from a strictly linguistic viewpoint, such a token is a success xxx exactly if Bob is at the store. 


Before proceeding, I should make it clear what I do, and do not, hold. There is no doubt that (HB) is false. (For expository reasons, let us momentarily forget about the type-token distinction.) “Bob is at the store” is a complex expression. It means what it does because of what its components mean; it means Bob is at the store because of what is meant by “Bob”, “store”, “at”, and so on. So the reason that “Bob is at the store” means Bob is at the store is not that people agreed to let that particular expression have that particular meaning. 
      But, right now, that is irrelevant. Here what I wish to ask is this: Leaving aside the question of whether it is true or even plausible, is (HB) circular? Is it characterized by the same kind of vicious circularity as (HM) and (HT)? 
       My answer is “no.” But there are two reasons why many would say “yes.” Let us consider these before proceeding. The first reason is that the expression “linguistic” occurs in (HB). 
       So far as (HB) seems circular, that has nothing to do with its content, and is strictly a matter of how it is formulated. First of all, there is no denying that some kind of pre-verbal communication exists. Within limits, including people, manage to make it clear to other creatures that they have certain intentions, feelings, and so on. When a dog growls at you, he is letting you know that you should back off. In general, language isn’t required for people to exchange certain pieces of information. Rather, language seems to be a way of extending the scope and precision of existing, non-verbal ways of communicating. 
          As we just noted, the activity of exchanging information does exist among pre-verbal entities, albeit in an extremely modest form. That activity defines a unique field of endeavor: a sphere of conduct to which a special conception variety of success attaches. (Remember Aristotle’s point that, to each kind of endeavor, there corresponds a unique kind of success.) Let us refer to that sphere of conduct as SC. Given this, we remove the aforementioned circularity from (HB) by rephrasing it thus: 


(HB*) Tokens of “Bob is at the store” mean Bob is at the store because there is an agreement among people that, within SC, such a token is a success exactly if Bob is at the store. 


Of course, (HB*) presupposes that our pre-linguistic ancestors – the ones who had no language before they themselves instituted it – are aware that SC exists. In other words, it presupposes that, at some level, they know there to exist among themselves an activity of exchanging information. But this is obviously a reasonable supposition; for it is not out of the question to suppose that pre-linguistic humans were intelligent enough to know that they had methods of communication. It is readily seen that (HB*) is not guilty of the just described circularity. 
       But one might believe (HB), and also (HB*), to be guilty of another kind of circularity. It has been said that the very instituting of agreements presupposes language. If this is the case, then (HB) and (HB*) are indeed viciously circular. 
       But given the points made a moment ago, it is hard to take this objection seriously. There is obviously non-linguistic communication. Obviously people sometimes make themselves understood non-verbally. In response to this, it might be said that such non-verbal understandings are parasitic on language. But it is implausible to hold that infants and non-human animals are categorically incapable of making themselves understood to one another. So, taken as an empirical point, the objection that all communication is linguistic seems to be false. 
        As a counter-response, the objector might say that it is not an empirical, but an analytic point, that any exchange of information is linguistic. But if that is right, then any exchange of information is ipso facto linguistic, and the expression “linguistic communication” becomes a pleonasm, like “unmarried bachelor.” We’d then have to produce a new expression, e.g. “verbal behavior”, to distinguish between linguistic and non-linguistic behavior. But then all of the questions that we currently have in connection with the term “linguistic behavior” would re-arise in connection with the term “verbal behavior.” This shows that one is making a purely terminological point in saying that exchanges of information are necessarily linguistic.
       I will henceforth use term “linguistic behavior” to refer to the activity of expressing oneself through speech, writing, and the like, and will use the “non-linguistic behavior” to express oneself in other ways (e.g. by kicking over furniture, scowling, and the like). 
       There is one last possible problem with our analysis: it presupposes that propositions can be grasped independently of language. For there to be understandings of the kind described by (HB) and (HB*), it must be possible to have a non-linguistic grasp of the proposition that Bob is at the store. (Of course, non-linguistic entities wouldn’t have stores. But that can be dealt with by changing the example.) Not all philosophers would grant this. But there is good reason to think that such philosophers are wrong. We’ve already seen that there is no linguistic activity where there isn’t a grasp of semantic rules, and that a grasp of semantic rules is nothing other than a grasp of (meta-linguistic) propositions. We’ve also seen that linguistic competence does not consists in one’s having so many dispositions. Of course, given that I know that “Socrates” refers to Socrates, I have am disposed to use that expression in certain ways and not others. But, given what we saw at the end of Chapter 18, those dispositions are mere effects of my linguistic competence, and are therefore not constitutive of it. In general, linguistic competence must be seen as embodying bona fide knowledge – knowledge of propositions to the effect that such and such sounds (or ink-marks…) have such and such meanings -- and cannot be dispositionalized away. So just as our analysis requires, the ability to grasp propositions is a pre-requisite to the ability to use a language. The latter is therefore not constitutive of the former.


How to explain the meaningfulness of sentence-parts in terms of the concept of success


         I am proposing that it is agreements among people that endow noises and ink-marks with linguistic meaning. Supposing this to be true, those agreements do not directly assign any meaning to whole sentences. They do so by way of agreements concerning the expressions that compose sentences – expressions like “Bob”, “store”, “at”, and “wet.”
        Here we confront an apparent problem for our analysis. Sub-sentential utterance don’t have success-conditions. Leaving aside cases where single words are merely elliptical formulations of complete sentences, there is no circumstance such that an utterance of “store” or “but” or “Fred” is a success (in the relevant sense) in that context. The concept of success, in the relevant sense, is inapplicable to utterances of “Fred” or “store.” 
        The resolution of this difficulty is not hard to see, so long as we take into account the fact that expressions are to be defined contextually. This was point made by Frege (1884) and Russell (1905). And to solve our current problem, we need only generalize their insight. 
       As we saw in Chapter 3, tokens of “Fred” refer to Fred exactly if, in virtue of having the form ┌Fred has phi┐, a sentence-token has for its meaning a proposition that is true exactly if Fred has phi. In other words, there is some x, such that x=Fred, and such that, in virtue of having the form ┌Fred has phi┐, a sentence-token encodes the singular proposition: x has phi. Put another way, occurrences of “Fred” refer to Fred exactly if, in virtue of having the form ┌…Fred…┐, a sentence-token encodes a proposition that has Fred as a constituent. (Right now we are going to consider only assertoric sentences. We will soon generalize what we say about such utterances to questions, imperatives, and so on.) 
          In light of this, consider the following: 


(F) There is an agreement among people to the effect that, in virtue of having the form ┌…Fred….┐, a noise (or ink-mark…) S encodes a piece of information P such that Fred is a constituent of P and S is a success exactly if P is true. 


       (I said “noise (or ink-mark…)”, and not “expression”, because use of the term “expression” might have been viciously circular. For it seems that there can be bona fide expressions only in a context where there is already language.) 
       What is the idea behind (F)? Consider the sentence “Fred is at the store.” As we’ve discussed, there is some x such that x=Fred and such that, from a strictly semantic viewpoint, an utterance of that sentence is a success exactly if x is as the store. Now consider the sentence “Fred is tall.” There is some x, such that x is identical with Fred, and such that an utterance of “Fred is tall” is a success, in the strictly linguistic sense, exactly of x is tall. Such examples can be generated ad libidum. Given these points, we may conclude the following. In virtue of having the form, ┌…Fred…┐, a sentence S encodes a piece of information P such that P has the form…Fred...and such that, the strictly semantic sense, S is a success exactly if P is true. 
        So while utterances of “Fred” do not by themselves have success-conditions, whole sentences of the form ┌…Fred…┐ do have such conditions; and the semantics of “Fred” is given by giving the success-conditions of sentences falling into this category. So while it is true that no agreement among people directly gives meaning to “Fred is at the store”, and while it is also true that sub-sentential expressions do not have success-conditions, there is no reason to deny that sentence-level expressions are given meaning through agreements among people as to the success-conditions of whole sentences. “Fred” refers to Fred because of an agreement or understanding among people to the effect that, if a noise (or ink-mark…) has the form ┌…Fred…┐, there is some piece of information P such that P is about Fred and such that S is a success, in the relevant sense, exactly if P is true. (to echo what we said a moment ago: I said “noise (or ink-mark…)” instead of “sentence-token” since, in this context, use of the latter might have involved vicious circularity.)
     As we saw earlier, the relevant kind of success does not have to be understood in linguistic terms, and the relevant kind of agreement does not presuppose the existence of language. So in putting forth (F), we are guilty of no vicious circularity, and we are able to account for the relevant facts about the semantics of “Fred”. In particular, we are able to explain why “Fred” refers to Fred, i.e. why in virtue of having the form ┌…Fred….┐ (or, equivalently, ┌Fred has phi┐)  a sentence is true just in case…Fred…(or, equivalently, Fred has phi).
        If our analysis is right, then “Fred” is defined to be “contextually.” This is not to say that “Fred” doesn’t refer to Fred. Obviously it does. It is to say that for “Fred” to refer to Fred is simply for expressions of the form ┌…Fred…┐ to have certain truth-conditions. 
      Independently of our analysis, this is obviously the case. It would be absurd to say that “Fred” referred to Fred, but to deny that, in virtue of being of the form ┌Fred has phi┐, a sentence was xxx true iff Fred has phi. And it would be absurd to deny that “Fred” referred to Fred but to maintain that, in virtue of being of the form ┌Fred has phi┐, such sentences were true iff Fred had phi. So “Fred” refers to Fred exactly if, in virtue of containing occurrences of “Fred”, sentences have certain meanings or truth-conditions. Exactly similar remarks apply to any referring expression. Tughendat (1970) and Dummett (1973: 196-203) make very similar points.
      Obvious variants of what we have said about “Fred” apply to predicates  (expressions like “tall” or “wet”). There is some property PHI such that PHI=tallness and such that, in virtue of having the form ┌…tall…┐,  a sentence-token S encodes a piece of information P such that P concerns tallness and such that S is a success exactly if P is true. Let S be a token of the sentence “Tom is tall.” There is some piece of information P such that P concerns (inter alia) the property of tallness such that, at the level of semantics, S is a success exactly if P is true. (Of course, P is information identical or equivalent with the proposition Tom is tall.) Given obvious extensions of these points, it is clear that all so-called “lexical” items are to be defined contextually. 
 
Xxx Why our analysis, unlike Grice’s, is consistent with the compositional character of linguistic meaning 


        Grice’s view is hard to reconcile with the fact that what a complex expression means is a function of what its parts mean.[283] Obviously “Bob is at the store” means Bob is at the store because each of its components has a certain meaning. Where sub-sentential expressions are concerned, speaker’s meaning necessarily diverges from word meaning. Whatever it is that is meant by “at” or “store” or “Bob”, that meaning cannot be the entirety of what some speaker means. (If you say “Bob” or “store”, xxx then either your statement is either elliptical for some whole sentence, e.g. “Bob is at the store”, or you cannot possibly mean what you are saying.) Therefore, any theory that, like Grice’s, identifies expression-meaning with speaker’s meaning is straightforwardly incapable of explaining what is meant by sub-sentential expressions. 
         Some Griceans counter-respond by saying more or less the following: 


        At some point in history, people uttered the noises socrateswaswise, socrateswastall, and socrateswasatthestore with the intention of affirming the propositions Socrates was wise, Socrates was tall, and Socrates was at the store. Thus, people uttered whole sentences of the form ┌…Socrates…┐ with the intention of affirming that…Socrates... Grice’s theory does apply to those sentences. After all, one can certainly wish to affirm whole propositions about Socrates. (What xxx you said a moment ago about “at” and “the” and other sub-sentential expressions is not true of sentences.) What all of those sentences have in common is that they encode propositions of the form…Socrates…So the mechanism described by Grice makes it a rule that socratessnored means that Socrates snored, socrateswaswise means that Socrates was wise, and so on.  Thus, the Gricean story explains why sentences having the form ┌…Socrates…┐ mean…Socrates… (Equivalently, the Gricean story explains why sentences having the form ┌Socrates has phi┐ are true exactly if Socrates has phi.) For “Socrates” to refer to Socrates just is for it to be the case that, in virtue of having the form ┌…Socrates…┐, an utterance is true exactly if…Socrates…Therefore, contrary to what we argued, Grice’s theory does explain what it is for “Socrates” to mean what it currently does. These points (mutatis mutandis) are true of any given morpheme.[284]




          Even if this hypothesis is correct, it shows only that historical antecedents of contemporary semantic facts can be understood in Gricean terms. Xxx It does not, as we will now see, show that that the same is true of those facts themselves. xxx 
          The hypothesis just stated has the form: 


Such and such events led to its being the case that socratessnored, socrateswaswise, and socrateswastall came to mean Socrates snored, Socrates was wise, and Socrates was tall. And that fact led to its being the case that, in virtue of having the form ┌…Socrates…┐, an utterance is true exactly if…Socrates…


 We want to know what it is for it to be the case that, in virtue of having the form ┌…Socrates…┐, an utterance is true exactly if…Socrates…If correct, the hypothesis under examination tells us what led to that semantic fact. It gives us a causal, not a conceptual, analysis of that fact. But we don’t want to know how that fact came about. We want to know what that fact is: we want to know its structure. And the hypothesis in question is silent on that score. 
       The following objection might be made in response to this point: 


       But surely that hypothesis does give us a conceptual analysis of that fact. After all, that analysis tells us what it is for noises of the form…Socrates…to be true exactly if…Socrates….It tells us that noises of the form…Socrates…are true iff…Socrates…exactly if such noises are produced by people with certain intentions. So that explanation shows how the fact that such noises have such meanings constitutively depends on people’s producing those noises with certain intentions. So in direct opposition to what you say, that analysis tells us what it is for such noises to bear such meanings. It doesn’t merely tell us what historical events led to that semantic fact. 


             
         This objection muddles a subtle but crucial distinction. Given only that socratessnored means that Socrates snored, that socrateswastall means that Socrates was tall, and so on, it doesn’t follow that it is in virtue of having the form…socrates…that a noise makes a statement about Socrates. In other words, it doesn’t tell us that a noise’s making a statement about Socrates depends on its containing the sound socrates. It tells us that sounds  of the form…socrates…have meanings that concern Socrates. But given only that those sounds to have those meanings, it doesn’t follow that it is in virtue of having the form…socrates…that those sounds have those meanings. 
        Let L be a language that has three primitive symbols – namely, “socratessnored”, “socrateswastall”, and “socrateswaswise” -- whose meanings are, respectively, Socrates snored, Socrates snored, and Socrates was wise. Because they are semantically primitive, those sentences don’t have a semantic unit in common corresponding to the sound socrates. So it is not in virtue of the fact that they all contain that sound that they are all about Socrates. Of course, those sentences are semantically similar: after all, they are all about Socrates. And they are also acoustically similar: they all contain the noise socrates. But, as we just saw, it is not in virtue of their having that acoustical similarity that they have that semantic similarity. Their being similar in both respects is only a coincidence. (That is, it is a coincidence from a semantic point of view, though it may not be a coincidence from some other point of view.) 
       If correct, the hypothesis under examination shows us why Grice’s story is compatible with the fact that socrateswastall means that Socrates was tall, with the fact that socrateswaswise means that Socrates was wise, and with the fact that socrateswasatthestore means that Socrates was at the store. But that hypothesis doesn’t show that the Gricean story is consistent with the one fact that is relevant in this context, namely: it is in virtue of the fact that it contains the sound socrates that a present-day utterance of “Socrates snored” makes a statement about Socrates. The hypothesis in question gives us the semantics of L, not of English. It gives us the semantics of a language all of whose expressions have English homonyms, but that isn’t English, the reason being that its sentences have completely different decompositions from their English counterparts.  
         The word “why” has both causal and conceptual meanings. If I want to know why the interior angles of some surface add up to approximately 180°, I can be given either a conceptual explanation (“because that surface is triangular, and the interior angles of a triangle add up to 180°”), or I can be given a causal explanation (“because it used to be a square, but the carpenter sawed it into two, triangular halves…”). If correct, the hypothesis under examination provides a causal-historical explanation of the fact that the noise socratessnored means Socrates snored. So in the causal sense of “why”, it tells us why that noise has that meaning. But, regardless of whether it is correct, it doesn’t tell us what it is for “Socrates” to mean what it currently does, or therefore how the meaning  of a sentence  of the form ┌…Socrates…┐ depends on the meaning of “Socrates.” 
        The hypothesis in question exposes a problem that is endemic to Grice’s theory. For the sake of argument, suppose that people uttered socrateswaswise, socratessnored, socrateswastall, and so forth, with the intention of affirming propositions about Socrates. Given only that people did this, it doesn’t follow that it ever became a rule that one must produce sounds of the form…socrates…to affirm proposition about Socrates. Given only that an activity is customary, it doesn’t follow that it is de rigueur. Of course, norms often develop out of regularities. It is now a law that (in certain countries) one must drive on the right, and it is possible that this law developed out of what was once a mere regularity.[285] It is theoretically possible that it was once merely customary for people to produce sounds of the form…socrates…with the intention of affirming statements about Socrates. And it is also theoretically possible that the rules now governing the use of “Socrates” grew out of those regularities. But even if they are correct, these historical hypotheses merely identify the historical precursors of the fact that “Socrates” now has a certain semantics. Those hypotheses don’t constitute an analysis of what it is for “Socrates” to mean what it currently does or, consequently, of how the meanings of sentences of the form ┌…Socrates…┐ depend on the meaning of “Socrates.”[286] 
        Wittgenstein (1958) and Searle (1969) rightly emphasize that there is no language where there are no rules: a noise or ink-mark doesn’t token xxx a linguistic expression unless it represents an attempt on somebody’s part to follow an existing body of rules. Grice tries to show that expression-meaning can be understood in terms of what people are trying to affirm by means of various sounds (or ink-marks or hand-movements…). If Grice’s account is to be free of vicious circularity, it must be assumed that the sounds in question do not represent the outcomes of people trying to follow existing linguistic rules. But if a given person xxx isn’t following existing rules, then xxx what he xxx does is, at most, a simulation of actual linguistic behavior. It doesn’t matter what proposition that person is trying to affirm, and it doesn’t matter what noise or ink-mark that person makes in his effort to affirm it. Therefore, the activity of such a person cannot be constitutive of any semantic system, even though it is theoretically possible that such activity might help bring such a system into existence. We see once again that Grice’s theory involves a failure to distinguish conceptual from causal explanation.  
        Let us sum up this lengthy discussion. The essence of Grice’s theory is that expressions mean what we mean by them. But this cannot be right. 666 Speaker’s meaning cannot possibly be anything other than a complete proposition. What a speaker means can never be what is meant by “at” or “the” or “Bill.” Grice’s theory can explain, at most, what it is for “billisatthestore” to mean Bill is at the store, i.e. that theory may be able to explain what it is for some homonym of “Bill is at the store” to mean Bill is at the store. But that theory has nothing to tell us about that sentence itself. We may conclude that, just as we alleged, Grice’s theory cannot be reconciled with the fact that what complex expressions mean is a function of what their parts mean.  
         Our analysis does not have this problem. Built into our theory is an explanation as to how the meaning of “Socrates snored” derives from the meanings of its constituents. In fact, our analysis doesn’t have any of the problems associated with Grice’s superficially plausible but systemically flawed identification of expression-meaning with speaker’s meaning.  
         At the same time, our analysis is also consistent with the kernel of truth in Grice’s theory, viz. that what people think is at least partially determinative of what words mean. (Of course, what this or that specific person thinks may not be determinative of what any English words mean. But surely the fact that “red” means red and “Socrates” refers to Socrates is not entirely independent what everybody throughout time has thought.) 
       Further, our analysis isn’t guilty of vicious circularity. Non-linguistic creatures are capable of having understandings or agreements with one another; and the specific agreement described by (H) doesn’t involve any distinctively linguistic conceptso. To be sure, it demands that non-linguistic creatures have the conceptso of truth and falsity and, more generally, of information. So it presupposes that pre-verbal humans can have some understanding of what it is to be misinformed or correctly informed. But this is not an unreasonable presupposition, and it is one that would seem to have a great deal of empirical support.
          Finally, our analysis is consistent with the fact that linguistic activity is necessarily rule-governed. According to our analysis, E’s referring to O consists in its being the case that there is a rule according to which utterances of the form…E…are successes or failures, depending on whether…O…
  
Some additional, apparent problems with our analysis 


           The relationship between “Fred” and Fred is not strictly parallel to the relationship between “wet” and the property of wetness. This point, or one like it, was made by Frege. The expression “the property of wetness” refers to the property of wetness. But “I sat on a wet chair” is meaningful and potentially true, whereas “I sat on a the property of wetness chair” is not meaningful or, therefore, potentially true. Our analysis, it might be said, models all semantic relations on the relationship between “Fred” and Fred and is thus in error. 
       This objection is misguided. Our analysis is not to the effect that all semantic relations are to be understood in terms of the relationship between a singular term and its referent. I chose to illustrate my theory with discussions of singular terms. (For obvious reasons, that theory would have been much harder to take in if my initial illustrations had concerned adverbs or quantifiers.) The essence of our analysis is that semantic rules can be understood in terms of agreements to the effect that sentences having a certain property (e.g. the property of comprising “Fred” or “tall” or “or”) are ipso facto to have certain success-conditions. Obviously the specific agreements involved will vary from expression to expression, and also from expression-category to expression-category. But there is no difficulty extending what we said about singular terms to other kinds of expressions. 
      In fact, our theory is especially well-suited to giving the semantics of expressions other than singular terms. Given any expression that is not a singular term, it is obvious that its meaning can be given only contextually. Conceivably, one might deny this, saying that “wet”, “tall”, and “intelligent refers to wetness, tallness, and intelligence. But that definition would be inadequate since it wouldn’t distinguish (for example) “wet” from “the property of wetness” – since, in other words, it wouldn’t provide the relevant syntactical information. So while it is true that our analysis demands that expressions be definable contextually, it is clear on independent grounds that expressions other than singular terms must be so defined, and we have seen that singular terms must be so defined. 
        In fact, a slight generalization of a point made in Chapter 1 (p.15) provides an additional reason to hold that singular terms must be defined contextually. As we just saw, a definition is adequate only if it provides the syntactical properties of the expression in question. You are missing crucial semantic information if you know what an expression refers to, but don’t know how to combine it with other expressions. So far as statements like “that guy [accompanied by an ostension of person x] is named ‘Socrates’” or  “‘Socrates’ refers to Socrates” are adequate, it is because they are equivalent with statements that give the syntactical properties of “Socrates.”  xxx Supposing that x is the person ostended, an utterance of “that guy [accompanied by an ostension of x] is named ‘Socrates’” is to the effect that then any sentence-token of the form ┌…Socrates…┐ means…x…(i.e. that ┌Socrates has phi┐ is true iff x has phi). Ultimately, the only adequate definitions are contextual definitions. So it is not to the discredit of our theory that it demands that expressions be contextually definable.     


 Some additional problems with our theory (continued): non-assertoric utterances 


         A more substantive problem with our analysis has to do with the fact that it doesn’t apply to non-indicative sentences. But this problem is easily remedied. Non-assertoric utterances are, of course, neither true nor false. But, as we noted, given any such utterance S, there is some proposition P such that S is a xxx success, in the relevant sense, exactly if P is true. Suppose I ask you whether Smith went to the store. From a strictly linguistic standpoint, my speech-act is a success exactly if, upon hearing it (or otherwise encountering it), you correctly affirm either that Smith went to the store or its negation.[287]  (For expository reasons, either pretend that you are Jones or substitute your actual name for each occurrence of “Jones” in the upcoming discussion.) So there is some proposition of the form…Smith…such that my utterance is a success exactly if that proposition is true. That proposition is not: Smith went to the store. Rather, that proposition is Jones correctly affirms whether or not Smith went to the store.  
      Suppose that I order you to meet Smith at the store. From a strictly linguistic standpoint, my speech-act is a success exactly if, upon hearing it, you make it the case that you meet Smith at the store. So there is some proposition of the form…Smith…such that my utterance is a success exactly if that proposition is true. But that proposition is not: Jones meets Smith at the store. Rather, that proposition is Jones makes it the case that he meets Smith at the store.[288] 
         Here is what this suggests. “Socrates” refers to Socrates exactly if, given an utterance S that has the form ┌…Socrates…┐, there is some proposition P having the form…Socrates…such that S is a success, in the relevant sense, exactly if P is true. The semantic rule that pairs off Socrates with “Socrates” is thus an understanding among people that assigns such success-conditions to utterances of that form. A book-length defense of this analysis is given in Kuczynski (2005c). What is important here is that, if this line of thought is even approximately correct, it follows that SCT is viciously circular. The reason, of course, is that such understandings presuppose the existence of thought and indeed, of specifically propositional thought. 
       An advocate of SCT might counter-respond by saying that the representations mediating our thought are not assigned their meanings by rules of that kind. But in that case, they are not assigned meaning by anything comparable to the semantic rules that assign meaning to the expressions of a public language, and it is thus no longer appropriate to describe those representations as “sentences.” 


Conclusion 
      
     
     Semantics isn’t pre-semantics. Content isn’t truth-maker. Data isn’t meta-data. 
     In Part I, we found that, given these three distinctions, there are many reasons to reject content-externalism and many reasons to accept semantic externalism. 
      Content externalism has some implausible consequences. It entails that one can rationally accept both a proposition and its negation; it strips the mental of causal powers; and it makes one’s knowledge of oneself as uncertain as one’s knowledge of the external world. We found that there is no reason to accept any of these highly revisionist views, since the relevant data can be accommodated without them. 
       Advocates of content-externalism have attempted to reconcile that doctrine with our pre-theoretic views about self-knowledge and mental causation. But those attempts are failures. 
       We found that Kripke’s argument for synthetic necessary truth involves a failure to distinguish between semantics and pre-semantics. We also found that a descriptivist conception of conception can be reconciled with the fact that, in at least some cases, having a concept of an object involves having a certain kind of causal connection to it. 
        Our descriptivist conception of conception is incompatible with Fodor’s conceptual atomism. xxx But we found in Part II that atomism is false. Since atomism is false, so is SCT. Since SCT is false, so is CTM.  
        We also found that, setting aside the erroneousness of conceptual atomism, there are good reasons to reject SCT and CTM. Two are of special note. 
       First, in the arguments on behalf of CTM, the term “syntax” has at least three different meanings. Sometimes it refers to an expression’s morphology; sometimes it refers to its semantic decomposition; and sometimes it refers to its proof-theoretic relation to the semantic rules constituting the language of which it is a part. The expressions “form”, “algorithm”, and “mechanical procedure” are used in a comparably ambiguous manner. Many of the arguments for CTM collapse once these ambiguities are recognized. 
       Second, supposing that Gareth Evans is right to distinguish between conceptual and non-conceptual content, it follows that not all mental content has a sentential structure. We found that Evans’ distinction is both defensible and theoretically fruitful. 
         Content-externalism demands an acceptance of conceptual atomism and also of a strictly causal theory of conception. We have found that all three of these doctrines are false and that the relevant data can be modeled without them. Our model has the virtue of being entirely consistent with Kripke’s powerfully argued semantic insights. We may conclude that both content-internalism and semantic-externalism are correct. 
   
Bibliography 


Armstrong, David. 1989. Universals: an opinionated introduction. Boulder: Westview Press. 


Ayer, Alfred Jules. 1952. Language, Truth, and Logic. New York: Dover Publications.


Ayer, Alfred Jules. 1954. “Can there be a private language?” In The Philosophy of Language, A.P. Martinich (ed), 449-456. Oxford: Oxford University Press.


Bach, Kent. 1984. Thought and Reference. Oxford: Clarendon. 


Barwise, Jon. 1989. The Situation in Logic. Palo Alto: CSLI Publications. 


Barwise, Jon and Perry, John. 1983.  “Semantic Innocence and Uncompromising Situations.” In The Philosophy of Language, A.P. Martinich (ed), 392-404. Oxford: Oxford University Press.


Barwise, Jon and Perry, John. 1999.  Situations and Attitudes. Palo Alto: CSLI Publications.


Berkeley, George. 1934. An Essay Towards a New Theory of Vision. Oxford: Clarendon Press. 
Bilgrami, Akeel. 1992. “Can externalism be reconciled with self-knowledge?” In The Twin-Earth Chronicles, A. Pessin and S. Goldberg (eds), 323-341. Armonk, NY: M.E. Sharpe.
Blackburn, Simon. 1984. Spreading the Word. Oxford: Clarendon. 


Boguslawski, Andrzej. 1994. “Sentential Complementation and Truth.” In The Syntax of Sentence and Text, S. Čmejrková and F. Štícha (eds), 317-332. Philadelphia: John Benjamins.


Bonjour, Laurence. 1985. The Structure of Empirical Knowledge. Harvard: Harvard University Press.


Bonjour, Laurence. 1998 In Defense of Pure Reason. Cambridge: Cambridge University Press.


Brandom, Robert. 1998. Making it Explicit. Cambridge: Harvard University Press. 
Burge, Tyler. 1979. “Individualism and the Mental.” In The Twin-Earth Chronicles, A. Pessin and S. Goldberg (eds), 125-141. Armonk, NY: M.E. Sharpe.
Tyler Burge. 1980. “Computer proof and a priori knowledge.” In Journal of Philosophy 77: 797-803
Burge, Tyler. 1982. “Other Bodies”. In The Twin-Earth Chronicles, A. Pessin and S. Goldberg (eds), 142-160. Armonk, NY: M.E. Sharpe.
Burge, Tyler. 1986. “Individualism and Self-knowledge”. In The Twin-Earth Chronicles, A. Pessin and S. Goldberg (eds), 342-354. Armonk, NY: M.E. Sharpe.
Cain, M.J. 2002. Fodor: Language, Mind and Philosophy. Cambridge: Polity Press.


Carnap, Rudolph. 1934. The Unity of Science. London: K. Paul, Trench, Kubner & Co, Ltd. 


Carnap, Rudolph. 1937. The Logical Syntax of Language. London: Routledge & Kegan Paul. 


Carnap, Rudolph. 1947. Meaning and Necessity. Chicago: University of Chicago Press.


Carnap, Rudolph. 1950. Logical Foundations of Probability Theory. Chicago: University of Chicago Press.


Carnap, Rudolph. 1956. Introduction to Symbolic Logic and its Applications. New York: Dover. 


Carnap, Rudolph. 1966. Introduction to the Philosophy of Science. New York: Dover.


Chalmers, David. 1996. The Conscious Mind. New York: Oxford University Press.


Chomsky, Noam. 1959. "A Review of B. F. Skinner's Verbal Behavior." In Language 35 (1): 26-58.


Chomsky, Noam. 1965. Aspects of the Theory of Syntax. Cambridge: M.I.T. Press.


Chomsky, Noam. 1975. Reflections on Language. New York: St. Martin’s Press. 


Chomsky, Noam. 1980. Rules and Representations. New York: Columbia University Press. 


Chomsky, Noam. 1988. “Language and the problems of knowledge.” In The Philosophy of Language, A.P. Martinich (ed), 509-527. Oxford: Oxford University Press.


Chomsky, Noam. 1998. On Language. New York: The New Press.


Coulter, Jeff. 1983. Rethinking Cognitive Theory. New York: St. Martin’s Press. 
Crane, Tim. 1991. “Social Content and Psychological Content.” In The Twin-Earth Chronicles, A. Pessin and S. Goldberg (eds), 284-304. Armonk, NY: M.E. Sharpe.
Churchland, Paul. 1981. “Eliminative materialism and the propositoinal attitudes.” In D. Rosenthal (ed.), The Nature of Mind, 601-612. New York: Oxford University Press.


Cresswell, Max. “Structured meanings.” In Meaning and Truth, J. Garfield and M. Kiteley (eds), 446-452.
Davidson, Donald. 1967. “Truth and Meaning.” In The Philosophy of Language, A.P. Martinich (ed), 91-101. Oxford: Oxford University Press.
Davidson, Donald. 1980. Essays on Actions and Events. New York: Oxford University Press. 


Davidson, Donald. 1980b. Inquiries into Truth and Interpretation. New York: Oxford University Press. 
Davidson, Donald. 1987. “Knowing One’s Own Mind.” In The Twin-Earth Chronicles, A. Pessin and S. Goldberg (eds), 323-341. Armonk, NY: M.E. Sharpe.
Davidson, Donald. 2004. Problems of Rationality. New York: Oxford University Press. 
Davidson, Donald. 2005. Subjective, Intersubjective, Objective. New York: Oxford University Press. 
Dennett, Daniel. 1975. “Eliminative materialism and the propositoinal attitudes.” In In D. Rosenthal (ed.), The Nature of Mind, 502-507. New York: Oxford University Press.


Dennett, Daniel. Brainstorms. 1978. Cambridge: MIT press. 


Donnellan, Keith. 1966. “Reference and Definite Descriptions.” In A.P. Martinich (ed).  The Philosophy of Language, 235-257. Oxford: Oxford University Press.


Donnellan, Keith. 1974. “Speaking of nothing.” The Philosophical Review 74: 3-31.


Dretske, Fred. 1982. Knowledge and the Flow of Information. Cambridge: MIT Press.


Dummett, Michael. 1978. Truth and Other Enigmas. Cambridge: Harvard University Press. 


Dummett, Michael. 1973. Frege: Philosophy of Language. Cambridge: Harvard University Press. 


Evans, Gareth. 1982. The Varieties of Reference. Oxford: Clarendon Press.


Evans, Gareth. 1985. Collected Papers. Oxford: Clarendon Press.


Falvey, Kevin. 1994. “Externalism, Self-Knowledge, and Skepticism.” Unpublished Dissertation. Department of Philosophy. University of Minnesota.


Falvey, Kevin and Owens, Joseph. 1994. “Externalism, Self-Knowledge, and Skepticism.” Philosophical Review 103: 107-137. 


Field, Hartry. 1977. “Logic, Meaning, and Conceptual Role.” Journal of Philosophy 69: 378-408. 


Fodor, Jerry. 1968. Psychological Explanation. New York: Random House. 


Fodor, Jerry. 1975. The Language of Thought. New York: Thomas Y. Crowell


Fodor, Jerry. 1981. “Methodological Solipsism Considered as a Research Strategy in Cognitive Psychology.” In D. Rosenthal (ed.), The Nature of Mind, 485-498. New York: Oxford University Press.


Fodor, Jerry. 1981b. Representations. Cambridge: The MIT Press.


Fodor, Jerry. 1983. The Modularity of Mind. Cambridge: The MIT Press.


Fodor, Jerry. 1987. Psychosemantics. Cambridge: The MIT Press.
Fodor, Jerry. 1987b. “Individualism and Supervenience.” In The Twin-Earth Chronicles, A. Pessin and S. Goldberg (eds), 192-218. Armonk, NY: M.E. Sharpe.
Fodor, Jerry. 1990. A Theory of Content and Other Essays. Cambridge. The M.I.T. Press. 


Fodor, Jerry. 1994. “Fodor.” In S. Guttenplan (ed.), A Companion to the Philosophy of Mind, 292-300. Oxford: Blackwell


Fodor, Jerry. 1994b. The Elm and the Expert: Mentalese and Its Semantics. Cambridge: M.I.T. Press. 
Press. 


Fodor, Jerry. 1998. Concepts. Clarendon Press: Oxford.


Fodor, Jerry and Lepore, Ernest. 2002. The Compositionality Papers. New York: Oxford University Press.


Fodor, Jerry and Pylyshin, Zenon. 1988. “Connectionism and cognitive architecture: a critical analysis.” In Connections and Symbols, S. Pinker (ed.), pp. 3-72. Amsterdam: Elsevier.


Frege, Gottlob. 1884. Grundlagen der Arithmetik, eine logisch-mathematische Untersuchung über den Begriff der Zahl. Breslau: W. Koebner.


Frege, Gottlob. 1891. “On Function and Concept.”  In The Frege Reader, Michael Beaney (ed), 130-148. Oxford: Blackwell. 


Frege, Gottlob. 1892. “On Sinn and Bedeutung.” In The Frege Reader, Michael Beaney (ed), 151-171. Oxford: Blackwell. 


Frege, Gottlob. 1892b. “On Concept and Object.” In The Frege Reader, Michael Beaney (ed), 181-193. Oxford: Blackwell. 


Frege, Gottlob. 1918. “Negation.” In The Frege Reader, Michael Beaney (ed), 346-361. Oxford: Blackwell. 


Frege, Gottlob. 1918. “Thought.” In The Frege Reader, Michael Beaney (ed), 325-345. Oxford: Blackwell. 


Frege, Gottlob. 1954. The Foundations of Arithmetic. Translated by J.L. Austin. New York: Oxford University Press.


Freud, Sigmund. 1915. “The unconscious.” In P. Rieff (ed) General Psychological Theory, 116-150. New York: Macmillan Publishing Co. 


Freud, Sigmund. 1965. New Introductory Lectures on Psychoanalysis. London: W.W. Norton and Co. 


Freud, Sigmund. 1998. The Interpretation of Dreams. New York: Basic Books.


Garfield, Jay. 1994. “Modularity.” In S. Guttenplan (ed) A Companion to the Philosophy of Mind, 441-448.


Gödel, Kurt. 1953. “Is mathematics syntax of language?” In Kurt Gödel: Collected Works, Volume III, S. Feferman (ed.), pp. 334-356. New York: Oxford. 


Grice, H.P. 1957. “Meaning.” In The Philosophy of Language, A.P. Martinich (ed), 72-78. Oxford: Oxford University Press.


Grush, Rick. 1999. Guide to Gareth Evans’ The Varieties of Reference. Unpublished e-manuscript (http://mind.ucsd.edu/mix.resources/evans/chapterguides). 


Hacker, P.M.S. 1999. Wittgenstein on Human Nature. New York: Routledge.


Hacker, P.M.S. 1996. Wittgenstein: Mind and Will. Oxford: Blackwell.


Hacker, P.M.S and Baker, Gordon. 1980. Wittgenstein: Understanding and Meaning. Oxford: Blackwell.


Hacker, P.M.S and Baker, Gordon. 1984. Scepticism, Rules, and Language. Oxford: Blackwell.


Hacker, P.M.S and Baker, Gordon. 1984b. Language, Sense, and Nonsense. Oxford: Blackwell.


Hacker, P.M.S and Baker, Gordon. 1985. Wittgenstein: Rules, Grammar, and Necessity. Oxford: Blackwell.


Hacking, Ian. 1975. Why does language matter to philosophy? Cambridge: Cambridge University Press.


Hale, Bob and Wright, Crispin (eds.). 1997. A Companion to the Philosophy of Language. Oxford: Basil Blackwell.


Hart, H.L.A. 1961. The Concept of Law. Oxford: The Clarendon Press. 


Hempel, Carl Gustav. 1952. Fundamentals of Concept Formation in Empirical Science. Chicago: University of Chicago Press. 


Hempel, Carl Gustav. 1965. Aspects of Scientific Explanation. New York: The Free Press.


David Hershenov: 2002. A Defense of the Biological Approach to Personal Identity. Unpublished dissertation. Department of Philosophy, University of California at Santa Barbara. 


David Hershenov: 2005. “Do Dead Bodies Pose a Problem for Biological Approaches to Personal Identity?” In Mind (114): 31-59


Horst, Stephen. 1996. Symbols, Computation, and Intentionality. Berkeley: University of California Press.


Jackendoff, Ray. 1989. “What is a concept, that people may grasp it?” In Concepts: Core Readings, E. Laurence and S. Laurence (eds), 305-334. Cambridge: MIT Press.


Jackson, Frank and Pettit, Philip. 2004.  “Causation in the Philosophy of Mind”. In Mind, Morality, and Explanation, F. Jackson, P. Pettit, and M. Smith (eds), 45-68. Oxford: Oxford University Press.


Jackson, Frank and Pettit, Philip. 2004b.  “Some content is narrow.” In Mind, Morality, and Explanation, F. Jackson, P. Pettit, and M. Smith (eds),  69-94. Oxford: Oxford University Press.


Jackson, Frank and Pettit, Philip. 2004c.  “Functionalism and Broad Content” In Mind, Morality, and Explanation, F. Jackson, P. Pettit, and M. Smith (eds),  95-118. Oxford: Oxford University Press.


Jackson, Frank and Pettit, Philip. 2004d.  “Program Explanation: A General Perspective”. In Mind, Morality, and Explanation, F. Jackson, P. Pettit, and M. Smith (eds), 119-130. Oxford: Oxford University Press.


Kaplan, David.  “Quantifying In.” 1968. In The Philosophy of Language, A.P. Martinich (ed), 370-391. Oxford: Oxford University Press.


Kaplan, David , 1975. “Dthat”. In The Philosophy of Language, A.P. Martinich (ed), 316-329. Oxford: Oxford University Press.
Kaplan, David. 1975b. “How to Russell a Frege-Church.” Journal of Philosophy 72: 716-729.
Kaplan, David. 1978. “On the Logic of Demonstratives.” Journal of Philosophical Logic 8: 81-98. 


Kaplan, David.  1989.  “Demonstratives.” In Themes from Kaplan, J. Almog, J. Perry,, H. Wettstein (eds), 481-564. Oxford: Oxford University Press. 


Kaplan, David. 1989b. “Afterthoughts.” In Themes from Kaplan, J. Almog, J. Perry,, H. Wettstein (eds), 565-614. Oxford: Oxford University Press. 


Katz, Jerrold. 1972. Semantic Theory. New York: Harper and Row.


Kim, Jaegwon. 1993. Supervenience and Mind. Cambridge: Cambridge University Press.
King, Jeffrey C., 1995, “Structured Propositions and Complex Predicates”, Nous 29(4), 516-535 
King, Jeffrey C., 1996, “Structured Propositions and Sentence Structure”, Journal of
Philosophical Logic 25: 495-521. 


King, Jeffrey C., 1997, “Structured Propositions” in the Stanford Encyclopedia of Philosophy. On-line publication. http://plato.stanford.edu/entries/propositions-structured/ 


Kripke, Saul. 1971. “Identity and Necessity.” In Identity and Individuation, M. K. Munitz (ed). New York: New York University Press.


Kripke, Saul. 1972. Naming and Necessity. Cambridge: Harvard University Press. 


Kripke, Saul. 1977. “Speaker’s Reference and Semantic Reference.” In A.P. Martinich (ed).  The Philosophy of Language, 248-266. Oxford: Oxford University Press.


Kripke, Saul. 1979. “A Puzzle about Belief.” In Meaning and Use, A. Margalit (ed). Dordrecht: Reidel.


Kripke, Saul. 1982. Wittgenstein on Rules and Private Language. Cambridge: Harvard University Press.


Kuczynski, John-Michael. 2007.  “Intensionality”, forthcoming in the Journal of Pragmatics.


Kuczynski, John-Michael. 2007b.  “The Analogue-Digital Distinction and the Cogency of Kant’s Transcendental Arguments”, forthcoming in Existentia Meletaisophias.


Kuczynski, John-Michael. 2006. “Does Possible World Semantics Turn all Propositions into Necessary ones?”, forthcoming in the Journal of Pragmatics. 


Kuczynski, John-Michael. 2006b. “Two Concepts of Sentential ‘Form’ and the So-called Computational Theory of Mind.” Philosophical Psychology 19 (6): 1-27. 


Kuczynski, John-Michael. 2006c. “Formal Operations and Simulated Thought.” Philosophical Explorations  9 (2): 221-234. 


Kuczynski, John-Michael. 2006d. “On Marga Reimer’s Descriptions and Beyond.” Pragmatics and Cognition  14 (1):  196-204.


Kuczynski, John-Michael. 2005. “The Concept of a Symbol and the Vacuousness of the Symbolic Conception of Thought.” Semiotica 154 (4): 243-264. 


Kuczynski, John-Michael. 2005b. “Must one Know a Language to Grasp Propositions?” Teorema 24 (2): 43-65.


Kuczynski, John-Michael. 2005c. Literal Meaning and Cognitive Content. Unpublished manuscript. 


Kuczynski, John-Michael. 2004. “A non-Russellian Treatment of the Referential-Attributive Distinction.” Pragmatics and Cognition. Volume 12, Number 2, 2004, pp. 253-294 


Kuczynski, John-Michael. 2004b. “Why Definite Descriptions Really are Referring Expressions.” Grazer Philosophische Studien 68: 45-79.


Kuczynski, John-Michael. 2004c. “Another Argument against the Thesis that there is a Language of Thought”. Communication and Cognition  37 (2): 83-104.


Kuczynski, John-Michael. 2004d. “Non-declarative sentences and the theory of descriptions”. Principia (8) 1: 119-154. 


Kuczynski, John-Michael. 2003. “Some Arguments against Intentionalism.” Acta Analytica  19 (32): 107-142. 


Kuczynski, John-Michael. 2002. “Does the Idea of a ‘Language of Thought’ Make Sense?”  Communication and Cognition 35 (4): 173-192.  


Langford, C.H. 1942. “The notion of analysis in Moore’s philosophy.” In P.A. Schilpp (ed) The Philosophy of G.E. Moore, 321-342. LaSalle: Open Court. 


Lepore, Ernie. 1994 “Conceptual Role Semantics.” In A Companion to the Philosophy of Mind, S. Guttenplan (ed), 193-200, 193-199.  Blackwell: Cambridge, MA.
Lewicki, Pawel and Hill, Thomas and Czyzewska, Maria. 1992. “Nonconscious acquisition of information.” American Psychologist 47 (6): 796-801.
Lewis, Clarence Irving. 1946. An Analysis of Knowledge and Valuation. Cambridge: Harvard University Press.


Lewis, Clarence Irving. 1952. “The modes of meaning.”  In Semantics and the Philosophy of Language. L. Linsky (ed.), 50-66. Chicago: University of Illinois Press.


Lewis, David. 1972 “Psychophysical and Theoretical Identifications.”  In D. Rosenthal (ed.), The Nature of Mind, 204-210. New York: Oxford University Press.


Lewis, David. 1980. “Mad pain and Martian pain.”  In D. Rosenthal (ed.), The Nature of Mind, 229-234. New York: Oxford University Press.


Lewis, David. 1975. “Language and Languages.” In The Philosophy of Language, A.P. Martinich (ed), 489-508. Oxford: Oxford University Press.


Lewis, David. 1984. On the Plurality of Worlds. Oxford: Blackwell. 
Loar, Brian. 1985. “Social Content and Psychological Content.” In The Twin-Earth Chronicles, A. Pessin and S. Goldberg (eds), 180-191. Armonk, NY: M.E. Sharpe.
Loewer, Barry. 1999. ‘A Guide to Naturalizing Semantics.” In A Companion to the Philosophy of Language, B. Hale and C. Wright (eds), 108-126. Oxford: Blackwell.


Lowe, E.J. 1996. Subjects of Experience. Cambridge: Cambridge University Press.


Lycan, William. 1984. Logical Form in Natural Language. Cambridge: MIT Press. 


Lyons, John. 1977. Semantics. Cambridge: Cambridge University Press.


Mates, Benson. 1952. “Synonymy.” In Semantics and the Philosophy of Language. L. Linsky (ed.), 111-138 Chicago: University of Illinois Press. 


McCawley, James D. 1981. Everything that Linguists Have Always Wanted to Know about Logic. Chicago: University of Chicago Press.


McCawley, James D. 1998. The Syntactic Phenomena of English. Chicago: University of Chicago Press.


McCulloch, Gregory. 1989. The Game of the Name. Clarendon: Oxford.


McDowell, John. 1994. Mind and World. Cambridge: Harvard University Press. 


McDowell, John. 1998. Meaning, Knowledge & Reality. New York: Oxford University Press. 


McGinn, Colin. 1988. Mental Content. New York: Oxford University Press.


McGinn, Colin. 2002. The Making of a Philosopher. New York: Harper Collins.
McKinsey, Michael. 1991. “Anti-individualism and privileged access.” In The Twin-Earth Chronicles, A. Pessin and S. Goldberg (eds), 355-361. Armonk, NY: M.E. Sharpe.
Merricks, Trenton. 2001. Objects and Persons. New York: Oxford University Press.


Montague, Richard. 1974. “The Proper Treatment of Quantification in Ordinary English.” In Formal Philosophy, Richard Thomason (ed). New Haven: Yale University Press. 
Moore, Robert. C. 1995. Logic and Representation. Palo Alto: CSLI Publications.
Nagel, Ernest. 1962. The Structure of Science. Indianapolis: Hackett 
Neale, Stephen. 1990. Descriptions. Cambridge: The M.I.T. Press.
Neri-Castañeda, Hector. 1989. Thinking, Language, and Experience. Minneapolis: University of Minnesota Press.
Pap, Arthur. 1958. Semantics and Necessary Truth. New Haven: Yale University Press.
Pap, Arthur. 1962. Introduction to the Philosophy of Science. New Haven: Yale University Press.
Peacocke, Christopher. 1989. “Perceptual Content.” In Themes from Kaplan, J. Almog, J. Perry,, H. Wettstein (eds), 297-330. Oxford: Oxford University Press. 
Peacocke, Christopher. 1992. A Study of Concepts. Cambridge: MIT Press.
Peacocke, Christopher. 1996. “Précis of A Study of Concepts.” In Concepts, E. Margolis and S. Laurence (eds), 335-338.
Perry, John. 2000. The Problem of the Essential Indexical and Other Essays. Palo Alto: CSLI Publications. 


Plantinga, Alvin. 1974. The Nature of Necessity. New York: Oxford University Press. 


Platts, Marc. 1979. The Ways of Meaning. London: Routledge & Kegan Paul. 
Putnam, Hilary. 1975.  “The Meaning of ‘Meaning’”. In The Twin-Earth Chronicles, A. Pessin and S. Goldberg (eds), 1-52. Armonk, NY: M.E. Sharpe.
Putnam, Hilary. 1996.  “Introduction to The Twin-Earth Chronicles.” In The Twin-Earth Chronicles, A. Pessin and S. Goldberg (eds), xv-xxii. Armonk, NY: M.E. Sharpe.
Pylyshin, Zenon W. 1984. Computation  and Cognition. Cambridge: The M.I.T. Press.
Quine, W.V.O. 1951. “Two dogmas of empiricism.” In The Philosophy of Language, A.P. Martinich (ed), 26-39. Oxford: Oxford University Press.
Quine, W.V.O. 1953. From a Logical Point of View. Cambridge: Harvard University Press.
Quine, W.V.O. 1960. Word and Object. Cambridge: MIT Press.
Quine, W.V.O. 1970. Philosophy of Logic. Cambridge: Harvard University Press.
Recanati, François. 2004. Literal Meaning. Cambridge: Cambridge University Press.
Rescorla, Michael. 2003. “Is Thought Explanatorily prior to Language?” Unpublished Dissertation. Department of Philosophy. Harvard University.
Rey, George. 1996. “Resisting primitive compulsions.” In Concepts, E. Margolis and S. Laurence (eds), 339-343..
Richard, Mark. Propositional Attitudes. 1991. Cambridge: Cambridge University Press.


Rosenthal, David M. 1986. “Two concepts of consciousness.” In D. Rosenthal (ed), The Nature of Mind, 462-477. New York: Oxford University Press.


Russell, Bertrand. 1903. Principles of Mathematics. Cambridge: Cambridge University Press.


Russell, Bertrand. 1905.  “On Denoting.” In The Philosophy of Language, A.P. Martinich (ed), 203-211.  The Philosophy of Language Oxford: Oxford University Press.


Russell, Bertrand. 1917. Mysticism and Logic. London: George Allen Unwin.


Bertrand, Russell. 1918. “The philosophy of logical atomism.” In Logic and Knowledge, R.C. Marsh (ed), 175-282. 


Russell, Bertrand. 1920. Introduction to Mathematical Philosophy. London: George Allen Unwin.


Russell, Bertrand. 1921. The Analysis of Mind. London: George Allen Unwin


Russell, Bertrand. 1927. An Outline of Philosophy. London: George Allen Unwin


Russell, Bertrand. 1957. Mysticism and Logic. Garden City, New Jersay: Doubleday.


Russell, Bertrand. 1948. Human Knowledge: Its Scope and Limits. London: George Allen Unwin. 


Russell, Bertrand. 1950. “Logical positivism.” In Logic and Knowledge, R.C. Marsh (ed), 367-382. 


Russell, Bertrand. 1959. My Philosophical Development. London: George Allen Unwin. 


Russell, Bertrand. 1984. Theory of Knowledge. London: George Allen Unwin.


Salmon, Nathan. 1986. Frege’s Puzzle. Cambridge: M.I.T. Press. 


Salmon, Nathan. 1989. “Tense and Singular Propositions.” In Themes from Kaplan, J. Almog, J. Perry,, H. Wettstein (eds), 331-332. Oxford: Oxford University Press. 


Salmon, Nathan. 2005. “Two conceptions of semantics.” In Semantics and Pragmatics, Z. Szabo (ed), 317-328. Ithaca: Cornell University Press. 


Salmon, Nathan. 2005. Metaphysics, Mathematics, and Meaning. New York: Oxford. 


Salmon, Wesley. 1984. Scientific explanation and the causal structure of the world. Princeton: Princeton University Press. 


Saussure, Ferdinand de. 1966. Course in General Linguistics. New York: McGraw-Hill Book Company.


Searle, John. 1969. Speech Acts. Cambridge: Cambridge University Press.


Searle, John. 1979. Expression and Meaning. Cambridge: Cambridge University Press.


Searle, John. 1983. Intentionality: an Essay on the Philosophy of Mind. Cambridge: Cambridge University Press.


Searle, John. 1984. Minds, Brains, and Science. Cambridge: Harvard University Press.


Searle, John. 1992. The Rediscovery of the Mind. Cambridge: MIT Press. 


Sellars, Wilfred. 1963. Science, Perception and Reality. New York. Routledge & Kegan Paul.


Shoemaker, Sydney. “Parfit on Identity.” In Jonathan Dancy (ed.), Reading Parfit. Oxford: Basil Blackwell.


Shope, R.K. 1983. The Analysis of Knowing. Princeton: Princeton University Press.


Sklar, Lawrence. 1974. Space, Time, and Spacetime. Berkeley: University of California Press.


Soames, Scott. “Direct Reference and Propositional Attitudes.” In Themes from Kaplan, J. Almog, J. Perry, H. Wettstein (eds), 393-420. Oxford: Oxford University Press. 


Soames, Scott. 2001. Beyond Rigidity. Princeton: Princeton University Press. 


Stich, Stephen. 1978.  “Scientific versus folk psychology.” In D. Rosenthal (ed), The Nature of Mind, 591-600. New York: Oxford University Press.


Stich, Stephen P. 1983. From Folk Psychology to Cognitive Science: A Case Against Belief. Cambridge: the MIT Press.


Strawson, Galen. 1994. Mental Reality. Cambridge: MIT Press.


Strawson, Peter. 1950. “On Referring.” In The Philosophy of Language, A.P. Martinich (ed.), 219-234. Oxford: Oxford University Press.


Strawson, Peter. 1959. Individuals. New York: Routledge.


Strawson, Peter. 1969. “Meaning and Truth.” In The Philosophy of Language, A.P. Martinich (ed.), 91-101. Oxford: Oxford University Press.


Stroud, Barry. 2001. The Quest for Reality. Oxford: Oxford University Press.


Taylor, Kenneth. 1998. Truth & Meaning. Oxford: Blackwell. 


Tughendat. Ernst. 1970. “The Meaning of ‘Bedeutung’ in Frege.” In Analysis 30: 177-189. 


Wittgenstein, Ludwig. 1922. Tractatus Logico-philosophicus. London: Routledge, Kegan & Paul.


Wittgenstein, Ludwig. 1958. The Philosophical Investigations. Oxford: Blackwell.


Wittgenstein, Ludwig. 1974. Philosophical Grammar. Oxford: Blackwell. 


Wittgenstein, Ludwig. 1980. Remarks on the Foundations of Psychology. Volume 1. Chicago: University of Chicago Press.


Wittgenstein, Ludwig. 1980b. Culture and Value. Oxford: Blackwell.


Wittgenstein, Ludwig. 1983. Remarks on the Foundations of Mathematics. Cambridge: M.I.T. Press. 






________________
[1]
 See Burge (1979, 1982), Kaplan (1989b: 322-326), McGinn (1986), Salmon (1986), and  Davidson (2004: 77-86).  


[2] Blackburn (1984: 328-333) makes this point. 
[3]
 This position is taken by McGinn (1986: 20-30).


[4] Stich (1978: 590-591) powerfully explains why it is not an option, even for the content-externalist, to say that Max and twin-Max are psychologically different. 
[5]
 McGinn holds that content-externalism is correct and that, consequently, one’s mind is spread out all over the cosmos. See McGinn (1986: 20-30). McGinn then argues that this consequence of content-externalism is innocuous since the mind is not a “substance.” 
    It is extremely unclear what it means to say that the mind is not a “substance.” But what is clear is that there are representational mental events. Once this is granted, it follows that, if content-externalism is correct, your mind has long gone stars as veritable constituents. It follows that content-externalism is false, given that your mind came into existence only a few decades ago.
[6]
 Matters are actually not quite as simple as this. Given only the just described differences between W and W*, it is still possible that they are dynamically different, even though kinematically they are the same. See Schlick (1919) and Reichenbach (1958). The thought-experiment has to be developed further to generate the result that Poincaré wants. But these subtleties are obviously not relevant here.  
[7]
 This is John McDowell’s position. See McDowell’s commentary on Chapter 6 of Evans’ Varieties of Reference (Evans 1982: 203-204).


[8]
 It is an open question in the philosophy of science whether there can be two different but equivalent ways of modeling the same data.  
[9]
 Loar (1985) is a soft content-externalist. So are Jackson and Pettit (2004b). Chalmers’ (1996) argument for dualism involves a version of soft content-externalism.
[10]
 Fodor (1998). 
[11]
 Fodor (1990). 
[12]
 Sellars (1963) made a strong case for non-atomism. Non-atomism is now generally, but not universally, accepted. Bonjour (1985) discusses why non-atomist must be accepted. Fodor (1998) argues that it must be rejected. In Kuczynski (2003, 2004), I provide non-Sellarsian arguments for non-atomism. Elsewhere (Kuczynski 2007c), I have argued that a version of Sellars’ argument was given by Berkeley in A Theory of Vision and, in fact, that Berkeley’s version is superior to Sellars’.     
[13]
 This general line of thought lurks beneath the arguments found in Fodor (1990). But it is not explicitly stated there. Nor, to my knowledge, is it explicitly stated anywhere in the externalist (or, for the matter, the internalist) literature. 
[14]
 We will defend this claim in Chapters 13 and 14. But it is not a new or controversial claim. See Carnap (1937, 1956) and Gödel (1953).
[15]
 Of course, spatiotemporal points and lines, and so forth, lack causal powers. But they are not occupants of space-time. Rather, they are sets of space-time coordinates.
[16]
 See MacDowell’s commentary in Evans (1982: 203-204).
[17]
 I am borrowing an argument given by Russell (1919: 165).
[18]
 See Kim (1993: 339-367).
[19]
 Stroud (2001) describes sense-perception as “predicative.” I am using this term in the same way as Stroud.   
[20]


 As I said previously, I believe that Berkeley’s (1935) argument for this is in some ways superior to Sellars: it is more lucid and more general. See Kuczynski (2007c) for a discussion of this.
[21]


 See Fodor (1983) for a classic discussion of the “modular” nature of sense-perception. 
[22]
 Russell (1927: 94) makes a similar point when he writes: “Prejudice tells you that you see the same [Russell’s emphasis] table on two different occasions; you think that experience tells you this. If it really were experience, you could not be mistaken; yet a similar table may be substituted without altering the experience…there is nothing to show that one identical entity causes the two sensations.” See also Russell (1948: 271-294). 


[23]
 See Evans (1982: chapter 5). In his discussion of Evans (1982), Rick Grush writes:  “Evans then discusses the appropriate way to specify the content of informational states. His primary point is that in specifying the content of an informational state, one need not, and one should not, mention any specific objects. Rather, it should be specified by mentioning and properties and objective-variables (in an open sentence). This does mean that we cannot perfectly well speak of the information being of this or that specific object. Two identical photographs might be such that one is of Bob and the other is of Rob, Bob’s twin brother. But in specifying the content of the photograph, we should not mention Rob or Bob, but should rather say something like “a tall person with a red hat”, a specification that both photographs would share.” See the chapter of Grush (1999) entitled “Guide to Chapter 5 of Gareth Evans’ Varieties of Reference.”  


[24] See Blackburn (1984: 317-322). I should make it clear that Blackburn rejects hard-line content-externalism. Indeed, many of our criticisms of content-externalism are anticipated by Blackburn (1984: Chapter 9).
[25]
 This terminology is borrowed from Blackburn (1984). 


[26] The stock example of this is Meinong’s view that “the square circle” and “Pegasus” do refer to objects, albeit ones that “subsist” and do not “exist.” See Russell (1905). 
[27]
 See Soames (2001, 2005). 
[28]
 Kripke (1972: Lecture I).
[29]
 Kripke (1972: Lecture II). 
[30]
 Kripke 1972: Lecture II.
[31]
 Of course, one could say this: 


    “Because you haven’t been given any kind of definition of ‘Argo’, you cannot really use that term with understanding, and you cannot really know what is meant by sentences containing it. When you produce the sounds “Argo sounds like a bad person”, you are really making some kind of metalinguistic statement, some statement like: ‘ “Argo” refers to somebody who is bad.’ And when you hear sentences like ‘Argo was a cad’, you cannot really understand them; what you understand is some related meta-linguistic claim like: ‘ “Argo” refers to somebody who was a cad.’


    This position cannot be summarily dismissed; and I will not dismiss it. But, for our purposes, it is enough to note that the objector’s point seems quite false. Cases like the one just described are pervasive. There are many cases where no ostensive or descriptive definition is involved in our appropriation of a proper name. We hear the term being used and – presto! – can use it ourselves. If the objector’s point is correct, we are not really using any of these terms: we are merely mentioning them. When we produce sentences containing them, we are talking not about people, but about symbols denoting people. But this seems false. I have never been given a descriptive or ostensive definition of the term “Charlemagne.” But it certainly appears as though I can make statements about Charlemagne, and not just about “Charlemagne.” I am thus going to operate on the assumption that I can make statements about Charlemagne himself.
[32]
 It is not guilty of the circularity that Kripke (1972) rightly ascribes to one of Russell’s theories concerning the semantics of proper names. 
[33]
 As we discussed earlier, words undergo phonetic degradation and alteration as they change hands. The first person who uses the word “Argo” might pronounce it one way; the people who “pick up” that name from that person might pronounce it differently. But this fact obviously doesn’t affect the principles governing appropriation of that word. Brown might pronounce “Argo” one way; Smith might pronounce it differently; you might pronounce it a third way; the people to whom you transmit this word might pronounce it a fourth way. After a few transmissions, what is left might bear little resemblance to Brown’s pronunciation. In some contexts, that fact is of importance. But that fact has no bearing on our point that, whenever somebody “picks up” a name – whenever they add it to their lexicon in manner (ii) – it is in virtue of their acquiring knowledge of a uniquely individuating description of the kind we have been describing. 
       It is obvious how these points apply to names like “Socrates.” The word that Socrates’ own acquaintances used to refer to him was not “Socrates” (although that word probably had some phonetic similarities to “Socrates”). Nonetheless, however distorted “Socrates” may be relative to the word that the Ancient Greeks used, the principles governing the “picking up” of that word are the same. In each case, whenever one adds “Socrates”  to their lexicon in manner (ii), it is in virtue of their acquiring knowledge of the right kind of uniquely individuating description. 
      Suppose that “Sukrat” is the Ancient Greek word for Socrates. Glaucon learns what “Sukrat” means through an ostensive definition. Glaucon is engaged in a discussion with Zenon. Glaucon never gives Zenon any ostensive or descriptive definition of “Sukrat.” But Glaucon does produce a sentence of the form “…Sukrat…” Thus, for reasons discussed, Zenon acquires the ability to use “Sukrat” to refer to Socrates; and, for reasons already discussed, Zenon’s ability to do this involves his knowing a uniquely individuating description of the previously discussed kind. Zenon has a conversation with Phoebus. Zenon slightly mispronounces “Sukrat.” In a manner analogous to that just described, Phoebus acquires the ability to use that mispronounced version of “Sukrat” to refer to Socrates. In this way, variants of “Sukrat” are transmitted from person to person, and from generation to generation. What we are left with, two thousand years later, is a word that is quite different (at least phonetically) from “Socrates.” But one’s acquiring the ability to use that word, however distorted it might be relative to the original word for “Socrates”, involves one’s learning some true claim of the form: somebody x uniquely has phi and “Socrates” names x. 
      In most cases, “phi” will be some property like  described, on such and such occasion, by so and so, as having thus and such property. “Phi” will not be a property of historical moment; it will not be a property like great philosopher of antiquity who drank hemlock or philosopher who figured as the protagonist in most of Plato’s dialogues. The property in question will be some highly contextual one, some property that doesn’t connect in any significant way with Socrates’ intellectual or historical countenance.
[34]
 Here I am basically repeating a point made, in different forms, by Kripke, Kaplan, and Evans.
[35]
 This directly contradicts Evans’ (1982: Chapter 7) position. Chapter 8 of the present work is dedicated to discussing whether Evans’ view is correct or not. 
[36]
 See Soames (2001) for an excellent discussion of Dummett’s descriptivism.
[37]
 This point was made in private correspondence (in response to an earlier draft of the present-work) by Steven Horst. Horst’s position is found in Fodor (1998) and, in some form, in Burge (1982) and, indeed, in almost any work that makes any concessions to content-externalism. 
[38]
 Kaplan (1989) makes a similar point. 
[39]
 See Russell (1917: 152-167).
[40]
 At some junctures of his career, Russell held that one can be acquainted with universals and also with one’s self. See Russell (1984).
[41]
 Russell also held, at least at certain junctures, that every proposition that one grasps is equivalent to some proposition about sense-data. This, everyone (including myself) now believes, is quite wrong. But the position that one’s beliefs about the external  world are beliefs about sense-data is entirely distinct from the position that one grasps external objects by knowing existence-claims that they uniquely satisfy.  It is one thing to hold that singular propositions can be only grasped through general ones. It is another thing to hold to hold that singular propositions concerning external objects can only be grasped through propositions concerning one’s own sense-data.  


[42] The point just made – that what is linguistically simple is seldom, if ever, what is actually simple, and that facts about language saddle us with some very wrong views about logic and metaphysics – is made very clearly by Russell himself in a number of places. For example, see Russell (1959: 238-245). 
[43]
 Merrick (2001) holds that people are ultimate constituents of the spatiotemporal world. Otherwise, his view is in close agreement with ours. If, like Merrick (and Plato and Bishop Butler), you believe that people are fundamental constituents of spatiotemporal reality, then replace my mention of “Socrates” with mention of an inanimate object. 
[44]
 See the previous footnote.
[45]
 An argument very similar to this one is given by Andrzej Boguslawski (1994). Anticipations of some aspects of our argument are found in Recanati (2003). 
[46]
 Bach (1984). 
[47]
 For reasons that are not important in this context, (*) is only an approximately statement of the general rule for semantic descriptions. A less approximate statement of that rule is: 


(*C) Given any context C, if there is exactly one salient thing x in C which has phi, then a token t of ┌the phi┐ in C has x for its sole semantic content. 


[48] Of course, even a linguist’s knowledge of these rules is sub-personal. That is, the knowledge that enables the linguist to speak grammatically is sub-personal. In his capacity as a linguist, he may generate analogous knowledge at the personal level. But we are dealing with two different representations of the same (or analogous) information. We are not dealing with one instance of knowing, but with two. 
[49]
 See Kuczynski (2006d).
[50]
 See Russell (1905) and Neale (1990).
[51]
 There are other reasons for advocating Russell’s theory. These relate to issues having to do with variable-binding and anaphora. See Neale (1990). For reasons that I have given elsewhere (Kuczynski 2005c), I believe that these reasons for holding Russell’s theory are spurious. But a discussion of this would take us off our present course.


[52] See Kuczynski (2004b, 2006d).
[53]
 See Mates (1952) for a similar line of thought. 
[54]
 This was told to me by Nathan Salmon, who studied under Kripke. 
[55]
 The expression “pragmatic epiphenomenon” is due to Kent Bach (1984). 


[56] See Blackburn (1984: 308-310) and Neale (1990). In Kuczynski (2004) I discuss the viability of attempts to blame pragmatics for the apparent discrepancies between Russell’s theory and the data.  
[57]
 See Kuczynski (2004b, 2006d).
[58]
 See Kuczynski (2004b, 2006d).
[59]
    There is another problem Russell’s theory: it makes it more difficult than it would otherwise be to explain the obvious grammatical similarities between definite descriptions, on the one hand, and indexicals and proper names, on the other.
     Of course, Russell was acutely aware of the fact that, if his theory is correct, then the grammar of definite descriptions becomes very misleading as to what is actually meant by such utterances. He did not seem troubled by this consequence; and he seemed to hold that, in natural language, there was such a pervasive mismatch between grammatical and logical form that it didn’t redound to the discredit of his theory that 666 it put the grammatical properties of definite descriptions out of alignment with their semantic (or logical) properties. 
     But it is a 666 controversial question whether semantic theories can embody such a deep disregard for grammatical facts. Jackendoff (1989) has argued compellingly that a sine qua non for a semantic theory’s correctness is that it have a certain consonance with grammatical facts. My own view is that Jackendoff is right. If we reject Jackendoff’s view, then (it seems to me) facts about grammar become free-wheels – wheels that turn independently (more or less) of semantics. But, it is not unreasonable to presume, grammatical facts are not entirely without semantic significance. In Kuczynski (2005c), I argue that grammatical facts are semantic facts, and that it is therefore self-contradictory to suppose that grammar might be independent of meaning. The basic idea is that the difference between “Smith sees Jones” and “Smith, the relation of seeing, Jones” is semantic and is also grammatical and that, consequently, we must suppose grammatical inflections to contribute material that connects the denotations of expressions. Grammatical material is connective semantic material.
[60]
 In fact, Frege seems to have introduced this crucial notion to the study of semantics.
[61]
 I actually think that they are truisms or tautologies. I have argued for this in Kuczynski (2005c). But we can leave that aside here.
[62]
 Frege did not, at least not in this context, make any distinction between types and tokens. He did not distinguish between tokens of (2) and (2) itself; and he did not distinguish, at least not in this context, between tokens of “the richest man in America” and the type itself. Frege was aware of the type-token distinction in general; and he had some keen insights into it. But that distinction has no significant role in the theories of his that we are about to present.


[63] See McCawley (1981: 22-56), especially pp. 22-23: 


 “[T]his chapter will be concerned with the “syntax” of quantifiers: elements of logical structure that correspond to words like all, some, and most, which say which or how many of some set of things have a given property.” 


The boldfacing is McCawley’s own. 
     I don’t believe that McCawley’s definition is quite right. An utterance of “that man over there is bald” says that a certain member of a certain set (the set of men in a certain area) has a certain property (the property of being bald). So in virtue of having the form ┌…that man over there…┐ that sentence-token says which member of a certain set has a certain property, and thus qualifies as a quantifier according to McCawley’s definition.  But, as Kaplan (1989) established, “that man over there” is not a quantifier. 
     Nonetheless, McCawley’s is right to say that a quantifier is an expression that says how many members of a certain set have a certain property.  


[64] An argument very similar to this is given by Russell (1912). Barwise and Perry (1983, 1999) also present this argument, or one like it, in a clear and persuasive fashion; and, on the basis of this argument, they have made a powerful case for some significant semantic positions. But the philosophical community has been curiously unreceptive to their efforts. For example, Neale’s (2005) book Facing the Facts only references it in passing, even though it is clear that, if cogent, that argument is completely devastating to practically the entirety of Neale’s discussion.
[65]
 McDowell (1998: Chapter 13) denies exactly this claim. But his justification for his rejection of this is predicated on the correctness of his extremely strong form of content-externalism. We have found reason to doubt whether any kind of content-externalism is correct, let alone McDowell’s extreme version of it. We will continue to find reasons to question content-externalism.
[66]
 Kripke (1972: Lecture II).
[67]
 Kripke (1972: Lecture II).
[68]
 Before moving on, let us deal with one more criticism of our analysis: 
 
     Contrary to what you say, the proposition meant by (1) is logically equivalent with: 


(1*) something x is uniquely identical with Bill Gates, and x is smart. 


     So even if direct reference theory is right, (1) is logically equivalent with an existential generalization. 


     But there is a crucial respect in which (1*) and (2P) are not comparable. (1*) is equivalent with a singular proposition of the form: x is smart. (2 P) is not equivalent with any such proposition. The proposition meant by (1) can be collapsed into one that doesn’t involve the concept there is or is identical with. This is not true of the proposition meant by (2 P). Any perspicuous statement of its truth-conditions will involve such concepts. The same is true of (2), if indeed, Frege is right to hold that (2) and (2 P). So if Frege is right, (2) is (as we might put it) irreducibly equivalent with some quantified proposition, whereas (1) is only reducibly equivalent with such a proposition.  
[69] Davidson (1980b: Chapter 1) has ably argued that Frege’s position is incompatible with the fact that English (and other natural languages) learnable. Given how effectively Davidson presents his argument, I will not repeat it, and will merely refer to the reader to Davidson’s article. In Kuczynski (2005c), I deal with some of the objections that might be made to Davidson’s argument. 
[70]
 In any case, this is the traditional view. See Neale (1990). 
    But, in actuality, what was just said is true only of indicative sentences containing definite descriptions. Given a sentence or imperative containing a definite description, Russell’s theory has the consequence that it is, on at least one disambiguation, ill-formed and thus without any coherent meaning. Neale (1990) considers only indicative sentences, and thus doesn’t confront this problem. In Kuczynski (2004d), I show that Russell’s theory wrongly predicts that any non-indicative sentence containing a definite description is ill-formed on at least one disambiguation. 
[71]


 See Kripke (1977) for a classic discussion of why facts about cognitive significance shouldn’t be explained by positing semantic ambiguities if there is an available non-semantic explanation of those facts. 
 
[72] In any case, there is one, important disambiguation of the term “English” on which that language isn’t English. From a syntactician’s or phonetician’s standpoint, the two languages are not significantly different. But here we are doing semantics, not syntax or phonetics. In Chapter 16, we will discuss the various possible delineations of the term “English” and, thus, of “Chinese”, “French”, and so on.
[73]
 McDowell (1998) says that Kripke’s arguments falsely presuppose that Russell’s and Frege’s views are ultimately the same. McDowell’s argument for this is tethered to his content-externalism, which we have seen to be false. In Chapter 7, we will discuss the underpinnings of McDowell’s claim at length.  
[74]
 The argument about to be given is found in Kripke (1972). But it is actually due to Quine (1953: 155). 
[75]
 See Kuczynski (2006d). 
[76]
 Much of what we just said is found in Boguslawski (1994). 


[77] Keith Donnellan (1974) and Jerry Fodor (1990, 1998) hold it. Kaplan (1968) held it early in his career, though he later retracted it (1989b).        


[78] We have said that to have a conception of x is to know some true proposition of the form…C…, where C is a uniquely individuating description of x.  There are, of course, cases where a causal connection to x is essentially involved. But, as we have seen, the causal connection is always embedded in knowledge of a proposition of the kind just described. 
     But there is an obvious problem with this view: a problem that doesn’t threaten the things we’ve said, but must still be dealt with. I myself do not know who invented the fugue. Let O be that person, whoever it is. (To simplify discussion, let us suppose that exactly one person invented the fugue.) I certainly know some true proposition of the form:…C…, where C is a description that applies uniquely to O. I know that the following are true: 


(i) Somebody x uniquely invented the fugue and he had at least some musical ability. 
(ii) Somebody x uniquely invented the fugue and he lived before the 19th century. 
(iii) Somebody x uniquely invented the fugue and x invented the fugue. 




   Obviously knowing some uniquely individuating description that applies to O isn’t enough to know who O is. And it therefore isn’t enough to know which proposition is semantically encoded in sentences like: 


(iv) “O was a talented composer”.
(v) “O died of scurvy.”
(vi) “O incurred the wrath of his less talented contemporaries.” 


    Remember what we said earlier about “Julius” and “Newman I”. Unless one knows which individuals these terms refer to, one doesn’t know which propositions are encoded in “Julius was tall” and “Newman 1 will be a genius”; one has a simulated, but not an actual, understanding of what is meant by such sentences. One has knowledge of a description of the proposition that is encoded in such a sentence, but one doesn’t know which proposition is thus described. One knows that “Julius was tall” is true exactly if somebody x uniquely invented the zipper and x was tall. So it is clear that knowing who so and so is, and thus knowing the literal meanings of terms that refer to so and so, does not consist (merely) in knowing some uniquely individuating description that applies to so and so. 
    What else is needed? The short, very approximate answer is:  To identify is to re-identify. To know who so and so is, one must know of two existence-claims that are uniquely verified by so and so and, further, one must know that some one person uniquely verifies them. Suppose you meet Bob on Monday. Since you have just met him, there is a sense in which you don’t know who he is. If somebody asks you, “do you know who this is?”, you must say: “I am afraid I do not.”  But, of course, in meeting him, you are uploading information that enables you to think about him – you are acquiring a concept of him. As we saw, this information is existential. Suppose that, a day later, you see Bob again. This time, there is a sense in which you know who you are seeing. As we saw earlier, your recognizing Bob consists in your knowing the truth of two existence claims of which he is the sole verifier, and in your also knowing that some one entity verifies both of them. 
    That is the short answer to the question “what is it to know who somebody (or something) is?”. Here is the long answer. Identification is a contextual notion; it is always relative to some background question, or relative to some body of knowledge, that one knows, or fails to know, who somebody is. Suppose you have been living next door to Bob for years. You know very little about Bob. He doesn’t talk much. He politely waves at you when he mows his lawn. But beyond that, he is a mystery. Later you and your wife are at the beach. You see somebody in the distance. Mary, who has poor vision, asks: “do you know who that is?” You, have better vision, say: “yes: it is Bob, our neighbor.” From some viewpoint, you know who it is that you are seeing: you can identify that person. 
  The next day, C.I.A. agents come to your house. They brusquely ask you: “Do you have any idea who your neighbor is?” You say: “I don’t understand. He’s just some guy who waves at me when he mows the lawn.” They say: “Your neighbor is really the ringleader of an extensive terrorist organization. The government has been looking for him for years…”
   When you saw Bob at the beach, you did know who he was, at least from one viewpoint. But, from some other viewpoint, you have never known who Bob is, at least not until you were briefed by the C.I.A. agents. So you did, and you did not, know who Bob was.    
    What happened here? As we saw earlier, having a conception of an external world object involves two things: having knowledge of existence claims of which that object is the sole verifier; having a certain kind of  knowledge about those existence claims – more specifically, knowing that some one entity satisfies them all.
     Whenever somebody verbally, or ostensively, indicates an object, some existence claim, of which that object is the unique verifier, is implicated. Mary points out Bob to you. You see Bob: in seeing Bob, what is given to you is some existence claim like: there is somebody x to whom I am attending, and x is standing in such and such place, and has such and such appearance…When Mary asks you “do you know who that is?”, what is really being asked is something like: there is somebody x over there, to whom we are attending, and x has such and such features: do you know who x is? And in being asked do you know who x is? you are being asked to identify a more comprehensive set of interlocking existence claims of which x is the unique verifier. Because your vision is good, you are able to do this: you are able to say something  like somebody y is uniquely our neighbor and x is identical with y. (Of course, these are not the words you would use. But this would be the import of your statement.) In saying “that is Bob, our neighbor”, you are conveying (though this isn’t what your words literally mean): 


(*) somebody x uniquely lives on the left side of our house, mows his lawn frequently, goes by “Bob”, and x THAT PERSON  over there is identical with x. 


The only qualification is the person who you are now seeing on the beach – the person whom you can see sharply, and whom Mary can see only blurrily – is given to you through an existence claim: there is somebody y to whom we are now  attending…So (*) really amounts to this: 


(**)somebody x uniquely lives on the left side of our house, mows his lawn frequently, goes by “Bob”,  there is somebody y (over there, building a sand-castle)  to whom we are now  attending, and  y  is identical with x. 


  Your background knowledge of Bob consists in your having knowledge of a set of interlocking existence claims. So your being able to identify the man in the beach consists in your being able to generate knowledge another such existence claim, and in your knowing of that new existence claim that it is satisfied by the same individual who satisfies the others (i.e. in knowing some one individual uniquely satisfies that new existence claim and the other ones). So relative to that background knowledge – to your knowledge of those existence claims – you know the answer to the question “who is that?” 
    But relative to other bodies of background knowledge, this is not the case. You know that there were various bombings, in various cities. You know that somebody or other headed the organization responsible. So you know something like:


(^) Somebody x is responsible for such and such atrocities. 


   You also know that you have a harmless-seeming neighbor. So you know something like: 


(^^) Somebody y lives in the house to the left, and y waves at me while he mows the lawn. 


   When the C.I.A. agents say to you “you have no idea who Bob is”, the import of their words is: somebody x is your neighbor, and somebody y committed such and such atrocities, and you don’t know that x=y. Relative to (^) you don’t know the identity of the man who waves at you as he mows his lawn. But relative to some other existence claim, you do know the identity of the person whom you and Mary are seeing at the beach. To identify someone (or something) is to connect one existence claim to some other existence claim. Identification is a relative notion. Suppose that Bob is given to you through existence claim E1. You may be able to relate E1 to E2, i.e. you may know that someone uniquely satisfies both E1 and E2. But you may not be able to relate E1 to E3, i.e. you may not know that someone uniquely satisfies both E1 and E3. 
     There is a sense in which any three year old knows what water is. But there is also a sense in which any three year old (except for a few prodigies) do not know what water is. Suppose you point to water and ask little Timmy, “what is that?” He says: “that is water.” He has correctly identified the substance in the glass. So, in that sense, he knows the identity of the liquid in the glass. 


(w1)  There is some substance x such that Timmy drinks x, bathes in x, and so forth. 




Timmy knows that w1 is true. Timmy also knows that 




(w2) there is some substance y such that y is in the glass being indicated. 




Further, Timmy knows that 


(w3) There is some substance x such that Timmy drinks x, bathes in x, and so forth; there is some substance y such that y is in the glass being indicated; and y=x. 


So relative to w1, Timmy can identify the substance in the glass. But relative to other existence claims, this is not the case. 




(w4) There is a substance z such that z has thus and such chemical structure. 




Obviously non-prodigy Timmy doesn’t know that: 




(w5) There is a substance z such that z has thus and such chemical structure; and there is some substance y such that y is in the glass being indicated; and y=x. 




So relative to (w4), Timmy doesn’t know what is in the glass. There is no paradox here. Identification is relative to background knowledge. Being able to identify an object is being able to connect it to background knowledge. Timmy can connect the liquid in the glass to certain bodies of knowledge, but not to others. So, from some certain viewpoints, but not all, Timmy knows what is in the glass. 
   Being able to understand 




(J) “Julius was tall” 




involves knowing who “Julius” refers to. (Here we are using “Julius” in Evans’ sense, as a descriptive name that refers to that person, whoever it might be, that invented the zipper.) Knowing who “Julius” refers to involves knowing not just one existence claim that he satisfies: it involves knowing (at least) two such claims, and also knowing that some one person satisfies them both. Further, knowing who “Julius” refers to is contextual: relative to some existence claims, you might know it; relative to others, you might not. So the concept of knowing what a term refers to, and therewith the concept of being able to assign meaning to a term, is contextual: so, therefore, is the concept of understanding a sentence-token. 


[79] See especially Evans (1985: Chapter 6).


[80] Fodor (1990, 1998) argues that conception always has a causal component. In Chapters 22-23, we will see some reason to hold that this contention is false. 


[81] Except where a few scholars are concerned. But, even then, what is conscious is not the knowledge of which I am speaking. Rather, what is conscious is an analogue of that knowledge. When a cognitive scientist acquires conscious knowledge of the cognitive operations mediating between his retinal disturbances and his subsequent visual experiences, neither those operations, nor the knowledge they embody, become constituents of consciousness. Rather, they become objects of consciousness. In and of themselves, they no more become part of consciousness than the star which I am now seeing through my window.
[82]
 See Searle (1983: 225-228) for a similar line of thought.
[83]
 Alternatively, we would say that so far as x does have a concept of Smith, that concept is importantly different from his concept of something that x has personally seen or from which he was otherwise receiving information via some casual process (e.g. historical records, testimony, film). x’s concept of (say) his wife, or even of Socrates, has a robustness that his concept (if that word can even be used) of Smith lacks.
[84]
 I repeat that, in this context, “conception” refers only to our conception of spatiotemporal entities – our concepts of abstracta are dealt with in Chapters 22 and 23.


[85] Dretske (1982), Fodor (1990).
[86]
 This is a point that pervades Evans (1982); and it is because of a reading of that work that I appreciate its significance.
[87]
 See Kaplan (1989) for similar remarks.
[88] Or, alternatively, that Jones’ concept is less robust than the concept Jones would have in virtue of knowing (*).  
[89]
 A similar line of thought is found in Frege (1918): 


“If someone wants to say the same today as he expressed yesterday using the word ‘today’, he must replace this word with ‘yesterday.’ Although the  thought is the same its verbal expression must be different so that the sense, which otherwise be affected the by the differing time, is readjusted.” Quoted in Kaplan (1989: 501). 


   Kaplan (1989: 500-505) makes and develops this point. 
[90]
 His reasons for rejecting the photograph model are very different from ours. Evans seems to hold that, if the photograph model were correct, then one could exercise a given concept only in the context of a belief – and not in the context of a non-affirmative attitude towards a proposition (e.g. an attitude of questioning or supposing). See (Evans 1982: Chapter 3) and Grush (1999). The idea seems to be that my mental representation of a state of affairs just is a causal connection with that state of affairs, then I must always be mentally affirming the existence of that state of affairs, so long as my concept of it remains in existence. So far as it can express any kind of propositional attitude towards what it depicts, a photograph of a man on a horse can only affirm that there is a man on a horse. It cannot express a conditional proposition or a question or a supposition. 
       This idea connects with independently corroborated and significant lines of thought. Freud (1965: 24)  argued that visual imagery is incapable of expressing propositional attitudes other than mere affirmation: 


“The latent dream-thoughts are…transformed into a collection of sensory images and visual scenes. It is as they travel on this course that what seems to us so novel and so strange occurs to them. All the linguistic instruments by which we express the subtler relations of thought – the conjunctions and propositions, the changes in declension and conjugation – are dropped, because there are no means of representing them; just as in a primitive language without any grammar, only the raw material of thought is expressed and abstract terms are taken back to the concrete ones that are at their basis.” 
 
Because dreams are ideographic, as opposed to linguistic, means of representation, non-affirmative attitudes towards dreamt contents has to be expressed in highly indirect means. For example, an attitude of incredulity (“that would never happen: Lucille would never marry Bob”) has to be expressed by in some roundabout way (e.g. through an image of there being flying pigs or pink elephants at the marriage-ceremony). See Freud (1998: 346-366) for an extremely sophisticated discussion of the difficulties that are involved in giving a strictly pictorial representation to non-affirmative propositional attitudes. (This work of Freud’s was originally published in 1900.)
       More direct confirmation for Evans’ view is found in Rescorla (2003). Rescorla points out that you can’t form a “conditional map” by juxtaposing two maps. A juxtaposition of two maps doesn’t result in a single, complex representation: all that is left are 666 two semantically disconnected maps. So there is, as Rescorla says, no map-negation, map-conditionalization, and so on 666. 
        Evans’ criticism thus seems to be a kind of extension of a criticism that, in private conversation with David Pears, I made of the “picture-theory” of thought advocated in the Tractatus. If a thought is just a picture or isomorph of the corresponding fact (or proposition), then how can one have conditional thoughts or negative thoughts? A purely pictorial language is thus a non-starter. (Egyptian hieroglyphs are not mere sequences of pictures; they are grammatically structured.)
       So Evans’ point has substance, as it point to a fundamental fact about ideation. (Purely visual – or, more generally, iconic – representation is fundamentally different from linguistic representation. Language can express a variety of different attitudes towards a different content, whereas iconic representation cannot.) 
       But Evans doesn’t put his finger on what is fundamentally wrong with the photograph-model. What is fundamentally wrong with it is that it doesn’t account for any kind of conception. Given only that x is a photograph of y, it doesn’t follow that x is some kind of awareness of y – it no more follows that x is an affirmation of y’s existence than it does that x is an affirmation of y’s non-existence. The problem with the photograph model, as I discuss in Chapter 13, is that mistakes the permissibility of an inference with the actual making of that inference. Given known causal laws, x’s state (its being discolored in a certain way) warrants the inference that y occurred. Given a film of Smith committing the murder, it can reasonably (though defeasibly) be inferred that Smith committed the murder. But it doesn’t follow that the film is an awareness of the occurrence of some event involving Smith – unless one has an independent grounds for the highly implausible view that a causal inference has been made wherever it can be made. 
[91]
 Or, rather, in my reconstruction of that argument. Evans’ own version of the argument is quite compressed, so I thought it appropriate to expand it into a number of different steps. 
[92]
 It is unclear what McDowell would say here. Given what he says in McDowell (1998: Chapter 13), it seems as though McDowell’s position would be that  there is no significant entity you and twin-you have in common in virtue of being molecular twins. It seems, then, that McDowell would reject any psychological theory – any attempt to formulate psychological laws – that assumed otherwise. So he would either say that psychology xxx is not a legitimate domain of research or that psychology must be done along externalist lines – I must know whether the transparent liquid that we drink is H2O or XYZ or ABC…Both options are highly revisionist. 
[93]
 Stich (1978, 1983) makes this very point. 
[94]
 Soames (2001, 2003) discusses why, according to many philosophers, there is an inconsistency here, and he also discusses why (in his view), they are wrong.   
[95]
 This argument is to be found in Evans (1982: 50-51, 1985: Chapter 10.An excellent clarification of Evans’ views is to be found in Grush (1999). But for Grush’s commentary, my level of understanding of Evans’ work – especially in relation to the concept of a de re sense – would have been much more tenuous than it is. See the chapter of Grush (1999) entitled “Guide to Chapter 6 of Gareth Evans’ Varieties of Reference.”  
[96]
 Evans (1982: 50-52) also holds that, on rare occasions, descriptive proper names come into existence more or less naturally, putative examples being “Deep throat” and “Jack the Ripper.” So the semantics for “Jack the Ripper” would be: if somebody x uniquely committed the White Chapel murders, then “Jack the Ripper” refers to x. If nobody satisfies that condition, then “Jack the Ripper” doesn’t refer at all and ┌Jack the Ripper has phi ┐  fails to encode any proposition. 


[97] Here one might make the following reply on Evans’ behalf: 


        For a moment let us forget about the niceties of Evans’ own argument. Suppose we stipulate that “Julius” is a device of singular reference and that “Julius” has the concept unique zipper-inventor as a component. Given this, let P* be the proposition semantically encoded in “Julius was tall.”  P* would have x himself as a constituent; and P would also have the concept unique-zipper inventor (and possibly also some concept built out of that concept) as a component. In this case, it seems to me, P* might well be the kind of proposition that Evans had in mind: a proposition that comprises a sense that is de re with respect to some external object. 


    
       In that case, the question is: which proposition is P*?  P* cannot be x was tall. After all, by hypothesis, P* must be a proposition which has the concept unique zipper-inventor as a component. P* cannot be identical with, or logically equivalent t: 


(#)  something y was a unique zipper-inventor and y was tall. 


For neither (#), nor any proposition logically equivalent therewith (apart from the previously discussed irrelevant exceptions), has x as a constituent. Further, (#) doesn’t have the same truth-conditions as the proposition that, according to Evans’ own stipulation, is meant by “Julius was tall.” Also, if (#) were the meaning of “Julius was tall”, then that sentence would have a quantified generalization for its meaning. In that case, as we saw earlier, “Julius” would be a quantifier, contradicting Evans’ stipulation that it is a device of reference. 
       Of course, there are propositions that are both object-involving with respect to x and have the concept unique zipper-inventor as a constituent, for example: 


(^) x was tall and something y was a unique zipper-inventor and y was tall. 


But (^) doesn’t have any de re sense as a constituent. Further, to echo a point made a moment ago, (^) isn’t logically equivalent with the proposition that, according to  Evans’ own stipulation, is meant by “Julius was tall.” More importantly, it is pretty clear that (^) isn’t what Evans had in mind. 
        Also, if (^) were the meaning of “Julius was tall”, then “Julius” would be both a singular term – one that picks out x – and something that has a sense (unique zipper-inventor). But it would not have both of these properties by virtue of having a de re sense. It would have both those properties by being a device of singular reference and a quantifier. But these two roles wouldn’t fuse together into a de re sense. “Julius” would simply be an orthographically condensed representation of two entirely distinct functions. 
       Of course, Evans didn’t think that (^) in particular was the meaning of “Julius was tall.” Nor did he believe that, if (^) were the meaning of that sentence, “Julius” would be of any particular theoretical interest. But what we said about (^) is true of any proposition that has both x and the concept unique zipper-inventor as constituents. Any such proposition will lack a de re sense. And if any such proposition is the meaning of “Julius was tall”, the result is not that “Julius” is a sense-bearing singular term – the result is not some kind of fusion of description with reference. Rather, the result is that “Julius” is a phonetically condensed way of encoding two quite separate semantic functions – reference and, separately from that, description – and fails to illustrate anything non-trivial concerning actual or possible languages. 
      Let us sum up this preliminary argument. Evans wants to show that a kind of descriptive singular reference is possible, at least in principle. But he doesn’t show this. By his own stipulation, if P is the proposition meant by “Julius is tall”, P is true in a world w iff x is tall in w. So, with the irrelevant exceptions cited earlier, P isn’t logically equivalent with anything has the concept zipper-inventor (or even just zipper) as a component. If we stipulate that the meaning of “Julius is tall” does have that concept as a component, then “Julius” ends up either being a quantifier, contrary to Evans’ own stipulation, or it ends being a phonetically condensed representation of two entirely distinct semantic functions – reference and, separately from that, description. Under no circumstances, does “Julius” become a device of descriptive reference; and under no circumstance does it become something that is in any way associated with a de re sense.
[98]
 See Kripke (1977), Salmon (1986), Neri-Castañeda (1989), Kaplan (1989).
[99]
 See Burge (1982) and McDowell (1998: Chapters 10-13) for a similar line of thought. 
[100]
 We see yet another vindication of Russell’s epistemology. As we discussed earlier, Russell (1917: 52-67) believed that we could be acquainted with propositions that had items of one’s own consciousness as constituents, but that we couldn’t be acquainted with propositions that had external objects as constituents. 


[101] See McDowell (1998: 260-274).
[102]
 See McDowell (1998: 260-264).
[103]
 Much of what I will say here is anticipated by Russell (1917: 152-167). 


[104]   Of course, you could mean snow is white by “snow is white” even if you that thought that the literal meaning of that sentence was “grass is green.” A person’s boss can mean you’re fired with the words “I can’t guarantee that your future here will be a good one”, knowing that those words don’t literally mean you’re fired. But the boss knows that given what they already, those words will convey that message under the present circumstances. So the boss is able to mean you’re fired by those words because, in  effect, he knows that there is a pre-existing symbolic relationship between those words and that message. So the boss effectively believes that, pragmatically if not semantically, those words already mean you’re fired in this kind of context. So we don’t have a meaningful exception to the principle that speaker-meaning is to be understood in terms of expression-meaning. So far as we seem to have such an exception, that is because we are conflating the concept of literal meaning, which is a very special kind of meaning, with the concept of meaning tout court. 
    For exactly similar reasons, one could mean snow is white by an utterance of “snow is white” without believing that the latter literally means the former. But this would be possible only if the speaker believed there to be some kind of pre-existing symbolic relationship between those sounds and that proposition. So we don’t have a genuine exception to the principle that speaker-meaning is to be understood in terms of expression-meaning. So the concept of speaker’s meaning is to be understood in terms of the concept of literal meaning, and not vice versa.


[105] Wittgenstein (1958 § 510) observed that you cannot say “snow is white”, but mean grass is green. This was meant to corroborate his view that linguistic meaning is to be understood in (at least partially) non-psychological terms. This argument of Wittgenstein’s appears to be cogent. 


[106]
 Wittgenstein (1958) seems to deny this, at least on one natural reading of his work. We will consider his views in Chapter 17.  
[107]
 This seems to be what Russell (1917: 152-167) says. That position also seems to be implicit in Frege’s (1892) view.
[108]
 Of course, unless you are learning English as a second language, the second method is not going to be the one that is used.
[109]
 In case this, this is what  practically everyone believes. Wittgenstein (1958) famously denies it. In a moment, we will discuss why, in my view, Wittgenstein’s view is simply a muddle.
[110]
 I think that (A) entails (B) and that, in fact, they are equivalent. If that is right, then (B) is technically redundant. But we needn’t investigate this subtlety here. 
[111]
  Freud made a good case that many of our propositional attitudes are unconscious. One can unconsciously hate (or love) someone 666. One can unconsciously yearn for a divorce or for the death of a good friend. Even though they are not denizens of consciousness, such attitudes often have pronounced effects on consciousness. Being expressions of attitudes that have no place within the structure of what we consciously believe about ourselves, special efforts on the subject’s part must be taken to reconcile those disturbances with his consciously held belief-system. Those efforts are what we refer to as rationalizations – spurious attempts to show that our conscious beliefs about ourselves are consistent with some occurrence that, in fact, is proof of their erroneousness. Once these rationalizations are constructed and thus come to have a place in consciousness, the conditions that an attitude must meet to be consistent with the contents of consciousness are even more stringent than before. After all, attitudes must now be consistent with those rationalizations, along with whatever was present in consciousness before they came along. So the existence of a 666 rationalization 666 tends to keep attitudes out of consciousness, and thus itself extends the very abridgments to self-knowledge that motivate them.  
      The contents of the Freudian unconscious are basically of the same nature as the contents of consciousness. Those unconscious contents consist of loves, hates, yearnings, and so on. Further, those attitudes can become conscious. What was once an unconscious hatred of Smith can become a conscious hatred of him. So the contents of the Freudian unconscious are close to consciousness in two respects. First, they are dynamically close, i.e.  they can (in principle) become consciousness. Second, they are qualitatively close, i.e. they are of the same basic nature as the contents of consciousness. So there is a sense in which the Freudian unconscious is not deeply unconscious. 
       Chomsky made a strong case that there is unconscious ideation of a much deeper and more alien sort. According to Chomsky, the learning and use of language is mediated by cognitive processes that, first of all, cannot possibly be transferred to consciousness and, second, bear no significant resemblance to the propositional attitudes that populate consciousness. So the Chomskyan unconscious is both dynamically and qualitatively remote from consciousness. It is, as Chomsky puts it, deeply unconscious. 
       Analogues of Chomsky’s analysis of linguistic cognition have proven applicable to many other domains of cognitive activity. With each such advance, we must increase our estimate of the scope of the deeply unconscious. 
[112]
 What I say in this chapter is similar to, though not coincident with, what McKinsey (1991) and Bilgrami (1992) say. For reasons of space, I cannot go into the specifics concerning the differences among our three systems. Suffice it to say that there is a core of agreement and that I learned much from their superb articles. 
[113]
 I repeat that what I say here is not unlike – though it by no means coincides with -- what McKinsey (1991) and Bilgrami (1992) say. 
[114]
 This is argued by Kevin Falvey. See Falvey (1994) and Falvey and Owens (1994).
[115]
 Davidson (2005: 15-38). A strong anticipation of Davidson’s position is found in Churchland (1981: 602-603).
[116] Kuczynski (2003).
[117]
 In any case, there doesn’t seem to be any way of describing the contents of the personal stratum of cognition except in terms of those concepts. It is another matter altogether whether the same is true of the contents of the sub-personal stratum.  In fact, it seems that those processes are not to be understood in terms of those concepts. 
      But this doesn’t help Davidson. First of all, Davidson’s point concerns the contents of the personal stratum of mentation; and we’ve already seen why that point is false with respect to those contents. It should be noted that Davidson rejects the very idea of sub-personal mentation.  
[118]
 Davidson (1980: Chapter 11).
[119]
 Davidson (1980: 215).
[120]
 Facts about the magnifying glass may be meta-data. If it turns out that magnifying power of the glass was less than what I was led to believe by the person who sold it to me, or it turns out that our views about optics are seriously wrong, then I will re-appraise the data that I generated with the help of the magnifying glass. I will, for example, revise my view as to the size of the dust-mite that I was studying. But this shows that the magnifying glass is of interest to the entomologist only to the extent that it helps him generate data about insects. Information about the magnifying glass itself is of interest only in so far as it is relevant to the generation of such data. 
[121]
 Some philosophers, most notably Paul Churchland, deny that mental phenomena are to be understood in terms of concepts like belief, doubt, and the like. Such concepts, argues Churchland, belong to folk-psychology, and are to be given no more credence than the concepts of folk-physics or folk-medicine. Given this, it might seem that Davidson’s position is immune to the arguments we’ve put forth, provided that Churchland’s view is right.  
      This is not the case. Churchland doesn’t hold that representational content doesn’t exist, but rather that it has been misconstrued. In fact, Churchland’s view is that, given a system of folk-psychological categories, it is not possible to account for the fact that so much information (or content) is housed and processed by brains. Further, so far as there is support for Churchland’s rejection of folk-psychology, that support lies in the success of theories (such as those of Chomsky and Marr) that very much take for granted the existence (and efficacy) of mental content. Indeed, those theories posit extensions, not diminutions, of the range of phenomena that are to be understood in terms of the processing of representational content. So no support for Davidson’s position is found in Churchland’s position or in anything that supports Churchland’s position. 
      Churchland describes himself as having an “eliminativist” attitude towards the mental. But really Churchland has an eliminativist attitude not towards the mental, but towards the entities posited by what he refers to folk-psychology. Churchland has a strongly realistic attitude towards sub-personal mental processes. Indeed, as we just noted, his eliminitavism in regards to folk-psychological entities is grounded in his acceptance of mental entities that defy folk-psychological description. See Churchland (1981: Section V). In general, so far as eliminitavism (so-called) is plausible, the arguments for it presuppose the acceptance of mental representations, albeit ones that are alien to our ordinary way of thinking about the mental. So Davidson’s position gains no support from the eliminitavist’s. 
      This is not to mention that much of Davidson’s work implodes if theories positing sub-personal thought are correct. (For example, Davidson argues that only creatures that already speak a language can think. If there are sub-personal cognitive processes, they obviously pre-date the individual’s ability to use language, given that they would be pre-requisites to the perceptions and cognitive operations involved in the learning of language. So if there is sub-personal mentation, then Davidson’s views on the relation between language and thought are false.  Given how important those views are to the system of ideas that Davidson produced, that system collapses if there are in fact sub-personal cognitive processes of the kind posited by Chomsky and Marr. ) So Davidson is barred from using Churchland’s view as a way of combating our criticisms, even though others might not be thus barred.  
[122]
 It seems to me that underlying Davidson’s analysis is an underestimation of how much two empirically equivalent systems of measurement must have in common. I am putting my argument for this in a footnote because that argument is not yet cogent. 
        Davidson is obviously right to say that, for any object O and any number N, there is some viable system of measurement S such that, relative to S, O’s mass is N. But it doesn’t follow that the concepts used by an adequate system of measurement can be jettisoned. In actuality, given two empirically adequate systems of measurement, it must be possible to establish a strict correspondence between the concepts used by the one system and those used by other. What is true of measurement is true of description generally. Supposing that folk-psychology is empirically adequate, it follows that concepts similar to those used by it are indispensable to psychological explanation. To substantiate these points, we must briefly set aside any discussion of propositional attitudes and focus exclusively on the concept of measurement.          
       In some cases, the differences between systems of measurement are purely verbal. Length can be measured in feet or in yards. If we are measuring an object’s length in feet, let us say that we are using system MF; and if we are measuring it in yards, let us say that we are using MY. The statement: 


(i) “X is three feet long”


is only verbally different from 


(ii) “X is a yard long.”


          (i) and (ii) use the very same concepts, and they differ only in respect of the words they use to refer to X’s length. In general, MF and MY use the same concepts, and differ only in respect of the expressions they use to express those concepts.   
            Not all differences between systems of measurement as trivial as the one just described. If the distance between x and y is small (but not too small), it can be measured in terms of how many rods of a given length are needed to connect x and y. But distances of considerable length, e.g. those between celestial bodies, cannot be measured with yard-sticks. For this reason, such distances must be measured in other ways, e.g. in terms of the amount of time it takes for light to travel from x to y. Here we are dealing with two genuinely different systems of measurement. 
        But great care had to be taken to ensure that, where distances that can be measured in terms of either method are concerned, the measurements generated with the one system coincide with those generated with the other. Otherwise, the statement “the distance between the Earth and the Moon is over a thousand times greater than the distance between Santa Barbara and Los Angeles” would be meaningless. For exactly similar reasons, where moderate temperatures (such as those on the surface of the Earth) are concerned, the methods that are used to measure the temperature of a very hot body, such as the sun, must yield the same results as those generated by using a mercury-thermometer. Otherwise statements comparing the temperature of Santa Barbara with those on the surface of the Sun would be meaningless. Hempel (1952: 62-78, 1965: 123-134) cogently argues for these very points. 
          For argument’s sake, suppose that there were no way of establishing a one-one correspondence between the amount of time needed for light to travel between two points and the number of times a meter-rod of a given length could be laid endwise XXX between those points. In that case, those two methods would measure different properties. Regardless of whether we use meter-rods or light beams, we can speak of length simpliciter only because empirical research has established that (within certain extremely narrow horizons) there is a one-one correspondence between statements reporting the results of the one method of measurement and statements reporting the results of the other kind of measurement. See Hempel (1952: 62-78, 1965: 123-134) and Pap (1962: Chapter 8).
         In general, a given quantity can be measured in different ways only if it is established that those different methods yield identical results (with respect to situations to which both methods are applicable). If two systems of measurement don’t satisfy this requirement, then either they don’t measure the same quantity or one of them is generating erroneous measurements.
         Let us synthesize these points. In some cases, two systems of measurement are only verbally different. (This is the case with MF and MY.) In other cases, the equivalence of two systems presupposes a posteriori knowledge of physical law. But given the equivalence of two such systems, the statements generated by the one can be mapped onto those made by the other. It is not analytic that (for small distances) operations with meter-rods yield statements that are equivalent with those yielded by measurements of time-intervals between light-signals. But given that equivalence, any statement S generated by the one method will be analytically equivalent some statement S* generated by the other (provided that S and S* concern distances that can be measured using either method). So given two adequate methods of measuring a given quantity, the statements produced by the one method are analytic transformations of those produced by the other.  
          In light of these points, let us once again look at Davidson’s analysis. Let H be the method of psychological description that we ordinarily use. So H is the method that generates statements like Sally believes that 1+1=2 and Fred wants to go to Hawaii. 
         First of all, it seems to me that H is empirically adequate – at least within its narrow horizons. It is probably not appropriate for the description of sub-personal cognitive processes. But it is at least partially adequate for the description of personal psychological processes. It is hard to believe that statements such Sally believes that 1+1=2 are always simply wrong. 
         Let H* be any method of describing the mind that can recognize the obvious fact that Sally believes that 1+1=2. It seems to me that, given plausible extensions of the points just made regarding measurement, H* must use concepts that are identical with, or comparable to, those used by H. If this is right, then concepts similar to those used by H are constitutive of any empirically way of describing psychological facts.
[123]
 Nathan Salmon (1986) denies it. 
[124]
 This example is borrowed from Jackson and Pettit (2004) who, in turn, borrowed it from Putnam. We are, of course, making assumptions as to the comparative sizes of the peg and the whole, and also as to the degrees of rigidity of the peg and of the material surrounding the whole.
[125]
 In my doctoral dissertation, The Moral Structure of Legal Obligation, I argued that that the Jackson-Pettit analysis of causality makes it possible to solve a number of a puzzles relating to the concepts of institutional behavior and legal obligation.  
[126]
  Conceivably, the content-externalist could respond by advocating a four-dimensionalist conception of existence: objects that have “ceased to exist” still exist, albeit in another temporal place. But it seems suspicious that content-externalism – a doctrine about mental content – presupposes the truth of such a view, even if that view happens to be correct. 
      Also, even if four-dimensionalism is correct, that doesn’t help the content-externalist. For it is a fact that right now – at this time, i.e. in this temporal place – my visual perception has a complete content; and, for the reasons just stated, content-externalism cannot accommodate that fact. 
    
[127]
 At least not if the term “state of affairs” is to be taken in a causally significant sense. We could conceivably speak of mathematical facts as “states of affairs.” Referring to the fact that there are infinitely many primes, a mathematician might say: “given this state of affairs, it follows that Riemann’s efforts were…” But that is obviously not a sense of “state of affairs” that is relevant here.
[128]
 See Jackson and Pettit (2004: 55-59).
[129]
 One last example will help identify the fallacy in Jackson-Pettit analysis. Pans P and P* are qualitatively identical, and are under qualitatively identical circumstances, but are thousands of miles apart. Flames of equal heat and volume are placed underneath them. They heat up by the same amount. Smith asks Jones why the proposition: 


(PH) P and P* heat up by the same amount


is true. Brown answers say saying: 


(PA) Because P and P* were heated by the same amount. 


        Brown’s has provided a correct causal explanation of (PH). But how can this be, given that causes operate locally? Jackson and Pettit would say the following. Given (PH), it is guaranteed that (PA) is true; therefore (PH) gives a program-explanation of (PA)’s truth. 
       But given obvious extensions of what we just said, the relationship between (PH) and (PA) isn’t comparable to the relationship between the peg is square and the peg won’t go into the hole. In the latter case, we have a state of affairs (the peg’s being square) which consists in various mass-energy displacements, which effectively cause some other state of affairs (the peg’s remaining in a certain place above the template with the hole in it, despite my pushing against the peg with all my might). We don’t have anything like this in the first case. After all, there is no state of affairs consisting in flames of equal intensities being put under the pans. Of course, the expression “the fact that  flames of equal intensities were put under the pans” is not an empty one – it is not like “the king of France.” But that expression doesn’t denote a constituent of the spatiotemporal world; that expression thus isn’t like “the flame” or “the peg’s being square.” 
       The real relationship between (PH) and (PA) is this. (PH) entails that, for some specific values of p1…pn, both of the following singular propositions are true:


(F) A flame with properties p1…pn was placed beneath P at t.  
(F*) A flame with properties p1…pn was placed beneath P* at t.  


Notice that (F) describes a state of affairs (or event). Further, (F) describes what, given Jackson and Pettit’s own statements, must be described as a program-cause of P’s heating up by a certain amount. What is involved in this last fact? Among the constituents of the flame that is placed underneath P* are various events that effectively cause pan P to heat up by amount Q (by time t*). 
      For exactly similar reasons, (F*) gives a program-cause of pan P*’s heating up by amount Q (by time t*); and this is because (F*) identifies a state of affairs (or event) among whose constituents are effective-causes of P*’s heating up by Q. 
        Thus, given accepted principles of physics, (F) renders probable


(FH) P heats up by amount Q by time t*,


and given those same principles (F*) renders probable some singular proposition of the form: 


(FH*) P* heats up by amount Q by time t*. 


Given that (FH) and (FH*) are both true, (PA) logically follows. 
        Here two points deserve special mention. One is a point we have already emphasized, namely: neither (PA) nor (PH) describes a state of affairs. For reasons already discussed, that by itself makes it questionable whether we are dealing with anything comparable to the relationship between the squareness of the peg and the peg’s resistance to going into the hole. 
       The other point is one we have not yet made. By Jackson and Pettit’s own lights – by their own explicit pronouncements – the fact that a flame with properties p1…pn is being placed beneath P programs for P’s heating up by a certain amount (after a certain interval). At the same time, Jackson and Pettit would also say that (PA) provides a program-explanation for (PH). Whether this constitutes vicious circularity is a question I will leave aside. But it seems clear that relationship between (PA) and (PH) is of a different logical-order from the relationship between P being put on a flame with certain properties and P’s subsequently heating up. The first relationship is given by a certain sequence of propositions, and the second is given by what is merely one small segment of that sequence. 
    The first relationship has a very complicated structure. It starts with a generalization. It then transitions to two singular two singular propositions. From each of these singular propositions, it derives what is must be regarded as a program-explanation, given Jackson and Pettit’s own explicit statements. (So we are dealing with program-explanations embedded with what is supposedly a program-explanation.) From each of these two embedded program-explanations, it derives two cases explanation in terms of effective-causes. Finally, on the basis of these last two explanations, it logically derives another generalization.
       The embedded program-explanations obviously don’t have the same structure as the explanation of (PA) in terms of (PH). In fact, it seems that, on pain of vicious regressiveness, they couldn’t have that structure. (But, as I said before, I will not discuss this last point.) What is clear is that Jackson and Pettit have over-extended the term “program-cause” in using it to apply to both kinds of relationships.
[130] This argument is similar to one made by Kripke (1982) and also to one made by Wittgenstein (1958). I will set aside the question whether it actually coincides with anything either of these authors said. See also Lepore (1994: 197-199).
[131]
 See Kripke (1982), Blackburn (1984: Chapter 2). 
[132]
 There is a third option. One could say that, because one’s dispositions are consistent with one’s having any number of different beliefs, we should hold that it is “indeterminate” what our beliefs really are. So supposing that + A, + B, and + C are “bent” versions of addition, Smith believes 1+A2=3, 1+B2=3, 1+C2=3, and so on, no less than he believes 1+2=3. Given such a view, it is a short step to advocating a kind of anti-realism about propositional attitudes. Since I obviously don’t believe 1+B2=3, and since I believe that proposition no less than I believe 1+2=3, it follows that I don’t believe the latter. Given any supposed instance of belief, it is obvious how to generalize this line of thought so as to demonstrate the non-existence of that belief. Thus, no one really believes anything. In general, one could take functionalism as demonstrating the need for an anti-realist view of propositional attitudes. Wittgenstein (1958) and Quine (1960) seem to hold exactly this. 
      But it seems incoherent to deny that there are propositional attitudes, since such a denial itself embodies a propositional attitude. (This argument is not a new one. Versions of it are found in Strawson 1994 and Hacker 1996.) In any case, it is suspicious that functionalism has such revisionist consequences; and  I am taking it for granted that people do have beliefs, aspirations, and so on. 
[133]
 See Bonjour (1985) and Stich (1983). Sellars (1963) and Wittgenstein (1958, 1975) deserve credit for giving modern epistemology its generally non-atomist orientation. But, as I have previously said, it is really in George Berkeley’s book A Theory of Vision that one finds the earliest, and also the most cogent and perspicuous, defense of non-atomism. 
[134]
 This work was written in 1914. Under pressure from Wittgenstein, Russell decided not to publish it, and it thus wasn’t published until 1984. 
[135]
 Bas van Fraassen (1982) revived a version of anti-realism with regard to theoretical entities. 
[136]
 See Hempel (1952: 23-39) for what are generally considered to be cogent refutations of the thesis that hypotheses about imperceptible entities are reducible to statements about the macroscopic or the phenomenal. 
 
[137] Or, at any rate, before it was a widely accepted doctrine.
[138]
 Fodor (1987: 18-20).
[139]


 Fodor (1981: 13-17, 226-227, 1987: 18-20, 1994: 294-298). 
[140]
 Fodor (1998: 13) writes: “For fear of circularity, I can’t both tell a computational story about inferences and tell an inferential story about what content is. Prima facie, at least, if I buy into Inferential Role Semantics, I undermine my theory of thinking.”
[141]
 Fodor and Lepore (2002) write: “Inferentialism is prohibited from taking this route, since the inferentialist’s point in a nutshell is that meaning is a construct from inferential role, not the other way around.” 
[142]
 Kripke (1972), Fodor and Lepore (2002). 
[143]
 I believe that a version of this argument is found in Wittgenstein (1958) and (1983).
[144]
 See Grice (1957) for a pithy discussion of the ambiguity of the word “meaning.” 
[145]
 Fodor (1981: 13-17, 1987: 18-20, 1990: 22, 1994: 294-298).
[146]
 In any case, this is the philosophical conventional wisdom. It could be said that “Socrates snores” and “some man snores” are grammatically different and that it is only relative to a kind of “folk-grammar” – comparable to folk-physics or folk-medicine – that they have the same grammatical form. I believe that this is the conceit underlying Montague’s (1974) work. This general idea is validated by Chomsky’s work, since the latter shows how far “grammar” fails to reveal the true structure of natural-language sentences. I discuss this in Footnote 17 of Kuczynski (2006b).
[147]
 This point is made clearly in Barwise and Perry (1999: 32-39) and Kaplan (1989: 508).
[148]
 See Russell (1903: Chapter I) for a similar point. 
[149]
 Also, for reasons that cannot be discussed here, I don’t think that this objection can be accepted. So far as that objection is correct, it is because expressions “logical” and “formal” truth are used to refer to a number of different, non-equivalent notions, and are thus used in an incoherent manner. Given any coherent delineation of those terms, there is, for reasons outlined, no choice but to say that S’s being logico-formally true is identical with its being assigned truth by the semantic rules that assign it meaning. But it isn’t possible to go into this here. Nor is it necessary, since our argument against CTM goes through whether the objector is right or not. 


[150] Hart (1961).
[151]
 See, for example, McCawley (1998). 
[152]
 Let us consider another objection to our analysis: 


      “You say that a sentence’s syntax lies not in what it means, but in how it means it. It seems a truism that a sentence’s semantics lies in what it means. So your position is that a sentence’s syntax lies not in what its semantics is, but in how it has hat semantics.  But earlier you said that a sentence’s syntax is an aspect of its semantics. So you have both affirmed and denied that syntax is an aspect of semantics.” 


          
     We’ve seen that a sentence’s syntax is bound up with its semantics: the former lies in how that sentence has the latter. So syntax is a meaning-involving affair. We can take my earlier statements to the effect that “syntax is an aspect of semantics” as an abbreviated way of saying this. It is readily seen that this will not have any negative effects on the arguments in which that statement figured, since those arguments depended on the thesis that syntax was an aspect of meaning – it being left open whether that aspect concerned the how, as opposed to the what, of meaning. So while I concede that, technically speaking, I have used the term “semantics” equivocally, the equivocation is merely terminological, and has no substantive bearing on any of our arguments. 
       
[153]


 Of course, what counts as a “significant” proof-theoretic difference is a function of the dialectical context. This suggests that it probably isn’t possible to speak of the concept of syntactic structure, even if we confine ourselves to the logician’s disambiguation of the word “syntax.” Similar remarks hold in connection with the linguist’s disambiguation of that term.  
[154]
 Consider the following two scenarios. First scenario: nations A and B are engaged in a dispute. Jones, who is the dictator of nation A, responds by waging an all-out attack on B. The attack involves only foot-soldiers: no planes or long-range missiles are used. Second scenario: nations C and D are engaged in a dispute. Smith, who is the dictator of C, responds by waging on all-out attack on D. But Jones uses only long-range missiles: no foot-soldiers are involved. The question “how did Jones resolve the dispute between his nation and B?” may or may not receive the same answer as the question “how Smith Jones resolve the dispute between his nation and D?” A military strategist might say that those questions are to be given different answers, the reason being that, from his viewpoint, Smith and Jones behave in very different ways. (From a military strategist’s viewpoint, there is an important difference between using foot-soldiers and using long-range missiles.) But a psychologist might say that those questions are to be given the same answer, the reason being that, in every characterologically significant respect, Smith and Jones behaved in the same way. (Both used brute force instead of diplomacy or economic measures. The fact that one chose to use long-range missiles, while the other chose to use foot-soldiers, doesn’t indicate any fundamental difference in their characters.)
       Both linguists and mathematical logicians agree that syntax is meaning-how. But the question “how is (i) assigned the meaning that it has?” may or may not be given the same answer as the question “how is (ii) assigned the meaning that it has?” The linguist is interested in issues relating to learnability and mental representation; and from that viewpoint, these two questions are to given the same answer. The mathematician is interested in issues relating to provability; and from that viewpoint, those questions are to be given different answers. The linguist and the mathematical logician agree that syntax is meaning-how, even though, given the differences in their concerns, they operate with different contextualizations of that notion.  
[155]
 An exceptionally clear and powerful defense of this general line of thought is found in Horst (1996). See Wittgenstein (1974) and Coulter (1983) for similar viewpoints.
[156]
 See Wittgenstein (1974), Coulter (1983), Horst (1996). An insightful discussion that in many ways anticipates our analysis is found in Burge (1980).
[157]
   See Fodor (1987: 19): 


 “The operations of the machine [on which I am modeling the human mind] consist entirely of transformations on symbols; in the course of performing these operations, the machine is sensitive solely to syntactic properties of the symbols; and the operations that the machine performs on the symbols are entirely confined to altering their shapes.”
   
See also Fodor (1990: 22):


 “You connect the causal properties of a symbol with its semantic properties via its syntax…To a first approximation, we can think of its syntactic structure as an abstract feature of its (geometrical or acoustic) shape [Fodor’s emphasis]. Because, to all intents and purposes, syntax reduces to shape [my emphasis], and because the shape of a symbol is a potential determinant of its causal role, it is fairly easy to see how there could be environments in which the causal role of a symbol correlates with its syntax. It’s easy, that is to say, to imagine symbol tokens interacting causally in virtue of [Fodor’s emphasis] their syntactic structures. The syntax of a symbol might determine the causes and effects of its tokenings in much the way that the geometry of a key determines which locks it will open.
       But, now, we know from modern logic that certain of the semantic relations among symbols can be, as it were, ‘mimicked’ by their syntactic relations; that, when seen from a very great distance, is what proof-theory is about. So, within certain famous limits, the semantic relation that holds between two symbols when the proposition expressed by the one is entailed by the proposition expressed by the other can be mimicked by syntactic relations in virtue of which one of the symbols is derivable from the other. We can therefore build machines which have, again within famous limits, the following property: 
   
    The operations of the machine consist entirely in transformations of symbols; 
   in the course of performing these operations, the machine is sensitive solely to syntactic properties of the symbols; 
   and the operations that the machine performs on the symbols are entirely confined to altering their shapes. 


    Yet the machine is so devised that it will transform one symbol into another if and only if the propositions expressed by the symbols that are so transformed stand in certain semantic relations – e.g. the relation that the premises bear to the conclusion in a valid argument. Such machines – computers, of course, -- just are [Fodor’s emphasis] environments in which the syntax of a symbol determines its causal role in a way that respects its content. This is, I think, a pretty terrific idea; not least because it works.”
      
 Fodor (1981: 226) writes. 


“[C]omputational processes are both symbolic and formal. They are symbolic because they are defined over representations, and they are formal because they apply to representations in virtue of (roughly) the syntax of the representations.” 


A few paragraphs later, Fodor (1981: 227) writes: “[F]ormal operations apply in terms of the, as it were, shapes of the objects in their domain.”  See also Fodor 1981 (22): “[M]achines operate on symbols in virtue of their formal (not their semantic) properties…”, and Fodor (1994: 86, 1987: Chapter 1).




[158]
 Chomsky (1959) provides a cogent argument against a doctrine that is called “behaviorism.” But it is not exactly the kind of behaviorism that Fodor is arguing against. Chomsky’s argument is concerned with behavioristic theories of language-learning, i.e. with views according to which language-learning is a matter of being behaviorally conditioned to have certain verbal responses in response to certain situations. Fodor is concerned with the view that for somebody to have a mental state of type X is simply for that person to behave in certain ways or, at any rate, to have a disposition to so behave. These doctrines are obviously similar; and I believe that some of the criticisms that Chomsky makes of the one kind of behaviorism can be adapted to apply to apply to the other kind. But the kind of behaviorism that Chomsky is attacking isn’t necessarily committed to the view that all mental states are nothing but dispositions towards certain behaviors. An advocate of that view could hold that, for example, affective states (states of pleasure or pain) are not dispositions of that kind. 
[159]
   I would like to propose a psychological hypothesis as to why it is so widely held that thought can be mechanized. As we discussed in Chapter 1, our intuitions often ascribe too much to our sense-perceptions. We confuse data with meta-data. We confuse what we see with what we learn on the basis of what we see. We see a series of innocuous discolorations on a piece of paper or computer-screen. We happen to know a great deal about the socio-psychological conditions that gave rise to those discolorations and into which those discolorations are subsequently re-assimilated. Because of our tendency to confuse perceptual with meta-perceptual data, we end up saying about those discolorations what should really be reserved for those socio-psychological conditions.
        
[160] Stich (1983: 79-81) sets forth a similar argument. 


[161] This brings us to another problem with attempts to understand psychological concepts in terms of the Ramsey-sentence. Such attempts explicitly liken psychological terms to theoretical terms. Of course, some psychological terms (e.g. “reaction formation”, “counter-cathexis”, “depth grammar”) are  theoretical. But some (e.g. “tickle”, “feeling of sadness”) are not. The advocate of (AF) is quite right to say that, for a theoretical term to have meaning, it must have some links, however circuitous and theory-mediated, with non-theoretical phenomena; and it may (or may not: see below) follow from this that the meaning of a theoretical term (e.g. “electron”) is at least partially given by sentences linking the truth-values of sentences of the form “…electron…” with sentences describing non-theoretical (observable) states of affairs 
        But it does not follow that the same is true of psychological terms. Obviously pain, tickles, and other psychological phenomena have behavioral expressions. But it is decidedly implausible to suppose that the sentences giving these linkages are constitutive of the meanings of terms like “pain”, “tickle”, and the like. (Wittgenstein disagrees. We will deal with this position in a moment.)
        I believe that, so far as philosophers have thought otherwise, it is because they were confusing the term “observable” with the term “publicly observable”, and were then equating the latter with the term “non-theoretical.” Your pains are not theoretical entities, at least not from your viewpoint. Further, your pains are observable – they are observable to you, though not to me. (Of course, you don’t observe them in the sense that you sense-perceive them. But you observe them in the sense that their existence is made directly  known to you, at least in so far as anything is directly known to anyone.) These facts, by themselves, call into question (AF)’s categorical assimilation of psychological to theoretical terms. 
        Most importantly, even though your pains and tickles are known to me only through hypothesis, and are therefore theoretical from my viewpoint, it doesn’t follow that the terms “tickle”, “pain”, and “sadness” are theoretical terms. Obviously they are not; “pain” is as non-theoretical a term as we’ll ever find. 
        So the advocate of (AF) is simply wrong to say that, in order to have empirical significance, statements containing terms like “tickle” and “pain” must be linked with sentences referring to publicly observable facts. In any case, he is wrong to say this in so far as his grounds for it lie in his presumption that terms like “tickle” are comparable to terms like “electron”, the reason being 666 that both terms denote “theoretical” and “non-observable” entities. 
      Also, that claim is false tout court. A brain in a vat could obviously feel pain, joy, and so on. The advocate of (AF) could counter-respond by saying that such a brain would behave in certain ways if it were disembodied. Such a counterfactual is true, of course, but only because such behaviors would be the effects of those pains and tickles on the host-body. Given that cause and effect are distinct, that counterfactual presupposes that, in direct contradiction to (AF), pains and tickles are not to any degree constituted by their behavioral expressions. A similar argument is found in Pap (1962: 383-393)
       Wittgenstein (1958) famously argued that the meaning of words like “pain” and “tickle” is  at least partly behavioral and that such words would be meaningless if their sole function were to pick out private internal states.  
        This position involves a failure to distinguish reference-fixing from meaning-giving. “Pain” refers to pain. It doesn’t refer to behavior, and nothing concerning behavior is any part of its meaning. Of course, when we wish to tell another person, e.g. somebody learning English as a second-language,  what “pain” means, our doing so often involves our indicating certain behaviors. While grimacing or writhing, we say (for example): 


(*) “this is pain.” 


But the meaning of (*) is:


(**) There is some psychological state x such that x causes people to act like this [accompanied by some kind of an indication of grimacing or writing or other stereotypically pain-driven behavior], and “pain” refers to x. 


The meaning of (*) is not: 


(***) “Pain” refers to anything x that causes behavior like this [accompanied by an indication of grimacing or writhing]. 


Wittgenstein’s view involves a failure to distinguish between meaning-fixing and reference-giving and, therewith, to register the ambiguities of scope concealed in statements like (*). 
       Much of what we just said about beliefs, and mental states generally, is true of all attempts to “Ramsify out” out theoretical terms. Here we must consider an argument given by Hempel (1965: 204-205). So far as its meaning can be given through the procedure that Ramsey and Lewis describe, the term  “electron” is ends up being frozen. Every sentence containing the term “electron” now countenanced by physical science becomes constitutive of the meaning of that term, and is thus as  incapable as any other tautology of being refuted by scientific progress. One might counter-respond by saying that the Ramsey-sentence is meant only to fix the referent of “electron”, not to give its meaning. But in that case, the idea that theoretical terms can be “Ramsified out” reduces to the triviality that observation terms help people to know what is meant by theoretical terms. 
      A few pages back, we distinguished three different meanings of the word “proof”, and we argued that CTM involves a conflation of these meanings. The word “derivation” has three different meanings, and these correspond to the different meanings of the word “proof.” A “derivation” can be an abstract object: a relationship between two sentences. It can be the mental act of discovering such a structure. Finally, it can be the act of writing down or otherwise communicating such a discovery. Obviously overt behaviors can be effects of one’s having the relevant knowledge, and they are often partial causes of one’s having such knowledge. But under no circumstances are they constitutive of it. So far as it seems reasonable to think otherwise, that is because we are confusing the communication of a cognitive accomplishment with the accomplishment itself.  


[162] See Searle (1984) for a similar line of thought.
[163]
 In his novel The Stand, Stephen King describes a situation where the government collapses and dollar bills become (as King himself puts it) “as worthless as Monopoly money.” I am borrowing his apt expression. 
[164]
 To simplify discussion, let us set aside all of the legal niceties relating to the authentication of duplicates of contracts.  
[165]
 This point is powerfully defended in Wittgenstein (1958).


[166] This is borrowed from Fodor and Pylyshin (1988: 35).
[167]
 See Kuczynski (2002, 2005) for a detailed discussion of these reasons. See Russell (1950: 371) for a pithy and lucid discussion of some those reasons. 
[168]
 This is the position taken by Fodor (1975) and Lycan (1984: 237) in response to the regress-argument just given.  
[169]
 See Lycan (1984: 247), Kuczynski (2002, 2004d). 
[170]
 Fodor, private correspondence. The capitalizations are Fodor’s own. 
[171]
 See, for example, Fodor (1987: 18-20). See also Cain (2002: 135). 
[172]
  Incidentally, this line of thought suggests a certain approach to an old metaphysical question. It is often asked whether objects – rocks, trees, people, and so forth -- have essential properties. Is there such a thing as the essence of the rock or the essence of your friend Smith? The question would seem to be ill-formed, given that it is not objects, but states of affairs, that are causally and explanatorily important. When we talk about “essences” and “essential properties”, we are presumably referring to things that have some kind of causal or explanatory significance. As we’ve seen, Smith is a non-entity, as far as explanation and causation are concerned. What is not a non-entity is Smith’s having a million dollars or Smith’s resenting you for your good looks. Obviously it is essential to Smith’s having those properties that he have certain other properties. One does not just have a million dollars. One’s having a million dollars supervenes on one’s having various other properties -- for example, one has bits of green paper in a brief-case under one’s bed, where those bits of green paper play a certain role in the society of which one is a part. So Smith’s having a million dollars does have an essence. The same is true of Smith’s resenting you for your looks. But it doesn’t follow that Smith has an essence. And to the extent that essences are supposed to be explanatorily significant entities,  it isn’t clear how he,  as opposed to his having this or that property, could have an essence. 


[173] Strictly speaking, it isn’t quite right to say without qualification of that inscription that it is physically complex. Whether it is complex, and if so how, is a function of the explanatory context. But we needn’t pursue this.
[174]
 Fodor (1998: Chapter 4).
[175]
        Let us address a possible objection to our argument: 


   “Not all analytic dependencies correspond to conceptualo structure. x is knowledge entails x is not a  square circle. But this analytic dependency doesn’t show us anything specifically about the concepto of knowledge. After all, x is a case of painting entails x is not a  square circle, as do x is a house and x is a barber. The fact that x is knowledge entails x is not a square circle evidently tells us nothing about the structure of the concepto of knowledge. So it would appear that you were wrong to see analytic dependencies as indicating conceptualo structure, and that your argument against Fodor was misguided.”
       


        This objection actually reinforces our criticism of Fodor’s argument. Consider the entailment given by the statement: 


 (*) “For any x, if x is knowledge, then x is belief.” 


If the occurrence of “knowledge” is replaced with an occurrence of “a house” or “case of painting”, what results is a falsehood. So (*) does give us differential information about the structure of the concepto of knowledge, thus confirming our point. 


[176] See, for example, Carnap (1966).
[177]
 It is similar to an objection that George Rey (1996) makes of Peacocke’s (1992, 1996) analysis of conception.
[178]
 Or, more likely, it refers to some kind of idealization of this information. As we discussed, the information through which one computes the meaning of tokens of “Hesperus”, and thus of sentence-tokens containing that term, varies from person to person. No two people will learn what is meant by “Hesperus” in quite the same way. Given any two people to whom that term is defined ostensively, their respective optical relations to Hesperus will probably not be exactly the same; and the same is true of any two people to whom it is defined indirectly or non-ostensively. So far as there is one  “concepto of Hesperus” – i.e. so far as the term “the concepto of Hesperus” is not an improper, and thus non-referring, definite description -- that term seems to refer to some concepto that abstracts from all of these person-to-person variations, leaving only some core concepto like unique last body to disappear from the morning sky, or some such. (Of course, this is exactly what Frege and Russell, and all pre-Kripke semanticists, would have identified as “the concepto of Hesperus.”) 
      What is important here is that if by “the concepto of Hesperus” one means the information through which people think about Hesperus – or, more exactly, through which they compute the semantics of occurrences of expressions like T – then the concepto of Hesperus is by no means conceptuallyo simple, as it consists of the conceptso morning, luminescent, and so on.
[179]
 Dummett (1973: Chapter 17) presents a similar argument. 
[180]
 This was the thesis of my doctoral dissertation. 


[181] Wittgenstein (1975) deserves credit for making this point. In Kuczynski (2006) I discuss why, in my judgment, Wittgenstein’s insight warrants a non-atomistic conception of conception
[182]
 An argument similar to the one just given is found in Dummett (1978: Chapter 22).
[183]
 See Hempel (1965: 123-134).
[184]
 Fodor (1998: Chapter 3).
[185]
 A similar point is urged by Evans (1982).
[186]
 This is a point that Berkeley made long ago in his A Treatise Concerning the Principles of Human Knowledge. 
[187]
 Incidentally, this discussion doesn’t presuppose a Lockean-empiricist conception of conception. (Fodor 1981 has done an admirably good job of showing why such a conception is untenable.) It could well be that it is in virtue of our innate cognitive endowment that we human beings are able to hone in on the property that is had in common by all and only those situations that instantiate the property of redness. It could be that experience has only a “triggering” role in our grasping this concepto. But that is of no importance in this context. What is important is that, however it is that we come to grasp that concepto, doing so involves our seeing what different situations have in common. 


[188] See Langford (1942). This conception of conceptualo analysis pervades the view advocated in Fodor (1998), as I discuss in my article “Another argument against the thesis that there is a language of thought” (Kuczynski 2004).
[189]
 In light of the points made in this section, a case can be made that Fodor’s first argument for atomism is question-begging. Fodor starts with the assumption that there is analytic structure only where there is the possibility of a biconditional of the kind just mentioned. This is tantamount to the assumption that, for any concepto C, there is some set of conceptso C1…Cn such that x falls under C iff x falls under C1…Cn is analytically true and non-trivial. Assuming that those conceptso don’t have infinitely complex decompositions, we sooner or later arrive at a set of conceptso that are not decomposable. And from this it follows that there is some set of simple and unanalyzable conceptso out of which all other conceptso are composed. 
         It is hard to believe that there is a set of conceptso of the kind just described. It is also hard to believe that any given concepto has an infinitely complex conceptual decomposition. Given how implausible both of these views are, it seems reasonable to seek alternatives to the assumptions that led to them. In this case, such alternatives are not hard to find. We reject Fodor’s assumption that conceptualo analyses give the decompositions of conceptso, and we say that such an analysis identifies different ways of conceptualizing a single content. Given that there different, but equally adequate analyses of many conceptso, this is a position we would wish to take anyway. Leaving aside the – in this context – question-begging belief that conceptso are either analytically unstructured or decompose into analytically unstructured conceptso, it becomes unclear what reason there could be for holding onto the view that analyzing a concepto consists in showing how it decomposes into other conceptso. Basically, Fodor’s conception of analysis has such counter-intuitive consequences that one would hold onto it only if one had a pre-existing wish to validate those very consequences. To this extent, Fodor’s first argument for atomism is question-begging.
[190]
 Astonishingly, this position has been taken. It has often been said that what we know cannot exceed what we can say. See Blackburn (1984: 140) for a discussion of this problem.
[191]
 Of course, some musical dictionaries contain a so-called “definition” of that term. But nothing is easier than to find songs that satisfy the definition but that are very obviously not instances rock ‘n’ roll. The same is true in my experience of any supposed definition of any musical any form. 


[192]
 In case a brief recap is needed, here it is. The concepto of rock ‘n’ roll music has analytic structure, and Jones’ apprehension of that concepto consists in his knowing what that structure is. But the analytic structure of that concepto is to be understood not in terms of its relations to other conceptso but in terms of its relations to non-conceptualo information. The reason that the concepto of rock ‘n’ roll is easier to handle than the conceptso into which it supposedly decomposes – e.g. the conceptso sub-dominant, 12:3 rhythm, augmented fifth – is that the latter are of a higher-order than the former. If the concepto of rock ‘n’ roll music is of order n, then these other conceptso are at least of order n+1. 


[193] Churchland (1981) argues for this point very effectively.
[194]
 See, for example, Lewicki et al. (1992). 
[195]
 That said, there seem to be at least some instances of innate (and thus “instinctive”) declarative knowledge. The stock example is that infants know that breasts provide milk. Whether this is a bona fide case of declarative knowledge is a question that lies outside the scope of the present work. 
[196]
 See Lewicki et al. (1992). 


[197] Many philosophers – e.g. Hacker and Baker (1984) -- ridicule the idea that abilities – e.g. the ability to speak English or ride a bicycle – involve sub-personal knowledge of conceptso like NP-deletion. So far as this scorn is not based merely on the view that such views simply must be false, given how at variance they are with common-sense, they are generally based on arguments found in Wittgenstein and, to a lesser extent, in Searle. We will consider those arguments in the next chapter. 
     It should be pointed out that Fodor (1975) does a superb job of diminishing the plausibility of the common-sense-based rejection of sub-personal cognition by showing how the details of theories that posit such cognition are extremely well-supported by experimental evidence. 
[198]
 See Fodor (1975).
[199]
 Fodor (1998: Chapter 2). 


[200] Actually, given the points made in Chapter 9, it isn’t clear whether this much agreement is necessary. What is necessary that, for some x such that x=2, you accept some sentence whose truth-maker (not content) has the form x has phi and that I accept some sentence – not necessarily the same as yours – satisfying the same condition. 
[201]
 I say “more or less like”, and not “identical with”, in acknowledgement of the fact that, for reasons we’ve discussed, the passage of time demands that the indexicals in the sentences expressing one’s concept change so as to reflect changes in one’s spatiotemporal relation to the object in question. So, for example, if (6) gives my concept of Socrates on Monday, then on Tuesday, the sentence expressing that concept will contain the word “yesterday” in the place where, on Monday, the corresponding sentence contained the word “now.”
[202]
  IRA is an extremely popular doctrine. It is advocated by Sellars (1963), Peacocke (1992, 1996), and Brandom (1998), to name but a few of its exponents. 
     Brandom (1998: 94--97) argues that Frege held an inferential conception of propositional content. In defense of this, Brandom (1998: 94) cites the following passage from Frege: 


“In my formalized language [Begriffsschrift]…only that part of judgments which affects the possible inferences is taken into consideration. Whatever is needed for a correct [richtig] inference is fully expressed, what is not needed is…not”


   The idea seems to be that what does not affect possible inferences is truth-conditionally inert and irrelevant from the view point of a symbolic system whose purpose is to capture cognitive content. 
   Brandom cites another passage from Frege (Brandom 1998: 95): 


       “There are two ways in which the content of two judgments may differ; it may, or it may not, be the case that all inferences that can be drawn from the first judgment when combined with certain other ones can always also be drawn from the second when combined with the same other judgments. The two propositions ‘The Greeks defeated the Persians Plataea’ and ‘the Persians were defeated by the Greeks at Plataea’ differ in the former way; even if a slight difference of sense is discernible, the agreement of sense is preponderant. Now I call that part of the content that is the same in both the conceptual content. Only this has significance for our symbolic language [Begriffsschrift].” 


[203] Of course, it isn’t always clear what counts as a viable permutation of the concepts composing a given thought, and this makes it unclear whether our thinking is unlimitedly systematic. Is the thought the property of being loving is ambivalent towards Bob’s ambivalence towards Mary a viable permutation of  Bob is ambivalent towards Mary and Mary loves Ted? If it is, then there seem to be some limitations as to how systematic thought is, given that one can probably grasp the second proposition without grasping the first. But, first of all, this objection may fail to take into account the distinction between performance and competence. Second, and more importantly, given our purposes, it is enough that thought be approximately systematic and that we have an approximate understanding of what involves. Delicate issues like the ones just raised needn’t be resolved.
[204]
 My use of the term “module” is not necessarily meant to correspond precisely to what that term has come to mean in cognitive psychology. (So I am not using that term in the sense in which it is used in, for example, Fodor 1983.)  I am using that term in a more generic sense.
[205]
 See Churchland (1981).
[206]
 Searle (1992: 212-214).
[207]
 Of course, this view is due to Hume. It is now extremely unpopular in philosophical circles. (See Merrick (2001: 122). Merrick points out that Strawson (1959: Chapter 3), Shoemaker (1997: 139), and Lowe (1989, 1996: 25 ff.) are also opponents of the Humean view.) This is probably because it is generally interpreted more narrowly than I am interpreting it. But a rejection of it seems to involve the idea that there is something beneath various property instances. Even if there are such things, they don’t do any work, except in so far as they instantiate the relevant properties. But in that case, as we just said, it is really the property-instances that are doing the work. 
      Also we must distinguish the question “what is it for two thoughts to belong to the same mind?” from the question “what is personal identity, i.e. under what circumstance are two events or states of affairs constitutive of the same person?” The Humean view that selves are mere “bundles” of thoughts and perceptions is vulnerable to non-trivial criticisms. In general, psychological conceptions of personal identity, such as Hume’s, are deeply problematic; and, at least arguably, should be replaced by biological or organismic conceptions. (See Hershenov 2002 and 2005.)
         But none of this has any bearing on whether minds are anything over and above their contents. The biological account of personal identity says that selves are not mere minds; it doesn’t say that minds are mental contents plus biology. Given only that selves are more than minds, and a fortiori are more than collections of mental contents, it would be absurd to say that the same was true of minds. Thus, the view that minds might consist of mysterious selves underlying their various contents seems to me to derive from a failure to distinguish the question “what are minds?” from the question “what are selves?” 


[208] This is exactly the position that Russell (1940: 226-235) took. I am not claiming any originality here. 
[209]
 Of course, it is not the case that, given any two thoughts T and T* had by a single person, the one R-causes the other. First of all, there are simultaneous thoughts, and simultaneous thoughts obviously don’t generate one another; second, there are thoughts T1 and Tn that belong to the same mind such that T1 doesn’t R-cause Tn, even though, for each i (1≤i≤n), Ti R-causes Ti+1; and, finally, there are non-simultaneous thoughts T1 and Tn such that the condition just met is not fulfilled. (What I am saying borrows heavily from Russell (1940: 226-235), and my use of the term “R-connected” is obviously an echo of his term “R-sequence.”) Given any two thoughts T1 and Tn, let us say that they are R-connected iff  for each i (1≤i≤n), Ti R-causes Ti+1. Given this, two thoughts belong to the same person iff there is some thought Tm such that both are R-connected to Tm (it doesn’t matter what direction the connecting goes in). 
      Here is an illustration. I think grass is green at time t. A moment later, I think I want milk. There is no special connection between these two occurrences. But there would be no difficulty finding a thought Tm such that both of these thoughts were R-connected to Tm. Tm might be a memory that I had thought grass is green and then subsequently wanted milk. Here some might  make the following objection to our analysis: 


   “Can’t we conceive of two thoughts had by a single person being totally isolated from each other? What about cases of split-personality? What about the distinction between sub-personal and personal thought? Don’t these phenomena show that two co-personal thoughts can fail to be R-connected.”


     
     No. As we’ve discussed, different modules of a person interact. Of course, by definition,  information doesn’t flow as freely between modules as it does within molecules. But they do exchange information. (In any case, there would be no reason to posit their existence if they didn’t.) The information in my visual module obviously interacts with the information in my language module (I am supposing, for expository reasons, that there is a single visual module and a single language module). If those modules didn’t interact, then I couldn’t read and I couldn’t say anything, at least not anything worth saying (I couldn’t say, upon seeing a fire, “call the fire-department!”). Further, the way in which information is exchanged between those two modules is obviously vastly more direct than the way in which information is exchanged between two different people. The difference between intra- and inter-personal communication is that in the former case the flow of information is mediated by relatively directly connected neural (and cognitive) pathways, whereas in the latter case the transmission of information involves neurally and cognitively “dead” intermediaries (inanimate sounds, ink-marks, and so forth). The difference, in other words, lies in the mode of causation. In the one case, causation is relatively direct. In the other case, it is not. The difference does have anything to do with the fact that, in the one case, there is some one underlying entity that “has” both sets of thoughts, whereas in the other case, the sets of thoughts are had by two such mysterious entities. It is true, of course, that one person is involved in the one case, and that two people are involved in the other. But what this, in its turn, consists in is a different in the causal mechanisms involved, not in anything having to do with the involvement of a mysterious, unpropertied cognitive substrate. 
     What about cases of split personality? So far as such cases really do involve a complete separation of two systems of thought from one another – so far as there really is no cognitive communication at all between Jekyll and Hyde – we are dealing with two people who happen to share a body. (Of course, in this context, the term “communication” is meant to refer to communication of the intra-personal type described a moment ago. Obviously if those two systems communicate in the way in which two different people communicate – if, for example, one leaves notes for the other – then they don’t constitute a single person.) And so far as there is communication (of the relevant type) between the two systems, it seems that the boundaries between their identities are fuzzy. It is an open empirical question whether two distinct people can inhabit a single body. But it seems that this question deserves an affirmative answer precisely to the extent that the same is true of the question “can there be two cognitive systems within a single body that are as isolated with respect to each other as are the cognitive systems of two different people (e.g. Kennedy and Johnson)?” So no matter what it turns out to involve, the phenomenon of split-personality confirms our analysis. 
       Here is another, rather more substantial objection:


      “You take it for granted that any two thoughts had by a single person are R-connected to some one thought. But that seems like an empirical hypothesis that might turn out to be false.” 




        Let us start with a comparison. Simultaneous events cannot affect each other. But non-simultaneous events can stand in this relation – indeed, they must. More exactly, events E and E* are non-simultaneous if there is a (nomically possible) causal sequence beginning with one of them and ending with the other, and simultaneous otherwise. Of course, our awareness of this principle was triggered by empirical developments in physics (in particular, by the astonishing discovery that the speed of light is framework-invariant). But is it itself an empirical proposition? Can we imagine two non-simultaneous, but spatiotemporally related events E and E* that are necessarily completely causally isolated from each other? It seems not. It seems that being in the same “causal space” is constitutive of spatiotemporal relatedness. That may or may not mean that non-simultaneous events must be connected by some actual causal sequence. (In my view, it does mean that. Causal connections consist in disruptions of fields of energy. They do not, contrary to what Hume seemed to believe, consist in sequences of discrete events. A field’s intensity decreases continuously, and never reaches zero. It follows that any two non-simultaneous events are in fact causally connected. Reichenbach (1958) gave what I believe to be a completely cogent argument to the effect that spatio-temporal order is to be defined in terms of causality. 
         We must also remember Schlick’s (1919) point that, given a field-conception of causality, what we would ordinarily described as the location of an event is better described as the location of the center of that event. Here, of course, the word “center” has both a geographic and a temporal meaning. Given what we said a moment ago, there is no part of the universe that isn’t involved in a disruption of a field. So a field-conception demands that every event be seen as being spread out through all of space-time. It follows vacuously that any two events occupy the same region of space-time. But the center of one event, i.e. the region of space-time where the disruption is greatest, may not coincide with the center of some other event.)
      Similarly, if two thoughts are to belong to the same person, they must belong to the same “R-causal space.” Maybe the objector is right; maybe two non-simultaneous co-personal thoughts don’t have to be connected by an actual R-sequence. But given what we’ve said, it seems not unreasonable to say that they must be related to each other in a manner that is comparable to (and, in fact, is a special case of) the manner in which two non-simultaneous events must be related. 
      There is another point to make. (This one is much more conjectural than the previous one.) The objector presupposes that thoughts interact with one another in much the same way that billiard balls (used to be erroneously thought to) interact. He presupposes a “mechanical”, rather than a “field”, model of the mind. If connectionist theories are correct, the field model is the right one,  meaning that any mental event has “ripples” that are felt in the furthest reaches of the subject’s mind. (See Cain (2002: 102-111 for a brief but effective discussion of the merits of connectionism, and also of some of the problems that it poses for CTM.) This, of course, would corroborate my original view that any two non-simultaneous mental events are connected by an actual R-sequence and are thus not merely in the same R-causal space. 




[210] Searle (1992: 187-190, 227-254).
[211]
 In my view, aptitudes – e.g. the ability to play the piano – are expressions of sub-personal conception. But this is a debatable point, and I won’t insist on it here. I provide some argument for it at the end of Chapter 16. Chomsky’s work can be seen as an attempt to show that our knowledge of language expresses sub-personal knowledge of various rules, and thus expresses a sub-personal grasp of various concepts. (I am now in the process of trying to show that this attempt on Chomsky’s part does not have the shortcoming that are sometimes ascribed to it.)  


[212]
 In the movie Rain Man, Dustin Hoffman plays an idiot savant (named “Raymond”) who can do extraordinarily difficult math problems, but is totally incapable of the most rudimentary applications of that knowledge.  If asked “what is 87,067 divided by 546?”, he can instantly come up with the answer. But he draws a blank if asked “if Bob has one house, and Larry has two houses, how many houses do they have altogether?” To my limited knowledge, that movie is clinically accurate. 
       How do cases such as this one bear on Evans’ point that concepts are not frozen – that a genuine understanding of (say) addition or anything else is not going to be expressed in just one way? I would suggest that what is going on is as follows. A grasp of the concepts of addition, multiplication, and so on, is present at one stratum of Raymond’s mind. Further, that knowledge is not frozen with respect to the other contents of that stratum of cognition. But even though it is unfrozen vis-à-vis the other concepts in the stratum just mentioned, that knowledge is frozen vis-à-vis the contents of other strata of cognition. In particular, that knowledge can interact only to a limited degree with the contents of the personal stratum of cognition. 
       The mind is divided into different modules. (In any case, this is what Fodor (1983) asserts, and I find his arguments compelling.) Those modules communicate. But the amount of communication between modules is miniscule compared to the amount of communication within a module. So a piece of knowledge may be frozen vis-à-vis the bodies of  knowledge that don’t belong to the same module as that knowledge. But no piece of knowledge is frozen vis-à-vis the body of knowledge that does belong to the same module as that knowledge. In any case, this is not an entirely unreasonable conjecture. And if it is correct, it is consistent with Evans’ contention that it is of the very nature of knowledge that it not be frozen.    
[213]
 This point is clearly articulated and powerfully argued in Hacker (1999:  52-55). Hacker plausibly attributes it to Wittgenstein. 
[214]
 This is the title of one of the chapters of Searle (1992).
[215]
 A similar argument is found in Chomsky (1998: 166-224). 
[216]
 Baker and Hacker usually work together. Their books are usually co-authored.
[217]
 My reconstructions of Wittgenstein’s arguments owe much to Kripke’s (1982) reconstructions of them. The accuracy of Kripke’s reconstructions of both arguments, especially the rule-following argument, was strongly contested by Hacker and Baker (1984). According the latter, Wittgenstein is saying the exact opposite of what Kripke imputes to him. According to Kripke’s account, Wittgenstein is advocating a kind of nihilist-behavioristic account of meaning-grasping. According to Baker and Hacker, Wittgenstein takes it for granted that such an account is false, and his analysis is meant to be a reductio ad absurdum, i.e. Wittgenstein is trying to show that certain views must be rejected because they lead to skepticism, behaviorism and other forms of reductionism with regard to the grasping of rules and, more generally, of meanings. Many philosophers (e.g. McGinn 2002: 146-148) take the Baker-Hacker critique of Kripke’s reconstruction of Wittgenstein to be correct. 
     In light of this, what right do I have to accept a Kripkean  understanding of Wittgenstein’s arguments? First of all, Kripke’s arguments correspond very well to what people have taken Wittgenstein to mean. It may not be clear what Wittgenstein intended  to say. But Kripke has succeeded in articulating the doctrines that (whatever his intentions were) Wittgenstein bequeathed to philosophy. 
     I am not a Wittgenstein scholar. But (so far as my untutored intuitions are able to judge) the Kripkean account certainly seems to fit Wittgenstein’s prose. Baker and Hacker may be right to say that, so far as his statements correspond to Kripke’s reconstruction, Wittgenstein was being ironic or otherwise indirect. But there is nothing in Wittgenstein’s prose that makes it obvious (to neophytes like myself) that Wittgenstein is saying anything other 666 than what he means. Also, in other writings of Wittgenstein (e.g. Wittgenstein 1973, 1983), one finds what seem to be non-ironic affirmations of the doctrines that Kripke imputes to him. Also, 666 it is not obvious (to me) that Kripke’s account is unfaithful 666 to what philosophy has taken from Wittgenstein’s writings. 
     There is another relevant fact. The doctrines imputed to Wittgenstein by Kripke are extremely clear (though I will argue that they are false), and thus form a good platform for philosophical discussion. But the doctrines ascribed to Wittgenstein by Hacker and Baker are quite nebulous. Before they could be assessed for truth or falsehood, those doctrines would have to be precisified. This, by itself, would be a time-consuming task, and its results would almost certainly be disputed. 
      For these reasons, I am going to take it for granted that Kripke’s (1982) reconstruction is at least approximately correct. 
[218]
 The Private Language argument is given in Wittgenstein (1958: §§ 234-334).
[219]
 At the same time, those cognitive scientists almost never say what, exactly, the error in question is supposed to be. Other philosophers, e.g. A.J. Ayer (1968), have (I believe) identified at least some of the errors in that argument. But those same philosophers are typically unreceptive to the idea that there is sub-personal, or even personal but sub-conscious, ideation.


[220] Of course, one can use the term “language” to refer, not to a set of semantic rules, but to certain kind of  sequence of such sets. By that definition, our English is identical with Chaucer’s English. But in this context it is obviously preferable not to take the word “language” in this way. Also, if that word is defined in the way just proposed, then what are obviously different languages – e.g. Latin and Spanish – end up being falsely identified with each other.  
[221]Ayer (1968) provides a similar criticism of the Private Language argument.


[222] See my article “Can one grasp propositions without knowing a language?” (Kuczynski 2005b) for an argument similar to that just given. 
[223]
 For example, see Dennett (1978: 39-52, 90-108). 
[224]
 See Fodor (1975). 


[225] See Brandom (1998).
[226]
 See Kripke (1982).
[227]
  The Rule-following argument is given in Wittgenstein (1958: §§ 138-238, 1983: §§ 5-111). Before we present Wittgenstein’s argument (or, in any case, my reconstruction of it), a preliminary point is in order. There are different kinds of rules. The function F(x)=x2 can be described as a “rule”, and the same is true of the law requiring one to stop one’s vehicle at certain kinds of signs (red, hexagonal signs on street-corners, with the word STOP on them). The second describes an obligation, and thus has a normative component. The first has no such component and merely describes an abstract pairing of numbers. These two “rules” are thus in very different categories. In fact, given that it applies to such different things, the word “rule” is arguably ambiguous. 
          In his rule-following argument, Wittgenstein appears not to clearly distinguish  rules like F(x)=x2 from rules like you must stop at stop-signs.  In fact, it seems as though part of what he is arguing is that there is no distinction – that the first class of rules is a sub-set of the second. Wittgenstein sometimes seems to be saying that rules of the first kind are ultimately social rules, and are thus in the same category as rules of the second kind. In any case, in keeping with Wittgenstein’s own usage, we will use the word “rule” indiscriminately in our reconstruction of Wittgenstein’s argument,  and will not worry about any pluralities of meaning that might characterize it.
[228]
 This argument is found in Searle (1992: Chapter 7). Freud (1915: 116-121) considers that very argument, and provides counter-arguments that are at least prima facie compelling. Searle acknowledges those arguments, but dismisses them summarily.
[229]
 Incidentally, Wittgenstein (1980, 1980b) said that Freud wasn’t producing a substantive theory, and that he was really only suggesting that we play a new “language game” – that the rules to which expressions such as “mental state” and “unconscious” are subject be changed. 
      I believe that Wittgenstein’s point is quite absurd. For reasons that I am now in the process of explicating, the question whether Freud’s theories are right is a strictly empirical one, and is not a question of preferring one mode of speech to another. 
[230]
 See Searle (1992). Searle adopts a dispositionalist view of many cognitive abilities. Searle also rejects functionalism. But dispositionalism is a form of functionalism. So, in this respect, Searle’s views are internally inconsistent.
[231]
 Pap makes a similar point. See Pap (1962: Chapter 20), especially pages 393-400.
[232]
 Beliefs, hopes, and propositional attitudes generally are not constituents of consciousness; but they are obviously mental entities. As we’ve seen, once it is granted that bona fide mental entities cannot be mere dispositions, it immediately follows that there are mental entities that are not constituents of consciousness, and it thus follows that what is comprised by consciousness is a proper part of what is comprised by the mental. But, for some reason, a dispositionalist conception of mental states has always been extremely popular, even though few wish to deny that propositional attitudes are among the denizens of the psyche. Why has the dispositionalist view always been so popular? 
        One reason, I suspect, is a failure to realize that what we think of as situations that involve no change are in fact situations that involve constant, as opposed to variable, change. Consider an object (some rock, let us suppose) that would not ordinarily be described as changing. Every moment of its existence involves innumerable displacements of mass-energy. This is not to say that there isn’t a profound difference between an object that would be described as undergoing change, e.g. a building that is being torn down, and one that is not. Obviously there is such a difference. But the difference is not that the building does, whereas the rock does not, instantiate various changes. The difference is that, in the case of the rock, the changes are structure-internal, whereas in the case of the building they are structure-external. Although the rock is characterized by various changes, those changes do not themselves change. The changes that occur are regular. This is not the case with the building. Here we are dealing, not merely with changes, but with changes in the manner in which changes occur. Supposing that the building is destroyed at time t, the patterns of energy-exchange that constituted the building before t have either been altered or obliterated.  
       A physical object is no more changeless than a nation. A politically and economically stable nation is teeming with economic and political activity. Such a nation is not one where there is no political or economic activity or change: it is one where such change happens in a constant manner. There is constant change; but those changes are internal to structures that do not themselves change, and there is thus no change in the manner of change. But if there is a coup d’êtat, and a consequent change of government, there is a change in the manner in which those changes occur. As we’ve seen, an analogous point holds of any large or medium-sized object. 
       We must distinguish conditions from events. An event is a change in a manner of change: a hyper-change. A condition is a situation of constant of change. The difference between events and conditions is not to be understood in strictly chronological terms. An event can take years; a condition can last for a nanosecond. World War II took six years. But a poorly built building that collapsed a nanosecond after being erected would, for a short period, constitute a condition. In a moment we will see the relevance of this point to our inquiry.
        To close this line of thought, I am going to make some highly conjectural points. It seems to me that psychological entities rise above the threshold of consciousness only if they are events. (But, of course, there are innumerable psychological events that remain well below that threshold. We are dealing, at most, with necessary, not sufficient, conditions for becoming conscious.) Consciousness seems to track disruptions. One ceases to be consciously aware of a noise that doesn’t change. (This is, of course, only approximately true. For example, it doesn’t hold of extremely loud noises.) One becomes aware of a background hum when there is some kind of change – when the hum stops, or changes pitch or timbre, or becomes louder. But notice that this change is really a hyper-change. The hum itself was a change: it represented a continuous jet of auditory stimulation. But this change did not itself change: the jet didn’t become more or less intense. But when this change itself changed – when it ceased to exist or doubled in loudness – then the subject suddenly became aware of it. 
       One could explain this by saying that there is now a perception where previously there was no perception prior to the change (that is, to the hyper-change). But that view strikes me as rather arbitrary. It posits an ex nihilo change, thus creating a causal anomaly (where there is no reason, apart from what we have seen to be a dubious antagonism towards the unconscious, to believe that anything anomalous is occurring). It also conflicts with a dim intuition that, all along, the perception in question lay just outside the periphery of consciousness.
       I thus follow Leibniz in saying that the perception was indeed present all along. Instead of merely having the perception, the subject pays attention to it; and it is because it is now the object of scrutiny that the perception has become a constituent of consciousness. The change consists in the subject’s focusing on some that he had all along, but previously paid no attention to. Freud (1915: 40) put it by saying that the perception has become “hyper-cathected”, this being why it is now conscious. Freud’s view is that the contents of consciousness are categorically hyper-cathected. It seems that recent so-called “higher-order thought” (HOT) theories of consciousness represent a kind of echo, or recrudescence, of Freud’s view. See, for example Rosenthal (1986).
        If this line of thought is correct, then strictly speaking what is conscious is not the perception, but one’s awareness thereof. (This was  Freud’s (1915) position.) This shows to what a large extent our theories of consciousness may involve a failure to distinguish the constituents of consciousness from the objects of consciousness. What we assume to be constituents of consciousness turn out to be objects of consciousness. When the perception “becomes conscious”, what is really happening is that there comes into existence conscious awareness of it. The perception per se doesn’t necessarily change. What is a veritable constituent of consciousness is not the perception itself, but is rather one’s awareness of it. (Again, this was Freud’s (1915) view.) If that is right, then we see once again how antipathy towards the notion of unconscious mentation expresses a failure to distinguish between the notion of an object of consciousness and an object’s being a constituent of consciousness.
         In any case, where there is psychological changelessness (or, more accurately, where there is constancy of psychological change) there is a tendency to become unconscious; and where there is psychological change (or, more accurately, change in the manner of change), there is a tendency to become conscious. These facts suggest that consciousness is associated, not with psychological existence in general, but rather with changes in psychological conditions – or, indeed, with changes in manner in which psychological conditions change. 
      Admittedly, this argument must be qualified. While there is clearly some tendency for unconscious changes (or hyper-changes) to enter consciousness, this tendency is a weak one. There is no tendency for sub-personal hyper-changes to become conscious. And the internal disequilibria that, according to Freud’s theories, constitute the bulk of our psychological lives remain below the threshold of consciousness. 
        But we must not be too quick to take these points to warrant a rejection of our conjecture that consciousness is to be understood in terms of psychological hyper-changes and unconsciousness in terms of an absence of such changes. If Freud’s theory, or anything even remotely like it, is correct, it is only because of special resistances that those disequilibria fail to come to the attention of consciousness. Also, their symptomatic derivatives do become conscious. (Otherwise we would know nothing of them, as Freud himself emphasized.) We might say that they do become conscious, albeit in pathologically distorted forms. It thus seems that repressed psychological events form no counterexamples to our principle that ceteris paribus consciousness consists of hyper-changes (or of our consciousness of such changes) – just as (to use a point of Mill’s) helium-filled balloons are no counterexamples to the principle that gravity tends to draw objects nearer to one another. 
         Of course, there is no tendency for sub-personal changes (or hyper-changes) to gain entry into consciousness. But I don’t think that this demands a rejection of our principle. So far as one has a tendency to think otherwise, one is guilty of a confusion similar to that discussed a moment ago. 
      A metaphysical digression is needed to clarify my meaning. Some events happen within frameworks without themselves being constitutive of frameworks; and other events are themselves constitutive of frameworks. The activities of police-officers, judges, and administrators create, and thus constitute, social frameworks within which people operate. When I stop at a stop-sign, I am operating within that framework; but my behavior is not constitutive of it. My behavior is a causal effect of that framework and therefore cannot be a part of it. 
        This line of thought generalizes. A building is made of bricks; those bricks are composed of mass-energy displacements. Those displacements are thus constitutive of a certain structure or framework. A mouse that is running through the heating vent of that building is operating within that framework, but its activity is not constitutive of it. The impact of a wrecking-ball with the side of the building is not only not constitutive of the structure of the building, but also fails to occur within that structure: in fact, it damages that structure. The activity of somebody playing basketball ten miles from the building is not constitutive of the structure of the building; nor does it happen within that structure; nor does it alter that structure. 
         In light of these points, let us resume our discussion of the sub-personal. The sub-personal events posited by Chomsky and Marr constitute our cognitive framework. The conditions and events associated with the personal level of mentation presuppose sub-personal activity. Sense-perceptions occur at the personal level of mentation. But sense-perceptions are the outcome of innumerable sub-personal processes. These processes never gain entry into consciousness, or into any other facet of the personal level of mental activity, because they provide the framework within which conscious and, more generally, personal activity occurs. The mass-energy displacements that compose a building do not become events that happen within the building – unless some kind of structural breakdown occurs. 
     Leaving aside systemic breakdowns, events that are constitutive of a structure do not occur within that structure. Because sub-personal cognition forms the structure that houses personal psychological activity – the activity consisting of perceiving, wishing, intending, believing, and so forth – such cognition cannot itself enter the sphere of personal activity. The fact that the sub-personal cannot enter the sphere of personal ideation is thus not a significant challenge to our principle that hyper-changes tend to become conscious, whereas constant changes do not. That fact is simply an expression of the general metaphysical principle that the events that that compose a structure do not happen within that structure.  
       I would like to develop the points made a moment ago concerning the difference between structure-internal and structure-external changes. Spatiotemporal reality doesn’t consist of scattered events. Events often happen within structures. If they did not, then reality would be far less amenable to explanation and prediction than it actually is. Because I know that Jim works for a corporation, and that he has certain duties, I can predict what he will do with a fairly high-degree of accuracy. If Jim operated outside of any structure – if he didn’t have a job in a corporation and weren’t in any other comparable situation – then it would become very difficult to predict his behavior: I would need special knowledge about his internal processes. But in so far as Jim as merely a part of a system, such high-resolution, Jim-specific knowledge isn’t necessary to know, in broad terms, what he will do on a given day. (This point is powerfully defended in Jackson and Pettit 2004d.) 
     Another example: Because I know that brick R is part of a stable building, I have a pretty good idea where it is going to be tomorrow. But if that brick were relying on a side-walk, I would have a much harder time making predictions as to its whereabouts tomorrow. To make such a prediction, I would need quite specific knowledge about the brick’s environment – about the people who live there, their attitudes towards bricks that are lying on the side-walk, the meteorological and seismic conditions that obtain in that area, and so on. 
     Where there is structure, there is constancy in change, and accurate predictions can be made on the basis of highly generic knowledge. Where there is no structure, predictions can be made only on the basis of highly specific knowledge (Jackson and Pettit 2004d).
       We tend to think of those structures as not involving changes of any kind. But that is false: those structures consist 666 of changes. The building consists of mass-energy displacements. Structures consist of constant changes – changes that do not change. Events consist in changes in the manner of change – they consist of hyper-changes. Given a structure, a given hyper-change may happen within that structure, while not being constitutive of it, or it may not happen within the structure. If an event doesn’t happen within a structure, and it isn’t constitutive of that structure, it may or may not alter that structure. 
        We have a tendency to think of frameworks as inert – as involving no change. But this is false, as we’ve seen. Frameworks consist of constant change – in both senses of the word “constant.” Those changes are incessant (so they are “constant” in that sense). But those changes do not themselves change (so they are “constant” in that sense). What we think of as events are occurrences that are not constitutive of structures. Where there are frameworks, there is predictability and a consequent absence of disruptions. For obvious reasons, we focus on disruptions, not on constancies. For this reason, we come to see structures, like buildings, as involving no change. We tend to think of them in strictly dispositional terms. 
      Given that conception of what a structure is, it is a short-step to saying that structures just are the regularities that are associated with them. Everything that is not an event becomes a mere disposition to create events. So everything that is not event becomes nothing more than a tendency for events to occur with a certain regularity. This means, ultimately, that only events exist.  
       But this view involves a failure to make a number of distinctions: the distinction between changes (conditions) and hyper-changes; the distinction between an occurrence that is constitutive of a structure and an occurrence that takes place within a structure; and, finally, the distinction between an event that happens within structures, while not constituting that structure, and an event that does not happen within structures. 
         Given these distinctions, there is little room in reality for “mere dispositions.” Once the notion of a mere disposition is gone, so is the idea that beliefs, character traits, and “non-occurrent” mental entities generally could be mere dispositions. The idea that a belief is nothing other than a disposition for certain inputs to bring about certain outputs turns out to be a special case of the fallacious view that, where there are no events, there is nothing at all (except possibly for some kind of indefinable “potentiality”). The latter view, in its turn, is an expression of the failure to realize that what we refer to as “events” are hyper-changes, as opposed to changes simpliciter, and that what we refer to as “stable conditions” are constant changes and are therefore causally pregnant. 
      Hume argued that a causal sequence is a nothing other than a juxtaposition of events that instantiates some kind of regularity. This conception of causality involves the view that there isn’t really anything where there are no events. It involves the view that there are changes only where there events and that, consequently, where there are no events, there is nothing that can do anything. Anything that is not event becomes, at most, a “disposition” for events to occur. What is not an event becomes nothing. 
     We have seen at least one reason why such a view must be questioned. There is constant change where there are no events. There is thus causality where there are no events, given that change involves causality. Because it applies only to events -- i.e. only to changes in the manner of change, and not to change in general – Hume’s analysis of causality is severely limited in scope.
        In fact, given that hyper-changes are presumably to be understood in terms of changes, and given that Hume’s analysis is silent as regards the nature of the causal forces governing the latter, it becomes questionable whether Hume’s analysis has anything viable to say about causation of any kind. My guess is that, once we register the various distinctions that we’ve been discussing, it becomes impossible even to articulate Hume’s analysis of causality. But that is a matter for another work. 


[233] Fodor and Pylyshin (1988) argue that CTM is preferable to a doctrine known as “connectionism” on the grounds that connectionism is harder to reconcile than CTM with the systematic character of thought. Whether connectionism is a correct or otherwise meritorious doctrine falls outside the scope of the present work. But given what we’ve said, it is clear that CTM doesn’t explain the systematic character of thought and that it therefore doesn’t explain it any better than connectionism. 
[234]
 Fodor and Pylyshin (1988) make this point. 
[235]
 Robert Brandom (1998) makes and ably defends this point. 
[236]
 Writes Fodor (1975: 39-40): “[S]o far as anyone can tell, simplicity metrics must be sensitive to the form of the hypotheses that they apply to, i.e. to their syntax and vocabulary. That is, so far as anyone can tell, we get an a priori ordering of hypotheses [a simplicity metric] only if we take account of the way in which the hypotheses are expressed. We need such an ordering if we are to provide a coherent account of the order in which values of P are selected in the concepto-learning [and induction-forming] situation. But this means that a theory of concepto-learning [and induction-formation] will have to be sensitive to the way that the organism represents its hypotheses. But the notion of the organism representing its hypotheses in one way or another (e.g. in one or another vocabulary or syntax) just is the notion of the organism possessing a representational system.”


[237] In Kuczynski (2007b).
[238]
   In the argument being considered, Fodor seems to be alluding to Carnap’s (1950) efforts to formalize induction. It is worth noting that Carnap’s system, along with all other efforts to formalize induction, have radically counter-intuitive results. (See (Pap 1962: Chapters 11-13) for a discussion of this.) 666 For this reason, it is no longer widely held that induction can be formalized. 
      It should be pointed out that, given only that induction cannot be formalized, it doesn’t follow that there is no analytic, non-trivial characterization of inductive rationality. Let L be any language that is capable of expressing all inductively reasonable inferences. To say any that induction cannot be formalized is to deny that, for any sentence S of L that expresses an inductively reasonable inference, it is a theorem of L’s semantic rules that S has that property. 
       But we know that the category of formal truth is a small sub-category of the category of analytic (i.e. strictly conceptual, non-empirical) truth. This is to be expected, given that the concept of formal truth must be understood in terms of concepts (such as theorem and consequence) that are themselves to be understood in terms of the concept of analytic truth. So given only that induction cannot be formalized, it doesn’t follow that induction defies rational analysis any more than mathematics.  
[239] See Dennett (1978: Chapter 6), Lycan (1984: 237), Kuczynski (2002, 2005), Searle (1984, 1992).


[240] Putnam (1996) later changed his position on this. As we’ve seen, Burge (1979, 1982) and others have argued that extensions of Putnam’s arguments for semantic externalism could establish the truth of content externalism. Putnam came to regard these arguments as cogent, and thus came to be a content-externalist: he came to hold that Bob and Twin-Bob are having different thoughts. As we’ve seen, those arguments are not cogent; and, given a few basic distinctions, content-externalism loses any plausibility that it might otherwise have had. 
[241]
 Some linguists – so-called “discourse-theorists” – think that languages are just patterns of behavior and thought. For the reasons just outlined, I believe this to be false. But given only that discourse-theory is (so I believe) false, and that there are such things as semantic rules, it doesn’t follow that semantic rules are platonic entities.  
      
[242] A similar argument is found in Strawson (1969).
[243]
 See Salmon (2005) for a similar argument. 


[244]
 Blackburn (1984: 122-134). Blackburn himself (1984: 113) uses the term “fossilized.” 




[245] See, for example, Kaplan (1989: 494), R. Moore (1995: 100-115). This view is found in Russell (1904: Chapter V). 
[246] 
 There is an obvious challenge to the idea that propositions must have structures similar to the sentences that express them. “Caesar killed Brutus” and “Brutus was killed by Caesar” presumably express the same proposition; but those sentences differ structurally. Also, the syntax of the Albanian translation of “Caesar killed Brutus” is (for all I know) syntactically different from its English counterpart. 
           This challenge is not hard to deal with. “Caesar killed Brutus” and “Brutus was killed by Caesar” have different derivation-trees. This shows that the way in which Caesar is assigned to the constituency of what is meant by the one sentence differs from the way in which it is  the constituency of what is meant by the other sentence. But it doesn’t show that those constituencies themselves differ, either in respect of their membership or their internal organization. 
       It may be true that the syntax of Albanian translation of “Caesar killed Brutus” is different from its English counterpart. But the discoveries of depth-grammarians show that these differences are more apparent than actual – that they hold only if the term “syntax” is taken in a folk-grammatical and pre-scientific sense. In Russian, the present tense of the verb “to be” is seldom used. One doesn’t say “I am thirsty”, but merely “I thirsty.” On this basis, one might conclude that the proposition meant by “I am thirsty” cannot resemble the English sentence that expresses it, given that the corresponding Russian sentence has a different structure (though, admittedly, not a very different structure). Chomskyan linguistics has made a strong case that Russian sentence does contain an occurrence of the verb “to be”, i.e. the equivalent of “am”, but that it contains it “aphonically” (i.e. it isn’t realized at the level of acoustics of orthographics). If this is right, then there is no reason to believe that “I am thirsty” is syntactically different from its Russian translation, given only that the latter does not overtly contain an expression corresponding to “am.” 
      But even if the argument just given turns out to be fallacious, it is undeniable that sentences have a certain non-trivial similarity with the propositions they express. Leaving aside the grammatical differences between languages, and between different sentences within a language that express the same proposition, it is clear that the meanings of sentences decompose into a finite (and usually very small) number of discrete parts. The meaning of “Smith punched Jones” has a discrete part corresponding to Smith, a discrete part corresponding to “punch” (let us momentarily set aside the niceties relating to the tense-marker), and a discrete part relating to “Jones.” This property will be shared by any sentence having the same meaning – by any translation of that sentence and by any English sentence expressing the same proposition (“Jones was punched by Smith”). “Smith punched Jones” has a digital structure: it decomposes into discrete, minimal units of significance; and its meaning therefore has a structure that composes into discrete, mutually independent parts. What is true of that sentence is true of all sentences of all languages. 
     It is easy to find pairs of sentences that are synonymous but appear to differ syntactically. But given any one of these pairs, the line of thought presented a moment ago is easily extended to show that it is no threat to the notion that propositions have a structure similar to the sentences that express them. 
      Here is an illustration (again involving Russian). Russian is a highly inflected language. Even though “Ivan” and “Ivana” are the Russian translations of “John” and “Ivana”, one doesn’t  translate “John loves Jane” by saying “Ivan lyubit Ivana” (“lyubit” being the translation of “loves”). One must say “Ivan lyubit Ivanu” (actually, in Russian, it doesn’t matter, or matters much less than in English, what order the words have). In Russian, the direct object must be inflected. 
      Does this mean the proposition meant by “John loves Jane” does not have a structure comparable to that of the corresponding sentence? No. As we parenthetically noted a moment ago, Russian has a relatively free word-order, whereas English has an extremely rigid word-order (a fact that native-speakers of Russian often find to be irritating when translating their thoughts into English). This is plausibly taken to mean that, in English, word-order does the job that inflections do in Russian. So, in effect, English does contain inflections (or the equivalent); but whereas inflections are realized by discrete, phonetically realized entities in Russian, they are realized by word-order in English.
[247]
 There are apparent exceptions to my claim that indexicals work through broad rubrics.  For example, one can say “that is lovely” or “that is hot” and be understood. One doesn’t have to say “that rose is lovely” or “that pan is hot.” But that only means that one can acoustically omit the semantically present sortal term. 


[248] I used to find this argument of McDowell’s compelling. For this reason, in Kuczynski (2003), I advocated the view that all content was propositional in nature. 
[249]
 The argument given in this paragraph and the next is clearly stated in an unpublished dissertation by Michael Rescorla (Rescorla, 2003). 
      In 1995, I provided the same argument in a paper on Wittgenstein’s “picture-theory” of meaning. As I later discovered, that argument is found in much of the literature on the Tractatus.
[250]
 Again, this point is made very clearly in Rescorla (2003), and also in much of the literature on the Tractatus. In his work in dreams, Freud often makes a similar point. See, for example, Freud (1965: 24).
[251]
 Here we must head off an objection to the line of thought just presented: 


      Your analysis confuses the concept of an instance with that of a sub-category. R2 is not an instance of the concept of redness. Rather, it is a sub-category of that property. Let r2 be the specific instance of redness associated with the rose. r2 is not, whereas R2 is, something of which there can be instances. r2 is an instance both of R2 and of redness. Redness is a property not of R2, but of r2. R2 is a sub-category of the category (or property) of redness, not an instance of it. And contrary to what you say, and to what is patently obvious, r2 does instantiate redness no less than instantiates R2. So redness is not a property of properties. It is just a property. 
      
       A property is something of which there could multiple instances. It is a “way that things are”, to use David Armstrong’s (1989) expression. In any case, it is a way that things could be. (There are some subtle – and, in this context, irrelevant -- qualifications to this platitude, relating to the supposed existence of properties that cannot possibly be had and that, consequently, cannot correspond to ways that things might be. An example would be the property picked out by the predicate “round square.” That predicate, I propose, is best thought of as expressing a concept that fails to pick out a property. So rather than saying that “round square” picks out a property that nothing could have, we should say that, although its grammatical function is to pick out a property, it fails to do so – just as we say that “the rational square root of two” fails to pick anything out, even though its grammatical function is to do so.) So far as any spatiotemporal thing X is red, it is because X has R1 or R2 or…There is thus a clear-cut sense in which R1 is a way that spatiotemporal things can be. 
      But there is only a circuitous sense in which redness is a way that such things can be. At the same time, there is a non-circuitous sense in which “red” describes a way that a property could be. There is, no doubt, some property R that each of R1…Rn has and that specific shades of blue or specific temperatures do not have. (When I say “specific shades of blue or specific temperatures”, I am referring to properties and not to instances of properties; I am referring to things of which there could be instances, and not to the instances themselves.) Of course, R is nothing other than the property of redness. (In any case, the property of redness is one possibility as to what R is.) Supposing that B3 is some specific shade of blue there is some property that B3 does not have that any one of R1…Rn does have. There is, to use Armstrong’s language, a way that any one of R1…Rn is that B3 is not.
     To sum up, it seems a datum that “red” indicates something that different specific colors have in common. Given this, it follows immediately that “red” is a property of colors, and is thus a property of properties. The latter properties have spatiotemporal instances. But we mustn’t say that redness itself has such instances.  If we say that a given rose instantiates both R2 and some property that R2 itself has, then we end up embracing the dubious view that a property of an abstract object can also be a property of a spatiotemporal object. But this would blur the line between the particular and the universal – between the spatiotemporal and the non-spatiotemporal. If anything is certain in metaphysics, it is that this line must be kept sharp. 
      There are indeed expressions that denote sub-categories, as opposed to instances, of the thing denoted by “red.” Examples are “burgundy”, “maroon”, and so on. But two things that are burgundy can differ in respect of color. By contrast, two things that are R2 cannot so differ. So predicates like “burgundy” and “maroon” are not comparable to predicates like “R1”  and  “R2.”
[252] Russell held that definite descriptions in general are in the same category as “the average man.” For reasons given earlier, I believe that he is wrong about this. But this has no bearing on his view that the significance of non-denotative noun-phrases is to be explained, not by ontologizing, but by identifying the relevant contextual definitions.
[253]
 There is a caveat here. When Russell said that “the king of France” must be defined contextually, he meant that any given sentence of the form ┌the king of France has phi┐ is synonymous, or at least analytically equivalent, with some sentence not containing any apparent reference to a French monarch. Leaving aside the empirical knowledge in which one’s knowledge of English semantic rules is embodied, no empirical knowledge is needed to know how “the king of France” parses out of “the king of France is bald.” (Russell didn’t arrive at this Theory of Descriptions by doing experimental psychology.) 
         But when I say that “the rod’s having a temperature of 78°” is to be understood contextually, I don’t mean that it is analytic, or (what is different) a mere matter semantics, how it is to parse out. I am saying only that it ultimately meets the same fate as “the average man” and “the limit of F(x) as x approaches 2.” Any occurrence of “the rod’s having a temperature of 78°” conceals a great deal of relational structure. An obvious corollary is that, so far as a sentence doesn’t conceal that structure, it doesn’t contain an occurrence of that, or any comparable, expression. If we are right, then what we said about that particular definite description is true in general of expressions referring (so to speak) to property-instances.
[254]
 See Merrick (2001) for a different argument for a viewpoint not unlike that about to be presented. 
[255]
 See Russell (1927: 40) for a similar point. 
[256]
   One point must be made clear. Let us continue to suppose that you have maximally acute vision and a maximally good memory. Under these circumstances, you would, of course, be right to say “I saw Smith yesterday”; and, as we’ve just emphasized, that statement would embody a meta-perceptual judgment. But it doesn’t follow that your statement would involve any element of conjecture. No conjecture would be involved here. By hypothesis, you have seen (and, we may suppose, remembered) everything that there is to see. (Of course, some might say that any use of perception or memory involves conjecture. In that case, my point is that, leaving aside the element of conjecture inevitably involved in any use of perception or memory, your statement that you saw Smith does not express a conjecture, even though it expresses a judgment.) 
        When a physicist conjectures that a certain kind of particle-jump is responsible for a certain macroscopic effect, he is going beyond what he sees. He sees a needle-displacement. He infers that a certain kind of micro-event occurred. He is making a judgment and a conjecture. 
        When you (under the idealized circumstances described a moment ago) say “I saw Smith yesterday”, your statement does indeed involve your going beyond what is given to you in the visual perception that you had yesterday. So relative to that particular perception, your statement is not a case of innocent reportage. But where Smith is concerned, there is nothing that you haven’t seen; and your statement is therefore not a conjecture. You don’t have to make a leap into the unseen. You must relate what was given to you in your yesterday-perception with what was given to you in perceptions from earlier days; and doing this would obviously involve certain cognitive abilities: it would presuppose the ability to generate memories of perceptions and to organize these memories in a certain way. But your statement that you saw Smith would not reflect your having made a theoretical leap, and would reflect only your duly generating and organizing memories of what you had seen. 
        Now let us consider the case where you are subject to human limitations – where your vision and memory are not maximally powerful. Under these circumstances, when you say “I saw Smith yesterday”, your statement would involve an element of conjecture (not – as we will soon discuss - of quite the same type as the physicist’s conjecture, but a conjecture no less). But the conjecture wouldn’t involve your positing some special entity. The conjecture would be to the effect that, mediating between the situation that you saw yesterday and other situations that saw on previous occasions, there were other, comparable situations that you didn’t see. The physicist’s conjecture involves the positing of something very different from what he has seen or (conceivably) even could see. When the physicist conjectures that a certain micro-event is responsible for a certain perceptible disturbance, he is not merely positing that there exists a certain continuity between certain seen (or seeable) situations. (A hundred years ago, philosophers of science would have said that this is precisely what such a conjecture consists in. But it has been reasonably well established that this is false.) But when you say that you saw Smith, the conjecture involved in your statement (so far as any conjecture is involved) is precisely that, mediating between the situation that you saw yesterday, and other situations that you saw on prior occasions, are various other comparable, but (by you) unseen, situations. 
       
[257] Except in so far as there are “experiences” of platonic abstracta. But while I have no doubt that we can grasp platonic abstracta – that, indeed, we grasp them quite directly, and without the mediation of symbols --  it seems false to say that we experience them. It seems, in fact, what we mean by the word “experience” is cognizance that has concrete, not abstract situations for its cognizance. 
[258]
 I recall John Perry making this point. But I haven’t been able to find the article where he makes it. 
[259]
 This, by the way, seems to refute the Tractarian view that the proposition Smith punched Jones is some structure consisting of Smith, Jones, and punching that is isomorphic with the kind of state of affairs would make that proposition true. If that structure is an isomorph of such a situation, then it seems that it would be such a situation; in any case, it would be some situation in which Smith stood in a certain relation to Jones. But then the mere existence of the proposition would predetermine the truth of many, potentially false empirical propositions. 
      
[260] Carnap (1937: 42) writes: “by the logical content of [a sentence]…we understand the class of non-analytic consequences of [that sentence].” 
    Clarence Lewis (1946: 55) writes: “The intension of a proposition comprises whatever the proposition entails: and it includes nothing else” (quoted in Bonjour 1998: 40). 
     This view is not an anachronism. Brandom (1998: 96) holds it, and it also underlies the contemporary view that propositions are sets of worlds (or, equivalently, functions from worlds to truth-values). 




[261] Of course, a person could know what is meant by “Jones punched Smith” without knowing what is meant by “Smith punched Jones.” An example of such a person would be someone who doesn’t speak English but has been told what “Smith punched Jones” means. But, as we discussed in Chapter 13, such a person doesn’t really understand that sentence. 
[262]
 As we saw, all expressions – even “Socrates” and “Plato” – are to be defined contextually. To say that “Socrates” refers to x is to say that expressions of the form ┌Socrates has phi ┐  are true iff x has phi. To point to an object x and say “that is Socrates” is to say, implicitly, that an utterance of the form ┌Socrates has phi┐ is true iff x has phi. So denotative definition collapses into contextual definition.
[263]
 The essential idea behind PWS – a sentence’s content is the class of worlds where it is true – is found in C. Lewis and Carnap. Lewis writes (1946: 56).: “[W]e might say that the intension of a proposition comprises whatever must be true of any possible world in order that this proposition should be true of or apply to it.” And Carnap (1956) writes: “Hence it seems plausible to define the content of a sentence as the class of possible cases in which it does not hold…” Ultimately, the conceit behind PWS goes back to Wittgenstein (1922).
[264]
 In Kuczynski (2006), I try to give a relatively complete account of what the problems are with PWS, and also how PWS could try to circumvent them. 
[265]
 This is only the beginning of a statement as to what is wrong with PWS. In Kuczynski (2006), I provide a more detailed assessment of PWS. But for our purposes, the remarks made in the preceding paragraph ought to be enough to show that, in this context, PWS does not provide a viable answer to the question “what is a proposition?” I leave it open whether there are contexts – e.g. contexts of a purely logical or mathematical kind – where PWS is adequate.
         
[266]       In this context, we will, for brevity’s sake, ignore the distinctions between properties and hyper-properties and hyper-hyper-properties…and will simply use the term “property.” Also, in this context, we will speak rather naively about the nature of property instantiation and of propertyhood. We will, in our exposition, not always make the necessary allowances for these points. But we will see that this is purely an expository aid – a way of keeping our discussion from being prohibitively long and tedious -- and that there is no difficulty  reincorporating those points into our analysis.                 


[267] Here it would be more convenient if we were writing in a richly inflected language, such as Russian or Latin. It would then be clearer how grammar unifies expressions into more complex expressions. In English, there is quite as much grammar as there is in Russian. But English-grammar is largely realized through word-order or, if Chomsky and other depth-grammarians are right, is without any acoustic (or orthographic) representation. So, where English sentences are concerned, its presence is less likely to be discerned than it would be if we were dealing with Russian sentences. 
[268]
 I mention intonation because where some languages are concerned, e.g. Mandarin, given two utterances that differ in intonation but are otherwise identical, one may be grammatical while the other is ungrammatical. Even in English, it is, at least arguably, ungrammatical not to end questions with a certain kind of intonation. So in some cases, intonation is a way of rendering grammatical an otherwise ungrammatical utterance. This is not always the case, of course.
[269]
 Here is another illustration of Peacocke’s analysis. Let there be some concepto C satisfying the following condition. For any proposition P, if you believe P, then you are primitively compelled to disbelieve CP (read: “C of P”). Under those circumstances, C is the concepto of negation, and you grasp that concepto because you satisfy its possession-conditions.
[270]
 See Peacocke (1989, 1992).
[271]
  Given that the former is itself an experience, it would make little sense to say that it was itself, in its entirety, a conceptualization of experiences. 
       Also, If we say that the former is a conceptualization of sorts, then we will only render the term “conceptualization” ambiguous. If we came up with a new pair of terms to mark the distinction that we just obliterated, then the very problems that we’ve been discussing would arise in connection with that pair. This shows that we are simply re-labeling conceptso, not analyzing them, by saying that my seeing Tom is a case of conceptualization.
[272]
 Fodor (1990, 1998) argues that one’s grasp of a concept – e.g. the concept of justice or of redness or of sentience – is completely non-descriptive. In Fodor’s view, for me to have a concept of justice just is for some instance of justice to have a certain causal connection to my present neural state. Fodor’s view has the radically implausible consequence that an otherwise conceptless entity, e.g. a photographic plate, could grasp the concepto of justice. It has the related consequence that one could grasp the concepto of justice without knowing anything about the structure of that concepto and therefore without having any understanding of what it is for one state of affairs to be more just than another.
     In our view, one’s grasp of the concepto of justice is descriptive. The analysis that we are proposing is obviously incompatible with Fodor’s. 
[273]
 Barwise and Perry (1999) make a similar point. 
[274]
 See Langford (1942).
[275]
 See Blackburn (1984: 110-118) for a very clear and compelling discussion of the problems with Grice’s view. Despite his own acute awareness of the problems with Grice’s theory, Blackburn ends up himself advocating a Gricean theory of meaning. In Footnote 238, I discuss why, in light of some points made by Platts and Chomsky, Blackburn’s formidable defense of neo-Griceanism is not ultimately feasible. 
[276] In any case, this is what I believe, and it is what most people (and most philosophers and practically all contemporary psychologists) believe. Surprisingly, some authors have denied that animals and pre-verbal infants have any true or false mental activity. See, for example, Davidson (1980b: 141-170). Followers of the late Wittgenstein tend to have an attitude of antagonism towards any theory that ascribes intentionality to non-communal or non-linguistic creatures. See, for example, McDowell (1994) and Brandom (1998). We have already seen why no legitimate basis for such antagonism is found in Wittgenstein’s work. 
      I should point out that Fodor (1981) has done a superb job of articulating why Wittgenstein has failed to provide any legitimate reason to reject the basic tenets of cognitive science. An implication of Fodor’s cogent discussion is that, indeed, non-linguistic creatures can think.  
     Donald Davidson (1980b: 141-170) held that, in order to think, a creature must know a language; and he produced some interesting arguments in defense of this view. 
       Davidson’s arguments presuppose an acceptance of a very extreme form of content-externalism and must therefore be rejected, given what we saw in Part I of this work. 
      There is another problem with Davidson’s view. If Davidson is right, then ex hypothesi one’s linguistic competence isn’t mediated by any kind of intelligence. There are no cognitive processes between perceptual input and verbal output. 
        In that case the speaker is thus not significantly different from Pavlov’s dog. But Chomsky (1959) made it clear why Pavlovian (behaviorist) theories of linguistic cannot be accepted. Given Chomsky’s arguments, it is fair to say that linguistic competence can no more be explained without positing cognitive processes mediating between input and output than Brownian motion can be explained without assuming the actuality of molecules. There is thus good reason to believe that any theory like Davidson’s is a non-starter. 
      Further, Davidson’s position is incompatible with the very fact that anyone means anything by anything. As we’ve seen, speaker’s meaning presupposes conventional meaning. I cannot mean proposition P by my production of noise N unless I believe that N already means P. Since Davidson’s position is that one must know a language in order to believe anything, it follows that Davidson’s position is incompatible with the fact that anyone means anything by anything.  
      Knowledge of  language obviously facilitates thought. But it cannot be constitutive of one’s ability to think, since the ability to think is a pre-requisite to learning a language. In any case, we have seen good grounds for this view in the present work, and I try to present a cogent argument for it my article “Must one know a language to grasp propositions?” (Kuczynski 2005b).  In any case, it is not entirely unreasonable to assume that pre-linguistic creatures can have true and false mental contents: and this is all that is demanded by the argument presented in this chapter. 
[277]


 Frege (1884) eloquently defends this very point. Some philosophers deny that there are propositions and would therefore, presumably, deny that there was anything to be true or false prior to thought. But this seems straightforwardly false. Of course, nobody grasped that proposition before there was thought. But that is irrelevant.
[278] Searle (1969: 37-37) makes very similar points.


[279] The same is true of sentences having other moods, e.g. optatives (“would that she were here!”) and exhortatives (“let’s go!”). But obvious adaptations of what we say about assertions, questions, and orders apply to sentences of these other moods, and we therefore needn’t discuss them explicitly.
[280]
 Versions of this point are made by Tughendat (1970), Dummett (1973: 196-203) and also – as both of those authors point out – in Frege (1884).
[281]
 See Tughendat (1970) and Dummett (1973: 196-202).


[282] For expository reasons, we are idealizing away from the fact that it can also join noun-phrases, as in: “Bob and Ted played tennis.” That sentence is not equivalent with “Bob played tennis, and so did Ted.” But one knows everything there is to know about one disambiguation of “and” if one knows what affect an occurrence of “and” in a sentence-token T has on the T’s success-conditions. 


[283] See Chomsky (1980: 83) and  Platts (1979: 89-90). Chomsky and Platts are making what at first appears to be a different point. They are not saying that Grice’s view is incompatible with the compositional nature of sentence-meaning. Rather, they are saying that Grice’s view is incompatible with the fact that sentences that have never been uttered already have a definite meaning, given that nobody has ever meant anything by such a sentence. But these two points are equivalent, or nearly so. Why do unuttered sentences already have fixed meanings? Because their constituents already have meanings, and there are recursive rules saying how those meanings fix the meanings of sentences in which they occur. Where there is no semantic complexity, there is no possibility of there being expressions that are never used but have fixed meanings. And where there is such complexity, such expressions can exist. So the point objection that Chomsky and Platts are making to Grice’s theory is equivalent with the objection that I am making to it.   
    Blackburn (1984: 127-130) discusses this objection, and says that it is null and void. We are now going to consider Blackburn’s explanation as to why Grice’s theory is consistent with the compositional character of meaning.
[284]
 This is Blackburn’s (1984: 129) position. 


[285] This example is borrowed from Blackburn (1984: 119). Blackburn (1984: Chapter 4) provides an illuminating discussion  with of the problems relating to how mere verbal regularities could give rise to rules governing word-usage. 
[286]
 As a matter of historical fact, the English word “Socrates” did not come into existence as a result of people producing sounds of the form…socrates…with the intention of making statements about Socrates. English-speaker’s didn’t go around producing such noises until “Socrates” (or some other similar word) already referred to Socrates. That English word was borrowed from a word of another language (Medieval French, we may suppose). In its turn, that word was derived from a word of another language (Latin, we may suppose). And that word was derived from a word of yet another language (Ancient Greek, we may suppose). 
        Obviously the Ancient Greek word for Socrates didn’t come about in a way that validates the hypothesis under consideration. Suppose that sukrat is the sound of the Ancient Greek word in question. It isn’t as though the Ancient Greeks first went around uttering noises of the form…sukrat…and their word for Socrates eventually arose out of those pre-linguistic noises. No sooner was Socrates given a name than that name already had the semantic and recursive properties associated with “Socrates” or any other well-formed expression of an already completely developed language. 
       So the hypothesis in question obviously doesn’t apply to “Socrates” or, for exactly similar reasons, to any expression constitutive of any language that we know of. If that hypothesis applies to anything, it is to primordial events that pre-date recorded history. This underscores the fact that, if correct, Grice’s theory only identifies the historical precursors of semantic facts, and thus fails to analyze those facts themselves. It also shows how improbable it is that Grice’s theory is correct even as a hypothesis as to what those precursors are. 
[287]
 Strictly speaking, there is some proposition P such that my utterance is a success exactly if, in response to that utterance, you affirm either P or its negation. Suppose that you truthfully say either “Smith went to the store” or “Smith did not go to the store”, but that you were not prompted to do so by my utterance. Suppose, for example, that I foolishly ask somebody who is giving a speech on T.V. whether or not Smith to the store and that, by sheer coincidence, that person truly says “Smith went to the store” right after I asked the question. Under that circumstance, it seems to me, my speech-act was not a success, even though it was in some respects indistinguishable from that is a success. But in the present context, it isn’t necessary that we deal with this nicety, or with others like it. In Kuczynski (2005c), I give definitions of the terms “sentence”, “assertion”, “question”, and “imperative” that are intended to be correct at the level of detail. 
      What we just said about questions is true mutatis mutandis of what we are about to say about imperatives. 
[288]
 See the last sentence of the previous footnote.