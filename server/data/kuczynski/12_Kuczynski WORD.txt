Chapter 12
Skepticism and the Justification of Inductive Inference
1.0 What is skepticism?
A skeptic is a doubter, not a disbeliever. For me to be skeptical about Smith’s assertion that he’s an astronaut is for me to doubt that he’s an astronaut. It isn’t for me to be to disbelieve that assertion—only to question it. If I’m convinced that Smith is not an astronaut, I’m not skeptical about his claim. Skepticism is doubt, not disbelief.
But there is some tendency for skepticism to give way to disbelief. Even if I never definitively learn that Smith is not an astronaut, if I continue to find no good reason to believe that he is one, I’m more likely than not to disbelieve it. We feel that, if a claim is true, some positive evidence for it will turn up: the mere absence of counterevidence isn’t enough for us.
Does our human tendency to transition from doubt to disbelief have any logical basis? Or is it just another case of emotion and instinct corrupting rationality? It depends on the case. In some cases, but not all, failure to find positive evidence is itself counterevidence; and, in such cases, our tendency to slide form doubt to disbelief does have a logical basis. But, as we’ll see in this very chapter, unless some highly defensible forms of skepticism can be refuted, this claim of mine is simply wrong.
Many important debates in philosophy concern the merits of some form of skepticism. Are there non-spatiotemporal entities? (Skepticism about platonic entities.) Do we have beliefs, feelings, etc., that we aren’t aware of having? (Skepticism about unconscious ideation.) Could observation ever provide adequate grounds for believing in unobservables (e.g., electrons) or should we regard terms like “electron” as referring to fictions of some kind or as not referring to anything at all? (Skepticism about theoretical entities.)
As these examples indicate, philosophical skepticisms involve whole categories of truths. One doubts all truths affirming, or presupposing, the existence of non-spatiotemporal entities, unconscious emotions, theoretical entities, etc.
In this chapter, we’ll discuss what are probably the two most important forms of skepticism: skepticism about the external world and skepticism about inductive inference.
To be a skeptic about the external world is to doubt that what our senses are telling us is accurate. One is a skeptic of this kind if one believes there to be no good reason to believe that one’s sense-perceptions are anything other than hallucinations.
A bit of background is needed to say what it is for one to be a skeptic about inductive inference. Some knowledge is direct. One doesn’t have to figure it out—one just knows it. Somebody who is experiencing a searing pain knows it, and he didn’t have to figure it out. But much knowledge is indirect. Einstein didn’t “just know” that a body’s mass increases as its speed increases; he had to figure it out. In other words, he had to infer it. So for knowledge to be indirect is for it to be acquired through inference.
There are two parts to any inference: the premises and the conclusion. The conclusion is the belief arrived at—the thing that, when the inference leads from the right premises to the right conclusion in the right way, is “figured out.” The premises are the pre-existing beliefs or assumptions on the basis of which one arrives at the conclusion.
There are two kinds of inferences: deductive and inductive. An inference is deductive if, supposing that one’s premises are true and one’s reasoning non-faulty, it is impossible for one’s conclusion to be false. If my premise is that x is a square and my conclusion is that x has four sides, it’s logically impossible for my conclusion to be false if my premise is true. So this would be a case of a deductive inference. An inference is inductive if, supposing that one’s premises are true and one’s reasoning non-faulty, it is possible for one’s conclusion
to be false. If my premise is that, in the 35 years I’ve been drinking tap water, I have never become sick as a result of doing so, and my conclusion is that I won’t become sick as a result of drinking the glass of tap water in front of me, my conclusion may be false. So this would be a case of an inductive inference.
A skeptic about inductive inference holds that it is impossible, as a matter of principle, to learn anything through non-deductive inference. He holds, in other words, that one cannot acquire knowledge through inductive inference. All knowledge is either direct or is arrived at through deductive inference.
If this is right, then we know only an infinitesimally small fraction of what we think we know. This is because, for reasons thoroughly discussed in Chapter 10, no knowledge about the external world is direct, and only some knowledge of ourselves is direct.
We will start by discussing skepticism about induction.
2.0 Skepticism about induction
David Hume made it clear why it may be doubted whether inductive inference ever leads to knowledge. Here is Hume’s argument:

(HA) Consider some inductive inference—for example, “the sun has always risen in the past; therefore, it will rise tomorrow.” First of all, this argument is not deductive, since, even if the premise is granted, it isn’t a theoretical impossibility that the conclusion will be false. The sun might explode, after all. So the conclusion is, at best, probable. That’s step 1.
Here’s step 2. Given that the connection between premise and conclusion isn’t deductive, we must ask: how does the premise warrant the conclusion? In other words, what reason does the (supposed) truth of the premise give us for accepting the conclusion?
Here’s an answer that seems tempting at first: “The past resembles the future; the known resembles the unknown. Nature is uniform. So given that such and such has been the case until now, we may infer that such and such will continue to be the case. Given that, until now, pinewood has floated, metal has expanded when heated, water has quenched thirst, etc., it’s reasonable to conclude that pinewood will continue to float, and so on. It is thus the principle that nature is uniform—or, as we’ll call it, the uniformity principle (UP)—that allows us to make rational, non-deductive inferences about the unknown on the basis of the known.”
But this argument is no good. No one directly knows that UP holds for all places and times. At most, one knows that it has held for the fragments of nature that one has personally known of. One doesn’t directly know that it held of past objects that one didn’t know of; and one doesn’t directly know that it will hold of future objects that one will know or of future objects that one won’t know of. Any such knowledge must be indirect (i.e., must be inferential). The inference in question can’t be deductive. Given only that the ravens thus far known to one have been black, it doesn’t follow deductively that ravens not (yet) known to one are also black. In general, given only that such and such has held of the things I’ve known of, it obviously doesn’t deductively follow that it holds of the things that I haven’t (yet) known of. The inference must be inductive. But if it’s inductive, then it goes through only on the condition that UP is granted. But since that very inference must go through in order for UP to be granted, it doesn’t go through and, what is more, UP cannot be granted and, finally, there’s no way to justify inductive inference.
3.0 Problems with Hume’s argument
Nobody denies that inductive inferences are knowledge-conducive and, therefore, that the conclusion of Hume’s argument is false. Even Hume said that, in his bones, he couldn’t accept it. But there’s no accepted response to Hume’s extremely clever argument. Nonetheless, Hume’s argument is refutable and a refutation of it must lie in some argument not totally unlike the following.
There are two serious errors in Hume’s argument. First, it assumes that the primary form of non-deductive inference is induction by enumeration. In actuality, induction by enumeration is less important than, and subordinate to, a very different form of non-deductive inference known as inference to the best explanation. (The italicized terms will be defined shortly.) Second, Hume assumes that non-deductive inferences go through only if UP is granted (i.e. only if it’s granted that nature is uniform.) But UP is not the relevant principle. What must be granted, I propose, is that good explanations minimize causal anomalies. What must be granted, in other words, is that, other things being equal, theory T1 is better than theory T1 if the world as T1 describes it contains fewer unexplained causal connections—fewer causal links that must be taken for granted and left unexplained—than T1. Let’s refer to this principle as “MC” (short for “minimization of causal anomalies”).
Unlike UP, MC is, I submit, analytically true: it is inherent in the concept of what an explanation is that, other things being equal, the theory that eliminates the greater number of unexplained explainers—and, in particular, the greater number of unexplained causal connections—is the one to be preferred. Because this principle, unlike UP, is analytically true, it doesn’t have to be validated on inductive grounds. This makes it possible to validate inductive inference in a way that, unlike the way that Hume considers, is not viciously circular.
3.1 Inference to best explanation versus enumerative induction
There are two forms of inductive inference: induction by enumeration and inference to the best explanation. (See Chapter 12.) An induction by enumeration has the form: every F that I’ve ever known of was also a G; therefore all F’s are G’s. Example: All the balls that I’ve thus far removed from the urn have been white; therefore, all the balls in (or removed by me) the urn are white.
An inference to the best explanation has the form: it is known that S; it isn’t yet known that S*; but if S* were true, it would, without doing excessive violence to what we (think we) know about the world, explain why S is true; moreover, if S* weren’t true, it would be hard to find a viable alternative explanation of S. For example: I’m very careful with my credit cards (I never use them to make online purchases, I never let anyone besides reliable merchants see them, etc); and, before my friend Larry moved in with me, no unauthorized purchases were ever made with any card of mine. But after he moved in, my cards were used to make a series of unauthorized purchases. Moreover, the items bought were ones that, for work-related reasons, Larry desperately needs and that nobody outside of Larry’s rather unusual profession would have slightest use for. Knowing all of this, and not knowing any other way to account for the unauthorized purchases, I conclude that Larry made those purchases.
It’s widely assumed among philosophers that induction by enumeration is the more fundamental form of inference. This is a mistake. All cases of induction by inference, when legitimate, are parasitic on cases of inference to the best explanation. There are, of course, many cases where one of my reasons for thinking that all F’s are G’s is that every F I’ve ever known of was also a G. But, setting aside beliefs arrived at through spurious reasoning, there are no cases where that was my only reason for believing that all F’s are G’s. Hume’s argument focuses entirely on induction by enumeration. Hume is right, I believe, that this form of inference is unjustifiable. But we don’t use this form of inference. In any case, we don’t use it in the way that Hume thinks. Moreover, we shouldn’t use it, and we needn’t use it. In some cases we may think that we’re doing straight induction by enumeration. But, in almost all such cases, a little probing always shows that many interconnected background assumptions are at work and that, when these are made explicit, what we’re really trying to do is to produce an inference to the best explanation. And, although there are cases of straight induction by enumeration, they tend to occur in rather artificial contexts and that, when they do occur, they’re clearly spurious.
There is a well-known inductive error known as the “gambler’s fallacy.” (Sometimes it’s referred to as the “” fallacy.) You are playing a game of roulette. (This game involves rolling two dice into a spinning wheel, which is divided into numbered slots.) You know that nothing about the game is in any way rigged—that the dice aren’t loaded, and that neither the wheel nor the underlying apparatus were built or modified to favor any one outcome more than any other. And you thus know that, given only the physical properties of the game, a die, once thrown, is no more likely to land in this as opposed to that slot. (How you know Monte Carlo
this is irrelevant; we’ll just assume that you do.) You also know that, given any slot on the wheel, there is nothing about you that makes a die you’ve thrown more likely to land in that spot than in any other—nothing about your body, mind, or dice-throwing practices that favors this as opposed to that outcome. (Again, how you know this is irrelevant; we’ll just assume that you do.) You’ve rolled the dice seven times. Each time, at least one of the die has landed in slot #27. It must be stressed that you know there to be nothing about the game or about you that predisposed this to happen—that you know this to be entirely a matter of luck.
Under these circumstances, it would be natural to predict that you’ll roll a 27 next time. But that prediction would be irrational: you have no more reason to believe that you’ll roll a 27 than you will any other number. And if, by chance, you do roll a 27 next time, it will be natural to predict that you’ll roll a 27 the following time. But this too would be completely irrational. So long as you know that there’s nothing inherent in the game or in yourself that favors this as opposed to that outcome, you are never any more entitled to bet that, with the next throw, you’ll roll a 27 than you are to bet that you’ll throw any other available number. It doesn’t matter how many consecutive 27s you rolled prior to that throw: it could have been ten, a thousand, or a million. 
By the same token, no matter how many consecutive 27s you roll, you are never any more entitled to bet that, next time, you won’t roll a 27 than you are to bet that you won’t roll any one of the other available numbers. It would be natural to think otherwise, of course. Given how improbable it is that you will roll five consecutive 27s, let alone 50, you may have an urge, when rolling for the 51st time, to think: “this time, surely, I’m even more unlikely to roll a 27 than I am to roll any other available number. The game isn’t rigged. The likelihood of my rolling 51 consecutive 27s is infinitesimal and, therefore, is much smaller than 1/n (where n is the number of available slots). So a 27-roll is especially unlikely—more unlikely than a 5-roll or a 13-roll.” But this is spurious reasoning. You are no more, and no less, unlikely to roll a 27 than you are to roll any other number. With every throw, the chances of rolling any one of the available numbers are identical with the chances of throwing any one of the others. Since, by hypothesis, the conditions that obtain on any two occasions are identical, it would be irrational on any given occasion to think any one outcome any more or any less likely than any other. It would, in fact, be the ultimate absurdity—like the belief that, although doughnut x is an atom-for-atom duplicate of doughnut y, x is far more fattening than y.
3.1.1 When is enumerative induction rational?
When would it become rational to believe that, next time, you’re more likely than not to roll this as opposed to that number—that, for example, you’re especially likely to roll a 27? This belief becomes rational when, and only when, you have reason to believe that a 27-roll is favored by the structures involved in the game. And that belief, in its turn, is rational if you know that circumstances at all like the following obtain: 

*The dice are magnetically attracted to the 27-slot. 

*On any given occasion, you have an unconscious intention to roll a 27 (even though you have no conscious intention of doing this), and you’re such a talented dice-thrower that, if you can roll a 27 if it is your (subconscious) intention to do so.

*The 27-slot is much bigger than any of the other slots. In fact, it takes up so much space on the roulette wheel that the remaining spaces are too small for the ball to fit into them.

You are rational to believe that you’ll continue to roll 27s to the extent that your having thus far rolled multiple 27s in a row gives you reason to believe there to be some underlying structure favoring that outcome. And to the extent that a long run of 27-rolls doesn’t give you such a reason, you are irrational to believe that you’re any more (or any less) likely to roll a 27 than you are any other number. So, no matter how many consecutive 27s you roll, if you know with complete certainty that nothing about either yourself or the set-up of the game favors that outcome, it is irrational to think that, next time, you’re any more (or less) likely to roll
a 27 than you are a 5 or a 32. Put pedantically, it is only insofar as you have reason to believe in such a structure that you have reason to expect something that has the property of being a die thrown by you to have the property of landing in the 27-slot.
3.1.2 Generalizing these points
Your knowing of many phi’s that are psi’s and of none that are not doesn’t necessarily give you any reason to believe that the next phi you encounter will be a psi; it gives you such a reason only insofar as it gives you a reason to believe in some structure or mechanism that disposes phi’s to be psi’s. If you know on independent grounds that there is no such mechanism, no run of phi’s that are psi’s, no matter how long, gives you a reason to think that the next phi will be a psi; and you are guilty of the gambler’s fallacy—and thus, as we saw, of the most rank absurdity—so far as you think otherwise. Thus, in and of itself induction by enumeration is worthless; it’s a fallacious form of reasoning and falls in the same category as every other argumentative fallacy. Of course, if you know of many phi’s that are psi’s and of none that are not, you do have good reason to hold that, other things being equal, the next phi you encounter will be a psi. But this is because you’re having this knowledge gives you reason to believe there to be a principled or lawful connection between a thing’s being a phi, on the one hand, and its being a psi, on the other. Here, then, is the real structure of inferences that are wrongly thought of as cases if induction by enumeration: (i) you know of many phi’s that are psi’s and of no phi’s that are non-psi’s; (ii) on the basis of step (i), you believe there to be some principled connection between a thing’s being a phi and its being a psi; (iii) if you know of a given thing that is a phi, but don’t yet know whether or not it’s a psi, you know, given (ii), that it’s likely to be a psi; therefore, (iv) you conclude (if only tentatively) that it is a psi. 
Thus, any case of induction by enumeration that isn’t an instance of the gambler’s fallacy involves the positing some mechanism or law that, were it to exist, would explain a certain concomitance—it involves, in other words, a case of inference to the best explanation. The best explanation of the fact that all known phi’s are psi’s is that, thanks to some mechanism or, in any case, principled connection of some kind or other, a thing’s being a phi disposes it to be a psi; and as soon as such a mechanism has been posited, but not one second sooner, your knowing of a given thing that it’s a phi is a reason for you to hold that it’s a psi. So any non-fallacious “induction by enumeration” is nothing other than a case of inference to the best explanation (or, more precisely, is a case of applying some theory that embodies an inference to the best explanation).
Hume’s argument assumes that it is only through induction by enumeration that the past is any guide to the future. It assumes that, so far as we have any reason to believe that future phi’s will be psi’s, it is that past phi’s have been psi’s. But this assumption is dead wrong. The fact that past phi’s were psi’s, is not, in and of itself, reason to hold that future phi’s will be psi’s; it is such a reason only to the extent that it suggests some mechanism that disposes phi’s to be psi’s. Hume’s argument assumes otherwise and is thus guilty of assuming the legitimacy of the spurious form of inference involved in cases of the gambler’s fallacy. And, if it is to have a chance of going through, Hume’s argument must be so reconstructed that it no longer embodies that assumption.
4.0 The minimization of causal anomalies
We haven’t yet refuted Hume’s argument—we’ve only taken the first step towards doing so. Hume could defend his view against what we’ve said thus by far by saying the following: 

(HR) Suppose that, to explain why all phi’s thus far known are psi’s, you posit some underlying structure or law that disposes phi’s to be psi’s. Unless you think that nature is uniform, you have no right to expect that connection to continue to hold. But if, in order to deal with this, you suppose that nature is uniform, then you’re caught in the vicious circle that I described.

HR is correct. One is indeed caught in a vicious circle if, in order to show the legitimacy of inductive inference, one assumes UP; and the reason is that, just as Hume says, UP can be known, if at all, only on inductive grounds.
4.1. Why inductive inferences don’t presuppose the truth of the uniformity principle
But in making an inductive inference, one doesn’t assume UP and, moreover, one doesn’t assume anything that, like UP, can be known only on inductive grounds. What one assumes is that explanations are supposed to eliminate causal anomalies—that they are supposed to reduce the number of them and to limit the scope of those that aren’t eliminated. What one assumes, then, is that it is inherent in the very concept of explanation that, other things being equal, T1 is a better explanation than T2 if T1 does a better job of eliminating causal anomalies than T2.
The purpose of explanation is to minimize the breadth and depth of what must be taken for granted. The more a proposed theory requires you to say: “things just happen that way; there’s no explaining it,” the less successful an explanation it is.
Here’s an illustration. On Monday night, you park your car in the usual place, viz. right in front of your house, which is in a quiet residential neighborhood. As usual, you make sure that you lock the car and turn the car alarm on. You also put an almost, but not quite, indestructible device (popularly known as “The Club”) on the steering-wheel that locks it into place, making the car undriveable. Given where your home is in relation to where the car is parked, you’d almost certainly hear the car alarm go off, were it to do so. In fact, unless you were fast asleep, you’d even hear the footsteps of someone approaching the car. So even if the car alarm weren’t on, you might well hear the approach of a would-be thief and you’d certainly hear the noises made by somebody who, not having the keys needed to open the car or to unlock the steering wheel or to start the car, would have to jimmy the door lock, saw through the wheel lock, etc.
As it happens, you hear nothing all night. And you know that you didn’t sleep any more deeply than usual—that, for example, you weren’t in a particularly deep drug-induced slumber—and, in general, that you weren’t made less sensitive to noise than you usually are. (For argumentative purposes, we’ll set aside the question of how you know this.) Nonetheless, on Tuesday morning, the car is gone.
What are the various possible explanations of this? (By “possible,” I don’t necessarily mean “worthy of consideration,” only “not ruled out by the laws of logic.”) There are infinitely many; but here are three.

(E1) Using his or her super powers to bypass the security measures you took, some superhero-like creature made off with the car, making little or no noise and leaving few or no clues.

(E2) As you were sleeping, the laws of physics changed in such a way that hitherto noisy processes (e.g., those that occur when car alarms go off) are no longer noisy.

(E3) Your good friend Larry—who, despite his numerous convictions for auto-theft, simply radiates trustworthiness and decency, and to whom, without so much as a touch of anxiety, you therefore gave copies of all your keys—made off with the car. (For argumentative purposes, let’s assume that, given that the car is gone, it had to have been stolen; it could not, we will suppose, have been towed or simply borrowed.)

Each of E1 and E2 replaces the mystery of how your car could be noiselessly stolen with a far greater mystery. In fact, each creates a whole network of deep mysteries. E1, if correct, would generate a number of thorny questions concerning specific matters of fact and also concerning our knowledge of biological and physical law. (The features that we’d have to ascribe to the superhero in question would be ones that, unless modern biology is very wrong, a life form is most unlikely to have.) And E2, if correct, would do nothing less than create the greatest scientific mystery of all time.
E3 is not free from sin either. In general, you are a good judge of character. In any case, that’s what you believe and that’s what others tell you; and your judgments about people have generally been borne out by subsequent events. You’ve never been as convinced of anyone’s integrity as you are of Larry’s. Without being morose or censorious, he exudes a decency and centeredness that you’ve never even seen in a head of state, let alone a car thief. And although Larry’s extensive criminal background is consistent with his stealing your car, it is not, you are convinced, as consistent with it as his current excellence of character is inconsistent with it.
But, of course, E3 is hands down the best explanation. You may think you’re a good judge of character; but that doesn’t mean you are one. People proverbially overestimate their ability to read others. And even if you are a good judge of character, so what? Anybody can be fooled; everybody is fooled, at some point or other. And if Larry is a career criminal—which, given his rap-sheet, he may well be—then he has probably honed his skills as a con-man.
This doesn’t mean that E3 is completely innocuous. If correct, it raises the question of how somebody could seem so different from how they are. It also raises the question of how, despite being a crime expert, you could have been unwary enough to let yourself be seduced into trusting somebody who, given his background, was so obviously unworthy of trust. But these mysteries can be dealt with more easily than the mysteries created by E1–E2.
All of this goes to show that ceteris paribus the best explanation is the one that leaves us with the fewest unexplained explainers.
Of course, new theories raise questions of their own. This is almost a tautology. A new theory is, tautologously, a new way of looking at things; and a new way of looking things is, very obviously if not tautologously, one that raises new questions. But good new theories tend to facilitate the answering of the questions they raise. Relativity Theory raises questions that don’t arise for its predecessor, Newtonian mechanics. But Relativity Theory itself tends to contain hints as to how those questions are to be answered. The development of a good theory tends to consist largely in making explicit what is already present in that theory. The development of a bad theory consists in adding new material to it to help it deal with each new onslaught of counterevidence. In any case, what’s important in this context is that good theories get rid of causal gaps and they shrink the ones they can’t get rid of.
Before proceeding, we must make a certain distinction very clear. Little or nothing about the actual causal structure of the world is analytic. It isn’t analytic that there aren’t giant causal gaps in the causal structure of the world; that reality doesn’t consist of one ex nihilo event after another, that superheroes don’t suddenly pop into existence, steal cars, and then, without leaving a trace, vanish never to be heard from again. These things, if known, are known only on the basis of sense-experience. But it is analytic that, other things equal, good explanations are less dependent for their truth than bad ones on the existence of unexplained explainers. Given that E3 depends less for its truth on unexplained explainers than does any one of E1–E2, it is analytic that E3 is ceteris paribus the better explanation. 
But it isn’t analytic that E3 is correct. It’s a possibility—maybe only a bare theoretical possibility, but a possibility no less—that the laws of physics changed over night, that CIA super-agents have targeted you, that comic book characters now walk the Earth, etc. Anything’s possible. And so far as we know that E1–E2 are wrong, it’s through sense-perception. So, I repeat, it isn’t analytic that E3 is correct. But, given that it requires fewer unexplained explainers than others, it is analytic that ceteris paribus it’s the better explanation.
4.2 Correct explanations can be bad explanations
For an explanation to be good isn’t for it to be correct. Sometimes the right explanations are bad ones. A story will make this clear. I’m on a bus. The bus driver is smiling. A mystery! “What on Earth does he have to smile about?” I ask myself. His job is so boring, and his life must therefore be such a horror.” But then I remember that, just a minute ago, a disembarking passenger gave him fifty $100 bills as a tip. So I have my explanation: “he just came into a lot of money.”
But here is the very different explanation tendered by my seatmate Gus, who, in addition to being unintelligent, is also completely insane. “The bus-driver is a CIA assassin. This morning he killed somebody who, by coincidence, had the name ‘Benjamin Franklin.’ Benjamin Franklin (the statesman, not the murder victim) is on the $100 bill. So when the bus driver saw those bills, he immediately thought of that morning’s murder. The murder was a particularly enjoyable one; the bus driver had a chance to try out some innovative techniques. So, on being given the fifty $100 bills, the bus driver was reminded of that happy experience.” That, my seat-mate believes, is why the bus driver is smiling. The bus driver is indifferent to the fact that he is now richer by $5,000 than he was before. (He’s not a materialistic man. Plus, the CIA pays him a huge salary. $5,000 is nothing to him.)
Gus and I have access to the same empirical data. (Gus hasn’t read the bus driver’s diary; he doesn’t know the bus driver any more intimately than I do; and so on.) And Gus doesn’t have some sort of psychic gift that would give him access to otherwise unknowable facts about the bus driver’s mind that would legitimize his explanation. Indeed, a belief that he has such a gift isn’t even among Gus’s many delusions. Nor does he have any good reason—even if, for argument’s sake, one allows his delusions and hallucinations to count as good reasons—to believe that he has such a gift. So given the entirety of the data at our disposal, Gus’s explanation is a bad one. The only evidence in favor of Gus’s theory is that the bus driver started smiling upon being given the money.
But Gus is right. His explanation is correct down to the last detail.
Given that it turned out to be correct, should we say that, despite first appearances, Gus’s explanation is not a bad one? No! It’s a datum that it’s bad. It’s a bad explanation that turned out to be correct. Thus, for an explanation to be a good one isn’t for it to be correct.
But a short extension of our story illustrates the even stronger principle that for an explanation to be a good one isn’t even for it to be likely to be correct. Let W be the real world and let W* be a hypothetical world where we have the exact same experiences that we have in W, but in which the Gus’s of the world are always right. In W*, it’s because Santa Claus is personally delivering gifts to millions of people that they suddenly appear in living rooms round the globe; it isn’t because hard-working parents purchased them. In W*, your keys are missing because stealthy gnomes took them; it isn’t because you drunkenly threw them in the incinerator. And so on. In W*, the right explanations are the ones that, in our world, are extremely bad ones. The data on the basis of which those hypotheses are held in W* (so far as those hypotheses are held) is identical with the data on the basis of which they’re held here (same qualification). But in W*, they’re right, and the good explanations—the logical, sane, well-supported explanations—that they compete with are always wrong. So, in W*, good explanations aren’t even likely to lead to the truth. So there’s no inherent connection between an explanation’s being good and its being true: goodness (in the explanatory sense) cannot be identified with, or even understood in terms of, truth-conduciveness.
Explanatory goodness is a relationship, not between explanations and reality, but between explanation and data. The relations that hold in W* between theory and data coincide with those holding in W. That’s why the ones that are wrong in W* are no less good on that account. What is it that, in W*, makes wrong explanations be good? In general, what is the relationship that good theories bear with respect to the data?
First of all, “good” is a relative to term. An explanation is good relative to some body of data. No good explanation is inconsistent with the relevant data. And, of the various explanations consistent with a given body of data, the best one is the one that depends the least on unexplained explainers.
Here’s an illustration. I put an opaque plate on a table. I thus can’t see the part of the table covered by the plate. “Given only this data,” says my sophist friend Smith, “it’s a theoretical possibility that the moment you put the plate on the table, there suddenly came into existence a hole in the table the exact size of the plate.” Supposing that you’re right, I ask Smith, why didn’t the plate fall through the table? “Because,” Smith responds “when that hole came into existence, a special force was created that kept the plate in exactly the place that it would have occupied if there were no hole.” Why, I ask in response, did that force come into existence? “I don’t know,” says Smith. “It just did.”
Maybe this explanation is correct. We’ll never know for certain that it isn’t—at least not without presupposing the falsehood of various other, comparably ad hoc explanations.
Be that as it may, it’s a bad explanation. Why is it bad? Because it leaves us with more questions than answers. Why did the hole appear? Why did it happen to have just the right shape and size? Is it because the plate has special chemical properties? If so, why is it that, the moment the plate is whisked away from the table, the effects of any chemical interaction between the two are undone? Supposing that these questions can be answered, why did some force suddenly step into the breach left by the momentarily absent table surface? Why was that force just right—just enough to keep the plate on the table, but not so much that the plate rose above the table or trembled or did anything else inconsistent with its being on an ordinary table? And supposing that we have an answer to that question, why was there no independent evidence of the existence of that force? Why was its only effect to keep the plate in that very location, for that exact amount of time? Supposing
that, for some reason or other, we have highly sensitive instruments of measurement underneath the table, why didn’t any of them detect anything?
With every answer, a new hole arises. It may be that, for each hole that pops up, there is a way to plug it up that is not only consistent with the laws of logic but is also consistent with our other empirical beliefs. Or, if there arises a case where the hole cannot be plugged up without jettisoning some, or even all, of our remaining beliefs, maybe there is a way to revise those other beliefs in such a way that they remain consistent with the raw data and with the stopgap in question. It is generally said that a given body of data can be modeled by many different, mutually inconsistent hypotheses.
But even if this is true, it doesn’t follow that, for each hypothesis that models a given body of data in a way that has a given degree of success in the way of eliminating unexplained explainers, there is a logically incompatible way of modeling the data that also has that degree of success in that respect.
4.2.1 Correct explanations can be bad explanations (continued)
A continuation of our plate story will make it clear what this means and why it is true. Why doesn’t the plate fall through the table? Because, says the conventional wisdom, the table didn’t vanish. But, the skeptic will retort, maybe we can jettison that explanation; maybe there’s an alternative to it that is equally compatible with the perceptual data.
But, I would respond, supposing for argument’s sake that there is such an alternative, it doesn’t follow that it will create fewer holes to plug up than its predecessor did. It doesn’t follow that it’s comparable from a cost-benefit standpoint to the old one—that, in other words, it creates as few new mysteries as the old hypothesis while also eliminating as many existing ones.
But not only does this not follow: the exact opposite holds. Consider the alternative explanation that we considered a moment ago (viz. when the plate is placed on the table, a hole opens up, etc.) The explanatory cost of that hypothesis (in other words, what it leaves us having to explain that we didn’t have to explain before) was a thousand times greater than its explanatory value (in other words, what no longer has to be explained that did have to be explained before).
It would be very hard to produce an explanation that was incompatible with the conventional one and, while remaining consistent with the relevant data, was as inexpensive from an explanatory viewpoint as the conventional one. I invite you to verify this for yourself. If there is any reason to believe that there exists so much as a single such hypothesis, it isn’t that such a hypothesis has ever been produced or ever will be. That reason, if it exists, must be purely a priori. And, for reasons that will presently become clear, there can be no a priori reason to accept such a hypothesis.
4.2.2 Correct explanations can be bad explanations (continued)
But there is an even more immediate problem for this (or, by an analogous argument, any other non-standard) substitute for the conventional view that the table, even when obscured by the plate, continues to support it. It’s far from clear that, once all the relevant data is taken into account, that hypothesis is even logically possible. Let’s look at the statement:

(*) “when the plate is placed on the table, a hole that coincides with the under-surface of the plate opens up. But a force field is suddenly created that keeps the plate exactly where it would have been if, other things being equal, that hole hadn’t opened up.”

Taken by itself, (*) describes a situation that could hold. That statement is a coherent one. It’s not in the same category as “squares are round.”
But, while that’s obviously necessary for its being a logically feasible way of modeling the relevant data, it’s far from sufficient. Think of the various physical laws that must be broken for the table section underneath 
the plate to vanish. Violations of natural laws, were they possible, would not be innocuous; there would be ripple effects. Think of the forces that (so we believe) actually prevent that plate-sized chunk of table from vanishing. Think of the various equilibriums that would be altered if those forces were immediately suspended. Think of the various energy transfers that would be changed or destroyed if, all of a sudden, those forces were put out of commission.
Those forces don’t only keep that chunk of table in place. Were they all to be suspended, there would be many consequences other than the disappearance of the requisite table chunk. In other words, there would be a lot of explanatory “collateral damage,” meaning that many events would occur other than the ones that, given that our objective is to validate (*), we want to occur. And there’s no guarantee that those other events would be consistent—even in the narrowest, most emptily logical sense—with the data that, supposedly, is modeled just as well by (*) as it is by the conventional explanation (viz. “the place doesn’t fall because the table chunk doesn’t disappear”) that it replaces.
4.2.3 Correct explanations can be bad explanations (continued) 
We might try to deal with this batch of problems by positing second-order suspensions of natural law. So in addition to suspending those laws involved in keeping the table chunk in place, we also suspend those laws that, given the first suspension, lead to the just-mentioned unwanted collateral events.
The problem is that those second-order suspensions of law will be no more innocuous than their first-order counterparts. To counteract the unwanted effects of suspending the first set of forces, we have to suspend another set of forces. But just as the original forces did a lot more than keep the table intact, so these new forces will do a lot more than suspend the unwanted effects of suspending the first set of forces. And it’s obviously of no use to try to deal with this problem by bringing in a third set of forces.
“You may be right,” it will be said, “that if we hold onto our existing beliefs about physical law, then the disappearance of the table chunk would have all of this unwanted fall-out. But surely we could adjust those beliefs in such a way as to prevent this. Whatever those beliefs are, just get rid of them and replace them with ones that don’t lead to all of this unwanted fall-out.”
The very fact that this move must be made only proves my point, namely, that (*) is not consistent with what we know. In fact, it proves a stronger point, namely: (*) isn’t consistent with any body of beliefs at all like the ones we now have.
The objector is saying, rightly, that there is no way to square (*) with our existing beliefs—that it is only what we believe minus many of our beliefs about natural law that can be so squared. But when our beliefs about natural law are subtracted, so to speak, from the totality of our beliefs, the resulting body of beliefs bears very little resemblance to our current beliefs. Our beliefs about natural law are not in all cases neatly separable from our beliefs about specific matters of fact; and if we were to strip away enough of the former to compatibilize (*) with our belief system, we’d be biting off a lot more than we bargained for. This is because various beliefs about natural law are embedded in the concepts associated with expressions that, in order to say what’s on our minds, we must use every day (e.g., “microscope,” “telephone,” “radio,” “solar panel,” “cell phone,” “thermometer,” “thermostat”). Theory-laden though they are, we need those terms to describe facts of everyday, pre-theoretic experience. We therefore need them to state the pre-theoretic data that our theories are to model.
“But,” it will be said, “anything that can be described only by taking for granted some theoretical belief is ipso facto not a datum. A truth? Maybe. A datum? No.”
That may well be true. But, if so, our belief-system is so overrun with theoretical beliefs that no belief system free of such beliefs would bear even the slightest resemblance to it. Also, it is incoherent to suppose that there could exist a belief-system that wasn’t replete with theoretical content. The difference between a mere belief, on the one hand, and a belief-system, on the other, is that belief-systems are intended to be explanatory, whereas mere beliefs needn’t have this property. I believe that it’s raining because I see that it’s raining—not because, in an effort to model various observational data, I at some point hypothesized that it was raining. But psychoanalytic theory constitutes a belief-system, as opposed to a mere belief, because it is intended to be
explanatory. This suggests (though it doesn’t establish) that “belief-system” and “theory” are veritable synonyms. (Why the parenthetical hedge? “Because there are belief-systems that aren’t of a theoretical nature. Religious belief-systems aren’t theories.” But even this is arguable. Some would say, and I agree with them, that religious systems are proto-theories or para-theories—structures that make heavy allowances to emotional factors and make insufficient allowances to considerations of logic and evidence, but are, within these parameters, as theory-like as they could possibly be.) If, indeed, belief-systems are ipso facto theories, it makes no sense to speak of what our “belief-system” would be like if it were stripped of theoretical content. Long story short: although it’s obvious that, on its own, (*) is perfectly coherent, it’s far from obvious that (*) is compatible with our belief system as a whole or with any belief system that isn’t radically different from it. This was the very point we set out to establish. It goes without saying that what is true of (*) holds mutatis mutandis of each of many other “deviant” hypotheses.
But even if, for some reason, this last point is denied, there is no way to deny our main point, to wit: even if (*) is logically consistent with our belief system, or at least with some not-too-mutilated version of it, the explanatory benefits of countenancing (*) in favor of the conventional explanation are grossly outweighed by the explanatory costs.
4.3 Synthesizing these points
It will help if, before moving forward, we take a moment to synthesize the points thus far made. There’s no difference between committing the Gambler’s fallacy and performing an induction by enumeration. At the same time, knowledge of invariable concomitances is obviously an extremely valuable source of knowledge. But it isn’t, or in any case shouldn’t be, through enumerative induction that one transitions from (1) “all phi’s that I’ve known of were psi’s” to (2) “the next phi I come across will be a psi.” (In this context, it is to be assumed that that “x is a phi” doesn’t analytically entail “x is a psi.”)
The actual bridge between (1) and (2), supposing that there is one, lies in the fact that, given (1), it is reasonable to believe there to be some mechanism or natural law that requires (or at least disposes) phi’s to be psi’s. By itself, (1*) “all metal known to me has expanded when heated” provides no good reason to accept (2*) “all metal expands when heated.” (1*) provides a good reason for accepting (2) only to the extent that (1*) provides a good reason for accepting (3*) “there is a lawful connection between a thing’s being made of metal, on the one hand, and it’s expanding when being heated, on the other.”
4.3.1 Synthesizing these points (continued)
Before we continue, it’s crucial to note that none of this begs any questions against Hume. Hume is saying: “given only that every metal object that Smith has known of has expanded when heated, it doesn’t follow that metal that Smith has yet to encounter will (or is even likely to) expand when heated.” We agree. Smith is guilty of the gambler’s fallacy so far as he thinks otherwise. All we’re saying is this: Smith’s experience thus far suggests that “x’s being heated metal provides some kind of nomic basis for x’s expanding” has held for objects falling within the scope of Smith’s experience.
We’re not making the claim Smith’s experience entails that some such connection has held. Such a claim would simply be false. And we’re not making the claim that Smith’s past experience gives him a good reason to think that metal objects not (yet) known to him will be more likely to expand or even that they’ll be more likely than not to expand. Such a claim would beg the question against Hume. Finally, we’re not making the claim that Smith’s past experience gives him a good reason to think that there continues to exist any nomic connection between a thing’s being heated metal and its expanding. Echoing what we just said, such a claim would beg the question against Hume: for Hume’s very point is that a thing’s happening in the past is no guarantee of its continuing to happening the future. And we cannot, without begging the question against Hume, assert that a law’s having held in the past is evidence of its holding in the future. 
So what are we saying? Only that Smith’s experience gives him a reason to believe that such a connection has held, at least as far as metal objects falling within the scope of experience are concerned. And in making this obviously plausible claim, no questions have been begged against Hume.
4.3.2 Synthesizing these points (continued)
I propose that, armed only with this non-question-begging point along with the tautology that it is the purpose of explanations to eliminate unexplained explainers, we can show that Smith has reason to expect future metal objects to expand when heated.
We’ve agreed that Smith’s experience does give him some reason to think that, at least as far as objects thus far known to him are concerned, a thing’s being metal provides some kind of causal or nomic basis for its expanding when heated. Let P be this causal principle. P is of doubly limited scope. It applies only to past objects and it applies only to past objects that Smith knows of. Let’s suppose that Smith accepts P.
Smith has two options. (I am not counting a refusal draw any inferences as an option.) (i) Hold that provides no reason to believe that, outside Smith’s past, personal experience, a thing’s being a metal provides a basis of some kind for its expanding when heated. (ii) Hold that P does warrant some such generalization. One such generalization is: “that connection holds for all past objects, whether Smith knows of them or not; but it doesn’t hold of future objects.” Another is: “that connection holds for objects that Smith will know of, but not for those that he won’t know of.” But, of course, the most natural, not to say the most rational, generalization is this: 

(P*) “That connection holds generally. It holds no less for objects not known by Smith than for those known by him, no less for future objects than for past.” 

Let’s suppose that Smith chooses not to accept P* or any other generalization of P. How, in that case, would the world have to be for Smith’s belief system to hold? Metal objects that Smith became aware of would suddenly undergo a profound change: they would go from being things that, when heated, didn’t expand to being ones that did. And for this change to occur, each atom of every metal object known to Smith would have to change in fundamental ways. Given an acceptance of P, it may seem conservative not to accept any generalization of P. But it’s the very opposite. If you accept but reject any generalization thereof, you’re saying that objects miraculously undergo profound microstructural changes whenever you know of them and undergo equally profound changes when you stop being aware of them. And that hypothesis is not a conservative one.
And, quite clearly, it’s a bad one. Why is it bad? Because it creates more unexplained explainers than it eliminates—because it creates more questions than it answers.
4.3.3 Synthesizing these points (continued)
Of course, not accepting a hypothesis isn’t the same as rejecting it. Not accepting some generalization of P isn’t the same as rejecting it. And it’s obviously a good idea in many cases to hedge—to wait for evidence. But that’s irrelevant. The question is: given that there is enough information to warrant an acceptance of P, is there enough information to warrant acceptance of any generalization of P? If we answer by saying “no,” then we’re saying that, given only the evidence at our disposal, it’s no less likely than not that objects systematically undergo massive changes at the atomic level whenever they come or cease to be known by Smith. And that position, as we saw, creates more mysteries than it eliminates. So despite first appearances, there’s nothing conservative about refusing to countenance any generalization of P. And such refusal embodies acceptance of a principle that is straightforwardly, because tautologously, false, namely: “there’s no reason to prefer explanations that explain a lot and create little that has to be explained to those that explain a little and create a lot to be explained.” 
4.3.4 Synthesizing these points (continued)
These points are easily generalized. It’s no less absurd to suppose that, in the last nanosecond, all metal objects have undergone profound microstructural changes than it is to suppose that all metal objects known by Smith are microstructurally very different from those not known by him. This point provides the non-circular justification for UP that Hume sought but couldn’t find.
Let’s suppose that Smith has reason to believe (i) that, where metal objects that he has known of are concerned, a thing’s being heated provides some kind of basis for its expanding. Let’s also suppose that Smith holds (ii) that this principle won’t hold for metal objects that he will encounter (i.e., for metal objects that he hasn’t encountered but will and for those that he has already encountered and will encounter again). In holding (ii), he is ipso facto supposing that the laws of nature will abruptly change. And in positing this one change, he is positing innumerably many others, as we will now see.
A metal object’s being heated involves innumerable microstructural changes, and so does its expanding. The macroscopic supervenes on the microscopic. Given two objects that are microstructurally alike—that consist of the same particles interrelated in the same way—there is no possibility, even a purely logical one, that those two objects should differ at the macroscopic level. By the same token, given two objects that differ at the macroscopic level, there is no possibility, even a purely logical one, that those two objects should fail to be microstructurally different. A metal object’s being heated thus consists in its undergoing many microstructural changes, and so does its expanding. And if a metal object’s being heated causes it to expand, it is in virtue of the fact that the first set of microstructural disturbances result in, or are themselves constitutive of, the second set.
So given a law—even one that was confined to objects that Smith has encountered—to the effect that metal expands when heated, in order for that law to be annulled, each of innumerably many microparticles would suddenly have to undergo quite dramatic changes. So in assuming that, all of a sudden, a law that once held ceases to do so—or, what is the same thing, in assuming that the future, starting now, is governed by different laws from the past—one is positing not one change, but innumerably many. For, in making that assumption, one is (implicitly) supposing that each of the innumerably many microparticles will, all of a sudden, stop being governed by one set of laws and will start being governed by another. And one is thus creating what, for practical purposes, might as well be infinitely many unexplained explainers.
But not a single one of these unexplained explainers is created by the hypothesis that metal objects that we will encounter are governed by the same laws as those we have encountered. So given the truism that one explanation is better than another if, other things being equal, the first creates fewer unexplained explainers than the second, it follows that the rational move, at least until further evidence comes in, is to suppose that those microparticles will continue to be governed by the same laws that used to govern them.
According to what is now the conventional wisdom, which coincides with the viewpoint that Hume bequeathed to us, the conservative move is the agnostic one: stick to the evidence; generalize as little as possible; don’t assume that what you don’t know resembles what you do know. But the so-called conservative view is really less conservative than the alternative. (The alternative is: “assume that what you don’t know does resemble what you do know.”) The so-called conservative view posits giant schisms in the natural order and, therewith, masses of unexplained explainers. The alternative view does not.
5.0 Closing the argument
We can now succinctly say why Hume’s argument fails.
Step 1: It’s an analytic truth that ceteris paribus the better explanation is the one that creates fewer unexplained explainers. Let’s refer to this principle as “MC” (short for “minimization of causal anomalies”). Whereas UP, if it can be known at all, can be known only on inductive grounds, MC is analytic and, unlike UP, is therefore not to be known on empirical or, consequently, inductive grounds. Thus, MC, unlike UP, can be noncircularly assumed in the context of a defense of inductive inference. 
Step 2: It’s a datum that various concomitances are to be found among the objects known to one. It’s a datum that, so far as the object’s known to (say) Smith are concerned, putting a hand in boiling water causes intense pain, whereas putting that same hand in cool water causes intense relief.
Step 3: One creates more unexplained explainers by assuming that the unknown differs from the known than by assuming that it does not.
Step 4: If one remains agnostic—if one refuses to say, one way or the other, whether the unknown resembles the known—one is committed to the incoherent position that there’s no reason to prefer a hypothesis that creates few unexplained explainers to an otherwise comparable one that creates many. (The reason this view is incoherent is that for one explanation to be preferable to another just is for it to do more in the way of explaining, and thus less in the way of creating unexplained explainers, than the other.)
Step 5: Given MC, and given Steps 1–4, it follows that there is an analytic and therefore non-inductive reason to hold that, other things being equal, the unknown resembles the known.
Conclusion: Hume is wrong; Hume’s argument fails. This is a direct consequence of Step 5. Given the legitimacy of MC, it’s obvious why, though it may initially appear cautious and conservative, skepticism about the external world is actually an extravagant and irrational position. One’s sensory experience is replete with discontinuities. Every time you open your eyes or turn your head, you are flooded with sensory experiences that are totally unlike those that you were experiencing a moment earlier. According to the non-skeptic, these new experiences don’t come into existence ex nihilo; they are merely links in chains of events whose other links you don’t perceive. The skeptic says that it’s no more rational to believe this about our sensory experiences than it is to believe that those experiences come into existence ex nihilo. In saying this, the skeptic is saying, in effect, that it’s just as rational to accept a theory that creates more anomalies than it gets rid of than it is to accept an otherwise comparable theory that gets rid of more anomalies than it creates. Since it’s an analytic truth that, given two otherwise comparable theories, the one that leaves us with fewer anomalies is the one that ought to be preferred, it follows that the skeptic’s position is analytically false. Of course, it isn’t analytic that our sensory experiences are correct. But it is analytic that it’s rational to suppose our sensory experiences veridical to the extent that doing so leaves us with fewer causal anomalies than we’re otherwise left with. The skeptic’s denial of this embodies an analytically false conception of explanation.
ENDNOTES
Name: ____________________________________ Date: _____________________________
Exercises
1. True or false? Hume believes that, if deduction is to be shown to be a legitimate form of inference, it must be shown that the Uniformity Principle (UP) is correct.

2. True or false? Hume believes that UP can be non-circularly assumed in the context of an attempt to establish the legitimacy of inductive inference.

3. True or false? According to Hume, the problem with UP is that, if it’s correct, the data that licenses the inference from (i) “all past swans are white” to (ii) “all future swans will be white” also licenses the inference from (i) to “all future swans will be pink.”

4. Explain why, at least arguably, explanations are successful to the extent that they minimize causal anomalies and are unsuccessful to the extent that they don’t. Then attempt to refute that conception of explanation.

5. Explain why the anti-skeptic cannot, without begging the question against the skeptic, assume that a collection of consistent sense-perceptions are more likely to be veridical than a collection of mutually inconsistent sense-perceptions.

6. Explain why induction by enumeration is a bogus form of inference. Also explain how it is parasitic on inference to the best explanation.

7. How does Hume attempt to show that inductive inference is circular? How, if at all, does his argument fall short?

8. Identity three attempts to refute skepticism and say why they fail.

